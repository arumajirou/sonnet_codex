# ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ãƒ»ãƒ„ãƒ¼ãƒ«è¨­å®šå€¤å®šç¾©æ›¸
**Database and Tools Configuration Specification**

---

## ğŸ“‹ ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆæƒ…å ±

| é …ç›® | å†…å®¹ |
|-----|------|
| **ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã‚¿ã‚¤ãƒˆãƒ«** | ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ãƒ»ãƒ„ãƒ¼ãƒ«è¨­å®šå€¤å®šç¾©æ›¸ |
| **ãƒãƒ¼ã‚¸ãƒ§ãƒ³** | v1.0.0 |
| **ä½œæˆæ—¥** | 2025-11-04 |
| **å¯¾è±¡ã‚·ã‚¹ãƒ†ãƒ ** | NeuralForecast Auto Runner + Time Series Forecasting System |

---

## ç›®æ¬¡

1. [ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹è¨­å®šï¼ˆPostgreSQLï¼‰](#1-ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹è¨­å®špostgresql)
2. [ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ç’°å¢ƒå¤‰æ•°](#2-ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ç’°å¢ƒå¤‰æ•°)
3. [MLflowè¨­å®š](#3-mlflowè¨­å®š)
4. [Weights & Biasesè¨­å®š](#4-weights--biasesè¨­å®š)
5. [Rayè¨­å®š](#5-rayè¨­å®š)
6. [Optunaè¨­å®š](#6-optunaè¨­å®š)
7. [ãã®ä»–ã®ãƒ„ãƒ¼ãƒ«è¨­å®š](#7-ãã®ä»–ã®ãƒ„ãƒ¼ãƒ«è¨­å®š)
8. [Docker Composeè¨­å®š](#8-docker-composeè¨­å®š)
9. [ç’°å¢ƒåˆ¥è¨­å®šä¾‹](#9-ç’°å¢ƒåˆ¥è¨­å®šä¾‹)

---

## 1. ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹è¨­å®šï¼ˆPostgreSQLï¼‰

### 1.1 åŸºæœ¬æ§‹æˆ

```yaml
Database Configuration:
  Database Name: ts_forecast_system
  Database Engine: PostgreSQL
  Version: 14+ (æ¨å¥¨: 15.x)
  Encoding: UTF8
  Locale: en_US.UTF-8
  Timezone: UTC
  Default Port: 5432
```

### 1.2 æ¥ç¶šè¨­å®š

#### ç’°å¢ƒå¤‰æ•°

| ç’°å¢ƒå¤‰æ•°å | èª¬æ˜ | ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå€¤ | å¿…é ˆ |
|-----------|------|------------|------|
| `DATABASE_URL` | ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹æ¥ç¶šURL | `postgresql://postgres:password@localhost:5432/ts_forecast_system` | âœ… |
| `DATABASE_POOL_SIZE` | ã‚³ãƒã‚¯ã‚·ãƒ§ãƒ³ãƒ—ãƒ¼ãƒ«æœ€å°æ•° | `10` | âŒ |
| `DATABASE_MAX_OVERFLOW` | ãƒ—ãƒ¼ãƒ«ã‚ªãƒ¼ãƒãƒ¼ãƒ•ãƒ­ãƒ¼æœ€å¤§æ•° | `20` | âŒ |
| `DATABASE_POOL_TIMEOUT` | ãƒ—ãƒ¼ãƒ«æ¥ç¶šã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆï¼ˆç§’ï¼‰ | `30` | âŒ |
| `DATABASE_POOL_RECYCLE` | ã‚³ãƒã‚¯ã‚·ãƒ§ãƒ³å†åˆ©ç”¨æ™‚é–“ï¼ˆç§’ï¼‰ | `3600` | âŒ |
| `DATABASE_ECHO` | SQLãƒ­ã‚°å‡ºåŠ› | `false` | âŒ |

#### æ¥ç¶šURLå½¢å¼

```
postgresql://[user[:password]@][host][:port][/database][?options]
```

**ä¾‹**:
```bash
# ãƒ­ãƒ¼ã‚«ãƒ«é–‹ç™º
DATABASE_URL=postgresql://postgres:postgres@localhost:5432/ts_forecast_system

# æœ¬ç•ªç’°å¢ƒï¼ˆSSLæœ‰åŠ¹ï¼‰
DATABASE_URL=postgresql://user:password@db.example.com:5432/ts_forecast_system?sslmode=require

# Dockerç’°å¢ƒ
DATABASE_URL=postgresql://mlflow:mlflow@postgres:5432/mlflow
```

### 1.3 ã‚³ãƒã‚¯ã‚·ãƒ§ãƒ³ãƒ—ãƒ¼ãƒ«è¨­å®š

```python
# SQLAlchemyè¨­å®šä¾‹
from sqlalchemy import create_engine
from sqlalchemy.pool import QueuePool

engine = create_engine(
    DATABASE_URL,
    poolclass=QueuePool,
    pool_size=10,              # æœ€å°ã‚³ãƒã‚¯ã‚·ãƒ§ãƒ³æ•°
    max_overflow=20,           # æœ€å¤§ã‚ªãƒ¼ãƒãƒ¼ãƒ•ãƒ­ãƒ¼
    pool_timeout=30,           # ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆï¼ˆç§’ï¼‰
    pool_recycle=3600,         # å†åˆ©ç”¨æ™‚é–“ï¼ˆç§’ï¼‰
    pool_pre_ping=True,        # æ¥ç¶šç¢ºèª
    echo=False,                # SQLãƒ­ã‚°
)
```

### 1.4 ã‚¹ã‚­ãƒ¼ãƒæ§‹æˆ

```sql
-- ãƒ¡ã‚¤ãƒ³ã‚¹ã‚­ãƒ¼ãƒ
CREATE SCHEMA IF NOT EXISTS public;

-- ç›£æŸ»ãƒ­ã‚°ã‚¹ã‚­ãƒ¼ãƒ
CREATE SCHEMA IF NOT EXISTS audit;

-- ã‚¹ãƒ†ãƒ¼ã‚¸ãƒ³ã‚°ã‚¹ã‚­ãƒ¼ãƒ
CREATE SCHEMA IF NOT EXISTS staging;

-- ã‚¢ãƒ¼ã‚«ã‚¤ãƒ–ã‚¹ã‚­ãƒ¼ãƒ
CREATE SCHEMA IF NOT EXISTS archive;
```

### 1.5 ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ãƒ¦ãƒ¼ã‚¶ãƒ¼æ¨©é™

```sql
-- ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ãƒ¦ãƒ¼ã‚¶ãƒ¼ä½œæˆ
CREATE USER app_user WITH PASSWORD 'secure_password';

-- æ¨©é™ä»˜ä¸
GRANT CONNECT ON DATABASE ts_forecast_system TO app_user;
GRANT USAGE ON SCHEMA public TO app_user;
GRANT SELECT, INSERT, UPDATE, DELETE ON ALL TABLES IN SCHEMA public TO app_user;
GRANT USAGE, SELECT ON ALL SEQUENCES IN SCHEMA public TO app_user;

-- å°†æ¥ã®ãƒ†ãƒ¼ãƒ–ãƒ«ã«å¯¾ã™ã‚‹æ¨©é™
ALTER DEFAULT PRIVILEGES IN SCHEMA public
GRANT SELECT, INSERT, UPDATE, DELETE ON TABLES TO app_user;
```

### 1.6 ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—è¨­å®š

```bash
# ç’°å¢ƒå¤‰æ•°
BACKUP_DIR=/path/to/backups
BACKUP_RETENTION_DAYS=30
DB_NAME=ts_forecast_system
DB_USER=postgres
DB_HOST=localhost
DB_PORT=5432

# ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ã‚¹ã‚¯ãƒªãƒ—ãƒˆ
pg_dump -U ${DB_USER} -h ${DB_HOST} -p ${DB_PORT} \
  -Fc -Z9 ${DB_NAME} | gzip > "${BACKUP_DIR}/full_${DB_NAME}_$(date +%Y%m%d).sql.gz"
```

---

## 2. ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ç’°å¢ƒå¤‰æ•°

### 2.1 NF_ãƒ—ãƒ¬ãƒ•ã‚£ãƒƒã‚¯ã‚¹ç’°å¢ƒå¤‰æ•°ï¼ˆå®Œå…¨ãƒªã‚¹ãƒˆï¼‰

#### 2.1.1 ãƒ‘ã‚¹è¨­å®š

| ç’°å¢ƒå¤‰æ•°å | èª¬æ˜ | ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå€¤ | å‹ |
|-----------|------|------------|-----|
| `NF_DATA_CSV` | å…¥åŠ›ãƒ‡ãƒ¼ã‚¿CSVãƒ‘ã‚¹ | `./data.csv` | Path |
| `NF_OUTPUT_DIR` | å‡ºåŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª | `./nf_auto_runs` | Path |
| `NF_LOG_DIR` | ãƒ­ã‚°ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª | `./nf_auto_runs/logs` | Path |
| `NF_MODEL_DIR` | ãƒ¢ãƒ‡ãƒ«ä¿å­˜ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª | `./nf_auto_runs/models` | Path |
| `NF_ARTIFACT_DIR` | ã‚¢ãƒ¼ãƒ†ã‚£ãƒ•ã‚¡ã‚¯ãƒˆãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª | `./nf_auto_runs/artifacts` | Path |
| `NF_CHECKPOINT_DIR` | ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª | `./nf_auto_runs/checkpoints` | Path |
| `NF_PLOT_DIR` | ãƒ—ãƒ­ãƒƒãƒˆä¿å­˜ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª | `./nf_auto_runs/plots` | Path |

#### 2.1.2 å®Ÿè¡Œåˆ¶å¾¡

| ç’°å¢ƒå¤‰æ•°å | èª¬æ˜ | ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå€¤ | å‹ | ç¯„å›² |
|-----------|------|------------|-----|------|
| `NF_RANDOM_STATE` | ä¹±æ•°ã‚·ãƒ¼ãƒ‰ | `2077` | int | 0-2147483647 |
| `NF_TRIAL_NUM_SAMPLES` | è©¦è¡Œå›æ•° | `1` | int | 1-1000 |
| `NF_TRIAL_MAX_STEPS` | æœ€å¤§ã‚¹ãƒ†ãƒƒãƒ—æ•° | `50` | int | 1-1000 |
| `NF_DEFAULT_H` | ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆäºˆæ¸¬æœŸé–“ | `24` | int | 1-1000 |
| `NF_H_RATIO` | äºˆæ¸¬æœŸé–“æ¯”ç‡ | `0.1` | float | 0.0-1.0 |
| `NF_MAX_WORKERS` | æœ€å¤§ä¸¦åˆ—ãƒ¯ãƒ¼ã‚«ãƒ¼æ•° | `cpu_count//2` | int | 1-128 |
| `NF_ALLOW_RAY_PARALLEL` | Rayä¸¦åˆ—å®Ÿè¡Œã‚’è¨±å¯ | `false` | bool | true/false |
| `NF_SAVE_MODEL` | ãƒ¢ãƒ‡ãƒ«ä¿å­˜ã‚’æœ‰åŠ¹åŒ– | `true` | bool | true/false |
| `NF_OVERWRITE_MODEL` | ãƒ¢ãƒ‡ãƒ«ä¸Šæ›¸ãã‚’è¨±å¯ | `false` | bool | true/false |

#### 2.1.3 ãƒ‡ãƒ¼ã‚¿å‡¦ç†

| ç’°å¢ƒå¤‰æ•°å | èª¬æ˜ | ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå€¤ | å‹ |
|-----------|------|------------|-----|
| `NF_MAX_EXOG_F` | æœ€å¤§Futureå¤–ç”Ÿå¤‰æ•°æ•° | `256` | int |
| `NF_MAX_EXOG_H` | æœ€å¤§Historicalå¤–ç”Ÿå¤‰æ•°æ•° | `256` | int |
| `NF_MAX_EXOG_S` | æœ€å¤§Staticå¤–ç”Ÿå¤‰æ•°æ•° | `256` | int |
| `NF_DIR_TOKENS_MAXLEN` | ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªåæœ€å¤§é•· | `200` | int |

#### 2.1.4 ãƒ¢ãƒ‡ãƒ«ãƒ»ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ é¸æŠ

| ç’°å¢ƒå¤‰æ•°å | èª¬æ˜ | ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå€¤ | å‹ |
|-----------|------|------------|-----|
| `NF_MODELS` | ä½¿ç”¨ãƒ¢ãƒ‡ãƒ«ãƒªã‚¹ãƒˆï¼ˆã‚«ãƒ³ãƒåŒºåˆ‡ã‚Šï¼‰ | `auto` | str |
| `NF_BACKENDS` | è¨ˆç®—ãƒãƒƒã‚¯ã‚¨ãƒ³ãƒ‰ï¼ˆã‚«ãƒ³ãƒåŒºåˆ‡ã‚Šï¼‰ | `auto` | str |
| `NF_SEARCH_ALGS` | æ¢ç´¢ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ï¼ˆã‚«ãƒ³ãƒåŒºåˆ‡ã‚Šï¼‰ | `auto` | str |
| `NF_LOSSES` | æå¤±é–¢æ•°ï¼ˆã‚«ãƒ³ãƒåŒºåˆ‡ã‚Šï¼‰ | `auto` | str |
| `NF_SCALERS` | ã‚¹ã‚±ãƒ¼ãƒ©ãƒ¼ï¼ˆã‚«ãƒ³ãƒåŒºåˆ‡ã‚Šï¼‰ | `auto` | str |
| `NF_EARLY_STOPS` | Early Stoppingè¨­å®š | `auto` | str |

**ä½¿ç”¨ä¾‹**:
```bash
# ç‰¹å®šãƒ¢ãƒ‡ãƒ«ã®ã¿ä½¿ç”¨
export NF_MODELS="AutoNHITS,AutoLSTM"

# CUDAãƒãƒƒã‚¯ã‚¨ãƒ³ãƒ‰ã®ã¿
export NF_BACKENDS="cuda"

# è¤‡æ•°æ¢ç´¢ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ 
export NF_SEARCH_ALGS="grid,random,bayesian"

# è¤‡æ•°æå¤±é–¢æ•°
export NF_LOSSES="mae,mse,rmse"
```

#### 2.1.5 ãã®ä»–

| ç’°å¢ƒå¤‰æ•°å | èª¬æ˜ | ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå€¤ | å‹ |
|-----------|------|------------|-----|
| `NF_EXPAND_AXES` | è»¸å±•é–‹è¨­å®š | `auto` | str |
| `NF_COMBO_DEPTH` | çµ„ã¿åˆã‚ã›æ·±ã• | `3` | int |
| `NF_VAL_SIZE` | æ¤œè¨¼ã‚»ãƒƒãƒˆã‚µã‚¤ã‚º | `0.2` | float |
| `NF_PATCH_MODEL_INIT` | ãƒ¢ãƒ‡ãƒ«åˆæœŸåŒ–ãƒ‘ãƒƒãƒ | `false` | bool |
| `NF_DB_ENABLE` | ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹è¨˜éŒ²æœ‰åŠ¹åŒ– | `true` | bool |

### 2.2 æ¨™æº–ç’°å¢ƒå¤‰æ•°

#### 2.2.1 ä¸€èˆ¬è¨­å®š

| ç’°å¢ƒå¤‰æ•°å | èª¬æ˜ | ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå€¤ | å¿…é ˆ |
|-----------|------|------------|------|
| `LOG_LEVEL` | ãƒ­ã‚°ãƒ¬ãƒ™ãƒ« | `INFO` | âŒ |
| `LOG_FORMAT` | ãƒ­ã‚°ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆ | `json` | âŒ |
| `PYTHONPATH` | Pythonãƒ‘ã‚¹ | - | âŒ |
| `TZ` | ã‚¿ã‚¤ãƒ ã‚¾ãƒ¼ãƒ³ | `UTC` | âŒ |

#### 2.2.2 ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£

| ç’°å¢ƒå¤‰æ•°å | èª¬æ˜ | ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå€¤ | å¿…é ˆ |
|-----------|------|------------|------|
| `SECRET_KEY` | ã‚·ãƒ¼ã‚¯ãƒ¬ãƒƒãƒˆã‚­ãƒ¼ | - | âœ… |
| `JWT_ALGORITHM` | JWTç½²åã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ  | `HS256` | âŒ |
| `ACCESS_TOKEN_EXPIRE_MINUTES` | ãƒˆãƒ¼ã‚¯ãƒ³æœ‰åŠ¹æœŸé™ï¼ˆåˆ†ï¼‰ | `60` | âŒ |

---

## 3. MLflowè¨­å®š

### 3.1 ç’°å¢ƒå¤‰æ•°

| ç’°å¢ƒå¤‰æ•°å | èª¬æ˜ | ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå€¤ | å¿…é ˆ |
|-----------|------|------------|------|
| `MLFLOW_TRACKING_URI` | ãƒˆãƒ©ãƒƒã‚­ãƒ³ã‚°ã‚µãƒ¼ãƒãƒ¼URI | `file:./mlruns` | âœ… |
| `MLFLOW_EXPERIMENT_NAME` | å®Ÿé¨“å | `ts-autorunner` | âŒ |
| `MLFLOW_S3_ENDPOINT_URL` | S3ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆï¼ˆMinIOç­‰ï¼‰ | - | âŒ |
| `MLFLOW_TRACKING_USERNAME` | èªè¨¼ãƒ¦ãƒ¼ã‚¶ãƒ¼å | - | âŒ |
| `MLFLOW_TRACKING_PASSWORD` | èªè¨¼ãƒ‘ã‚¹ãƒ¯ãƒ¼ãƒ‰ | - | âŒ |

### 3.2 è¨­å®šä¾‹

#### ãƒ­ãƒ¼ã‚«ãƒ«ãƒ•ã‚¡ã‚¤ãƒ«ã‚¹ãƒˆãƒ¬ãƒ¼ã‚¸
```bash
export MLFLOW_TRACKING_URI="file:./mlruns"
```

#### ãƒªãƒ¢ãƒ¼ãƒˆãƒˆãƒ©ãƒƒã‚­ãƒ³ã‚°ã‚µãƒ¼ãƒãƒ¼
```bash
export MLFLOW_TRACKING_URI="http://mlflow-server:5000"
```

#### PostgreSQLãƒãƒƒã‚¯ã‚¨ãƒ³ãƒ‰
```bash
export MLFLOW_TRACKING_URI="postgresql://mlflow:password@db:5432/mlflowdb"
```

#### S3 Artifact Storeï¼ˆMinIOï¼‰
```bash
export MLFLOW_TRACKING_URI="http://mlflow-server:5000"
export MLFLOW_S3_ENDPOINT_URL="http://minio:9000"
export AWS_ACCESS_KEY_ID="minioadmin"
export AWS_SECRET_ACCESS_KEY="minioadmin"
```

### 3.3 MLflowã‚µãƒ¼ãƒãƒ¼èµ·å‹•è¨­å®š

```bash
# åŸºæœ¬èµ·å‹•
mlflow server \
  --backend-store-uri postgresql://mlflow:password@localhost:5432/mlflowdb \
  --default-artifact-root s3://mlflow-artifacts/ \
  --host 0.0.0.0 \
  --port 5000

# èªè¨¼æœ‰åŠ¹åŒ–
mlflow server \
  --backend-store-uri postgresql://mlflow:password@localhost:5432/mlflowdb \
  --default-artifact-root s3://mlflow-artifacts/ \
  --host 0.0.0.0 \
  --port 5000 \
  --app-name basic-auth
```

### 3.4 Python APIè¨­å®š

```python
import mlflow
import os

# ãƒˆãƒ©ãƒƒã‚­ãƒ³ã‚°URIè¨­å®š
mlflow.set_tracking_uri(os.getenv("MLFLOW_TRACKING_URI", "file:./mlruns"))

# å®Ÿé¨“è¨­å®š
mlflow.set_experiment(os.getenv("MLFLOW_EXPERIMENT_NAME", "ts-autorunner"))

# è‡ªå‹•ãƒ­ã‚°æœ‰åŠ¹åŒ–
mlflow.autolog()
```

---

## 4. Weights & Biasesè¨­å®š

### 4.1 ç’°å¢ƒå¤‰æ•°

| ç’°å¢ƒå¤‰æ•°å | èª¬æ˜ | ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå€¤ | å¿…é ˆ |
|-----------|------|------------|------|
| `WANDB_API_KEY` | W&B APIã‚­ãƒ¼ | - | âœ…ï¼ˆæœ‰åŠ¹åŒ–æ™‚ï¼‰ |
| `WANDB_PROJECT` | ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆå | `ts-forecasting` | âŒ |
| `WANDB_ENTITY` | ã‚¨ãƒ³ãƒ†ã‚£ãƒ†ã‚£åï¼ˆãƒ¦ãƒ¼ã‚¶ãƒ¼/ãƒãƒ¼ãƒ ï¼‰ | - | âŒ |
| `WANDB_MODE` | å‹•ä½œãƒ¢ãƒ¼ãƒ‰ | `online` | âŒ |
| `WANDB_DIR` | ãƒ­ã‚°ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª | `./wandb` | âŒ |
| `WANDB_SILENT` | ã‚µã‚¤ãƒ¬ãƒ³ãƒˆãƒ¢ãƒ¼ãƒ‰ | `false` | âŒ |
| `NF_WANDB_PROJECT` | ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆåï¼ˆNFç”¨ï¼‰ | - | âŒ |

### 4.2 å‹•ä½œãƒ¢ãƒ¼ãƒ‰

| ãƒ¢ãƒ¼ãƒ‰ | èª¬æ˜ | ç”¨é€” |
|--------|------|------|
| `online` | ã‚ªãƒ³ãƒ©ã‚¤ãƒ³åŒæœŸ | é€šå¸¸é‹ç”¨ |
| `offline` | ã‚ªãƒ•ãƒ©ã‚¤ãƒ³ä¿å­˜ã®ã¿ | ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯åˆ¶é™ç’°å¢ƒ |
| `disabled` | W&Bç„¡åŠ¹åŒ– | CI/ãƒ†ã‚¹ãƒˆç’°å¢ƒ |
| `dryrun` | ãƒ€ãƒŸãƒ¼å®Ÿè¡Œ | ãƒ‡ãƒãƒƒã‚° |

### 4.3 è¨­å®šä¾‹

#### åŸºæœ¬è¨­å®š
```bash
export WANDB_API_KEY="your_api_key_here"
export WANDB_PROJECT="time-series-forecasting"
export WANDB_ENTITY="your-team"
```

#### ã‚ªãƒ•ãƒ©ã‚¤ãƒ³ãƒ¢ãƒ¼ãƒ‰
```bash
export WANDB_MODE="offline"
export WANDB_DIR="./wandb_logs"
```

#### CI/ãƒ†ã‚¹ãƒˆç’°å¢ƒ
```bash
export WANDB_MODE="disabled"
```

### 4.4 Python APIè¨­å®š

```python
import wandb
import os

# åˆæœŸåŒ–
wandb.init(
    project=os.getenv("WANDB_PROJECT", "ts-forecasting"),
    entity=os.getenv("WANDB_ENTITY"),
    mode=os.getenv("WANDB_MODE", "online"),
    dir=os.getenv("WANDB_DIR", "./wandb"),
)

# ãƒ­ã‚°
wandb.log({"loss": 0.5, "accuracy": 0.95})

# çµ‚äº†
wandb.finish()
```

### 4.5 ã‚ªãƒ•ãƒ©ã‚¤ãƒ³ãƒ­ã‚°ã®åŒæœŸ

```bash
# ã‚ªãƒ•ãƒ©ã‚¤ãƒ³ã§ä¿å­˜ã—ãŸãƒ­ã‚°ã‚’åŒæœŸ
wandb sync ./wandb/offline-run-20231104_120000-abcd1234
```

---

## 5. Rayè¨­å®š

### 5.1 ç’°å¢ƒå¤‰æ•°

| ç’°å¢ƒå¤‰æ•°å | èª¬æ˜ | ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå€¤ | å¿…é ˆ |
|-----------|------|------------|------|
| `RAY_ADDRESS` | Rayã‚¯ãƒ©ã‚¹ã‚¿ã‚¢ãƒ‰ãƒ¬ã‚¹ | `auto` | âŒ |
| `RAY_NAMESPACE` | ãƒãƒ¼ãƒ ã‚¹ãƒšãƒ¼ã‚¹ | `default` | âŒ |
| `RAY_DEDUP_LOGS` | é‡è¤‡ãƒ­ã‚°å‰Šé™¤ | `1` | âŒ |
| `RAY_BACKEND_LOG_LEVEL` | ãƒ­ã‚°ãƒ¬ãƒ™ãƒ« | `warning` | âŒ |
| `RAY_NUM_CPUS` | CPUæ•° | `auto` | âŒ |
| `RAY_NUM_GPUS` | GPUæ•° | `auto` | âŒ |
| `RAY_OBJECT_STORE_MEMORY` | ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã‚¹ãƒˆã‚¢ãƒ¡ãƒ¢ãƒª | `auto` | âŒ |
| `RAY_TMPDIR` | ä¸€æ™‚ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª | `/tmp/ray` | âŒ |

### 5.2 æ¥ç¶šè¨­å®š

#### ãƒ­ãƒ¼ã‚«ãƒ«èµ·å‹•
```bash
# è‡ªå‹•ãƒ­ãƒ¼ã‚«ãƒ«ã‚¯ãƒ©ã‚¹ã‚¿èµ·å‹•
export RAY_ADDRESS="auto"
```

#### ãƒªãƒ¢ãƒ¼ãƒˆã‚¯ãƒ©ã‚¹ã‚¿æ¥ç¶š
```bash
# Headãƒãƒ¼ãƒ‰æ¥ç¶š
export RAY_ADDRESS="ray://ray-head:10001"

# ã¾ãŸã¯
export RAY_ADDRESS="ray://192.168.1.100:10001"
```

### 5.3 Ray Clusterèµ·å‹•

#### Head Node
```bash
ray start --head \
  --port=6379 \
  --dashboard-host=0.0.0.0 \
  --dashboard-port=8265 \
  --num-cpus=8 \
  --num-gpus=1 \
  --object-store-memory=10000000000
```

#### Worker Node
```bash
ray start \
  --address=ray-head:6379 \
  --num-cpus=8 \
  --num-gpus=1 \
  --object-store-memory=10000000000
```

### 5.4 Python APIè¨­å®š

```python
import ray
import os

# åˆæœŸåŒ–
ray.init(
    address=os.getenv("RAY_ADDRESS", "auto"),
    namespace=os.getenv("RAY_NAMESPACE", "default"),
    num_cpus=int(os.getenv("RAY_NUM_CPUS", "0")) or None,
    num_gpus=int(os.getenv("RAY_NUM_GPUS", "0")) or None,
    _temp_dir=os.getenv("RAY_TMPDIR", "/tmp/ray"),
)

# ãƒªã‚½ãƒ¼ã‚¹æƒ…å ±ç¢ºèª
print(ray.available_resources())

# ã‚·ãƒ£ãƒƒãƒˆãƒ€ã‚¦ãƒ³
ray.shutdown()
```

### 5.5 Ray Dashboard

| é …ç›® | è¨­å®šå€¤ |
|------|--------|
| URL | `http://localhost:8265` |
| èªè¨¼ | ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆãªã— |
| ãƒ¡ãƒˆãƒªã‚¯ã‚¹ | CPUã€ãƒ¡ãƒ¢ãƒªã€GPUä½¿ç”¨ç‡ |

---

## 6. Optunaè¨­å®š

### 6.1 ç’°å¢ƒå¤‰æ•°

| ç’°å¢ƒå¤‰æ•°å | èª¬æ˜ | ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå€¤ | å¿…é ˆ |
|-----------|------|------------|------|
| `OPTUNA_STORAGE` | ã‚¹ãƒˆãƒ¬ãƒ¼ã‚¸URL | `sqlite:///optuna.db` | âŒ |
| `OPTUNA_STUDY_NAME` | ã‚¹ã‚¿ãƒ‡ã‚£å | - | âŒ |
| `OPTUNA_N_TRIALS` | è©¦è¡Œå›æ•° | `100` | âŒ |
| `OPTUNA_TIMEOUT` | ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆï¼ˆç§’ï¼‰ | - | âŒ |
| `OPTUNA_N_JOBS` | ä¸¦åˆ—ã‚¸ãƒ§ãƒ–æ•° | `1` | âŒ |

### 6.2 ã‚¹ãƒˆãƒ¬ãƒ¼ã‚¸è¨­å®š

#### SQLiteï¼ˆãƒ­ãƒ¼ã‚«ãƒ«é–‹ç™ºï¼‰
```bash
export OPTUNA_STORAGE="sqlite:///optuna_study.db"
```

#### PostgreSQLï¼ˆæœ¬ç•ªç’°å¢ƒï¼‰
```bash
export OPTUNA_STORAGE="postgresql://optuna:password@localhost:5432/optuna_db"
```

#### MySQL
```bash
export OPTUNA_STORAGE="mysql://optuna:password@localhost:3306/optuna_db"
```

### 6.3 Python APIè¨­å®š

```python
import optuna
import os

# ã‚¹ãƒˆãƒ¬ãƒ¼ã‚¸è¨­å®š
storage = os.getenv("OPTUNA_STORAGE", "sqlite:///optuna.db")

# ã‚¹ã‚¿ãƒ‡ã‚£ä½œæˆ
study = optuna.create_study(
    study_name=os.getenv("OPTUNA_STUDY_NAME", "ts-optimization"),
    storage=storage,
    direction="minimize",
    load_if_exists=True,
)

# æœ€é©åŒ–å®Ÿè¡Œ
study.optimize(
    objective_function,
    n_trials=int(os.getenv("OPTUNA_N_TRIALS", "100")),
    timeout=int(os.getenv("OPTUNA_TIMEOUT", "0")) or None,
    n_jobs=int(os.getenv("OPTUNA_N_JOBS", "1")),
)
```

### 6.4 Optuna Dashboard

```bash
# ãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰èµ·å‹•
optuna-dashboard \
  sqlite:///optuna_study.db \
  --host 0.0.0.0 \
  --port 8080
```

---

## 7. ãã®ä»–ã®ãƒ„ãƒ¼ãƒ«è¨­å®š

### 7.1 TensorBoard

| ç’°å¢ƒå¤‰æ•°å | èª¬æ˜ | ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå€¤ |
|-----------|------|------------|
| `TENSORBOARD_LOG_DIR` | ãƒ­ã‚°ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª | `./logs` |
| `TENSORBOARD_PORT` | ãƒãƒ¼ãƒˆç•ªå· | `6006` |

```bash
tensorboard --logdir=${TENSORBOARD_LOG_DIR} --port=${TENSORBOARD_PORT}
```

### 7.2 Hydra

| ç’°å¢ƒå¤‰æ•°å | èª¬æ˜ | ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå€¤ |
|-----------|------|------------|
| `HYDRA_FULL_ERROR` | ãƒ•ãƒ«ã‚¨ãƒ©ãƒ¼è¡¨ç¤º | `1` |

### 7.3 CUDA/GPU

| ç’°å¢ƒå¤‰æ•°å | èª¬æ˜ | ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå€¤ |
|-----------|------|------------|
| `CUDA_VISIBLE_DEVICES` | ä½¿ç”¨GPU ID | `0` |
| `CUDA_LAUNCH_BLOCKING` | åŒæœŸå®Ÿè¡Œ | `0` |

```bash
# GPU 0, 1ã®ã¿ä½¿ç”¨
export CUDA_VISIBLE_DEVICES="0,1"
```

---

## 8. Docker Composeè¨­å®š

### 8.1 å®Œå…¨ãªdocker-compose.ymlä¾‹

```yaml
version: '3.8'

services:
  # PostgreSQL Database
  postgres:
    image: postgres:15-alpine
    container_name: ts_postgres
    environment:
      POSTGRES_USER: postgres
      POSTGRES_PASSWORD: postgres
      POSTGRES_DB: ts_forecast_system
      POSTGRES_INITDB_ARGS: "--encoding=UTF-8 --locale=en_US.UTF-8"
      TZ: UTC
    ports:
      - "5432:5432"
    volumes:
      - postgres_data:/var/lib/postgresql/data
      - ./init.sql:/docker-entrypoint-initdb.d/init.sql
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U postgres"]
      interval: 10s
      timeout: 5s
      retries: 5
    networks:
      - ts_network

  # MLflow Tracking Server
  mlflow:
    image: ghcr.io/mlflow/mlflow:latest
    container_name: ts_mlflow
    command: >
      mlflow server
      --backend-store-uri postgresql://mlflow:mlflow@postgres:5432/mlflow
      --default-artifact-root /mlflow/artifacts
      --host 0.0.0.0
      --port 5000
    environment:
      MLFLOW_TRACKING_URI: postgresql://mlflow:mlflow@postgres:5432/mlflow
      AWS_ACCESS_KEY_ID: minioadmin
      AWS_SECRET_ACCESS_KEY: minioadmin
      MLFLOW_S3_ENDPOINT_URL: http://minio:9000
    ports:
      - "5000:5000"
    volumes:
      - mlflow_artifacts:/mlflow/artifacts
    depends_on:
      postgres:
        condition: service_healthy
    networks:
      - ts_network

  # MinIO (S3-compatible storage)
  minio:
    image: minio/minio:latest
    container_name: ts_minio
    command: server /data --console-address ":9001"
    environment:
      MINIO_ROOT_USER: minioadmin
      MINIO_ROOT_PASSWORD: minioadmin
    ports:
      - "9000:9000"
      - "9001:9001"
    volumes:
      - minio_data:/data
    networks:
      - ts_network

  # Ray Head Node
  ray-head:
    image: rayproject/ray:latest-py311
    container_name: ts_ray_head
    command: >
      ray start --head
      --port=6379
      --dashboard-host=0.0.0.0
      --dashboard-port=8265
      --num-cpus=4
    environment:
      RAY_BACKEND_LOG_LEVEL: warning
    ports:
      - "6379:6379"
      - "8265:8265"
      - "10001:10001"
    volumes:
      - ray_data:/tmp/ray
    networks:
      - ts_network

  # Ray Worker Nodes
  ray-worker:
    image: rayproject/ray:latest-py311
    command: ray start --address=ray-head:6379 --num-cpus=4
    environment:
      RAY_BACKEND_LOG_LEVEL: warning
    depends_on:
      - ray-head
    deploy:
      replicas: 2
    networks:
      - ts_network

  # Application
  app:
    build:
      context: .
      dockerfile: Dockerfile
    container_name: ts_app
    environment:
      # Database
      DATABASE_URL: postgresql://postgres:postgres@postgres:5432/ts_forecast_system
      
      # Paths
      NF_DATA_CSV: /app/data/input.csv
      NF_OUTPUT_DIR: /app/outputs
      NF_LOG_DIR: /app/logs
      
      # Execution
      NF_RANDOM_STATE: 2077
      NF_TRIAL_NUM_SAMPLES: 10
      NF_MAX_WORKERS: 4
      NF_ALLOW_RAY_PARALLEL: "true"
      
      # Tracking
      MLFLOW_TRACKING_URI: http://mlflow:5000
      WANDB_MODE: disabled
      
      # Ray
      RAY_ADDRESS: ray://ray-head:10001
      
      # Logging
      LOG_LEVEL: INFO
      LOG_FORMAT: json
    volumes:
      - ./data:/app/data
      - ./outputs:/app/outputs
      - ./logs:/app/logs
    depends_on:
      - postgres
      - mlflow
      - ray-head
    networks:
      - ts_network

volumes:
  postgres_data:
  mlflow_artifacts:
  minio_data:
  ray_data:

networks:
  ts_network:
    driver: bridge
```

---

## 9. ç’°å¢ƒåˆ¥è¨­å®šä¾‹

### 9.1 ãƒ­ãƒ¼ã‚«ãƒ«é–‹ç™ºç’°å¢ƒ

```bash
# .env.local
# Database
DATABASE_URL=postgresql://postgres:postgres@localhost:5432/ts_forecast_system

# Paths
NF_DATA_CSV=./data/sample.csv
NF_OUTPUT_DIR=./outputs
NF_LOG_DIR=./logs

# Execution
NF_RANDOM_STATE=42
NF_TRIAL_NUM_SAMPLES=1
NF_MAX_WORKERS=2
NF_ALLOW_RAY_PARALLEL=false
NF_SAVE_MODEL=true

# Tracking
MLFLOW_TRACKING_URI=file:./mlruns
WANDB_MODE=disabled

# Logging
LOG_LEVEL=DEBUG
LOG_FORMAT=text
```

### 9.2 ã‚¹ãƒ†ãƒ¼ã‚¸ãƒ³ã‚°ç’°å¢ƒ

```bash
# .env.staging
# Database
DATABASE_URL=postgresql://app_user:${DB_PASSWORD}@db-staging:5432/ts_forecast_staging

# Paths
NF_DATA_CSV=/data/staging_data.csv
NF_OUTPUT_DIR=/outputs
NF_LOG_DIR=/logs

# Execution
NF_RANDOM_STATE=2077
NF_TRIAL_NUM_SAMPLES=10
NF_MAX_WORKERS=8
NF_ALLOW_RAY_PARALLEL=true
NF_SAVE_MODEL=true

# Tracking
MLFLOW_TRACKING_URI=http://mlflow-staging:5000
WANDB_MODE=online
WANDB_PROJECT=ts-forecasting-staging

# Ray
RAY_ADDRESS=ray://ray-head-staging:10001

# Logging
LOG_LEVEL=INFO
LOG_FORMAT=json
```

### 9.3 æœ¬ç•ªç’°å¢ƒ

```bash
# .env.production
# Database
DATABASE_URL=postgresql://app_user:${DB_PASSWORD}@db-prod:5432/ts_forecast_production
DATABASE_POOL_SIZE=20
DATABASE_MAX_OVERFLOW=40

# Paths
NF_DATA_CSV=/data/production_data.csv
NF_OUTPUT_DIR=/outputs
NF_LOG_DIR=/logs

# Execution
NF_RANDOM_STATE=2077
NF_TRIAL_NUM_SAMPLES=50
NF_MAX_WORKERS=16
NF_ALLOW_RAY_PARALLEL=true
NF_SAVE_MODEL=true

# Tracking
MLFLOW_TRACKING_URI=https://mlflow.example.com
MLFLOW_TRACKING_USERNAME=${MLFLOW_USER}
MLFLOW_TRACKING_PASSWORD=${MLFLOW_PASSWORD}
WANDB_MODE=online
WANDB_PROJECT=ts-forecasting-production
WANDB_ENTITY=your-org

# Ray
RAY_ADDRESS=ray://ray-head-prod:10001

# Security
SECRET_KEY=${SECRET_KEY}
JWT_ALGORITHM=HS256

# Logging
LOG_LEVEL=WARNING
LOG_FORMAT=json
```

### 9.4 CI/ãƒ†ã‚¹ãƒˆç’°å¢ƒ

```bash
# .env.test
# Database
DATABASE_URL=postgresql://postgres:postgres@localhost:5432/ts_forecast_test

# Paths
NF_DATA_CSV=./tests/fixtures/test_data.csv
NF_OUTPUT_DIR=./tests/outputs
NF_LOG_DIR=./tests/logs

# Execution
NF_RANDOM_STATE=42
NF_TRIAL_NUM_SAMPLES=1
NF_MAX_WORKERS=1
NF_ALLOW_RAY_PARALLEL=false
NF_SAVE_MODEL=false

# Tracking
MLFLOW_TRACKING_URI=file:./tests/mlruns
WANDB_MODE=disabled

# Logging
LOG_LEVEL=DEBUG
LOG_FORMAT=text
```

---

## 10. è¨­å®šæ¤œè¨¼

### 10.1 ç’°å¢ƒå¤‰æ•°ãƒã‚§ãƒƒã‚¯ã‚¹ã‚¯ãƒªãƒ—ãƒˆ

```python
#!/usr/bin/env python3
"""ç’°å¢ƒå¤‰æ•°ã®æ¤œè¨¼ã‚¹ã‚¯ãƒªãƒ—ãƒˆ"""

import os
import sys
from typing import Dict, List, Tuple

# å¿…é ˆç’°å¢ƒå¤‰æ•°
REQUIRED_VARS = [
    "DATABASE_URL",
]

# æ¨å¥¨ç’°å¢ƒå¤‰æ•°
RECOMMENDED_VARS = [
    "NF_DATA_CSV",
    "NF_OUTPUT_DIR",
    "MLFLOW_TRACKING_URI",
]

# å‹ãƒã‚§ãƒƒã‚¯
TYPE_CHECKS: Dict[str, type] = {
    "NF_RANDOM_STATE": int,
    "NF_TRIAL_NUM_SAMPLES": int,
    "NF_H_RATIO": float,
    "NF_ALLOW_RAY_PARALLEL": bool,
}

def check_required_vars() -> List[str]:
    """å¿…é ˆç’°å¢ƒå¤‰æ•°ã®ãƒã‚§ãƒƒã‚¯"""
    missing = []
    for var in REQUIRED_VARS:
        if not os.getenv(var):
            missing.append(var)
    return missing

def check_recommended_vars() -> List[str]:
    """æ¨å¥¨ç’°å¢ƒå¤‰æ•°ã®ãƒã‚§ãƒƒã‚¯"""
    missing = []
    for var in RECOMMENDED_VARS:
        if not os.getenv(var):
            missing.append(var)
    return missing

def validate_types() -> List[Tuple[str, str]]:
    """å‹æ¤œè¨¼"""
    errors = []
    for var, expected_type in TYPE_CHECKS.items():
        value = os.getenv(var)
        if value:
            try:
                if expected_type == bool:
                    if value.lower() not in ('true', 'false', '0', '1'):
                        errors.append((var, f"Expected bool, got {value}"))
                elif expected_type == int:
                    int(value)
                elif expected_type == float:
                    float(value)
            except ValueError:
                errors.append((var, f"Expected {expected_type.__name__}, got {value}"))
    return errors

def main():
    """ãƒ¡ã‚¤ãƒ³å‡¦ç†"""
    print("=== ç’°å¢ƒå¤‰æ•°æ¤œè¨¼ ===\n")
    
    # å¿…é ˆãƒã‚§ãƒƒã‚¯
    missing_required = check_required_vars()
    if missing_required:
        print("âŒ å¿…é ˆç’°å¢ƒå¤‰æ•°ãŒä¸è¶³:")
        for var in missing_required:
            print(f"  - {var}")
        sys.exit(1)
    else:
        print("âœ… å¿…é ˆç’°å¢ƒå¤‰æ•°: OK")
    
    # æ¨å¥¨ãƒã‚§ãƒƒã‚¯
    missing_recommended = check_recommended_vars()
    if missing_recommended:
        print("\nâš ï¸  æ¨å¥¨ç’°å¢ƒå¤‰æ•°ãŒä¸è¶³:")
        for var in missing_recommended:
            print(f"  - {var}")
    else:
        print("âœ… æ¨å¥¨ç’°å¢ƒå¤‰æ•°: OK")
    
    # å‹ãƒã‚§ãƒƒã‚¯
    type_errors = validate_types()
    if type_errors:
        print("\nâŒ å‹ã‚¨ãƒ©ãƒ¼:")
        for var, error in type_errors:
            print(f"  - {var}: {error}")
        sys.exit(1)
    else:
        print("âœ… å‹æ¤œè¨¼: OK")
    
    print("\nâœ… ã™ã¹ã¦ã®æ¤œè¨¼ã«åˆæ ¼ã—ã¾ã—ãŸ")

if __name__ == "__main__":
    main()
```

### 10.2 ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹æ¥ç¶šãƒ†ã‚¹ãƒˆ

```python
#!/usr/bin/env python3
"""ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹æ¥ç¶šãƒ†ã‚¹ãƒˆ"""

import os
import sys
from sqlalchemy import create_engine, text

def test_database_connection():
    """ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹æ¥ç¶šãƒ†ã‚¹ãƒˆ"""
    database_url = os.getenv("DATABASE_URL")
    
    if not database_url:
        print("âŒ DATABASE_URL ãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“")
        sys.exit(1)
    
    try:
        print(f"æ¥ç¶šãƒ†ã‚¹ãƒˆ: {database_url}")
        engine = create_engine(database_url)
        
        with engine.connect() as conn:
            result = conn.execute(text("SELECT version()"))
            version = result.fetchone()[0]
            print(f"âœ… æ¥ç¶šæˆåŠŸ: {version}")
            
    except Exception as e:
        print(f"âŒ æ¥ç¶šå¤±æ•—: {e}")
        sys.exit(1)

if __name__ == "__main__":
    test_database_connection()
```

---

## ä»˜éŒ²A: ç’°å¢ƒå¤‰æ•°ã‚¯ã‚¤ãƒƒã‚¯ãƒªãƒ•ã‚¡ãƒ¬ãƒ³ã‚¹

### ã‚«ãƒ†ã‚´ãƒªåˆ¥ç’°å¢ƒå¤‰æ•°ä¸€è¦§

```bash
# === ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ ===
DATABASE_URL=postgresql://user:pass@host:5432/db
DATABASE_POOL_SIZE=10
DATABASE_MAX_OVERFLOW=20

# === ãƒ‘ã‚¹ï¼ˆNF_ï¼‰ ===
NF_DATA_CSV=./data.csv
NF_OUTPUT_DIR=./nf_auto_runs
NF_LOG_DIR=./nf_auto_runs/logs
NF_MODEL_DIR=./nf_auto_runs/models

# === å®Ÿè¡Œåˆ¶å¾¡ï¼ˆNF_ï¼‰ ===
NF_RANDOM_STATE=2077
NF_TRIAL_NUM_SAMPLES=10
NF_MAX_WORKERS=8
NF_ALLOW_RAY_PARALLEL=true

# === MLflow ===
MLFLOW_TRACKING_URI=http://localhost:5000
MLFLOW_EXPERIMENT_NAME=my-experiment

# === Weights & Biases ===
WANDB_API_KEY=your_key
WANDB_PROJECT=my-project
WANDB_MODE=online

# === Ray ===
RAY_ADDRESS=ray://localhost:10001
RAY_NUM_CPUS=8
RAY_NUM_GPUS=1

# === Optuna ===
OPTUNA_STORAGE=sqlite:///optuna.db
OPTUNA_N_TRIALS=100

# === ãƒ­ã‚° ===
LOG_LEVEL=INFO
LOG_FORMAT=json
```

---

**Document End**

**ç·ç’°å¢ƒå¤‰æ•°æ•°**: 60å€‹ä»¥ä¸Š  
**ã‚«ãƒ†ã‚´ãƒªæ•°**: 8ã‚«ãƒ†ã‚´ãƒª  
**è©³ç´°åº¦**: å®Œå…¨ï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå€¤ã€å‹ã€ç¯„å›²ã€ä¾‹ã¾ã§è¨˜è¼‰ï¼‰
