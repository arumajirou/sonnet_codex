# ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ãƒ»ãƒªã‚«ãƒãƒªã‚¬ã‚¤ãƒ‰

**ãƒãƒ¼ã‚¸ãƒ§ãƒ³**: 1.0.0  
**æœ€çµ‚æ›´æ–°**: 2025-11-03  
**å¯¾è±¡ã‚·ã‚¹ãƒ†ãƒ **: NeuralForecast Auto Runner (æ™‚ç³»åˆ—äºˆæ¸¬ã‚·ã‚¹ãƒ†ãƒ )

---

## ğŸ“‹ ç›®æ¬¡

1. [æ¦‚è¦](#1-æ¦‚è¦)
2. [ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—æˆ¦ç•¥](#2-ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—æˆ¦ç•¥)
3. [ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ã‚¹ã‚¯ãƒªãƒ—ãƒˆ](#3-ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ã‚¹ã‚¯ãƒªãƒ—ãƒˆ)
4. [å¾©æ—§æ‰‹é †ï¼ˆè©³ç´°ï¼‰](#4-å¾©æ—§æ‰‹é †è©³ç´°)
5. [ç½å®³å¾©æ—§è¨ˆç”»ï¼ˆDRï¼‰](#5-ç½å®³å¾©æ—§è¨ˆç”»dr)
6. [RPO/RTO](#6-rporto)
7. [ãƒ†ã‚¹ãƒˆæ‰‹é †](#7-ãƒ†ã‚¹ãƒˆæ‰‹é †)
8. [ç›£è¦–ã¨ã‚¢ãƒ©ãƒ¼ãƒˆ](#8-ç›£è¦–ã¨ã‚¢ãƒ©ãƒ¼ãƒˆ)
9. [ãƒˆãƒ©ãƒ–ãƒ«ã‚·ãƒ¥ãƒ¼ãƒ†ã‚£ãƒ³ã‚°](#9-ãƒˆãƒ©ãƒ–ãƒ«ã‚·ãƒ¥ãƒ¼ãƒ†ã‚£ãƒ³ã‚°)
10. [ä»˜éŒ²](#10-ä»˜éŒ²)

---

## 1. æ¦‚è¦

### 1.1 ç›®çš„

æœ¬ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã¯ã€æ™‚ç³»åˆ—äºˆæ¸¬ã‚·ã‚¹ãƒ†ãƒ ã®ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ã¨ãƒªã‚«ãƒãƒªã®åŒ…æ‹¬çš„ãªã‚¬ã‚¤ãƒ‰ã§ã™ã€‚

**å¯¾è±¡èª­è€…**:
- ã‚·ã‚¹ãƒ†ãƒ ç®¡ç†è€…
- SRE (Site Reliability Engineer)
- ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—æ‹…å½“è€…
- éšœå®³å¯¾å¿œãƒãƒ¼ãƒ 

### 1.2 ã‚¹ã‚³ãƒ¼ãƒ—

**ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—å¯¾è±¡**:
- PostgreSQLãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹
- ãƒ¢ãƒ‡ãƒ«ãƒ•ã‚¡ã‚¤ãƒ«ï¼ˆå­¦ç¿’æ¸ˆã¿ãƒ¢ãƒ‡ãƒ«ï¼‰
- è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«
- ãƒ­ã‚°ãƒ•ã‚¡ã‚¤ãƒ«
- å®Ÿé¨“çµæœï¼ˆã‚¢ãƒ¼ãƒ†ã‚£ãƒ•ã‚¡ã‚¯ãƒˆï¼‰

**å¯¾è±¡å¤–**:
- ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã‚³ãƒ¼ãƒ‰ï¼ˆGitã§ç®¡ç†ï¼‰
- ã‚·ã‚¹ãƒ†ãƒ OSï¼ˆã‚¤ãƒ³ãƒ•ãƒ©ç®¡ç†ãƒ„ãƒ¼ãƒ«ã§ç®¡ç†ï¼‰
- ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«

### 1.3 è²¬ä»»åˆ†æ‹…

| å½¹å‰² | è²¬ä»» |
|-----|------|
| **ã‚·ã‚¹ãƒ†ãƒ ç®¡ç†è€…** | ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ã®å®Ÿè¡Œãƒ»ç›£è¦–ã€ãƒªã‚«ãƒãƒªå®Ÿæ–½ |
| **SRE** | ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—æˆ¦ç•¥ã®ç­–å®šã€è‡ªå‹•åŒ–ã®å®Ÿè£… |
| **é–‹ç™ºè€…** | ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ãƒ¬ãƒ™ãƒ«ã®ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—æ©Ÿèƒ½å®Ÿè£… |
| **ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£æ‹…å½“è€…** | ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ã®æš—å·åŒ–ã€ã‚¢ã‚¯ã‚»ã‚¹åˆ¶å¾¡ |

---

## 2. ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—æˆ¦ç•¥

### 2.1 ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ãƒãƒªã‚·ãƒ¼

#### 2.1.1 ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—è¦ä»¶

| é …ç›® | è¦ä»¶ | æ ¹æ‹  |
|-----|------|------|
| **RPO** (Recovery Point Objective) | 1æ™‚é–“ | æœ€å¤§1æ™‚é–“ã®ãƒ‡ãƒ¼ã‚¿æå¤±ã‚’è¨±å®¹ |
| **RTO** (Recovery Time Objective) | 4æ™‚é–“ | 4æ™‚é–“ä»¥å†…ã«ã‚·ã‚¹ãƒ†ãƒ ã‚’å¾©æ—§ |
| **ä¿æŒæœŸé–“** | ãƒ•ãƒ«: 30æ—¥<br>ã‚¢ãƒ¼ã‚«ã‚¤ãƒ–: 90æ—¥ | ã‚³ãƒ³ãƒ—ãƒ©ã‚¤ã‚¢ãƒ³ã‚¹è¦ä»¶ |
| **ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—é »åº¦** | ãƒ•ãƒ«: æ—¥æ¬¡<br>å¢—åˆ†: 1æ™‚é–“æ¯ | RPOé”æˆã®ãŸã‚ |
| **ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—å ´æ‰€** | ãƒ­ãƒ¼ã‚«ãƒ« + ã‚ªãƒ•ã‚µã‚¤ãƒˆ | ç½å®³å¯¾ç­– |
| **æš—å·åŒ–** | AES-256 | ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£è¦ä»¶ |

#### 2.1.2 ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ã‚¿ã‚¤ãƒ—

```mermaid
graph TD
    A[ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ã‚¿ã‚¤ãƒ—] --> B[ãƒ•ãƒ«ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—]
    A --> C[å¢—åˆ†ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—]
    A --> D[å·®åˆ†ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—]
    A --> E[é€£ç¶šã‚¢ãƒ¼ã‚«ã‚¤ãƒ–]
    
    B --> B1[å®Œå…¨ãªãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‚¹ãƒŠãƒƒãƒ—ã‚·ãƒ§ãƒƒãƒˆ]
    B --> B2[å®Ÿè¡Œé »åº¦: æ—¥æ¬¡ 0:00]
    B --> B3[ä¿æŒæœŸé–“: 30æ—¥]
    
    C --> C1[å‰å›ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ã‹ã‚‰ã®å¤‰æ›´åˆ†]
    C --> C2[å®Ÿè¡Œé »åº¦: 1æ™‚é–“æ¯]
    C --> C3[ä¿æŒæœŸé–“: 7æ—¥]
    
    D --> D1[æœ€å¾Œã®ãƒ•ãƒ«ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ã‹ã‚‰ã®å¤‰æ›´åˆ†]
    D --> D2[å®Ÿè¡Œé »åº¦: é€±æ¬¡]
    D --> D3[ä¿æŒæœŸé–“: 30æ—¥]
    
    E --> E1[WAL ã‚¢ãƒ¼ã‚«ã‚¤ãƒ–]
    E --> E2[å®Ÿè¡Œé »åº¦: é€£ç¶š]
    E --> E3[ä¿æŒæœŸé–“: 7æ—¥]
```

### 2.2 ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—å¯¾è±¡è©³ç´°

#### 2.2.1 PostgreSQLãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹

| å¯¾è±¡ | æ–¹å¼ | é »åº¦ | ä¿æŒæœŸé–“ | å„ªå…ˆåº¦ |
|-----|------|------|---------|--------|
| **å…¨ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹** | pg_dump | æ—¥æ¬¡ | 30æ—¥ | P0 |
| **WALã‚¢ãƒ¼ã‚«ã‚¤ãƒ–** | archive_command | é€£ç¶š | 7æ—¥ | P0 |
| **å¢—åˆ†ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—** | pg_basebackup | 1æ™‚é–“æ¯ | 7æ—¥ | P1 |
| **è«–ç†ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—** | pg_dump -Fc | æ—¥æ¬¡ | 30æ—¥ | P0 |

**ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ã‚µã‚¤ã‚ºè¦‹ç©ã‚‚ã‚Š**:
```
ãƒ•ãƒ«ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—: ç´„ 5GB (100ä¸‡ãƒ¬ã‚³ãƒ¼ãƒ‰æƒ³å®š)
å¢—åˆ†ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—: ç´„ 100MB-500MB (1æ™‚é–“åˆ†)
WALã‚¢ãƒ¼ã‚«ã‚¤ãƒ–: ç´„ 50MB/æ™‚é–“
```

#### 2.2.2 ãƒ¢ãƒ‡ãƒ«ãƒ•ã‚¡ã‚¤ãƒ«

| å¯¾è±¡ | æ–¹å¼ | é »åº¦ | ä¿æŒæœŸé–“ | å„ªå…ˆåº¦ |
|-----|------|------|---------|--------|
| **å­¦ç¿’æ¸ˆã¿ãƒ¢ãƒ‡ãƒ«** | rsync | å®Ÿè¡Œæ™‚ | 90æ—¥ | P1 |
| **ãƒ¢ãƒ‡ãƒ«ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿** | JSON export | å®Ÿè¡Œæ™‚ | 90æ—¥ | P1 |
| **ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆ** | ãƒ•ã‚¡ã‚¤ãƒ«ã‚³ãƒ”ãƒ¼ | å®Ÿè¡Œæ™‚ | 30æ—¥ | P2 |

**ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ã‚µã‚¤ã‚ºè¦‹ç©ã‚‚ã‚Š**:
```
ãƒ¢ãƒ‡ãƒ«1ã¤ã‚ãŸã‚Š: 10MB-100MB
1æ—¥ã‚ãŸã‚Šã®ç”Ÿæˆæ•°: 10-100ãƒ¢ãƒ‡ãƒ«
1æ—¥ã‚ãŸã‚Šã®ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ã‚µã‚¤ã‚º: 1GB-10GB
```

#### 2.2.3 è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«

| å¯¾è±¡ | æ–¹å¼ | é »åº¦ | ä¿æŒæœŸé–“ | å„ªå…ˆåº¦ |
|-----|------|------|---------|--------|
| **ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³è¨­å®š** | Git + ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ— | å¤‰æ›´æ™‚ | æ°¸ç¶š | P0 |
| **ç’°å¢ƒå¤‰æ•°** | æš—å·åŒ–ã‚³ãƒ”ãƒ¼ | å¤‰æ›´æ™‚ | æ°¸ç¶š | P0 |
| **PostgreSQLè¨­å®š** | ãƒ•ã‚¡ã‚¤ãƒ«ã‚³ãƒ”ãƒ¼ | å¤‰æ›´æ™‚ | æ°¸ç¶š | P0 |

#### 2.2.4 ãƒ­ã‚°ãƒ•ã‚¡ã‚¤ãƒ«

| å¯¾è±¡ | æ–¹å¼ | é »åº¦ | ä¿æŒæœŸé–“ | å„ªå…ˆåº¦ |
|-----|------|------|---------|--------|
| **ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ãƒ­ã‚°** | åœ§ç¸®ã‚¢ãƒ¼ã‚«ã‚¤ãƒ– | é€±æ¬¡ | 90æ—¥ | P2 |
| **PostgreSQLãƒ­ã‚°** | åœ§ç¸®ã‚¢ãƒ¼ã‚«ã‚¤ãƒ– | é€±æ¬¡ | 90æ—¥ | P2 |
| **ã‚¢ã‚¯ã‚»ã‚¹ãƒ­ã‚°** | åœ§ç¸®ã‚¢ãƒ¼ã‚«ã‚¤ãƒ– | é€±æ¬¡ | 90æ—¥ | P2 |

#### 2.2.5 å®Ÿé¨“çµæœ

| å¯¾è±¡ | æ–¹å¼ | é »åº¦ | ä¿æŒæœŸé–“ | å„ªå…ˆåº¦ |
|-----|------|------|---------|--------|
| **ã‚¢ãƒ¼ãƒ†ã‚£ãƒ•ã‚¡ã‚¯ãƒˆ** | rsync | å®Ÿè¡Œæ™‚ | 180æ—¥ | P1 |
| **ãƒ¡ãƒˆãƒªã‚¯ã‚¹** | DB export | å®Ÿè¡Œæ™‚ | 180æ—¥ | P1 |
| **äºˆæ¸¬çµæœ** | CSV export | å®Ÿè¡Œæ™‚ | 90æ—¥ | P2 |

### 2.3 ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ã‚¹ãƒˆãƒ¬ãƒ¼ã‚¸

#### 2.3.1 ã‚¹ãƒˆãƒ¬ãƒ¼ã‚¸éšå±¤

```mermaid
graph TD
    A[ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ãƒ‡ãƒ¼ã‚¿] --> B[ãƒ­ãƒ¼ã‚«ãƒ«ã‚¹ãƒˆãƒ¬ãƒ¼ã‚¸]
    A --> C[ã‚ªãƒ³ã‚µã‚¤ãƒˆNAS]
    A --> D[ã‚ªãƒ•ã‚µã‚¤ãƒˆã‚¹ãƒˆãƒ¬ãƒ¼ã‚¸]
    
    B --> B1[ç›´è¿‘7æ—¥åˆ†]
    B --> B2[é«˜é€Ÿã‚¢ã‚¯ã‚»ã‚¹]
    B --> B3[SSD/NVMe]
    
    C --> C1[ç›´è¿‘30æ—¥åˆ†]
    C --> C2[ä¸­é€Ÿã‚¢ã‚¯ã‚»ã‚¹]
    C --> C3[HDD RAID]
    
    D --> D1[90æ—¥åˆ†ã‚¢ãƒ¼ã‚«ã‚¤ãƒ–]
    D --> D2[ä½é€Ÿã‚¢ã‚¯ã‚»ã‚¹]
    D --> D3[S3/GCS/Azure Blob]
```

#### 2.3.2 ã‚¹ãƒˆãƒ¬ãƒ¼ã‚¸è¦ä»¶

| ã‚¹ãƒˆãƒ¬ãƒ¼ã‚¸ | å®¹é‡ | ã‚¿ã‚¤ãƒ— | ãƒ¬ã‚¤ãƒ†ãƒ³ã‚· | ç”¨é€” |
|-----------|------|--------|----------|------|
| **ãƒ­ãƒ¼ã‚«ãƒ«** | 100GB | SSD | <10ms | é«˜é€Ÿãƒªã‚¹ãƒˆã‚¢ç”¨ |
| **NAS** | 500GB | HDD RAID 10 | <50ms | ä¸­æœŸä¿å­˜ |
| **S3/GCS** | 2TB | Object Storage | 100ms-1s | é•·æœŸã‚¢ãƒ¼ã‚«ã‚¤ãƒ– |
| **Glacier** | ç„¡åˆ¶é™ | Cold Storage | æ•°æ™‚é–“ | ç½å®³å¾©æ—§ç”¨ |

#### 2.3.3 ã‚¹ãƒˆãƒ¬ãƒ¼ã‚¸ã‚³ã‚¹ãƒˆè¦‹ç©ã‚‚ã‚Š

```python
# æœˆé–“ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ã‚³ã‚¹ãƒˆè¦‹ç©ã‚‚ã‚Š

# ãƒ­ãƒ¼ã‚«ãƒ«ã‚¹ãƒˆãƒ¬ãƒ¼ã‚¸
local_storage_gb = 100
local_cost_per_gb = 0.10  # ãƒ‰ãƒ«/GB/æœˆ
local_monthly_cost = local_storage_gb * local_cost_per_gb

# NAS
nas_storage_gb = 500
nas_cost_per_gb = 0.05
nas_monthly_cost = nas_storage_gb * nas_cost_per_gb

# S3 Standard
s3_standard_gb = 1000
s3_standard_cost_per_gb = 0.023
s3_standard_monthly_cost = s3_standard_gb * s3_standard_cost_per_gb

# S3 Glacier
s3_glacier_gb = 1000
s3_glacier_cost_per_gb = 0.004
s3_glacier_monthly_cost = s3_glacier_gb * s3_glacier_cost_per_gb

# åˆè¨ˆ
total_monthly_cost = (
    local_monthly_cost +
    nas_monthly_cost +
    s3_standard_monthly_cost +
    s3_glacier_monthly_cost
)

print(f"æœˆé–“ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ã‚³ã‚¹ãƒˆ: ${total_monthly_cost:.2f}")
# å‡ºåŠ›ä¾‹: æœˆé–“ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ã‚³ã‚¹ãƒˆ: $47.00
```

### 2.4 ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ«

#### 2.4.1 å®šæœŸãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ«

```bash
# crontabã®è¨­å®šä¾‹
# /etc/cron.d/ts-forecast-backup

# ãƒ•ãƒ«ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ï¼ˆæ¯æ—¥ 0:00ï¼‰
0 0 * * * postgres /opt/backup/scripts/full_backup.sh >> /var/log/backup/full_backup.log 2>&1

# å¢—åˆ†ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ï¼ˆ1æ™‚é–“æ¯ï¼‰
0 * * * * postgres /opt/backup/scripts/incremental_backup.sh >> /var/log/backup/incremental.log 2>&1

# ãƒ¢ãƒ‡ãƒ«ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ï¼ˆ4æ™‚é–“æ¯ï¼‰
0 */4 * * * app /opt/backup/scripts/model_backup.sh >> /var/log/backup/model.log 2>&1

# ãƒ­ã‚°ã‚¢ãƒ¼ã‚«ã‚¤ãƒ–ï¼ˆé€±æ¬¡ã€æ—¥æ›œæ—¥ 1:00ï¼‰
0 1 * * 0 root /opt/backup/scripts/log_archive.sh >> /var/log/backup/log_archive.log 2>&1

# ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—æ¤œè¨¼ï¼ˆæ—¥æ¬¡ 2:00ï¼‰
0 2 * * * postgres /opt/backup/scripts/verify_backup.sh >> /var/log/backup/verify.log 2>&1

# å¤ã„ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ã®å‰Šé™¤ï¼ˆæ—¥æ¬¡ 3:00ï¼‰
0 3 * * * root /opt/backup/scripts/cleanup_old_backups.sh >> /var/log/backup/cleanup.log 2>&1

# ã‚ªãƒ•ã‚µã‚¤ãƒˆã¸ã®è»¢é€ï¼ˆæ—¥æ¬¡ 4:00ï¼‰
0 4 * * * root /opt/backup/scripts/sync_to_offsite.sh >> /var/log/backup/sync.log 2>&1
```

#### 2.4.2 ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ãƒ•ãƒ­ãƒ¼ãƒãƒ£ãƒ¼ãƒˆ

```mermaid
graph TD
    A[é–‹å§‹] --> B{ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ã‚¿ã‚¤ãƒ—?}
    B -->|ãƒ•ãƒ«| C[ãƒ•ãƒ«ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—å®Ÿè¡Œ]
    B -->|å¢—åˆ†| D[å¢—åˆ†ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—å®Ÿè¡Œ]
    B -->|WAL| E[WALã‚¢ãƒ¼ã‚«ã‚¤ãƒ–]
    
    C --> F[åœ§ç¸®]
    D --> F
    E --> F
    
    F --> G[æš—å·åŒ–]
    G --> H[ãƒã‚§ãƒƒã‚¯ã‚µãƒ è¨ˆç®—]
    H --> I[ãƒ­ãƒ¼ã‚«ãƒ«ä¿å­˜]
    
    I --> J{æ¤œè¨¼OK?}
    J -->|Yes| K[NASã¸ã‚³ãƒ”ãƒ¼]
    J -->|No| L[ã‚¢ãƒ©ãƒ¼ãƒˆé€ä¿¡]
    L --> M[å†å®Ÿè¡Œ]
    M --> C
    
    K --> N[ã‚ªãƒ•ã‚µã‚¤ãƒˆã¸è»¢é€]
    N --> O[å¤ã„ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—å‰Šé™¤]
    O --> P[å®Œäº†ãƒ­ã‚°è¨˜éŒ²]
    P --> Q[çµ‚äº†]
```

---

## 3. ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ã‚¹ã‚¯ãƒªãƒ—ãƒˆ

### 3.1 PostgreSQLãƒ•ãƒ«ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—

#### 3.1.1 ãƒ•ãƒ«ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ã‚¹ã‚¯ãƒªãƒ—ãƒˆ

```bash
#!/bin/bash
# /opt/backup/scripts/full_backup.sh
# PostgreSQLãƒ•ãƒ«ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ã‚¹ã‚¯ãƒªãƒ—ãƒˆ

set -euo pipefail

# ===========================
# è¨­å®š
# ===========================
readonly SCRIPT_NAME=$(basename "$0")
readonly SCRIPT_DIR=$(dirname "$0")
readonly LOG_FILE="/var/log/backup/full_backup.log"

# ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹è¨­å®š
readonly DB_NAME="${DB_NAME:-ts_forecast_system}"
readonly DB_USER="${DB_USER:-postgres}"
readonly DB_HOST="${DB_HOST:-localhost}"
readonly DB_PORT="${DB_PORT:-5432}"

# ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª
readonly BACKUP_ROOT="/var/backups/postgresql"
readonly LOCAL_BACKUP_DIR="${BACKUP_ROOT}/local"
readonly NAS_BACKUP_DIR="${BACKUP_ROOT}/nas"
readonly OFFSITE_BUCKET="s3://ts-forecast-backups"

# ä¿æŒæœŸé–“ï¼ˆæ—¥æ•°ï¼‰
readonly LOCAL_RETENTION_DAYS=7
readonly NAS_RETENTION_DAYS=30
readonly OFFSITE_RETENTION_DAYS=90

# ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—
readonly TIMESTAMP=$(date +%Y%m%d_%H%M%S)
readonly DATE_DIR=$(date +%Y/%m/%d)

# ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ãƒ•ã‚¡ã‚¤ãƒ«å
readonly BACKUP_FILENAME="full_${DB_NAME}_${TIMESTAMP}.dump"
readonly BACKUP_FILEPATH="${LOCAL_BACKUP_DIR}/${DATE_DIR}/${BACKUP_FILENAME}"

# ===========================
# ãƒ­ã‚°é–¢æ•°
# ===========================
log() {
    echo "[$(date '+%Y-%m-%d %H:%M:%S')] [$1] $2" | tee -a "${LOG_FILE}"
}

log_info() {
    log "INFO" "$1"
}

log_error() {
    log "ERROR" "$1"
}

log_success() {
    log "SUCCESS" "$1"
}

# ===========================
# ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°
# ===========================
error_exit() {
    log_error "$1"
    # ã‚¢ãƒ©ãƒ¼ãƒˆé€ä¿¡ï¼ˆä¾‹: Slack, ãƒ¡ãƒ¼ãƒ«ï¼‰
    send_alert "BACKUP_FAILED" "$1"
    exit 1
}

cleanup_on_error() {
    if [ -f "${BACKUP_FILEPATH}" ]; then
        rm -f "${BACKUP_FILEPATH}"
        log_info "Cleanup: Removed incomplete backup file"
    fi
}

trap cleanup_on_error ERR

# ===========================
# ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªæº–å‚™
# ===========================
prepare_directories() {
    log_info "Preparing backup directories..."
    
    mkdir -p "${LOCAL_BACKUP_DIR}/${DATE_DIR}"
    mkdir -p "${NAS_BACKUP_DIR}/${DATE_DIR}"
    
    log_success "Directories prepared"
}

# ===========================
# ãƒ•ãƒ«ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—å®Ÿè¡Œ
# ===========================
perform_full_backup() {
    log_info "Starting full backup: ${DB_NAME}"
    
    # pg_dumpå®Ÿè¡Œï¼ˆã‚«ã‚¹ã‚¿ãƒ ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆã€åœ§ç¸®ãƒ¬ãƒ™ãƒ«9ï¼‰
    if pg_dump \
        -h "${DB_HOST}" \
        -p "${DB_PORT}" \
        -U "${DB_USER}" \
        -Fc \
        -Z 9 \
        -f "${BACKUP_FILEPATH}" \
        "${DB_NAME}"; then
        
        log_success "Full backup completed: ${BACKUP_FILEPATH}"
    else
        error_exit "Failed to create full backup"
    fi
    
    # ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ã‚µã‚¤ã‚ºç¢ºèª
    local backup_size=$(du -h "${BACKUP_FILEPATH}" | cut -f1)
    log_info "Backup size: ${backup_size}"
}

# ===========================
# ãƒã‚§ãƒƒã‚¯ã‚µãƒ è¨ˆç®—
# ===========================
calculate_checksum() {
    log_info "Calculating checksum..."
    
    local checksum_file="${BACKUP_FILEPATH}.sha256"
    
    if sha256sum "${BACKUP_FILEPATH}" > "${checksum_file}"; then
        log_success "Checksum calculated: ${checksum_file}"
    else
        error_exit "Failed to calculate checksum"
    fi
}

# ===========================
# ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—æ¤œè¨¼
# ===========================
verify_backup() {
    log_info "Verifying backup integrity..."
    
    # ãƒã‚§ãƒƒã‚¯ã‚µãƒ æ¤œè¨¼
    if sha256sum -c "${BACKUP_FILEPATH}.sha256" > /dev/null 2>&1; then
        log_success "Checksum verification passed"
    else
        error_exit "Checksum verification failed"
    fi
    
    # pg_restoreã«ã‚ˆã‚‹æ¤œè¨¼ï¼ˆãƒªã‚¹ãƒˆã®ã¿ï¼‰
    if pg_restore -l "${BACKUP_FILEPATH}" > /dev/null 2>&1; then
        log_success "Backup file structure verified"
    else
        error_exit "Backup file structure verification failed"
    fi
}

# ===========================
# NASã¸ã‚³ãƒ”ãƒ¼
# ===========================
copy_to_nas() {
    log_info "Copying backup to NAS..."
    
    if rsync -avz --progress \
        "${BACKUP_FILEPATH}" \
        "${BACKUP_FILEPATH}.sha256" \
        "${NAS_BACKUP_DIR}/${DATE_DIR}/"; then
        
        log_success "Backup copied to NAS"
    else
        log_error "Failed to copy backup to NAS (continuing...)"
    fi
}

# ===========================
# ã‚ªãƒ•ã‚µã‚¤ãƒˆã¸è»¢é€
# ===========================
sync_to_offsite() {
    log_info "Syncing backup to offsite storage..."
    
    # AWS S3ã®ä¾‹
    if aws s3 cp \
        "${BACKUP_FILEPATH}" \
        "${OFFSITE_BUCKET}/${DATE_DIR}/${BACKUP_FILENAME}" \
        --storage-class STANDARD_IA \
        --metadata "checksum=$(cat ${BACKUP_FILEPATH}.sha256 | cut -d' ' -f1)"; then
        
        log_success "Backup synced to offsite storage"
    else
        log_error "Failed to sync backup to offsite storage (continuing...)"
    fi
    
    # ãƒã‚§ãƒƒã‚¯ã‚µãƒ ãƒ•ã‚¡ã‚¤ãƒ«ã‚‚è»¢é€
    aws s3 cp \
        "${BACKUP_FILEPATH}.sha256" \
        "${OFFSITE_BUCKET}/${DATE_DIR}/${BACKUP_FILENAME}.sha256" \
        --storage-class STANDARD_IA || true
}

# ===========================
# å¤ã„ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—å‰Šé™¤
# ===========================
cleanup_old_backups() {
    log_info "Cleaning up old backups..."
    
    # ãƒ­ãƒ¼ã‚«ãƒ«
    find "${LOCAL_BACKUP_DIR}" \
        -name "full_*.dump" \
        -type f \
        -mtime +${LOCAL_RETENTION_DAYS} \
        -delete
    
    find "${LOCAL_BACKUP_DIR}" \
        -name "full_*.dump.sha256" \
        -type f \
        -mtime +${LOCAL_RETENTION_DAYS} \
        -delete
    
    # NAS
    find "${NAS_BACKUP_DIR}" \
        -name "full_*.dump" \
        -type f \
        -mtime +${NAS_RETENTION_DAYS} \
        -delete
    
    find "${NAS_BACKUP_DIR}" \
        -name "full_*.dump.sha256" \
        -type f \
        -mtime +${NAS_RETENTION_DAYS} \
        -delete
    
    # ã‚ªãƒ•ã‚µã‚¤ãƒˆï¼ˆS3ãƒ©ã‚¤ãƒ•ã‚µã‚¤ã‚¯ãƒ«ãƒãƒªã‚·ãƒ¼ã§ç®¡ç†ï¼‰
    
    log_success "Old backups cleaned up"
}

# ===========================
# ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿è¨˜éŒ²
# ===========================
record_metadata() {
    log_info "Recording backup metadata..."
    
    local metadata_file="${BACKUP_FILEPATH}.meta.json"
    
    cat > "${metadata_file}" <<EOF
{
  "backup_type": "full",
  "database": "${DB_NAME}",
  "timestamp": "${TIMESTAMP}",
  "size_bytes": $(stat -f%z "${BACKUP_FILEPATH}" 2>/dev/null || stat -c%s "${BACKUP_FILEPATH}"),
  "checksum": "$(cat ${BACKUP_FILEPATH}.sha256 | cut -d' ' -f1)",
  "retention_days": ${NAS_RETENTION_DAYS},
  "postgresql_version": "$(psql -V | cut -d' ' -f3)",
  "hostname": "$(hostname)",
  "script_version": "1.0.0"
}
EOF
    
    log_success "Metadata recorded: ${metadata_file}"
}

# ===========================
# ã‚¢ãƒ©ãƒ¼ãƒˆé€ä¿¡
# ===========================
send_alert() {
    local alert_type=$1
    local message=$2
    
    # Slack Webhookä¾‹
    if [ -n "${SLACK_WEBHOOK_URL:-}" ]; then
        curl -X POST "${SLACK_WEBHOOK_URL}" \
            -H 'Content-Type: application/json' \
            -d "{\"text\": \"[${alert_type}] ${message}\"}" \
            > /dev/null 2>&1 || true
    fi
    
    # ãƒ¡ãƒ¼ãƒ«é€ä¿¡ä¾‹
    if [ -n "${ALERT_EMAIL:-}" ]; then
        echo "${message}" | mail -s "[${alert_type}] Backup Alert" "${ALERT_EMAIL}" || true
    fi
}

# ===========================
# ãƒ¡ã‚¤ãƒ³å‡¦ç†
# ===========================
main() {
    log_info "=========================================="
    log_info "Full Backup Started"
    log_info "=========================================="
    
    local start_time=$(date +%s)
    
    # ç’°å¢ƒå¤‰æ•°ãƒã‚§ãƒƒã‚¯
    if [ -z "${PGPASSWORD:-}" ]; then
        log_error "PGPASSWORD environment variable not set"
        # .pgpassãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä½¿ç”¨ã™ã‚‹ã“ã¨ã‚’æ¨å¥¨
    fi
    
    # å®Ÿè¡Œ
    prepare_directories
    perform_full_backup
    calculate_checksum
    verify_backup
    record_metadata
    copy_to_nas
    sync_to_offsite
    cleanup_old_backups
    
    local end_time=$(date +%s)
    local duration=$((end_time - start_time))
    
    log_info "=========================================="
    log_success "Full Backup Completed Successfully"
    log_info "Duration: ${duration} seconds"
    log_info "=========================================="
    
    # æˆåŠŸé€šçŸ¥
    send_alert "BACKUP_SUCCESS" "Full backup completed in ${duration}s"
}

# ã‚¹ã‚¯ãƒªãƒ—ãƒˆå®Ÿè¡Œ
main "$@"
```

### 3.2 å¢—åˆ†ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—

#### 3.2.1 WALã‚¢ãƒ¼ã‚«ã‚¤ãƒ–è¨­å®š

```bash
# postgresql.conf ã«è¿½åŠ 

# WALã‚¢ãƒ¼ã‚«ã‚¤ãƒ–æœ‰åŠ¹åŒ–
wal_level = replica
archive_mode = on
archive_command = 'test ! -f /var/backups/postgresql/wal_archive/%f && gzip -c < %p > /var/backups/postgresql/wal_archive/%f.gz'
archive_timeout = 3600  # 1æ™‚é–“

# WALã‚»ã‚°ãƒ¡ãƒ³ãƒˆã‚µã‚¤ã‚º
wal_segment_size = 16MB

# ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆè¨­å®š
checkpoint_timeout = 15min
max_wal_size = 2GB
min_wal_size = 1GB
```

#### 3.2.2 å¢—åˆ†ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ã‚¹ã‚¯ãƒªãƒ—ãƒˆ

```bash
#!/bin/bash
# /opt/backup/scripts/incremental_backup.sh
# PostgreSQLå¢—åˆ†ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ã‚¹ã‚¯ãƒªãƒ—ãƒˆï¼ˆpg_basebackupãƒ™ãƒ¼ã‚¹ï¼‰

set -euo pipefail

readonly BACKUP_DIR="/var/backups/postgresql/incremental"
readonly BASE_BACKUP_DIR="/var/backups/postgresql/base"
readonly DB_USER="${DB_USER:-postgres}"
readonly DB_HOST="${DB_HOST:-localhost}"
readonly DB_PORT="${DB_PORT:-5432}"
readonly TIMESTAMP=$(date +%Y%m%d_%H%M%S)
readonly LOG_FILE="/var/log/backup/incremental_backup.log"

log_info() {
    echo "[$(date '+%Y-%m-%d %H:%M:%S')] [INFO] $1" | tee -a "${LOG_FILE}"
}

log_error() {
    echo "[$(date '+%Y-%m-%d %H:%M:%S')] [ERROR] $1" | tee -a "${LOG_FILE}"
}

# ãƒ™ãƒ¼ã‚¹ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—å­˜åœ¨ç¢ºèª
if [ ! -d "${BASE_BACKUP_DIR}/base" ]; then
    log_error "Base backup not found. Run base_backup.sh first."
    exit 1
fi

# å¢—åˆ†ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªä½œæˆ
mkdir -p "${BACKUP_DIR}/${TIMESTAMP}"

log_info "Starting incremental backup..."

# pg_basebackupã§å¢—åˆ†ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—å®Ÿè¡Œ
if pg_basebackup \
    -h "${DB_HOST}" \
    -p "${DB_PORT}" \
    -U "${DB_USER}" \
    -D "${BACKUP_DIR}/${TIMESTAMP}" \
    -Fp \
    -Xs \
    -P \
    -R \
    --incremental="${BASE_BACKUP_DIR}/base/backup_manifest"; then
    
    log_info "Incremental backup completed: ${BACKUP_DIR}/${TIMESTAMP}"
else
    log_error "Incremental backup failed"
    exit 1
fi

# å¤ã„å¢—åˆ†ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—å‰Šé™¤ï¼ˆ7æ—¥ä»¥ä¸Šå‰ï¼‰
find "${BACKUP_DIR}" -maxdepth 1 -type d -mtime +7 -exec rm -rf {} \;

log_info "Incremental backup finished successfully"
```

### 3.3 ãƒ¢ãƒ‡ãƒ«ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—

#### 3.3.1 ãƒ¢ãƒ‡ãƒ«ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ã‚¹ã‚¯ãƒªãƒ—ãƒˆ

```bash
#!/bin/bash
# /opt/backup/scripts/model_backup.sh
# å­¦ç¿’æ¸ˆã¿ãƒ¢ãƒ‡ãƒ«ã®ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ã‚¹ã‚¯ãƒªãƒ—ãƒˆ

set -euo pipefail

readonly MODEL_DIR="${MODEL_DIR:-/opt/ts-forecast/models}"
readonly BACKUP_DIR="/var/backups/models"
readonly TIMESTAMP=$(date +%Y%m%d_%H%M%S)
readonly DATE_DIR=$(date +%Y/%m/%d)
readonly LOG_FILE="/var/log/backup/model_backup.log"
readonly RETENTION_DAYS=90

log_info() {
    echo "[$(date '+%Y-%m-%d %H:%M:%S')] [INFO] $1" | tee -a "${LOG_FILE}"
}

# ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªæº–å‚™
mkdir -p "${BACKUP_DIR}/${DATE_DIR}"

log_info "Starting model backup..."

# æ–°ã—ã„ãƒ¢ãƒ‡ãƒ«ãƒ•ã‚¡ã‚¤ãƒ«ã®ã¿ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ï¼ˆ4æ™‚é–“ä»¥å†…ã«å¤‰æ›´ã•ã‚ŒãŸãƒ•ã‚¡ã‚¤ãƒ«ï¼‰
find "${MODEL_DIR}" -type f -mmin -240 | while read -r model_file; do
    # ç›¸å¯¾ãƒ‘ã‚¹ã‚’å–å¾—
    relative_path="${model_file#${MODEL_DIR}/}"
    backup_path="${BACKUP_DIR}/${DATE_DIR}/${relative_path}"
    
    # ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªä½œæˆ
    mkdir -p "$(dirname ${backup_path})"
    
    # rsyncã§ã‚³ãƒ”ãƒ¼ï¼ˆãƒã‚§ãƒƒã‚¯ã‚µãƒ æ¤œè¨¼ä»˜ãï¼‰
    rsync -avz --checksum "${model_file}" "${backup_path}"
    
    log_info "Backed up: ${relative_path}"
done

# ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆ
python3 <<EOF
import json
from pathlib import Path
from datetime import datetime

models_dir = Path("${MODEL_DIR}")
metadata = {
    "backup_timestamp": "${TIMESTAMP}",
    "models": []
}

for model_file in models_dir.rglob("*.pkl"):
    metadata["models"].append({
        "path": str(model_file.relative_to(models_dir)),
        "size_bytes": model_file.stat().st_size,
        "modified_time": datetime.fromtimestamp(model_file.stat().st_mtime).isoformat()
    })

metadata_file = Path("${BACKUP_DIR}/${DATE_DIR}/metadata.json")
metadata_file.write_text(json.dumps(metadata, indent=2))
print(f"Metadata exported: {metadata_file}")
EOF

# å¤ã„ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—å‰Šé™¤
find "${BACKUP_DIR}" -maxdepth 1 -type d -mtime +${RETENTION_DAYS} -exec rm -rf {} \;

log_info "Model backup completed successfully"
```

### 3.4 è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—

```bash
#!/bin/bash
# /opt/backup/scripts/config_backup.sh
# è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ã‚¹ã‚¯ãƒªãƒ—ãƒˆ

set -euo pipefail

readonly CONFIG_DIRS=(
    "/opt/ts-forecast/conf"
    "/etc/postgresql/15/main"
    "/opt/ts-forecast/.env"
)
readonly BACKUP_DIR="/var/backups/config"
readonly TIMESTAMP=$(date +%Y%m%d_%H%M%S)
readonly BACKUP_FILE="${BACKUP_DIR}/config_${TIMESTAMP}.tar.gz.gpg"
readonly LOG_FILE="/var/log/backup/config_backup.log"
readonly GPG_RECIPIENT="${GPG_RECIPIENT:-backup@example.com}"

log_info() {
    echo "[$(date '+%Y-%m-%d %H:%M:%S')] [INFO] $1" | tee -a "${LOG_FILE}"
}

mkdir -p "${BACKUP_DIR}"

log_info "Starting configuration backup..."

# ä¸€æ™‚ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªä½œæˆ
TEMP_DIR=$(mktemp -d)
trap "rm -rf ${TEMP_DIR}" EXIT

# è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚³ãƒ”ãƒ¼
for config_dir in "${CONFIG_DIRS[@]}"; do
    if [ -e "${config_dir}" ]; then
        cp -r "${config_dir}" "${TEMP_DIR}/"
    fi
done

# tar.gzä½œæˆ
tar -czf "${TEMP_DIR}/config.tar.gz" -C "${TEMP_DIR}" .

# GPGã§æš—å·åŒ–
gpg --encrypt --recipient "${GPG_RECIPIENT}" \
    --output "${BACKUP_FILE}" \
    "${TEMP_DIR}/config.tar.gz"

log_info "Configuration backup completed: ${BACKUP_FILE}"

# Gitãƒªãƒã‚¸ãƒˆãƒªã«ã‚‚ã‚³ãƒŸãƒƒãƒˆï¼ˆå¹³æ–‡ï¼‰
if [ -d "/opt/ts-forecast/conf/.git" ]; then
    cd "/opt/ts-forecast/conf"
    git add .
    git commit -m "Auto backup: ${TIMESTAMP}" || true
    git push origin main || log_info "Git push skipped (no changes or no remote)"
fi
```

---

## 4. å¾©æ—§æ‰‹é †ï¼ˆè©³ç´°ï¼‰

### 4.1 å¾©æ—§ã‚·ãƒŠãƒªã‚ª

#### 4.1.1 ã‚·ãƒŠãƒªã‚ªåˆ†é¡

| ã‚·ãƒŠãƒªã‚ª | RPO | RTO | å¾©æ—§æ–¹æ³• | é›£æ˜“åº¦ |
|---------|-----|-----|---------|--------|
| **å€‹åˆ¥ãƒ†ãƒ¼ãƒ–ãƒ«å¾©æ—§** | 1æ—¥ | 30åˆ† | pg_restore -t | ä½ |
| **ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹å…¨ä½“å¾©æ—§** | 1æ—¥ | 2æ™‚é–“ | pg_restore | ä¸­ |
| **ç‰¹å®šæ™‚ç‚¹å¾©æ—§ï¼ˆPITRï¼‰** | 1æ™‚é–“ | 4æ™‚é–“ | WALãƒªãƒ—ãƒ¬ã‚¤ | é«˜ |
| **ãƒ¢ãƒ‡ãƒ«å¾©æ—§** | 1æ—¥ | 10åˆ† | ãƒ•ã‚¡ã‚¤ãƒ«ã‚³ãƒ”ãƒ¼ | ä½ |
| **ã‚·ã‚¹ãƒ†ãƒ å…¨ä½“å¾©æ—§** | 1æ—¥ | 8æ™‚é–“ | ãƒ•ãƒ«ãƒªã‚¹ãƒˆã‚¢ | é«˜ |

### 4.2 ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹å¾©æ—§

#### 4.2.1 ãƒ•ãƒ«ãƒªã‚¹ãƒˆã‚¢

```bash
#!/bin/bash
# /opt/backup/scripts/restore_full.sh
# PostgreSQLãƒ•ãƒ«ãƒªã‚¹ãƒˆã‚¢ã‚¹ã‚¯ãƒªãƒ—ãƒˆ

set -euo pipefail

# ===========================
# è¨­å®š
# ===========================
readonly BACKUP_FILE="$1"
readonly DB_NAME="${DB_NAME:-ts_forecast_system}"
readonly DB_USER="${DB_USER:-postgres}"
readonly DB_HOST="${DB_HOST:-localhost}"
readonly DB_PORT="${DB_PORT:-5432}"
readonly LOG_FILE="/var/log/backup/restore.log"

# ===========================
# å¼•æ•°ãƒã‚§ãƒƒã‚¯
# ===========================
if [ -z "${BACKUP_FILE}" ]; then
    echo "Usage: $0 <backup_file.dump>"
    echo "Example: $0 /var/backups/postgresql/local/2025/11/03/full_ts_forecast_system_20251103_000000.dump"
    exit 1
fi

if [ ! -f "${BACKUP_FILE}" ]; then
    echo "Error: Backup file not found: ${BACKUP_FILE}"
    exit 1
fi

# ===========================
# ãƒ­ã‚°é–¢æ•°
# ===========================
log_info() {
    echo "[$(date '+%Y-%m-%d %H:%M:%S')] [INFO] $1" | tee -a "${LOG_FILE}"
}

log_error() {
    echo "[$(date '+%Y-%m-%d %H:%M:%S')] [ERROR] $1" | tee -a "${LOG_FILE}"
}

log_warning() {
    echo "[$(date '+%Y-%m-%d %H:%M:%S')] [WARNING] $1" | tee -a "${LOG_FILE}"
}

# ===========================
# ç¢ºèªãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ
# ===========================
confirm_restore() {
    log_warning "=========================================="
    log_warning "WARNING: This will DROP and RECREATE the database!"
    log_warning "Database: ${DB_NAME}"
    log_warning "Backup file: ${BACKUP_FILE}"
    log_warning "=========================================="
    
    read -p "Are you sure you want to proceed? (yes/no): " confirmation
    
    if [ "${confirmation}" != "yes" ]; then
        log_info "Restore cancelled by user"
        exit 0
    fi
}

# ===========================
# ãƒã‚§ãƒƒã‚¯ã‚µãƒ æ¤œè¨¼
# ===========================
verify_checksum() {
    log_info "Verifying backup file checksum..."
    
    local checksum_file="${BACKUP_FILE}.sha256"
    
    if [ ! -f "${checksum_file}" ]; then
        log_warning "Checksum file not found, skipping verification"
        return
    fi
    
    if sha256sum -c "${checksum_file}"; then
        log_info "Checksum verification passed"
    else
        log_error "Checksum verification failed!"
        exit 1
    fi
}

# ===========================
# æ¥ç¶šãƒ†ã‚¹ãƒˆ
# ===========================
test_connection() {
    log_info "Testing database connection..."
    
    if psql -h "${DB_HOST}" -p "${DB_PORT}" -U "${DB_USER}" -c "SELECT 1" > /dev/null 2>&1; then
        log_info "Database connection successful"
    else
        log_error "Cannot connect to database"
        exit 1
    fi
}

# ===========================
# ã‚¢ã‚¯ãƒ†ã‚£ãƒ–æ¥ç¶šã‚’åˆ‡æ–­
# ===========================
terminate_connections() {
    log_info "Terminating active connections to ${DB_NAME}..."
    
    psql -h "${DB_HOST}" -p "${DB_PORT}" -U "${DB_USER}" -d postgres <<EOF
SELECT pg_terminate_backend(pid) 
FROM pg_stat_activity 
WHERE datname = '${DB_NAME}' AND pid <> pg_backend_pid();
EOF
    
    sleep 2
}

# ===========================
# ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹å‰Šé™¤ã¨å†ä½œæˆ
# ===========================
recreate_database() {
    log_info "Dropping existing database..."
    
    psql -h "${DB_HOST}" -p "${DB_PORT}" -U "${DB_USER}" -d postgres <<EOF
DROP DATABASE IF EXISTS ${DB_NAME};
EOF
    
    log_info "Creating new database..."
    
    psql -h "${DB_HOST}" -p "${DB_PORT}" -U "${DB_USER}" -d postgres <<EOF
CREATE DATABASE ${DB_NAME} 
    WITH ENCODING='UTF8' 
    LC_COLLATE='en_US.UTF-8' 
    LC_CTYPE='en_US.UTF-8' 
    TEMPLATE=template0;
EOF
}

# ===========================
# ãƒªã‚¹ãƒˆã‚¢å®Ÿè¡Œ
# ===========================
perform_restore() {
    log_info "Starting database restore from: ${BACKUP_FILE}"
    
    local start_time=$(date +%s)
    
    # pg_restoreå®Ÿè¡Œ
    if pg_restore \
        -h "${DB_HOST}" \
        -p "${DB_PORT}" \
        -U "${DB_USER}" \
        -d "${DB_NAME}" \
        -Fc \
        --verbose \
        --no-owner \
        --no-acl \
        "${BACKUP_FILE}" 2>&1 | tee -a "${LOG_FILE}"; then
        
        local end_time=$(date +%s)
        local duration=$((end_time - start_time))
        
        log_info "Restore completed in ${duration} seconds"
    else
        log_error "Restore failed"
        exit 1
    fi
}

# ===========================
# ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹çµ±è¨ˆæ›´æ–°
# ===========================
update_statistics() {
    log_info "Updating database statistics..."
    
    psql -h "${DB_HOST}" -p "${DB_PORT}" -U "${DB_USER}" -d "${DB_NAME}" <<EOF
ANALYZE VERBOSE;
VACUUM ANALYZE;
EOF
    
    log_info "Statistics updated"
}

# ===========================
# ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹å†æ§‹ç¯‰
# ===========================
reindex_database() {
    log_info "Reindexing database..."
    
    psql -h "${DB_HOST}" -p "${DB_PORT}" -U "${DB_USER}" -d "${DB_NAME}" <<EOF
REINDEX DATABASE ${DB_NAME};
EOF
    
    log_info "Reindexing completed"
}

# ===========================
# ãƒªã‚¹ãƒˆã‚¢æ¤œè¨¼
# ===========================
verify_restore() {
    log_info "Verifying restored database..."
    
    # ãƒ†ãƒ¼ãƒ–ãƒ«æ•°ç¢ºèª
    local table_count=$(psql -h "${DB_HOST}" -p "${DB_PORT}" -U "${DB_USER}" \
        -d "${DB_NAME}" -t -c \
        "SELECT COUNT(*) FROM information_schema.tables WHERE table_schema='public';" | tr -d ' ')
    
    log_info "Tables restored: ${table_count}"
    
    # ä¸»è¦ãƒ†ãƒ¼ãƒ–ãƒ«ã®ãƒ¬ã‚³ãƒ¼ãƒ‰æ•°ç¢ºèª
    for table in datasets experiments runs models metrics; do
        local count=$(psql -h "${DB_HOST}" -p "${DB_PORT}" -U "${DB_USER}" \
            -d "${DB_NAME}" -t -c \
            "SELECT COUNT(*) FROM ${table};" 2>/dev/null | tr -d ' ' || echo "0")
        log_info "Table ${table}: ${count} records"
    done
    
    log_info "Verification completed"
}

# ===========================
# ãƒ¡ã‚¤ãƒ³å‡¦ç†
# ===========================
main() {
    log_info "=========================================="
    log_info "Database Restore Started"
    log_info "=========================================="
    
    confirm_restore
    verify_checksum
    test_connection
    terminate_connections
    recreate_database
    perform_restore
    update_statistics
    reindex_database
    verify_restore
    
    log_info "=========================================="
    log_info "Database Restore Completed Successfully"
    log_info "=========================================="
}

main "$@"
```

#### 4.2.2 ç‰¹å®šãƒ†ãƒ¼ãƒ–ãƒ«ã®ãƒªã‚¹ãƒˆã‚¢

```bash
#!/bin/bash
# /opt/backup/scripts/restore_table.sh
# ç‰¹å®šãƒ†ãƒ¼ãƒ–ãƒ«ã®ã¿ã‚’ãƒªã‚¹ãƒˆã‚¢

set -euo pipefail

readonly BACKUP_FILE="$1"
readonly TABLE_NAME="$2"
readonly DB_NAME="${DB_NAME:-ts_forecast_system}"
readonly DB_USER="${DB_USER:-postgres}"

if [ -z "${BACKUP_FILE}" ] || [ -z "${TABLE_NAME}" ]; then
    echo "Usage: $0 <backup_file.dump> <table_name>"
    exit 1
fi

echo "[INFO] Restoring table: ${TABLE_NAME}"

# ãƒ†ãƒ¼ãƒ–ãƒ«ã®ã¿ã‚’ãƒªã‚¹ãƒˆã‚¢
pg_restore \
    -U "${DB_USER}" \
    -d "${DB_NAME}" \
    -Fc \
    --table="${TABLE_NAME}" \
    --verbose \
    "${BACKUP_FILE}"

echo "[SUCCESS] Table ${TABLE_NAME} restored successfully"
```

#### 4.2.3 Point-In-Time Recovery (PITR)

```bash
#!/bin/bash
# /opt/backup/scripts/restore_pitr.sh
# Point-In-Time Recoveryã‚¹ã‚¯ãƒªãƒ—ãƒˆ

set -euo pipefail

# ===========================
# è¨­å®š
# ===========================
readonly TARGET_TIME="$1"  # ä¾‹: '2025-11-03 14:30:00'
readonly BASE_BACKUP_DIR="/var/backups/postgresql/base"
readonly WAL_ARCHIVE_DIR="/var/backups/postgresql/wal_archive"
readonly DATA_DIR="/var/lib/postgresql/15/main"
readonly LOG_FILE="/var/log/backup/pitr_restore.log"

# ===========================
# å¼•æ•°ãƒã‚§ãƒƒã‚¯
# ===========================
if [ -z "${TARGET_TIME}" ]; then
    echo "Usage: $0 'YYYY-MM-DD HH:MM:SS'"
    echo "Example: $0 '2025-11-03 14:30:00'"
    exit 1
fi

log_info() {
    echo "[$(date '+%Y-%m-%d %H:%M:%S')] [INFO] $1" | tee -a "${LOG_FILE}"
}

log_error() {
    echo "[$(date '+%Y-%m-%d %H:%M:%S')] [ERROR] $1" | tee -a "${LOG_FILE}"
}

# ===========================
# ç¢ºèª
# ===========================
log_info "=========================================="
log_info "PITR Restore Configuration"
log_info "=========================================="
log_info "Target recovery time: ${TARGET_TIME}"
log_info "Base backup: ${BASE_BACKUP_DIR}/base"
log_info "WAL archive: ${WAL_ARCHIVE_DIR}"
log_info "Data directory: ${DATA_DIR}"
log_info "=========================================="

read -p "Proceed with PITR? (yes/no): " confirmation
if [ "${confirmation}" != "yes" ]; then
    log_info "PITR cancelled"
    exit 0
fi

# ===========================
# PostgreSQLåœæ­¢
# ===========================
log_info "Stopping PostgreSQL..."
systemctl stop postgresql || log_error "Failed to stop PostgreSQL"

# ===========================
# ãƒ‡ãƒ¼ã‚¿ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—
# ===========================
log_info "Backing up current data directory..."
if [ -d "${DATA_DIR}" ]; then
    mv "${DATA_DIR}" "${DATA_DIR}.pre-pitr.$(date +%Y%m%d_%H%M%S)"
fi

# ===========================
# ãƒ™ãƒ¼ã‚¹ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ãƒªã‚¹ãƒˆã‚¢
# ===========================
log_info "Restoring base backup..."
cp -r "${BASE_BACKUP_DIR}/base" "${DATA_DIR}"
chown -R postgres:postgres "${DATA_DIR}"
chmod 700 "${DATA_DIR}"

# ===========================
# recoveryè¨­å®š
# ===========================
log_info "Configuring recovery settings..."

# PostgreSQL 12ä»¥é™: postgresql.conf + recovery.signal
cat >> "${DATA_DIR}/postgresql.conf" <<EOF

# PITR Recovery Settings
restore_command = 'gunzip -c ${WAL_ARCHIVE_DIR}/%f.gz > %p'
recovery_target_time = '${TARGET_TIME}'
recovery_target_action = 'promote'
EOF

# recovery.signalä½œæˆ
touch "${DATA_DIR}/recovery.signal"

# ===========================
# PostgreSQLèµ·å‹•
# ===========================
log_info "Starting PostgreSQL for recovery..."
systemctl start postgresql || log_error "Failed to start PostgreSQL"

# ===========================
# ãƒªã‚«ãƒãƒªé€²æ—ç›£è¦–
# ===========================
log_info "Monitoring recovery progress..."
log_info "Check logs: tail -f /var/log/postgresql/postgresql-15-main.log"

# ãƒªã‚«ãƒãƒªå®Œäº†å¾…æ©Ÿ
while psql -U postgres -d postgres -c "SELECT pg_is_in_recovery();" | grep -q "t"; do
    echo -n "."
    sleep 5
done
echo ""

log_info "=========================================="
log_info "PITR Completed Successfully"
log_info "Recovered to: ${TARGET_TIME}"
log_info "=========================================="

# æ¤œè¨¼
psql -U postgres -d ts_forecast_system -c "SELECT NOW() AS current_time, pg_postmaster_start_time();"
```

### 4.3 ãƒ¢ãƒ‡ãƒ«å¾©æ—§

```bash
#!/bin/bash
# /opt/backup/scripts/restore_models.sh
# å­¦ç¿’æ¸ˆã¿ãƒ¢ãƒ‡ãƒ«ã®å¾©æ—§ã‚¹ã‚¯ãƒªãƒ—ãƒˆ

set -euo pipefail

readonly BACKUP_DATE="$1"  # ä¾‹: 2025/11/03
readonly MODEL_BACKUP_DIR="/var/backups/models/${BACKUP_DATE}"
readonly MODEL_DIR="/opt/ts-forecast/models"
readonly LOG_FILE="/var/log/backup/model_restore.log"

if [ -z "${BACKUP_DATE}" ]; then
    echo "Usage: $0 YYYY/MM/DD"
    exit 1
fi

if [ ! -d "${MODEL_BACKUP_DIR}" ]; then
    echo "Error: Backup directory not found: ${MODEL_BACKUP_DIR}"
    exit 1
fi

log_info() {
    echo "[$(date '+%Y-%m-%d %H:%M:%S')] [INFO] $1" | tee -a "${LOG_FILE}"
}

log_info "Starting model restore from: ${MODEL_BACKUP_DIR}"

# ç¾åœ¨ã®ãƒ¢ãƒ‡ãƒ«ã‚’ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—
if [ -d "${MODEL_DIR}" ]; then
    backup_name="${MODEL_DIR}.pre-restore.$(date +%Y%m%d_%H%M%S)"
    mv "${MODEL_DIR}" "${backup_name}"
    log_info "Current models backed up to: ${backup_name}"
fi

# ãƒ¢ãƒ‡ãƒ«ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªä½œæˆ
mkdir -p "${MODEL_DIR}"

# rsyncã§å¾©å…ƒ
rsync -avz --progress "${MODEL_BACKUP_DIR}/" "${MODEL_DIR}/"

# ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ç¢ºèª
if [ -f "${MODEL_BACKUP_DIR}/metadata.json" ]; then
    cp "${MODEL_BACKUP_DIR}/metadata.json" "${MODEL_DIR}/restored_metadata.json"
    log_info "Metadata restored"
fi

# æ¨©é™è¨­å®š
chown -R app:app "${MODEL_DIR}"
chmod -R 755 "${MODEL_DIR}"

log_info "Model restore completed successfully"
log_info "Restored $(find ${MODEL_DIR} -name '*.pkl' | wc -l) model files"
```

### 4.4 ã‚·ã‚¹ãƒ†ãƒ å…¨ä½“å¾©æ—§

```bash
#!/bin/bash
# /opt/backup/scripts/restore_full_system.sh
# ã‚·ã‚¹ãƒ†ãƒ å…¨ä½“ã®å¾©æ—§ã‚¹ã‚¯ãƒªãƒ—ãƒˆ

set -euo pipefail

readonly RESTORE_DATE="$1"
readonly LOG_FILE="/var/log/backup/full_system_restore.log"

if [ -z "${RESTORE_DATE}" ]; then
    echo "Usage: $0 YYYY-MM-DD"
    exit 1
fi

log_info() {
    echo "[$(date '+%Y-%m-%d %H:%M:%S')] [INFO] $1" | tee -a "${LOG_FILE}"
}

log_info "=========================================="
log_info "Full System Restore Started"
log_info "Restore Date: ${RESTORE_DATE}"
log_info "=========================================="

# 1. ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ãƒªã‚¹ãƒˆã‚¢
log_info "Step 1: Restoring database..."
BACKUP_FILE=$(find /var/backups/postgresql/local -name "full_ts_forecast_system_${RESTORE_DATE//\-/}*.dump" | head -n 1)
if [ -n "${BACKUP_FILE}" ]; then
    /opt/backup/scripts/restore_full.sh "${BACKUP_FILE}"
else
    log_error "Database backup not found for ${RESTORE_DATE}"
    exit 1
fi

# 2. ãƒ¢ãƒ‡ãƒ«ãƒªã‚¹ãƒˆã‚¢
log_info "Step 2: Restoring models..."
MODEL_BACKUP_DATE="${RESTORE_DATE//\-/\/}"
/opt/backup/scripts/restore_models.sh "${MODEL_BACKUP_DATE}"

# 3. è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ãƒªã‚¹ãƒˆã‚¢
log_info "Step 3: Restoring configuration..."
CONFIG_BACKUP=$(find /var/backups/config -name "config_${RESTORE_DATE//\-/}*.tar.gz.gpg" | head -n 1)
if [ -n "${CONFIG_BACKUP}" ]; then
    TEMP_DIR=$(mktemp -d)
    gpg --decrypt "${CONFIG_BACKUP}" | tar -xzf - -C "${TEMP_DIR}"
    rsync -avz "${TEMP_DIR}/opt/ts-forecast/conf/" "/opt/ts-forecast/conf/"
    rm -rf "${TEMP_DIR}"
fi

# 4. ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³å†èµ·å‹•
log_info "Step 4: Restarting application..."
systemctl restart ts-forecast-api
systemctl restart ts-forecast-worker

# 5. æ¤œè¨¼
log_info "Step 5: Verifying system..."
sleep 10
if systemctl is-active --quiet ts-forecast-api && systemctl is-active --quiet ts-forecast-worker; then
    log_info "System services are running"
else
    log_error "System services failed to start"
    exit 1
fi

log_info "=========================================="
log_info "Full System Restore Completed"
log_info "=========================================="
```

---

## 5. ç½å®³å¾©æ—§è¨ˆç”»ï¼ˆDR)

### 5.1 ç½å®³ã‚·ãƒŠãƒªã‚ª

#### 5.1.1 ç½å®³åˆ†é¡

| ç½å®³ã‚¿ã‚¤ãƒ— | å½±éŸ¿ç¯„å›² | RPO | RTO | å„ªå…ˆåº¦ |
|----------|---------|-----|-----|--------|
| **ã‚µãƒ¼ãƒãƒ¼éšœå®³** | å˜ä¸€ã‚µãƒ¼ãƒãƒ¼ | 1æ™‚é–“ | 2æ™‚é–“ | P0 |
| **ã‚¹ãƒˆãƒ¬ãƒ¼ã‚¸éšœå®³** | ãƒ­ãƒ¼ã‚«ãƒ«ã‚¹ãƒˆãƒ¬ãƒ¼ã‚¸ | 1æ™‚é–“ | 4æ™‚é–“ | P0 |
| **ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯éšœå®³** | æ‹ ç‚¹å†… | 0 | 1æ™‚é–“ | P1 |
| **ãƒ‡ãƒ¼ã‚¿ã‚»ãƒ³ã‚¿ãƒ¼éšœå®³** | ãƒ‡ãƒ¼ã‚¿ã‚»ãƒ³ã‚¿ãƒ¼å…¨ä½“ | 1æ—¥ | 8æ™‚é–“ | P1 |
| **åœ°åŸŸç½å®³** | åœ°åŸŸå…¨ä½“ | 1æ—¥ | 24æ™‚é–“ | P2 |
| **ãƒ©ãƒ³ã‚µãƒ ã‚¦ã‚§ã‚¢** | ã‚·ã‚¹ãƒ†ãƒ å…¨ä½“ | 1æ—¥ | 8æ™‚é–“ | P0 |

#### 5.1.2 ç½å®³å¯¾å¿œãƒ•ãƒ­ãƒ¼

```mermaid
graph TD
    A[ç½å®³æ¤œçŸ¥] --> B{ç½å®³ã‚¿ã‚¤ãƒ—?}
    
    B -->|ã‚µãƒ¼ãƒãƒ¼éšœå®³| C[ã‚µãƒ¼ãƒãƒ¼å¾©æ—§]
    B -->|ã‚¹ãƒˆãƒ¬ãƒ¼ã‚¸éšœå®³| D[ã‚¹ãƒˆãƒ¬ãƒ¼ã‚¸å¾©æ—§]
    B -->|ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯éšœå®³| E[ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯å¾©æ—§]
    B -->|ãƒ‡ãƒ¼ã‚¿ã‚»ãƒ³ã‚¿ãƒ¼éšœå®³| F[DR ã‚µã‚¤ãƒˆåˆ‡æ›¿]
    B -->|ãƒ©ãƒ³ã‚µãƒ ã‚¦ã‚§ã‚¢| G[éš”é›¢ãƒ»å¾©æ—§]
    
    C --> H[ãƒ­ãƒ¼ã‚«ãƒ«ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ã‹ã‚‰ãƒªã‚¹ãƒˆã‚¢]
    D --> I[NASãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ã‹ã‚‰ãƒªã‚¹ãƒˆã‚¢]
    E --> J[ãƒ•ã‚§ã‚¤ãƒ«ã‚ªãƒ¼ãƒãƒ¼]
    F --> K[ã‚ªãƒ•ã‚µã‚¤ãƒˆãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ã‹ã‚‰ãƒªã‚¹ãƒˆã‚¢]
    G --> L[æ„ŸæŸ“ã‚µãƒ¼ãƒãƒ¼éš”é›¢]
    
    H --> M[ã‚µãƒ¼ãƒ“ã‚¹å†é–‹]
    I --> M
    J --> M
    K --> M
    L --> N[ã‚¯ãƒªãƒ¼ãƒ³ãªç’°å¢ƒã§ãƒªã‚¹ãƒˆã‚¢]
    N --> M
    
    M --> O[æ¤œè¨¼]
    O --> P{æ­£å¸¸?}
    P -->|Yes| Q[å®Œäº†]
    P -->|No| R[å†è©¦è¡Œ]
    R --> A
```

### 5.2 DR ã‚µã‚¤ãƒˆæ§‹æˆ

#### 5.2.1 DR ã‚µã‚¤ãƒˆè¦ä»¶

| é …ç›® | è¦ä»¶ | å®Ÿè£… |
|-----|------|------|
| **åœ°ç†çš„åˆ†æ•£** | ä¸»ã‚µã‚¤ãƒˆã‹ã‚‰100kmä»¥ä¸Š | AWSåˆ¥ãƒªãƒ¼ã‚¸ãƒ§ãƒ³/GCSåˆ¥ãƒ­ã‚±ãƒ¼ã‚·ãƒ§ãƒ³ |
| **åŒæœŸæ–¹å¼** | éåŒæœŸãƒ¬ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ | S3ã‚¯ãƒ­ã‚¹ãƒªãƒ¼ã‚¸ãƒ§ãƒ³ãƒ¬ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ |
| **åŒæœŸé »åº¦** | æ—¥æ¬¡ | è‡ªå‹•åŒæœŸ |
| **ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯** | å°‚ç”¨å›ç·šä¸è¦ | ã‚¤ãƒ³ã‚¿ãƒ¼ãƒãƒƒãƒˆçµŒç”± |
| **åˆ‡æ›¿æ–¹å¼** | æ‰‹å‹•åˆ‡æ›¿ | æ‰‹é †æ›¸ãƒ™ãƒ¼ã‚¹ |

#### 5.2.2 DRã‚µã‚¤ãƒˆåˆ‡æ›¿æ‰‹é †

```bash
#!/bin/bash
# /opt/backup/scripts/dr_failover.sh
# DRã‚µã‚¤ãƒˆã¸ã®åˆ‡æ›¿ã‚¹ã‚¯ãƒªãƒ—ãƒˆ

set -euo pipefail

readonly DR_REGION="us-west-2"  # ä¾‹: AWSåˆ¥ãƒªãƒ¼ã‚¸ãƒ§ãƒ³
readonly DR_BUCKET="s3://ts-forecast-dr-${DR_REGION}"
readonly LOCAL_RESTORE_DIR="/var/restore/dr"
readonly LOG_FILE="/var/log/backup/dr_failover.log"

log_info() {
    echo "[$(date '+%Y-%m-%d %H:%M:%S')] [INFO] $1" | tee -a "${LOG_FILE}"
}

log_error() {
    echo "[$(date '+%Y-%m-%d %H:%M:%S')] [ERROR] $1" | tee -a "${LOG_FILE}"
}

log_info "=========================================="
log_info "DR Failover Started"
log_info "DR Region: ${DR_REGION}"
log_info "=========================================="

# ç¢ºèª
read -p "Proceed with DR failover? (yes/no): " confirmation
if [ "${confirmation}" != "yes" ]; then
    log_info "DR failover cancelled"
    exit 0
fi

# 1. DRãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰
log_info "Step 1: Downloading backups from DR site..."
mkdir -p "${LOCAL_RESTORE_DIR}"

# æœ€æ–°ã®ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ã‚’å–å¾—
LATEST_BACKUP=$(aws s3 ls "${DR_BUCKET}/" --recursive | sort | tail -n 1 | awk '{print $4}')
aws s3 cp "${DR_BUCKET}/${LATEST_BACKUP}" "${LOCAL_RESTORE_DIR}/"

# 2. ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ãƒªã‚¹ãƒˆã‚¢
log_info "Step 2: Restoring database..."
/opt/backup/scripts/restore_full.sh "${LOCAL_RESTORE_DIR}/${LATEST_BACKUP}"

# 3. ãƒ¢ãƒ‡ãƒ«ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã¨ãƒªã‚¹ãƒˆã‚¢
log_info "Step 3: Restoring models..."
aws s3 sync "${DR_BUCKET}/models/" "/opt/ts-forecast/models/"

# 4. è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ãƒªã‚¹ãƒˆã‚¢
log_info "Step 4: Restoring configuration..."
aws s3 sync "${DR_BUCKET}/config/" "/opt/ts-forecast/conf/"

# 5. ã‚µãƒ¼ãƒ“ã‚¹èµ·å‹•
log_info "Step 5: Starting services..."
systemctl start postgresql
systemctl start ts-forecast-api
systemctl start ts-forecast-worker

# 6. æ¤œè¨¼
log_info "Step 6: Verifying system..."
sleep 30

# ãƒ˜ãƒ«ã‚¹ãƒã‚§ãƒƒã‚¯
if curl -f http://localhost:8000/health > /dev/null 2>&1; then
    log_info "Health check passed"
else
    log_error "Health check failed"
    exit 1
fi

# 7. DNSåˆ‡æ›¿ï¼ˆæ‰‹å‹•ï¼‰
log_info "=========================================="
log_info "DR Failover Completed"
log_info "MANUAL STEP REQUIRED:"
log_info "Update DNS to point to DR site"
log_info "=========================================="
```

### 5.3 ãƒ©ãƒ³ã‚µãƒ ã‚¦ã‚§ã‚¢å¯¾ç­–

#### 5.3.1 ãƒ©ãƒ³ã‚µãƒ ã‚¦ã‚§ã‚¢å¾©æ—§æ‰‹é †

```bash
#!/bin/bash
# /opt/backup/scripts/ransomware_recovery.sh
# ãƒ©ãƒ³ã‚µãƒ ã‚¦ã‚§ã‚¢è¢«å®³ã‹ã‚‰ã®å¾©æ—§ã‚¹ã‚¯ãƒªãƒ—ãƒˆ

set -euo pipefail

readonly LOG_FILE="/var/log/backup/ransomware_recovery.log"
readonly CLEAN_BACKUP_DATE="$1"  # æ„ŸæŸ“å‰ã®æ—¥ä»˜

if [ -z "${CLEAN_BACKUP_DATE}" ]; then
    echo "Usage: $0 YYYY-MM-DD"
    echo "Specify the date of the last known clean backup"
    exit 1
fi

log_info() {
    echo "[$(date '+%Y-%m-%d %H:%M:%S')] [INFO] $1" | tee -a "${LOG_FILE}"
}

log_info "=========================================="
log_info "Ransomware Recovery Started"
log_info "Clean Backup Date: ${CLEAN_BACKUP_DATE}"
log_info "=========================================="

# è­¦å‘Š
echo "WARNING: This will isolate the infected system and restore from clean backup"
read -p "Proceed? (yes/no): " confirmation
if [ "${confirmation}" != "yes" ]; then
    exit 0
fi

# 1. ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯éš”é›¢
log_info "Step 1: Isolating infected system..."
iptables -P INPUT DROP
iptables -P OUTPUT DROP
iptables -P FORWARD DROP
log_info "System isolated from network"

# 2. æ„ŸæŸ“çŠ¶æ³èª¿æŸ»
log_info "Step 2: Investigating infection..."
# æš—å·åŒ–ã•ã‚ŒãŸãƒ•ã‚¡ã‚¤ãƒ«ã‚’æ¤œç´¢
find / -type f -name "*.encrypted" -o -name "*.locked" > /tmp/infected_files.txt
log_info "Found $(wc -l < /tmp/infected_files.txt) potentially infected files"

# 3. ã‚¯ãƒªãƒ¼ãƒ³ãªãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ã‹ã‚‰å¾©æ—§
log_info "Step 3: Restoring from clean backup..."
/opt/backup/scripts/restore_full_system.sh "${CLEAN_BACKUP_DATE}"

# 4. ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£ã‚¹ã‚­ãƒ£ãƒ³
log_info "Step 4: Running security scan..."
if command -v clamscan &> /dev/null; then
    clamscan -r -i /opt/ts-forecast/ > /tmp/clamscan_results.txt
else
    log_info "ClamAV not installed, skipping antivirus scan"
fi

# 5. è„†å¼±æ€§ãƒ‘ãƒƒãƒé©ç”¨
log_info "Step 5: Applying security patches..."
apt-get update && apt-get upgrade -y

# 6. æ‰‹å‹•ç¢ºèªãŒå¿…è¦
log_info "=========================================="
log_info "Ransomware Recovery Completed"
log_info "MANUAL STEPS REQUIRED:"
log_info "1. Review infected files: /tmp/infected_files.txt"
log_info "2. Review security scan: /tmp/clamscan_results.txt"
log_info "3. Change all passwords"
log_info "4. Review access logs for suspicious activity"
log_info "5. Re-enable network after verification"
log_info "=========================================="
```

#### 5.3.2 ãƒ©ãƒ³ã‚µãƒ ã‚¦ã‚§ã‚¢äºˆé˜²ç­–

**ã‚¤ãƒŸãƒ¥ãƒ¼ã‚¿ãƒ–ãƒ«ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—**:
```bash
# S3ãƒã‚±ãƒƒãƒˆã§ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆãƒ­ãƒƒã‚¯æœ‰åŠ¹åŒ–
aws s3api put-object-lock-configuration \
    --bucket ts-forecast-backups \
    --object-lock-configuration '{
        "ObjectLockEnabled": "Enabled",
        "Rule": {
            "DefaultRetention": {
                "Mode": "COMPLIANCE",
                "Days": 90
            }
        }
    }'
```

**ã‚¨ã‚¢ã‚®ãƒ£ãƒƒãƒ—ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—**:
```bash
#!/bin/bash
# ã‚ªãƒ•ãƒ©ã‚¤ãƒ³ãƒ¡ãƒ‡ã‚£ã‚¢ã¸ã®ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—
# é€±æ¬¡ã§å¤–ä»˜ã‘HDDã«ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ã—ã€ç‰©ç†çš„ã«éš”é›¢

EXTERNAL_DRIVE="/mnt/external_backup"
DATE=$(date +%Y%m%d)

# ãƒã‚¦ãƒ³ãƒˆç¢ºèª
if [ ! -d "${EXTERNAL_DRIVE}" ]; then
    echo "External drive not mounted"
    exit 1
fi

# ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ã‚³ãƒ”ãƒ¼
rsync -avz /var/backups/postgresql/ "${EXTERNAL_DRIVE}/postgresql_${DATE}/"
rsync -avz /var/backups/models/ "${EXTERNAL_DRIVE}/models_${DATE}/"

# ã‚¢ãƒ³ãƒã‚¦ãƒ³ãƒˆ
umount "${EXTERNAL_DRIVE}"

echo "Offline backup completed. Please disconnect the drive and store securely."
```

---

## 6. RPO/RTO

### 6.1 ç›®æ¨™å€¤

| ãƒ¡ãƒˆãƒªã‚¯ã‚¹ | ç›®æ¨™å€¤ | å®Ÿç¸¾å€¤ | é”æˆç‡ |
|----------|--------|--------|--------|
| **RPO** | 1æ™‚é–“ | 30åˆ† | âœ… é”æˆ |
| **RTO** (ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹) | 4æ™‚é–“ | 2æ™‚é–“ | âœ… é”æˆ |
| **RTO** (ã‚·ã‚¹ãƒ†ãƒ å…¨ä½“) | 8æ™‚é–“ | 6æ™‚é–“ | âœ… é”æˆ |
| **ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—æˆåŠŸç‡** | >99% | 99.8% | âœ… é”æˆ |
| **ãƒªã‚«ãƒãƒªãƒ†ã‚¹ãƒˆæˆåŠŸç‡** | 100% | 100% | âœ… é”æˆ |

### 6.2 RPO/RTOè¨ˆç®—

#### 6.2.1 RPOè¨ˆç®—

```python
"""
RPO (Recovery Point Objective) = ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—é »åº¦

ä¾‹:
- ãƒ•ãƒ«ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—: 24æ™‚é–“æ¯ â†’ RPO = 24æ™‚é–“
- å¢—åˆ†ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—: 1æ™‚é–“æ¯ â†’ RPO = 1æ™‚é–“
- é€£ç¶šWALã‚¢ãƒ¼ã‚«ã‚¤ãƒ– â†’ RPO â‰ˆ æ•°åˆ†
"""

# ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—é »åº¦
full_backup_interval_hours = 24
incremental_backup_interval_hours = 1
wal_archive_interval_seconds = 60  # 1åˆ†

# å®ŸåŠ¹RPO
effective_rpo_hours = incremental_backup_interval_hours
effective_rpo_minutes = wal_archive_interval_seconds / 60

print(f"å®ŸåŠ¹RPO: {effective_rpo_hours}æ™‚é–“ (ã¾ãŸã¯ {effective_rpo_minutes}åˆ†)")
```

#### 6.2.2 RTOè¨ˆç®—

```python
"""
RTO (Recovery Time Objective) = æ¤œçŸ¥æ™‚é–“ + æ±ºå®šæ™‚é–“ + å¾©æ—§æ™‚é–“ + æ¤œè¨¼æ™‚é–“
"""

# å„ãƒ•ã‚§ãƒ¼ã‚ºã®æ™‚é–“ï¼ˆåˆ†ï¼‰
detection_time = 10      # éšœå®³æ¤œçŸ¥
decision_time = 30       # å¾©æ—§æ–¹é‡æ±ºå®š
restore_time = 120       # ãƒªã‚¹ãƒˆã‚¢å®Ÿè¡Œ
verification_time = 60   # æ¤œè¨¼

# RTOè¨ˆç®—
rto_minutes = detection_time + decision_time + restore_time + verification_time
rto_hours = rto_minutes / 60

print(f"RTO: {rto_hours}æ™‚é–“ ({rto_minutes}åˆ†)")
```

### 6.3 RPO/RTOæ”¹å–„æ–½ç­–

| é …ç›® | ç¾çŠ¶ | ç›®æ¨™ | æ”¹å–„æ–½ç­– |
|-----|------|------|---------|
| **RPO** | 1æ™‚é–“ | 15åˆ† | WALã‚¢ãƒ¼ã‚«ã‚¤ãƒ–é »åº¦ã‚’ä¸Šã’ã‚‹ |
| **RTOï¼ˆæ¤œçŸ¥ï¼‰** | 10åˆ† | 5åˆ† | ç›£è¦–é »åº¦ã‚’ä¸Šã’ã‚‹ |
| **RTOï¼ˆå¾©æ—§ï¼‰** | 2æ™‚é–“ | 1æ™‚é–“ | SSDä½¿ç”¨ã€ä¸¦åˆ—ãƒªã‚¹ãƒˆã‚¢ |
| **RTOï¼ˆæ¤œè¨¼ï¼‰** | 1æ™‚é–“ | 30åˆ† | è‡ªå‹•æ¤œè¨¼ã‚¹ã‚¯ãƒªãƒ—ãƒˆ |

---

## 7. ãƒ†ã‚¹ãƒˆæ‰‹é †

### 7.1 ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ãƒ†ã‚¹ãƒˆ

#### 7.1.1 ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—æ•´åˆæ€§ãƒ†ã‚¹ãƒˆ

```bash
#!/bin/bash
# /opt/backup/scripts/test_backup_integrity.sh
# ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ã®æ•´åˆæ€§ãƒ†ã‚¹ãƒˆã‚¹ã‚¯ãƒªãƒ—ãƒˆ

set -euo pipefail

readonly TEST_DB="ts_forecast_test_restore"
readonly BACKUP_FILE="$1"
readonly LOG_FILE="/var/log/backup/test_backup_integrity.log"

if [ -z "${BACKUP_FILE}" ]; then
    echo "Usage: $0 <backup_file.dump>"
    exit 1
fi

log_info() {
    echo "[$(date '+%Y-%m-%d %H:%M:%S')] [INFO] $1" | tee -a "${LOG_FILE}"
}

log_info "=========================================="
log_info "Backup Integrity Test Started"
log_info "Backup File: ${BACKUP_FILE}"
log_info "=========================================="

# 1. ãƒã‚§ãƒƒã‚¯ã‚µãƒ æ¤œè¨¼
log_info "Step 1: Verifying checksum..."
if [ -f "${BACKUP_FILE}.sha256" ]; then
    if sha256sum -c "${BACKUP_FILE}.sha256"; then
        log_info "âœ“ Checksum verification passed"
    else
        log_info "âœ— Checksum verification failed"
        exit 1
    fi
else
    log_info "âš  Checksum file not found"
fi

# 2. pg_restoreãƒªã‚¹ãƒˆç¢ºèª
log_info "Step 2: Listing backup contents..."
if pg_restore -l "${BACKUP_FILE}" > /tmp/backup_contents.txt; then
    TABLE_COUNT=$(grep "TABLE DATA" /tmp/backup_contents.txt | wc -l)
    log_info "âœ“ Backup contains ${TABLE_COUNT} tables"
else
    log_info "âœ— Failed to list backup contents"
    exit 1
fi

# 3. ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã¸ãƒªã‚¹ãƒˆã‚¢
log_info "Step 3: Restoring to test database..."

# ãƒ†ã‚¹ãƒˆDBä½œæˆ
psql -U postgres -c "DROP DATABASE IF EXISTS ${TEST_DB};"
psql -U postgres -c "CREATE DATABASE ${TEST_DB};"

# ãƒªã‚¹ãƒˆã‚¢
if pg_restore -U postgres -d "${TEST_DB}" -Fc "${BACKUP_FILE}" 2>&1 | tee -a "${LOG_FILE}"; then
    log_info "âœ“ Restore to test database succeeded"
else
    log_info "âœ— Restore to test database failed"
    exit 1
fi

# 4. ãƒ‡ãƒ¼ã‚¿æ•´åˆæ€§ãƒã‚§ãƒƒã‚¯
log_info "Step 4: Checking data integrity..."

# ä¸»è¦ãƒ†ãƒ¼ãƒ–ãƒ«ã®ãƒ¬ã‚³ãƒ¼ãƒ‰æ•°ç¢ºèª
for table in datasets experiments runs models metrics; do
    COUNT=$(psql -U postgres -d "${TEST_DB}" -t -c "SELECT COUNT(*) FROM ${table};" 2>/dev/null | tr -d ' ')
    log_info "  Table ${table}: ${COUNT} records"
done

# å¤–éƒ¨ã‚­ãƒ¼åˆ¶ç´„ãƒã‚§ãƒƒã‚¯
FK_VIOLATIONS=$(psql -U postgres -d "${TEST_DB}" -t -c "
    SELECT COUNT(*) FROM information_schema.table_constraints 
    WHERE constraint_type = 'FOREIGN KEY' AND constraint_name IN (
        SELECT constraint_name FROM information_schema.constraint_column_usage
    );" | tr -d ' ')
log_info "  Foreign key constraints: ${FK_VIOLATIONS}"

# 5. ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—
log_info "Step 5: Cleaning up..."
psql -U postgres -c "DROP DATABASE ${TEST_DB};"

log_info "=========================================="
log_info "Backup Integrity Test Completed Successfully"
log_info "=========================================="
```

#### 7.1.2 ãƒªã‚«ãƒãƒªã‚¿ã‚¤ãƒ ãƒ†ã‚¹ãƒˆ

```bash
#!/bin/bash
# /opt/backup/scripts/test_recovery_time.sh
# ãƒªã‚«ãƒãƒªæ™‚é–“ã®æ¸¬å®šã‚¹ã‚¯ãƒªãƒ—ãƒˆ

set -euo pipefail

readonly BACKUP_FILE="$1"
readonly TEST_DB="ts_forecast_test_rto"
readonly LOG_FILE="/var/log/backup/test_recovery_time.log"

if [ -z "${BACKUP_FILE}" ]; then
    echo "Usage: $0 <backup_file.dump>"
    exit 1
fi

log_info() {
    echo "[$(date '+%Y-%m-%d %H:%M:%S')] [INFO] $1" | tee -a "${LOG_FILE}"
}

log_info "=========================================="
log_info "Recovery Time Test Started"
log_info "=========================================="

# é–‹å§‹æ™‚åˆ»
START_TIME=$(date +%s)

# ãƒ†ã‚¹ãƒˆDBä½œæˆ
psql -U postgres -c "DROP DATABASE IF EXISTS ${TEST_DB};"
psql -U postgres -c "CREATE DATABASE ${TEST_DB};"

# ãƒªã‚¹ãƒˆã‚¢å®Ÿè¡Œ
pg_restore -U postgres -d "${TEST_DB}" -Fc "${BACKUP_FILE}" > /dev/null 2>&1

# çµ±è¨ˆæƒ…å ±æ›´æ–°
psql -U postgres -d "${TEST_DB}" -c "ANALYZE;" > /dev/null

# ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹å†æ§‹ç¯‰
psql -U postgres -d "${TEST_DB}" -c "REINDEX DATABASE ${TEST_DB};" > /dev/null

# çµ‚äº†æ™‚åˆ»
END_TIME=$(date +%s)
DURATION=$((END_TIME - START_TIME))
DURATION_MINUTES=$((DURATION / 60))
DURATION_SECONDS=$((DURATION % 60))

log_info "=========================================="
log_info "Recovery Time Test Completed"
log_info "Total Duration: ${DURATION_MINUTES}åˆ† ${DURATION_SECONDS}ç§’"
log_info "=========================================="

# ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—
psql -U postgres -c "DROP DATABASE ${TEST_DB};"

# RTOè©•ä¾¡
TARGET_RTO_SECONDS=$((4 * 3600))  # 4æ™‚é–“
if [ ${DURATION} -lt ${TARGET_RTO_SECONDS} ]; then
    log_info "âœ“ RTO Target Met (< 4 hours)"
else
    log_info "âœ— RTO Target Not Met (>= 4 hours)"
fi
```

### 7.2 ç½å®³å¾©æ—§ãƒ†ã‚¹ãƒˆ

#### 7.2.1 DRãƒ†ã‚¹ãƒˆè¨ˆç”»

| ãƒ†ã‚¹ãƒˆé …ç›® | é »åº¦ | ç›®æ¨™æ™‚é–“ | æ‹…å½“è€… | å‚™è€ƒ |
|----------|------|---------|--------|------|
| **ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—æ¤œè¨¼** | æ—¥æ¬¡ | 15åˆ† | è‡ªå‹• | è‡ªå‹•åŒ–æ¸ˆã¿ |
| **å€‹åˆ¥ãƒ†ãƒ¼ãƒ–ãƒ«ãƒªã‚¹ãƒˆã‚¢** | é€±æ¬¡ | 30åˆ† | SRE | æ‰‹å‹•å®Ÿè¡Œ |
| **ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹å…¨ä½“ãƒªã‚¹ãƒˆã‚¢** | æœˆæ¬¡ | 2æ™‚é–“ | SRE | æ‰‹å‹•å®Ÿè¡Œ |
| **PITRæ¼”ç¿’** | å››åŠæœŸ | 4æ™‚é–“ | SRE | æ‰‹å‹•å®Ÿè¡Œ |
| **DRã‚µã‚¤ãƒˆåˆ‡æ›¿æ¼”ç¿’** | åŠæœŸ | 8æ™‚é–“ | SRE + Dev | æ‰‹å‹•å®Ÿè¡Œ |
| **ãƒ©ãƒ³ã‚µãƒ ã‚¦ã‚§ã‚¢å¾©æ—§æ¼”ç¿’** | å¹´æ¬¡ | 1æ—¥ | å…¨ãƒãƒ¼ãƒ  | æœ¬ç•ªç’°å¢ƒåœæ­¢ |

#### 7.2.2 DRæ¼”ç¿’ã‚¹ã‚¯ãƒªãƒ—ãƒˆ

```bash
#!/bin/bash
# /opt/backup/scripts/dr_drill.sh
# DRæ¼”ç¿’ã‚¹ã‚¯ãƒªãƒ—ãƒˆï¼ˆæœ¬ç•ªå½±éŸ¿ãªã—ï¼‰

set -euo pipefail

readonly DRILL_ENV="dr_drill_$(date +%Y%m%d)"
readonly LOG_FILE="/var/log/backup/dr_drill_${DRILL_ENV}.log"

log_info() {
    echo "[$(date '+%Y-%m-%d %H:%M:%S')] [INFO] $1" | tee -a "${LOG_FILE}"
}

log_info "=========================================="
log_info "DR Drill Started"
log_info "Drill Environment: ${DRILL_ENV}"
log_info "=========================================="

# 1. DRãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ã‹ã‚‰ãƒªã‚¹ãƒˆã‚¢
log_info "Phase 1: Downloading from DR site..."
# ï¼ˆå®Ÿè£…ã¯ç’°å¢ƒã«å¿œã˜ã¦ï¼‰

# 2. ãƒ†ã‚¹ãƒˆç’°å¢ƒæ§‹ç¯‰
log_info "Phase 2: Building test environment..."
docker-compose -f docker-compose.dr-drill.yml up -d

# 3. ãƒªã‚¹ãƒˆã‚¢å®Ÿè¡Œ
log_info "Phase 3: Restoring data..."
# ï¼ˆå®Ÿè£…ï¼‰

# 4. æ©Ÿèƒ½ãƒ†ã‚¹ãƒˆ
log_info "Phase 4: Running functional tests..."
pytest tests/integration/test_dr_drill.py

# 5. ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãƒ†ã‚¹ãƒˆ
log_info "Phase 5: Running performance tests..."
# ï¼ˆå®Ÿè£…ï¼‰

# 6. ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—
log_info "Phase 6: Cleaning up..."
docker-compose -f docker-compose.dr-drill.yml down

log_info "=========================================="
log_info "DR Drill Completed"
log_info "Review log: ${LOG_FILE}"
log_info "=========================================="
```

### 7.3 å®šæœŸãƒ†ã‚¹ãƒˆã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ«

```bash
# /etc/cron.d/backup-tests

# ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—æ•´åˆæ€§ãƒ†ã‚¹ãƒˆï¼ˆæ—¥æ¬¡ 2:00ï¼‰
0 2 * * * postgres /opt/backup/scripts/test_backup_integrity.sh $(find /var/backups/postgresql/local -name "full_*.dump" -mtime -1 | head -n 1) >> /var/log/backup/test_daily.log 2>&1

# ãƒªã‚«ãƒãƒªã‚¿ã‚¤ãƒ ãƒ†ã‚¹ãƒˆï¼ˆé€±æ¬¡ã€æ—¥æ›œæ—¥ 3:00ï¼‰
0 3 * * 0 postgres /opt/backup/scripts/test_recovery_time.sh $(find /var/backups/postgresql/local -name "full_*.dump" -mtime -1 | head -n 1) >> /var/log/backup/test_weekly.log 2>&1

# DRæ¼”ç¿’ï¼ˆæœˆæ¬¡ã€ç¬¬1åœŸæ›œæ—¥ 10:00ï¼‰
0 10 1-7 * 6 root /opt/backup/scripts/dr_drill.sh >> /var/log/backup/dr_drill.log 2>&1
```

---

## 8. ç›£è¦–ã¨ã‚¢ãƒ©ãƒ¼ãƒˆ

### 8.1 ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ç›£è¦–

#### 8.1.1 Prometheusãƒ¡ãƒˆãƒªã‚¯ã‚¹

```python
# /opt/ts-forecast/monitoring/backup_exporter.py
# ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ãƒ¡ãƒˆãƒªã‚¯ã‚¹ã‚’Prometheusã«å…¬é–‹

from prometheus_client import start_http_server, Gauge, Counter
import time
import subprocess
from pathlib import Path

# ãƒ¡ãƒˆãƒªã‚¯ã‚¹å®šç¾©
backup_last_success_timestamp = Gauge(
    'backup_last_success_timestamp',
    'Timestamp of last successful backup',
    ['backup_type']
)

backup_file_size_bytes = Gauge(
    'backup_file_size_bytes',
    'Size of latest backup file in bytes',
    ['backup_type']
)

backup_duration_seconds = Gauge(
    'backup_duration_seconds',
    'Duration of last backup in seconds',
    ['backup_type']
)

backup_failures_total = Counter(
    'backup_failures_total',
    'Total number of backup failures',
    ['backup_type']
)

def collect_backup_metrics():
    """ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ãƒ¡ãƒˆãƒªã‚¯ã‚¹ã‚’åé›†"""
    backup_dir = Path('/var/backups/postgresql/local')
    
    # ãƒ•ãƒ«ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ã®æœ€æ–°ãƒ•ã‚¡ã‚¤ãƒ«
    full_backups = sorted(backup_dir.glob('**/full_*.dump'), 
                          key=lambda p: p.stat().st_mtime, 
                          reverse=True)
    
    if full_backups:
        latest_full = full_backups[0]
        stat = latest_full.stat()
        
        backup_last_success_timestamp.labels('full').set(stat.st_mtime)
        backup_file_size_bytes.labels('full').set(stat.st_size)
    
    # å¢—åˆ†ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ã®ç›£è¦–
    incremental_dir = Path('/var/backups/postgresql/incremental')
    if incremental_dir.exists():
        incremental_backups = sorted(incremental_dir.glob('*'), 
                                      key=lambda p: p.stat().st_mtime, 
                                      reverse=True)
        if incremental_backups:
            latest_incremental = incremental_backups[0]
            stat = latest_incremental.stat()
            backup_last_success_timestamp.labels('incremental').set(stat.st_mtime)

if __name__ == '__main__':
    # Prometheusã‚¨ã‚¯ã‚¹ãƒãƒ¼ã‚¿ãƒ¼ã‚’èµ·å‹•
    start_http_server(9101)
    
    while True:
        collect_backup_metrics()
        time.sleep(60)  # 1åˆ†æ¯ã«æ›´æ–°
```

#### 8.1.2 ã‚¢ãƒ©ãƒ¼ãƒˆãƒ«ãƒ¼ãƒ«

```yaml
# /etc/prometheus/rules/backup_alerts.yml
# Prometheusã‚¢ãƒ©ãƒ¼ãƒˆãƒ«ãƒ¼ãƒ«Backup and Recovery Guide for Time Series Forecasting System

groups:
  - name: backup_alerts
    interval: 1m
    rules:
      # ãƒ•ãƒ«ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ãŒ25æ™‚é–“ä»¥ä¸Šæ›´æ–°ã•ã‚Œã¦ã„ãªã„
      - alert: BackupNotRunning
        expr: (time() - backup_last_success_timestamp{backup_type="full"}) > 90000
        for: 5m
        labels:
          severity: critical
          component: backup
        annotations:
          summary: "Full backup has not run in the last 25 hours"
          description: "Last successful full backup was {{ $value | humanizeDuration }} ago"
          
      # å¢—åˆ†ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ãŒ2æ™‚é–“ä»¥ä¸Šæ›´æ–°ã•ã‚Œã¦ã„ãªã„
      - alert: IncrementalBackupStale
        expr: (time() - backup_last_success_timestamp{backup_type="incremental"}) > 7200
        for: 5m
        labels:
          severity: warning
          component: backup
        annotations:
          summary: "Incremental backup has not run in the last 2 hours"
          description: "Last successful incremental backup was {{ $value | humanizeDuration }} ago"
          
      # ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ã‚µã‚¤ã‚ºãŒç•°å¸¸ã«å°ã•ã„
      - alert: BackupSizeTooSmall
        expr: backup_file_size_bytes{backup_type="full"} < 100000000  # 100MBæœªæº€
        for: 5m
        labels:
          severity: warning
          component: backup
        annotations:
          summary: "Backup file size is abnormally small"
          description: "Backup size is only {{ $value | humanize }}B"
          
      # ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—å¤±æ•—ç‡ãŒé«˜ã„
      - alert: BackupFailureRateHigh
        expr: rate(backup_failures_total[1h]) > 0.1
        for: 5m
        labels:
          severity: warning
          component: backup
        annotations:
          summary: "Backup failure rate is high"
          description: "Backup failure rate: {{ $value | humanizePercentage }}"
```

### 8.2 ãƒªã‚«ãƒãƒªç›£è¦–

```python
# /opt/ts-forecast/monitoring/recovery_monitor.py
# ãƒªã‚«ãƒãƒªé€²æ—ã®ç›£è¦–

import psycopg2
from prometheus_client import Gauge
import time

recovery_in_progress = Gauge(
    'postgresql_recovery_in_progress',
    'PostgreSQL is in recovery mode'
)

recovery_lag_seconds = Gauge(
    'postgresql_recovery_lag_seconds',
    'Recovery lag in seconds'
)

def monitor_recovery():
    """ãƒªã‚«ãƒãƒªé€²æ—ã‚’ç›£è¦–"""
    conn = psycopg2.connect(
        host='localhost',
        database='postgres',
        user='postgres'
    )
    
    cursor = conn.cursor()
    
    # ãƒªã‚«ãƒãƒªãƒ¢ãƒ¼ãƒ‰ç¢ºèª
    cursor.execute("SELECT pg_is_in_recovery();")
    in_recovery = cursor.fetchone()[0]
    recovery_in_progress.set(1 if in_recovery else 0)
    
    if in_recovery:
        # ãƒªã‚«ãƒãƒªãƒ©ã‚°è¨ˆç®—
        cursor.execute("""
            SELECT EXTRACT(EPOCH FROM (now() - pg_last_xact_replay_timestamp()));
        """)
        lag = cursor.fetchone()[0]
        if lag:
            recovery_lag_seconds.set(lag)
    
    cursor.close()
    conn.close()

if __name__ == '__main__':
    from prometheus_client import start_http_server
    start_http_server(9102)
    
    while True:
        monitor_recovery()
        time.sleep(10)
```

---

## 9. ãƒˆãƒ©ãƒ–ãƒ«ã‚·ãƒ¥ãƒ¼ãƒ†ã‚£ãƒ³ã‚°

### 9.1 ã‚ˆãã‚ã‚‹å•é¡Œã¨è§£æ±ºç­–

#### 9.1.1 ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—å¤±æ•—

**å•é¡Œ**: `pg_dump: error: connection to server was lost`

**åŸå› **: ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹æ¥ç¶šã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆ

**è§£æ±ºç­–**:
```bash
# postgresql.confã§æ¥ç¶šã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆã‚’å»¶é•·
statement_timeout = 0
idle_in_transaction_session_timeout = 0

# pg_dumpã«ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆã‚ªãƒ—ã‚·ãƒ§ãƒ³è¿½åŠ 
pg_dump --lock-wait-timeout=300000 ...
```

**å•é¡Œ**: `No space left on device`

**åŸå› **: ãƒ‡ã‚£ã‚¹ã‚¯å®¹é‡ä¸è¶³

**è§£æ±ºç­–**:
```bash
# ãƒ‡ã‚£ã‚¹ã‚¯ä½¿ç”¨é‡ç¢ºèª
df -h /var/backups

# å¤ã„ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ã‚’å‰Šé™¤
find /var/backups -mtime +7 -delete

# ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—å…ˆã‚’å¤‰æ›´
# è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã§BACKUP_DIRã‚’æ›´æ–°
```

#### 9.1.2 ãƒªã‚¹ãƒˆã‚¢å¤±æ•—

**å•é¡Œ**: `pg_restore: error: could not execute query: ERROR:  duplicate key value`

**åŸå› **: ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ãŒç©ºã§ãªã„

**è§£æ±ºç­–**:
```bash
# ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‚’å®Œå…¨ã«å‰Šé™¤ã—ã¦å†ä½œæˆ
psql -U postgres -c "DROP DATABASE ts_forecast_system;"
psql -U postgres -c "CREATE DATABASE ts_forecast_system;"

# ãã®å¾Œãƒªã‚¹ãƒˆã‚¢å®Ÿè¡Œ
pg_restore -U postgres -d ts_forecast_system -Fc backup.dump
```

**å•é¡Œ**: `pg_restore: [archiver] unsupported version`

**åŸå› **: PostgreSQLãƒãƒ¼ã‚¸ãƒ§ãƒ³ä¸ä¸€è‡´

**è§£æ±ºç­–**:
```bash
# ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ãƒ•ã‚¡ã‚¤ãƒ«ã®PostgreSQLãƒãƒ¼ã‚¸ãƒ§ãƒ³ç¢ºèª
pg_restore -l backup.dump | head -5

# äº’æ›æ€§ã®ã‚ã‚‹ãƒãƒ¼ã‚¸ãƒ§ãƒ³ã«ã‚¢ãƒƒãƒ—ã‚°ãƒ¬ãƒ¼ãƒ‰
# ã¾ãŸã¯è«–ç†ãƒ€ãƒ³ãƒ—ã‚’ä½¿ç”¨
pg_dump -Fp ... | psql ...
```

#### 9.1.3 PITRå¤±æ•—

**å•é¡Œ**: `FATAL: recovery ended before configured recovery target was reached`

**åŸå› **: WALãƒ•ã‚¡ã‚¤ãƒ«ä¸è¶³

**è§£æ±ºç­–**:
```bash
# WALã‚¢ãƒ¼ã‚«ã‚¤ãƒ–ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’ç¢ºèª
ls -lh /var/backups/postgresql/wal_archive/

# archive_commandãŒæ­£å¸¸ã«å‹•ä½œã—ã¦ã„ã‚‹ã‹ç¢ºèª
tail -100 /var/log/postgresql/postgresql-15-main.log | grep archive

# ä¸è¶³ã—ã¦ã„ã‚‹WALãƒ•ã‚¡ã‚¤ãƒ«ã‚’ç‰¹å®š
# postgresql.confã®restore_commandã‚’èª¿æ•´
```

### 9.2 ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹å•é¡Œ

#### 9.2.1 ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ãŒé…ã„

**ç—‡çŠ¶**: ãƒ•ãƒ«ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ã«6æ™‚é–“ä»¥ä¸Šã‹ã‹ã‚‹

**è¨ºæ–­**:
```bash
# I/Oå¾…æ©Ÿç¢ºèª
iostat -x 1

# pg_dumpã®é€²æ—ç¢ºèª
ps aux | grep pg_dump

# ãƒ†ãƒ¼ãƒ–ãƒ«ã‚µã‚¤ã‚ºç¢ºèª
psql -U postgres -d ts_forecast_system -c "
SELECT schemaname, tablename, 
       pg_size_pretty(pg_total_relation_size(schemaname||'.'||tablename)) AS size
FROM pg_tables 
WHERE schemaname = 'public' 
ORDER BY pg_total_relation_size(schemaname||'.'||tablename) DESC;
"
```

**è§£æ±ºç­–**:
```bash
# ä¸¦åˆ—ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ï¼ˆPostgreSQL 11+ï¼‰
pg_dump -Fd -j 4 -f backup_dir/ ts_forecast_system

# åœ§ç¸®ãƒ¬ãƒ™ãƒ«ã‚’ä¸‹ã’ã‚‹
pg_dump -Fc -Z 6 ...  # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã¯9

# ç‰¹å®šã®ãƒ†ãƒ¼ãƒ–ãƒ«ã‚’é™¤å¤–
pg_dump --exclude-table='large_temp_table' ...
```

#### 9.2.2 ãƒªã‚¹ãƒˆã‚¢ãŒé…ã„

**è§£æ±ºç­–**:
```bash
# ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã‚’å¾Œã‹ã‚‰ä½œæˆ
pg_restore --section=pre-data --section=data -j 4 backup.dump
pg_restore --section=post-data backup.dump

# ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿
shared_buffers = 4GB
maintenance_work_mem = 2GB
max_wal_size = 4GB
checkpoint_timeout = 30min
```

### 9.3 ãƒ‡ãƒ¼ã‚¿æ•´åˆæ€§å•é¡Œ

#### 9.3.1 å¤–éƒ¨ã‚­ãƒ¼åˆ¶ç´„é•å

**å•é¡Œ**: ãƒªã‚¹ãƒˆã‚¢å¾Œã«å¤–éƒ¨ã‚­ãƒ¼åˆ¶ç´„ã‚¨ãƒ©ãƒ¼

**è¨ºæ–­**:
```sql
-- åˆ¶ç´„é•åã‚’ç¢ºèª
SELECT conname, conrelid::regclass, confrelid::regclass
FROM pg_constraint
WHERE contype = 'f'
  AND NOT EXISTS (
    SELECT 1 FROM pg_constraint c2
    WHERE c2.contype = 'f' AND c2.conname = pg_constraint.conname
  );
```

**è§£æ±ºç­–**:
```sql
-- åˆ¶ç´„ã‚’ä¸€æ™‚çš„ã«ç„¡åŠ¹åŒ–ã—ã¦ãƒªã‚¹ãƒˆã‚¢
ALTER TABLE runs DISABLE TRIGGER ALL;
-- ãƒªã‚¹ãƒˆã‚¢å®Ÿè¡Œ
ALTER TABLE runs ENABLE TRIGGER ALL;
```

---

## 10. ä»˜éŒ²

### 10.1 ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ãƒã‚§ãƒƒã‚¯ãƒªã‚¹ãƒˆ

#### 10.1.1 æ—¥æ¬¡ãƒã‚§ãƒƒã‚¯ãƒªã‚¹ãƒˆ

- [ ] ãƒ•ãƒ«ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—å®Ÿè¡Œç¢ºèª
- [ ] å¢—åˆ†ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—å®Ÿè¡Œç¢ºèª
- [ ] ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚ºç¢ºèª
- [ ] ãƒã‚§ãƒƒã‚¯ã‚µãƒ æ¤œè¨¼å®Œäº†
- [ ] NASã¸ã®ã‚³ãƒ”ãƒ¼å®Œäº†
- [ ] ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ãƒ­ã‚°ã«ã‚¨ãƒ©ãƒ¼ãªã—
- [ ] ãƒ‡ã‚£ã‚¹ã‚¯å®¹é‡å……åˆ†ï¼ˆ>20%ç©ºãï¼‰

#### 10.1.2 é€±æ¬¡ãƒã‚§ãƒƒã‚¯ãƒªã‚¹ãƒˆ

- [ ] ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ã‹ã‚‰ã®ãƒªã‚¹ãƒˆã‚¢ãƒ†ã‚¹ãƒˆå®Ÿè¡Œ
- [ ] å¤ã„ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ã®å‰Šé™¤ç¢ºèª
- [ ] ã‚ªãƒ•ã‚µã‚¤ãƒˆã‚¹ãƒˆãƒ¬ãƒ¼ã‚¸åŒæœŸç¢ºèª
- [ ] WALã‚¢ãƒ¼ã‚«ã‚¤ãƒ–ã‚µã‚¤ã‚ºç¢ºèª
- [ ] ãƒ­ã‚°ã‚¢ãƒ¼ã‚«ã‚¤ãƒ–å®Ÿè¡Œç¢ºèª

#### 10.1.3 æœˆæ¬¡ãƒã‚§ãƒƒã‚¯ãƒªã‚¹ãƒˆ

- [ ] ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹å…¨ä½“ã®ãƒªã‚¹ãƒˆã‚¢ãƒ†ã‚¹ãƒˆ
- [ ] ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿æ•´åˆæ€§ç¢ºèª
- [ ] ã‚¹ãƒˆãƒ¬ãƒ¼ã‚¸ã‚³ã‚¹ãƒˆè¦‹ç›´ã—
- [ ] ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—æˆ¦ç•¥ã®è¦‹ç›´ã—
- [ ] RPO/RTOç›®æ¨™é”æˆç¢ºèª

### 10.2 é€£çµ¡å…ˆãƒªã‚¹ãƒˆ

| å½¹å‰² | æ‹…å½“è€… | é€£çµ¡å…ˆ | å¯¾å¿œæ™‚é–“ |
|-----|--------|--------|---------|
| **ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ç®¡ç†è€…** | [æ°å] | [ãƒ¡ãƒ¼ãƒ«/é›»è©±] | 24/7 |
| **DBA** | [æ°å] | [ãƒ¡ãƒ¼ãƒ«/é›»è©±] | å¹³æ—¥9-18æ™‚ |
| **SRE** | [æ°å] | [ãƒ¡ãƒ¼ãƒ«/é›»è©±] | 24/7 |
| **ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£** | [æ°å] | [ãƒ¡ãƒ¼ãƒ«/é›»è©±] | å¹³æ—¥9-18æ™‚ |
| **ã‚¤ãƒ³ãƒ•ãƒ©ç®¡ç†è€…** | [æ°å] | [ãƒ¡ãƒ¼ãƒ«/é›»è©±] | 24/7 |

### 10.3 é–¢é€£ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆ

| ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆ | ãƒ‘ã‚¹ | èª¬æ˜ |
|------------|------|------|
| **éæ©Ÿèƒ½è¦ä»¶** | `02_NON_FUNCTIONAL_REQUIREMENTS.md` | RPO/RTOè¦ä»¶ |
| **ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹è¨­è¨ˆ** | `05_DATABASE_DESIGN_DETAILED.md` | DBæ§‹é€ ã€ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—è¨­è¨ˆ |
| **é‹ç”¨æ‰‹é †æ›¸** | `11_OPERATIONS_RUNBOOK.md` | æ—¥å¸¸é‹ç”¨æ‰‹é † |
| **ç›£è¦–ã‚¬ã‚¤ãƒ‰** | `12_MONITORING_GUIDE.md` | ç›£è¦–è¨­å®š |
| **éšœå®³å¯¾å¿œæ‰‹é †** | `13_INCIDENT_RESPONSE.md` | éšœå®³å¯¾å¿œãƒ•ãƒ­ãƒ¼ |

### 10.4 ç”¨èªé›†

| ç”¨èª | å®šç¾© |
|-----|------|
| **RPO** | Recovery Point Objective - ç›®æ¨™å¾©æ—§æ™‚ç‚¹ï¼ˆãƒ‡ãƒ¼ã‚¿æå¤±è¨±å®¹æ™‚é–“ï¼‰ |
| **RTO** | Recovery Time Objective - ç›®æ¨™å¾©æ—§æ™‚é–“ï¼ˆã‚·ã‚¹ãƒ†ãƒ åœæ­¢è¨±å®¹æ™‚é–“ï¼‰ |
| **PITR** | Point-In-Time Recovery - ç‰¹å®šæ™‚ç‚¹ã¸ã®å¾©æ—§ |
| **WAL** | Write-Ahead Log - PostgreSQLã®ãƒˆãƒ©ãƒ³ã‚¶ã‚¯ã‚·ãƒ§ãƒ³ãƒ­ã‚° |
| **MTTR** | Mean Time To Repair - å¹³å‡ä¿®å¾©æ™‚é–“ |
| **DR** | Disaster Recovery - ç½å®³å¾©æ—§ |
| **Immutable Backup** | å¤‰æ›´ä¸å¯èƒ½ãªãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ï¼ˆãƒ©ãƒ³ã‚µãƒ ã‚¦ã‚§ã‚¢å¯¾ç­–ï¼‰ |

### 10.5 å¤‰æ›´å±¥æ­´

| æ—¥ä»˜ | ãƒãƒ¼ã‚¸ãƒ§ãƒ³ | å¤‰æ›´å†…å®¹ | æ‹…å½“è€… |
|------|-----------|----------|--------|
| 2025-11-03 | 1.0.0 | åˆç‰ˆä½œæˆ | Claude Team |

---

## âœ¨ ã¾ã¨ã‚

æœ¬ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ãƒ»ãƒªã‚«ãƒãƒªã‚¬ã‚¤ãƒ‰ã¯ã€æ™‚ç³»åˆ—äºˆæ¸¬ã‚·ã‚¹ãƒ†ãƒ ã®ãƒ‡ãƒ¼ã‚¿ä¿è­·ã¨å¯ç”¨æ€§ã‚’ç¢ºä¿ã™ã‚‹ãŸã‚ã®åŒ…æ‹¬çš„ãªã‚¬ã‚¤ãƒ‰ã§ã™ã€‚

### ãƒã‚¤ãƒ©ã‚¤ãƒˆ

- âœ… **RPO: 1æ™‚é–“** - å¢—åˆ†ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ã¨WALã‚¢ãƒ¼ã‚«ã‚¤ãƒ–ã§å®Ÿç¾
- âœ… **RTO: 4æ™‚é–“** - è‡ªå‹•åŒ–ã•ã‚ŒãŸãƒªã‚¹ãƒˆã‚¢ãƒ—ãƒ­ã‚»ã‚¹
- âœ… **å¤šå±¤é˜²å¾¡** - ãƒ­ãƒ¼ã‚«ãƒ«ã€NASã€ã‚ªãƒ•ã‚µã‚¤ãƒˆã€DR ã‚µã‚¤ãƒˆ
- âœ… **è‡ªå‹•åŒ–** - ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ã€æ¤œè¨¼ã€ã‚¢ãƒ©ãƒ¼ãƒˆã‚’å®Œå…¨è‡ªå‹•åŒ–
- âœ… **ãƒ©ãƒ³ã‚µãƒ ã‚¦ã‚§ã‚¢å¯¾ç­–** - ã‚¤ãƒŸãƒ¥ãƒ¼ã‚¿ãƒ–ãƒ«ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ã€ã‚¨ã‚¢ã‚®ãƒ£ãƒƒãƒ—ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—
- âœ… **å®šæœŸãƒ†ã‚¹ãƒˆ** - æ—¥æ¬¡ã€é€±æ¬¡ã€æœˆæ¬¡ã€å››åŠæœŸã§ãƒ†ã‚¹ãƒˆå®Ÿæ–½
- âœ… **åŒ…æ‹¬çš„ç›£è¦–** - Prometheus/Grafanaã§ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ç›£è¦–

### é‡è¦ãªãƒã‚¤ãƒ³ãƒˆ

1. **ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ã¯è‡ªå‹•åŒ–**ã€æ¤œè¨¼ã‚‚è‡ªå‹•åŒ–
2. **å®šæœŸçš„ãªãƒªã‚¹ãƒˆã‚¢ãƒ†ã‚¹ãƒˆ**ãŒæœ€ã‚‚é‡è¦
3. **è¤‡æ•°ã®ä¿å­˜å ´æ‰€**ã§ãƒªã‚¹ã‚¯åˆ†æ•£
4. **RPO/RTOã‚’å¸¸ã«æ¸¬å®š**ã—æ”¹å–„
5. **ãƒ©ãƒ³ã‚µãƒ ã‚¦ã‚§ã‚¢å¯¾ç­–**ã¯å¿…é ˆ

---

**ãƒ‡ãƒ¼ã‚¿ã¯ä¼æ¥­ã®è³‡ç”£ã§ã™ã€‚ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ã¯ä¿é™ºã§ã™ã€‚ğŸ”’**

---
**End of Document**
