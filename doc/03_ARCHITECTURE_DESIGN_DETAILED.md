# è©³ç´°ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£è¨­è¨ˆæ›¸
**Detailed Architecture Design for Time Series Forecasting System**

---

## ğŸ“‹ ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆæƒ…å ±

| é …ç›® | å†…å®¹ |
|-----|------|
| **ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã‚¿ã‚¤ãƒˆãƒ«** | æ™‚ç³»åˆ—äºˆæ¸¬ã‚·ã‚¹ãƒ†ãƒ  è©³ç´°ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£è¨­è¨ˆæ›¸ |
| **ãƒãƒ¼ã‚¸ãƒ§ãƒ³** | v1.0.0 |
| **ä½œæˆæ—¥** | 2025-11-03 |
| **æœ€çµ‚æ›´æ–°æ—¥** | 2025-11-03 |
| **å¯¾è±¡ã‚·ã‚¹ãƒ†ãƒ ** | NeuralForecast Auto Runner + Time Series Forecasting System |
| **ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã‚¹ã‚¿ã‚¤ãƒ«** | ãƒ¬ã‚¤ãƒ¤ãƒ¼ãƒ‰ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ï¼ˆ9å±¤ï¼‰ + Hexagonal Architecture |

---

## ç›®æ¬¡

1. [ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£æ¦‚è¦](#1-ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£æ¦‚è¦)
2. [9å±¤ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£è©³ç´°](#2-9å±¤ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£è©³ç´°)
3. [ã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆå›³](#3-ã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆå›³)
4. [ã‚·ãƒ¼ã‚±ãƒ³ã‚¹å›³](#4-ã‚·ãƒ¼ã‚±ãƒ³ã‚¹å›³)
5. [ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ­ãƒ¼å›³](#5-ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ­ãƒ¼å›³)
6. [ãƒ‡ãƒ—ãƒ­ã‚¤ãƒ¡ãƒ³ãƒˆå›³](#6-ãƒ‡ãƒ—ãƒ­ã‚¤ãƒ¡ãƒ³ãƒˆå›³)
7. [è¨­è¨ˆãƒ‘ã‚¿ãƒ¼ãƒ³](#7-è¨­è¨ˆãƒ‘ã‚¿ãƒ¼ãƒ³)
8. [å“è³ªå±æ€§ã®å®Ÿç¾](#8-å“è³ªå±æ€§ã®å®Ÿç¾)
9. [æŠ€è¡“ã‚¹ã‚¿ãƒƒã‚¯](#9-æŠ€è¡“ã‚¹ã‚¿ãƒƒã‚¯)
10. [ä»˜éŒ²](#10-ä»˜éŒ²)

---

## 1. ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£æ¦‚è¦

### 1.1 ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã‚¹ã‚¿ã‚¤ãƒ«

æœ¬ã‚·ã‚¹ãƒ†ãƒ ã¯ã€ä»¥ä¸‹ã®è¤‡æ•°ã®ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã‚¹ã‚¿ã‚¤ãƒ«ã‚’çµ„ã¿åˆã‚ã›ã¦è¨­è¨ˆã•ã‚Œã¦ã„ã¾ã™ï¼š

#### 1.1.1 ãƒ¬ã‚¤ãƒ¤ãƒ¼ãƒ‰ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ (Layered Architecture)

**9ã¤ã®å±¤ã§æ§‹æˆ**:

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Layer 9: Application Layer                              â”‚
â”‚  - CLI Entry Point, Web UI, Main Orchestrator          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                         â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Layer 8: Logging Layer                                  â”‚
â”‚  - Structured Logger, Progress Tracker, MLflow Bridge   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                         â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Layer 7: Artifact Management Layer                      â”‚
â”‚  - Artifact Manager, Model Saver, Prediction Saver      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                         â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Layer 6: Execution Layer                                â”‚
â”‚  - Executor, Serial/Parallel/Ray Executor               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                         â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Layer 5: Execution Plan Layer                           â”‚
â”‚  - Combination Generator, Execution Plan, Scheduler     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                         â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Layer 4: Hyperparameter Layer                           â”‚
â”‚  - Loss Registry, Scaler Registry, Search Algorithm     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                         â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Layer 3: Model Discovery Layer                          â”‚
â”‚  - Model Registry, Capability Analyzer, Backend         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                         â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Layer 2: Data Layer                                     â”‚
â”‚  - Data Loader, Preprocessor, Exog Encoder              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                         â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Layer 1: Configuration Layer                            â”‚
â”‚  - Config, Path Config, Execution Config                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                         â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Infrastructure Layer                                    â”‚
â”‚  - PostgreSQL, File System, MLflow, Ray, Optuna         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

#### 1.1.2 Hexagonal Architecture (Ports and Adapters)

**å¤–éƒ¨ã‚·ã‚¹ãƒ†ãƒ ã¨ã®çµ±åˆ**:

```mermaid
graph TB
    subgraph "Core Domain"
        Core[Business Logic<br/>Training, Prediction, Analysis]
    end
    
    subgraph "Ports (Interfaces)"
        InPort1[Data Port]
        InPort2[Model Port]
        InPort3[Tracking Port]
        OutPort1[Storage Port]
        OutPort2[Logging Port]
    end
    
    subgraph "Adapters"
        CSVAdapter[CSV Adapter]
        ParquetAdapter[Parquet Adapter]
        NFAdapter[NeuralForecast Adapter]
        DartsAdapter[Darts Adapter]
        MLflowAdapter[MLflow Adapter]
        WandBAdapter[W&B Adapter]
        PostgresAdapter[PostgreSQL Adapter]
        FileAdapter[File System Adapter]
    end
    
    Core --> InPort1
    Core --> InPort2
    Core --> InPort3
    Core --> OutPort1
    Core --> OutPort2
    
    CSVAdapter --> InPort1
    ParquetAdapter --> InPort1
    NFAdapter --> InPort2
    DartsAdapter --> InPort2
    MLflowAdapter --> InPort3
    WandBAdapter --> InPort3
    OutPort1 --> PostgresAdapter
    OutPort1 --> FileAdapter
    OutPort2 --> PostgresAdapter
```

---

### 1.2 ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£åŸå‰‡

#### 1.2.1 SOLIDåŸå‰‡

| åŸå‰‡ | èª¬æ˜ | å®Ÿè£…ä¾‹ |
|-----|------|--------|
| **S**ingle Responsibility | å„ã‚¯ãƒ©ã‚¹ã¯1ã¤ã®è²¬å‹™ã®ã¿ | `DataLoader`ã¯ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿ã®ã¿ |
| **O**pen/Closed | æ‹¡å¼µã«é–‹ã„ã¦ã€ä¿®æ­£ã«é–‰ã˜ã¦ã„ã‚‹ | `Config`ã‚’ç¶™æ‰¿ã—ã¦æ–°è¨­å®šè¿½åŠ  |
| **L**iskov Substitution | æ´¾ç”Ÿã‚¯ãƒ©ã‚¹ã¯åŸºåº•ã‚¯ãƒ©ã‚¹ã¨ç½®æ›å¯èƒ½ | ã™ã¹ã¦ã®`Executor`ã¯åŒã˜ã‚¤ãƒ³ã‚¿ãƒ¼ãƒ•ã‚§ãƒ¼ã‚¹ |
| **I**nterface Segregation | å°ã•ãªã‚¤ãƒ³ã‚¿ãƒ¼ãƒ•ã‚§ãƒ¼ã‚¹ã«åˆ†å‰² | `Saveable`, `Loadable`ãªã© |
| **D**ependency Inversion | æŠ½è±¡ã«ä¾å­˜ã€å…·è±¡ã«ä¾å­˜ã—ãªã„ | `Protocol`ã«ã‚ˆã‚‹ä¾å­˜æ€§æ³¨å…¥ |

---

#### 1.2.2 ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£è¨­è¨ˆåŸå‰‡

| åŸå‰‡ | èª¬æ˜ | å®Ÿè£… |
|-----|------|------|
| **é–¢å¿ƒã®åˆ†é›¢** | å„å±¤ã¯ç‹¬ç«‹ã—ãŸè²¬å‹™ã‚’æŒã¤ | 9å±¤æ§‹é€  |
| **ç–çµåˆ** | å±¤é–“ã®ä¾å­˜ã‚’æœ€å°åŒ– | ã‚¤ãƒ³ã‚¿ãƒ¼ãƒ•ã‚§ãƒ¼ã‚¹çµŒç”±ã®é€šä¿¡ |
| **é«˜å‡é›†** | é–¢é€£ã™ã‚‹æ©Ÿèƒ½ã‚’é›†ç´„ | å±¤å†…ã®ã‚¯ãƒ©ã‚¹ã¯å¯†æ¥ã«é–¢é€£ |
| **å˜æ–¹å‘ä¾å­˜** | ä¸Šä½å±¤ã‹ã‚‰ä¸‹ä½å±¤ã¸ã®ä¾å­˜ã®ã¿ | ä¸‹ä½å±¤ã¯ä¸Šä½å±¤ã‚’çŸ¥ã‚‰ãªã„ |
| **ä¾å­˜æ€§æ³¨å…¥** | ä¾å­˜ã‚’å¤–éƒ¨ã‹ã‚‰æ³¨å…¥ | ã‚³ãƒ³ã‚¹ãƒˆãƒ©ã‚¯ã‚¿ã‚¤ãƒ³ã‚¸ã‚§ã‚¯ã‚·ãƒ§ãƒ³ |

---

## 2. 9å±¤ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£è©³ç´°

### Layer 1: Configurationå±¤

#### 2.1.1 è²¬å‹™

- ã‚·ã‚¹ãƒ†ãƒ å…¨ä½“ã®è¨­å®šç®¡ç†
- ç’°å¢ƒå¤‰æ•°ã®èª­ã¿è¾¼ã¿ã¨æ¤œè¨¼
- è¨­å®šã®ä¸å¤‰æ€§ä¿è¨¼
- ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå€¤ã®æä¾›

#### 2.1.2 ã‚¯ãƒ©ã‚¹æ§‹æˆ

```mermaid
classDiagram
    class Config {
        <<abstract>>
        +from_env() Config
        +validate() None
        +to_dict() Dict
        +to_json() str
    }
    
    class PathConfig {
        +data_csv: Path
        +output_dir: Path
        +log_dir: Path
        +project_root: Path
        +model_dir: Path
        +artifact_dir: Path
        +from_env() PathConfig
        +create_directories() None
    }
    
    class ExecutionConfig {
        +random_state: int
        +trial_num_samples: int
        +trial_max_steps: int
        +default_h: int
        +h_ratio: float
        +max_workers: int
        +allow_ray_parallel: bool
        +save_model: bool
        +overwrite_model: bool
        +max_exog_futr: int
        +max_exog_hist: int
        +max_exog_stat: int
        +from_env() ExecutionConfig
    }
    
    class ModelSelectionConfig {
        +enable_auto_nhits: bool
        +enable_auto_lstm: bool
        +enable_auto_tft: bool
        +enable_auto_informer: bool
        +model_whitelist: List[str]
        +model_blacklist: List[str]
        +from_env() ModelSelectionConfig
        +get_enabled_models() List[str]
    }
    
    class ConfigLoader {
        +load_all() Dict[str, Config]
        +load_from_file(path: Path) Config
        +merge_configs(configs: List[Config]) Config
        +validate_all(configs: Dict) bool
    }
    
    Config <|-- PathConfig
    Config <|-- ExecutionConfig
    Config <|-- ModelSelectionConfig
    ConfigLoader --> Config
```

#### 2.1.3 ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ­ãƒ¼

```mermaid
sequenceDiagram
    participant App as Application
    participant CL as ConfigLoader
    participant PC as PathConfig
    participant EC as ExecutionConfig
    participant MC as ModelSelectionConfig
    participant Env as Environment Variables
    
    App->>CL: load_all()
    CL->>PC: from_env()
    PC->>Env: get("NF_DATA_CSV")
    Env-->>PC: "./data.csv"
    PC->>PC: validate()
    PC->>PC: create_directories()
    PC-->>CL: PathConfig
    
    CL->>EC: from_env()
    EC->>Env: get("RANDOM_STATE")
    Env-->>EC: "42"
    EC->>EC: validate()
    EC-->>CL: ExecutionConfig
    
    CL->>MC: from_env()
    MC->>Env: get("ENABLE_AUTO_NHITS")
    Env-->>MC: "true"
    MC->>MC: validate()
    MC-->>CL: ModelSelectionConfig
    
    CL-->>App: Dict[str, Config]
```

#### 2.1.4 ä¸»è¦ã‚¤ãƒ³ã‚¿ãƒ¼ãƒ•ã‚§ãƒ¼ã‚¹

```python
from dataclasses import dataclass, field
from pathlib import Path
from typing import Dict, Any, Optional
from abc import ABC, abstractmethod

@dataclass(frozen=True)
class Config(ABC):
    """è¨­å®šåŸºåº•ã‚¯ãƒ©ã‚¹"""
    
    @classmethod
    @abstractmethod
    def from_env(cls) -> 'Config':
        """ç’°å¢ƒå¤‰æ•°ã‹ã‚‰è¨­å®šã‚’æ§‹ç¯‰"""
        pass
    
    def validate(self) -> None:
        """è¨­å®šã®å¦¥å½“æ€§æ¤œè¨¼"""
        pass
    
    def to_dict(self) -> Dict[str, Any]:
        """è¾æ›¸ã«å¤‰æ›"""
        return {k: str(v) if isinstance(v, Path) else v 
                for k, v in self.__dict__.items()}
    
    def to_json(self) -> str:
        """JSONæ–‡å­—åˆ—ã«å¤‰æ›"""
        import json
        return json.dumps(self.to_dict(), indent=2)
```

---

### Layer 2: Dataå±¤

#### 2.2.1 è²¬å‹™

- ãƒ‡ãƒ¼ã‚¿ã®èª­ã¿è¾¼ã¿ï¼ˆCSV, Parquetï¼‰
- ãƒ‡ãƒ¼ã‚¿ã®å‰å‡¦ç†ï¼ˆæ¬ æå€¤ã€å¤–ã‚Œå€¤ã€æ­£è¦åŒ–ï¼‰
- å¤–ç”Ÿå¤‰æ•°ã®ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°
- å‘¨æœŸæ€§ã®æ¨å®š
- ãƒ‡ãƒ¼ã‚¿æ¤œè¨¼

#### 2.2.2 ã‚¯ãƒ©ã‚¹æ§‹æˆ

```mermaid
classDiagram
    class DataLoader {
        +load_csv(path: Path) DataFrame
        +load_parquet(path: Path) DataFrame
        +auto_detect_encoding(path: Path) str
        +infer_schema(df: DataFrame) Schema
    }
    
    class DataPreprocessor {
        +handle_missing_values(df: DataFrame) DataFrame
        +remove_outliers(df: DataFrame) DataFrame
        +normalize_datetime(df: DataFrame) DataFrame
        +sort_by_datetime(df: DataFrame) DataFrame
        +deduplicate(df: DataFrame) DataFrame
    }
    
    class ExogeneousVariableEncoder {
        +encode_categorical(df: DataFrame) DataFrame
        +encode_cyclical(df: DataFrame) DataFrame
        +encode_binary(df: DataFrame) DataFrame
        +auto_detect_type(series: Series) str
    }
    
    class FrequencyInferrer {
        +infer_frequency(dates: Series) str
        +detect_seasonality(series: Series) Dict
        +compute_acf(series: Series) ndarray
        +compute_pacf(series: Series) ndarray
    }
    
    class DataValidator {
        +validate_schema(df: DataFrame) ValidationResult
        +check_missing_values(df: DataFrame) Dict
        +detect_outliers(df: DataFrame) Series
        +check_temporal_order(df: DataFrame) bool
    }
    
    DataLoader --> DataValidator
    DataPreprocessor --> DataValidator
    ExogeneousVariableEncoder --> DataPreprocessor
    FrequencyInferrer --> DataLoader
```

#### 2.2.3 ãƒ‡ãƒ¼ã‚¿ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³

```mermaid
graph LR
    A[Raw CSV] --> B[DataLoader]
    B --> C[DataValidator]
    C --> D{Valid?}
    D -->|Yes| E[DataPreprocessor]
    D -->|No| F[Error Report]
    E --> G[ExogeneousVariableEncoder]
    G --> H[FrequencyInferrer]
    H --> I[Processed DataFrame]
    
    style A fill:#e1f5ff
    style I fill:#e7f9e7
    style F fill:#ffe1e1
```

#### 2.2.4 ä¸»è¦ã‚¤ãƒ³ã‚¿ãƒ¼ãƒ•ã‚§ãƒ¼ã‚¹

```python
from typing import Protocol, Optional
import pandas as pd

class DataLoaderProtocol(Protocol):
    """ãƒ‡ãƒ¼ã‚¿ãƒ­ãƒ¼ãƒ€ãƒ¼ã®ã‚¤ãƒ³ã‚¿ãƒ¼ãƒ•ã‚§ãƒ¼ã‚¹"""
    
    def load(
        self, 
        path: Path,
        *,
        encoding: Optional[str] = None,
        chunksize: Optional[int] = None,
    ) -> pd.DataFrame:
        """ãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã‚€"""
        ...

class DataPreprocessorProtocol(Protocol):
    """å‰å‡¦ç†ã®ã‚¤ãƒ³ã‚¿ãƒ¼ãƒ•ã‚§ãƒ¼ã‚¹"""
    
    def preprocess(
        self,
        df: pd.DataFrame,
        *,
        handle_missing: bool = True,
        remove_outliers: bool = True,
        normalize_dates: bool = True,
    ) -> pd.DataFrame:
        """å‰å‡¦ç†ã‚’å®Ÿè¡Œ"""
        ...
```

---

### Layer 3: Model Discoveryå±¤

#### 2.3.1 è²¬å‹™

- åˆ©ç”¨å¯èƒ½ãªãƒ¢ãƒ‡ãƒ«ã®æ¤œå‡º
- ãƒ¢ãƒ‡ãƒ«èƒ½åŠ›ã®åˆ†æ
- è¨ˆç®—ãƒãƒƒã‚¯ã‚¨ãƒ³ãƒ‰ã®æ¤œå‡º
- ãƒ¢ãƒ‡ãƒ«ã®æ¤œè¨¼

#### 2.3.2 ã‚¯ãƒ©ã‚¹æ§‹æˆ

```mermaid
classDiagram
    class ModelRegistry {
        -_models: Dict[str, Type[BaseModel]]
        +register(name: str, model_class: Type) None
        +get(name: str) Type[BaseModel]
        +list_available() List[str]
        +auto_discover() List[str]
        +is_available(name: str) bool
    }
    
    class ModelCapabilityAnalyzer {
        +analyze(model_class: Type) ModelCapability
        +supports_exogenous(model: Type) bool
        +supports_categorical(model: Type) bool
        +supports_quantile(model: Type) bool
        +get_constraints(model: Type) Dict
    }
    
    class BackendDetector {
        +detect_available_backends() List[str]
        +has_cuda() bool
        +has_mps() bool
        +get_gpu_info() Dict
        +recommend_backend() str
    }
    
    class ModelValidator {
        +validate_compatibility(model: Type, data: DataFrame) bool
        +check_requirements(model: Type) List[str]
        +validate_hyperparameters(model: Type, params: Dict) bool
    }
    
    ModelRegistry --> ModelCapabilityAnalyzer
    ModelRegistry --> ModelValidator
    BackendDetector --> ModelRegistry
```

#### 2.3.3 ãƒ¢ãƒ‡ãƒ«æ¤œå‡ºãƒ•ãƒ­ãƒ¼

```mermaid
sequenceDiagram
    participant App as Application
    participant MR as ModelRegistry
    participant MCA as ModelCapabilityAnalyzer
    participant BD as BackendDetector
    participant NF as NeuralForecast
    
    App->>MR: auto_discover()
    MR->>NF: inspect.getmembers()
    NF-->>MR: [AutoNHITS, AutoLSTM, ...]
    
    loop For each model
        MR->>MCA: analyze(AutoNHITS)
        MCA->>AutoNHITS: inspect signature
        AutoNHITS-->>MCA: parameters, constraints
        MCA-->>MR: ModelCapability
        
        MR->>BD: detect_available_backends()
        BD->>BD: check CUDA, MPS
        BD-->>MR: ["cuda", "cpu"]
        
        MR->>MR: register("AutoNHITS", AutoNHITS)
    end
    
    MR-->>App: List[str] (available models)
```

---

### Layer 4: Hyperparameterå±¤

#### 2.4.1 è²¬å‹™

- Lossé–¢æ•°ã®ç®¡ç†
- Scalerã®ç®¡ç†
- æ¢ç´¢ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ã®ç®¡ç†
- ãƒã‚¤ãƒ‘ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã®æ¤œè¨¼

#### 2.4.2 ã‚¯ãƒ©ã‚¹æ§‹æˆ

```mermaid
classDiagram
    class LossRegistry {
        -_losses: Dict[str, Type[Loss]]
        +register(name: str, loss: Type) None
        +get(name: str) Loss
        +list_available() List[str]
        +get_for_model(model: Type) List[str]
    }
    
    class ScalerRegistry {
        -_scalers: Dict[str, Type[Scaler]]
        +register(name: str, scaler: Type) None
        +get(name: str) Scaler
        +list_available() List[str]
        +recommend_for_data(df: DataFrame) str
    }
    
    class SearchAlgorithmManager {
        -_algorithms: Dict[str, SearchAlgorithm]
        +register(name: str, algo: SearchAlgorithm) None
        +get(name: str) SearchAlgorithm
        +create_study(name: str) Study
        +optimize(study: Study) Result
    }
    
    class HyperparameterValidator {
        +validate_range(param: str, value: Any) bool
        +validate_type(param: str, value: Any) bool
        +validate_dependencies(params: Dict) bool
        +suggest_defaults(model: Type) Dict
    }
    
    LossRegistry --> HyperparameterValidator
    ScalerRegistry --> HyperparameterValidator
    SearchAlgorithmManager --> HyperparameterValidator
```

#### 2.4.3 ãƒã‚¤ãƒ‘ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æ¢ç´¢ãƒ•ãƒ­ãƒ¼

```mermaid
graph TD
    A[Start Optimization] --> B[SearchAlgorithmManager]
    B --> C{Algorithm?}
    C -->|TPE| D[Optuna TPE]
    C -->|CMA-ES| E[Optuna CMA-ES]
    C -->|ASHA| F[Ray ASHA]
    
    D --> G[Create Study]
    E --> G
    F --> G
    
    G --> H[Define Objective Function]
    H --> I[Sample Hyperparameters]
    I --> J[Train Model]
    J --> K[Evaluate Model]
    K --> L{More Trials?}
    L -->|Yes| I
    L -->|No| M[Return Best Parameters]
    
    style A fill:#e1f5ff
    style M fill:#e7f9e7
```

---

### Layer 5: Execution Planå±¤

#### 2.5.1 è²¬å‹™

- å®Ÿè¡Œè¨ˆç”»ã®ç”Ÿæˆ
- çµ„ã¿åˆã‚ã›ã®ç”Ÿæˆ
- é‡è¤‡æ¤œå‡º
- ãƒªã‚½ãƒ¼ã‚¹æ¨å®š
- ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒªãƒ³ã‚°

#### 2.5.2 ã‚¯ãƒ©ã‚¹æ§‹æˆ

```mermaid
classDiagram
    class CombinationGenerator {
        +generate(models: List, losses: List, scalers: List) Iterator
        +filter_by_compatibility(combinations: Iterator) Iterator
        +apply_constraints(combinations: Iterator) Iterator
        +count_total(models: List, losses: List) int
    }
    
    class ExecutionPlan {
        +combinations: List[Combination]
        +total_count: int
        +estimated_time: float
        +estimated_resources: Dict
        +add(combination: Combination) None
        +remove(combination: Combination) None
        +optimize() None
    }
    
    class DuplicateDetector {
        +check_fingerprint(fingerprint: str) bool
        +add_fingerprint(fingerprint: str) None
        +get_existing_run(fingerprint: str) Run
        +compute_fingerprint(combination: Combination) str
    }
    
    class ResourceEstimator {
        +estimate_memory(model: Type, data_size: int) float
        +estimate_time(model: Type, data_size: int) float
        +estimate_gpu_memory(model: Type, batch_size: int) float
        +can_fit_in_memory(plan: ExecutionPlan) bool
    }
    
    class Scheduler {
        +schedule(plan: ExecutionPlan) Schedule
        +prioritize(combinations: List) List
        +allocate_resources(schedule: Schedule) None
        +handle_failures(failed: Combination) None
    }
    
    CombinationGenerator --> ExecutionPlan
    ExecutionPlan --> DuplicateDetector
    ExecutionPlan --> ResourceEstimator
    Scheduler --> ExecutionPlan
```

#### 2.5.3 å®Ÿè¡Œè¨ˆç”»ç”Ÿæˆãƒ•ãƒ­ãƒ¼

```mermaid
sequenceDiagram
    participant App as Application
    participant CG as CombinationGenerator
    participant EP as ExecutionPlan
    participant DD as DuplicateDetector
    participant RE as ResourceEstimator
    participant Sch as Scheduler
    
    App->>CG: generate(models, losses, scalers)
    CG->>CG: cartesian_product()
    CG->>CG: filter_by_compatibility()
    CG-->>EP: Iterator[Combination]
    
    loop For each combination
        EP->>DD: compute_fingerprint(comb)
        DD-->>EP: fingerprint
        EP->>DD: check_fingerprint(fp)
        DD-->>EP: exists=False
        
        EP->>RE: estimate_resources(comb)
        RE-->>EP: {memory: 8GB, time: 300s}
        
        EP->>EP: add(comb)
    end
    
    EP-->>Sch: ExecutionPlan
    Sch->>Sch: optimize()
    Sch->>Sch: prioritize()
    Sch-->>App: Schedule
```

---

### Layer 6: Executionå±¤

#### 2.6.1 è²¬å‹™

- ãƒ¢ãƒ‡ãƒ«ã®å­¦ç¿’å®Ÿè¡Œ
- ç›´åˆ—/ä¸¦åˆ—å®Ÿè¡Œã®åˆ¶å¾¡
- ãƒªã‚½ãƒ¼ã‚¹ç›£è¦–
- ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°
- ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆç®¡ç†

#### 2.6.2 ã‚¯ãƒ©ã‚¹æ§‹æˆ

```mermaid
classDiagram
    class Executor {
        <<abstract>>
        +execute(plan: ExecutionPlan) List[Result]
        +execute_single(combination: Combination) Result
        #_setup() None
        #_teardown() None
        #_handle_error(error: Exception) None
    }
    
    class SerialExecutor {
        +execute(plan: ExecutionPlan) List[Result]
        +execute_single(combination: Combination) Result
    }
    
    class ParallelExecutor {
        +max_workers: int
        +executor: ThreadPoolExecutor
        +execute(plan: ExecutionPlan) List[Result]
        +execute_batch(batch: List) List[Result]
    }
    
    class RayExecutor {
        +ray_address: str
        +num_cpus: int
        +num_gpus: int
        +execute(plan: ExecutionPlan) List[Result]
        +execute_remote(combination: Combination) Result
        +shutdown() None
    }
    
    class ResourceMonitor {
        +monitor_cpu() float
        +monitor_gpu() Dict
        +monitor_memory() float
        +log_resources() None
        +alert_on_threshold() None
    }
    
    Executor <|-- SerialExecutor
    Executor <|-- ParallelExecutor
    Executor <|-- RayExecutor
    Executor --> ResourceMonitor
```

#### 2.6.3 å®Ÿè¡Œãƒ•ãƒ­ãƒ¼ï¼ˆä¸¦åˆ—ï¼‰

```mermaid
sequenceDiagram
    participant App as Application
    participant PE as ParallelExecutor
    participant Pool as ThreadPool
    participant Worker1 as Worker 1
    participant Worker2 as Worker 2
    participant RM as ResourceMonitor
    
    App->>PE: execute(plan)
    PE->>Pool: create(max_workers=4)
    
    PE->>RM: start_monitoring()
    
    loop For each batch
        PE->>Pool: submit(execute_single, comb1)
        Pool->>Worker1: execute_single(comb1)
        PE->>Pool: submit(execute_single, comb2)
        Pool->>Worker2: execute_single(comb2)
        
        Worker1->>Worker1: train_model()
        Worker2->>Worker2: train_model()
        
        RM->>RM: monitor_cpu()
        RM->>RM: monitor_gpu()
        RM->>RM: monitor_memory()
        
        Worker1-->>Pool: Result1
        Worker2-->>Pool: Result2
        Pool-->>PE: [Result1, Result2]
    end
    
    PE->>RM: stop_monitoring()
    PE-->>App: List[Result]
```

---

### Layer 7: Artifact Managementå±¤

#### 2.7.1 è²¬å‹™

- ãƒ¢ãƒ‡ãƒ«ã®ä¿å­˜/èª­ã¿è¾¼ã¿
- äºˆæ¸¬çµæœã®ä¿å­˜
- ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã®ç®¡ç†
- ã‚¢ãƒ¼ãƒ†ã‚£ãƒ•ã‚¡ã‚¯ãƒˆã®ãƒãƒ¼ã‚¸ãƒ§ãƒ‹ãƒ³ã‚°

#### 2.7.2 ã‚¯ãƒ©ã‚¹æ§‹æˆ

```mermaid
classDiagram
    class ArtifactManager {
        +base_path: Path
        +save(artifact: Any, path: Path) None
        +load(path: Path) Any
        +list_artifacts(run_id: UUID) List[Path]
        +delete(path: Path) None
    }
    
    class ModelSaver {
        +save_model(model: BaseModel, path: Path) None
        +load_model(path: Path) BaseModel
        +save_checkpoint(model: BaseModel, epoch: int) None
        +list_checkpoints(run_id: UUID) List[Path]
    }
    
    class PredictionSaver {
        +save_predictions(df: DataFrame, path: Path) None
        +save_metrics(metrics: Dict, path: Path) None
        +append_predictions(df: DataFrame, path: Path) None
    }
    
    class MetadataManager {
        +save_metadata(metadata: Dict, path: Path) None
        +load_metadata(path: Path) Dict
        +update_metadata(path: Path, updates: Dict) None
        +compute_hash(artifact: Any) str
    }
    
    ArtifactManager <|-- ModelSaver
    ArtifactManager <|-- PredictionSaver
    ArtifactManager --> MetadataManager
```

#### 2.7.3 ä¿å­˜/èª­ã¿è¾¼ã¿ãƒ•ãƒ­ãƒ¼

```mermaid
graph LR
    A[Trained Model] --> B[ModelSaver]
    B --> C{Format?}
    C -->|PyTorch| D[torch.save]
    C -->|Pickle| E[pickle.dump]
    C -->|ONNX| F[onnx.export]
    
    D --> G[File System]
    E --> G
    F --> G
    
    G --> H[MetadataManager]
    H --> I[Compute Hash]
    I --> J[Save Metadata]
    J --> K[Database Record]
    
    style A fill:#e1f5ff
    style K fill:#e7f9e7
```

---

### Layer 8: Loggingå±¤

#### 2.8.1 è²¬å‹™

- æ§‹é€ åŒ–ãƒ­ã‚°ã®å‡ºåŠ›
- é€²æ—ãƒˆãƒ©ãƒƒã‚­ãƒ³ã‚°
- MLflow/W&Bçµ±åˆ
- ãƒ­ã‚°ã®ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°ãƒ»ãƒ­ãƒ¼ãƒ†ãƒ¼ã‚·ãƒ§ãƒ³

#### 2.8.2 ã‚¯ãƒ©ã‚¹æ§‹æˆ

```mermaid
classDiagram
    class StructuredLogger {
        +name: str
        +level: str
        +handlers: List[Handler]
        +log(level: str, message: str, **kwargs) None
        +info(message: str, **kwargs) None
        +warning(message: str, **kwargs) None
        +error(message: str, **kwargs) None
    }
    
    class ProgressTracker {
        +total: int
        +current: int
        +start_time: datetime
        +update(n: int) None
        +get_progress() float
        +get_eta() timedelta
        +reset() None
    }
    
    class MLflowBridge {
        +tracking_uri: str
        +experiment_name: str
        +start_run(run_id: UUID) ActiveRun
        +log_params(params: Dict) None
        +log_metrics(metrics: Dict) None
        +log_artifact(path: Path) None
    }
    
    class WandBBridge {
        +project: str
        +entity: str
        +init(config: Dict) None
        +log(data: Dict) None
        +log_artifact(path: Path) None
        +finish() None
    }
    
    StructuredLogger --> ProgressTracker
    StructuredLogger --> MLflowBridge
    StructuredLogger --> WandBBridge
```

#### 2.8.3 ãƒ­ã‚®ãƒ³ã‚°ãƒ•ãƒ­ãƒ¼

```mermaid
sequenceDiagram
    participant App as Application
    participant SL as StructuredLogger
    participant MLflow as MLflowBridge
    participant WandB as WandBBridge
    participant DB as PostgreSQL
    participant File as File System
    
    App->>SL: log("INFO", "Training started", run_id=...)
    
    SL->>SL: format_message()
    SL->>SL: add_context()
    
    par Log to multiple destinations
        SL->>MLflow: log_params({"lr": 0.001})
        MLflow->>MLflow: track_params()
        
        SL->>WandB: log({"step": 1, "loss": 0.5})
        WandB->>WandB: track_metrics()
        
        SL->>DB: INSERT INTO run_logs
        DB-->>SL: OK
        
        SL->>File: append_to_log_file()
        File-->>SL: OK
    end
    
    SL-->>App: None
```

---

### Layer 9: Applicationå±¤

#### 2.9.1 è²¬å‹™

- CLIã‚¨ãƒ³ãƒˆãƒªãƒ¼ãƒã‚¤ãƒ³ãƒˆ
- Webã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³
- ãƒ¡ã‚¤ãƒ³ã‚ªãƒ¼ã‚±ã‚¹ãƒˆãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³
- ãƒ¦ãƒ¼ã‚¶ãƒ¼ã‚¤ãƒ³ã‚¿ãƒ©ã‚¯ã‚·ãƒ§ãƒ³

#### 2.9.2 ã‚¯ãƒ©ã‚¹æ§‹æˆ

```mermaid
classDiagram
    class MainOrchestrator {
        +config: Dict[str, Config]
        +data_loader: DataLoader
        +model_registry: ModelRegistry
        +executor: Executor
        +run() None
        +setup() None
        +execute_workflow() List[Result]
        +teardown() None
    }
    
    class CLIEntryPoint {
        +parser: ArgumentParser
        +main(args: List[str]) None
        +parse_args(args: List[str]) Namespace
        +execute_command(args: Namespace) None
    }
    
    class WebUIApplication {
        +app: FastAPI
        +routes: List[Route]
        +start(host: str, port: int) None
        +register_routes() None
        +handle_request(request: Request) Response
    }
    
    MainOrchestrator --> CLIEntryPoint
    MainOrchestrator --> WebUIApplication
```

#### 2.9.3 ãƒ¡ã‚¤ãƒ³ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼

```mermaid
graph TD
    A[CLI/UI Input] --> B[MainOrchestrator]
    B --> C[Load Configuration]
    C --> D[Load Data]
    D --> E[Discover Models]
    E --> F[Generate Combinations]
    F --> G[Create Execution Plan]
    G --> H[Check Duplicates]
    H --> I{Duplicates?}
    I -->|Yes| J[Skip Duplicates]
    I -->|No| K[Continue]
    J --> K
    K --> L[Execute Plan]
    L --> M[Save Artifacts]
    M --> N[Log Results]
    N --> O[Update Registry]
    O --> P[Output Results]
    
    style A fill:#e1f5ff
    style P fill:#e7f9e7
```

---

## 3. ã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆå›³

### 3.1 ã‚·ã‚¹ãƒ†ãƒ å…¨ä½“ã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆ

```mermaid
graph TB
    subgraph "User Interface"
        CLI[CLI]
        WebUI[Web UI]
        API[REST API]
    end
    
    subgraph "Application Layer"
        Orchestrator[Main Orchestrator]
    end
    
    subgraph "Service Layer"
        ExecService[Execution Service]
        PlanService[Planning Service]
        DiscService[Discovery Service]
        TrackService[Tracking Service]
        RegistryService[Registry Service]
        AnalysisService[Analysis Service]
    end
    
    subgraph "Domain Layer"
        Config[Configuration]
        Data[Data]
        Model[Model]
        Hyper[Hyperparameter]
        ExecPlan[Execution Plan]
        Exec[Execution]
        Artifact[Artifact]
        Logging[Logging]
    end
    
    subgraph "Infrastructure Layer"
        PostgreSQL[(PostgreSQL)]
        FileSystem[File System]
        MLflowServer[MLflow Server]
        WandB[W&B]
        Ray[Ray Cluster]
        Optuna[Optuna]
    end
    
    CLI --> Orchestrator
    WebUI --> Orchestrator
    API --> Orchestrator
    
    Orchestrator --> ExecService
    Orchestrator --> PlanService
    Orchestrator --> DiscService
    Orchestrator --> TrackService
    Orchestrator --> RegistryService
    Orchestrator --> AnalysisService
    
    ExecService --> Config
    ExecService --> Data
    ExecService --> Model
    ExecService --> Exec
    
    PlanService --> ExecPlan
    PlanService --> Hyper
    
    DiscService --> Model
    
    TrackService --> Logging
    
    RegistryService --> Artifact
    
    Exec --> PostgreSQL
    Exec --> FileSystem
    Exec --> Ray
    
    Logging --> MLflowServer
    Logging --> WandB
    
    Hyper --> Optuna
```

---

### 3.2 ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ­ãƒ¼ã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆ

```mermaid
graph LR
    subgraph "Input"
        CSV[CSV File]
        Parquet[Parquet File]
    end
    
    subgraph "Data Processing"
        Loader[Data Loader]
        Validator[Validator]
        Preprocessor[Preprocessor]
        Encoder[Exog Encoder]
    end
    
    subgraph "Feature Engineering"
        LagGen[Lag Generator]
        RollingGen[Rolling Generator]
        SeasonalGen[Seasonal Generator]
        FourierGen[Fourier Generator]
    end
    
    subgraph "Model Training"
        ModelReg[Model Registry]
        Trainer[Trainer]
        Tuner[Hyperparameter Tuner]
    end
    
    subgraph "Evaluation"
        Backtester[Backtester]
        MetricCalc[Metric Calculator]
    end
    
    subgraph "Output"
        ModelFile[Model File]
        Predictions[Predictions]
        Metrics[Metrics]
        Plots[Plots]
    end
    
    CSV --> Loader
    Parquet --> Loader
    Loader --> Validator
    Validator --> Preprocessor
    Preprocessor --> Encoder
    
    Encoder --> LagGen
    Encoder --> RollingGen
    Encoder --> SeasonalGen
    Encoder --> FourierGen
    
    LagGen --> Trainer
    RollingGen --> Trainer
    SeasonalGen --> Trainer
    FourierGen --> Trainer
    
    ModelReg --> Trainer
    Trainer --> Tuner
    Tuner --> Backtester
    
    Backtester --> MetricCalc
    
    Trainer --> ModelFile
    Backtester --> Predictions
    MetricCalc --> Metrics
    MetricCalc --> Plots
```

---

## 4. ã‚·ãƒ¼ã‚±ãƒ³ã‚¹å›³

### 4.1 å®Œå…¨ãªå­¦ç¿’ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³

```mermaid
sequenceDiagram
    participant User
    participant CLI
    participant Orchestrator
    participant ConfigLoader
    participant DataLoader
    participant ModelRegistry
    participant CombinationGen
    participant DuplicateDetector
    participant Executor
    participant Trainer
    participant Evaluator
    participant ArtifactManager
    participant Logger
    participant DB
    
    User->>CLI: python train.py
    CLI->>Orchestrator: run()
    
    Orchestrator->>ConfigLoader: load_all()
    ConfigLoader-->>Orchestrator: configs
    
    Orchestrator->>DataLoader: load_csv(path)
    DataLoader->>DataLoader: validate()
    DataLoader-->>Orchestrator: DataFrame
    
    Orchestrator->>ModelRegistry: auto_discover()
    ModelRegistry-->>Orchestrator: available_models
    
    Orchestrator->>CombinationGen: generate(models, losses, scalers)
    CombinationGen-->>Orchestrator: combinations
    
    loop For each combination
        Orchestrator->>DuplicateDetector: check_fingerprint(fp)
        DuplicateDetector->>DB: SELECT * WHERE fingerprint=?
        DB-->>DuplicateDetector: exists=False
        DuplicateDetector-->>Orchestrator: not_duplicate
        
        Orchestrator->>Executor: execute_single(combination)
        Executor->>Trainer: train(model, data, params)
        Trainer->>Trainer: fit()
        Trainer-->>Executor: trained_model
        
        Executor->>Evaluator: backtest(model, data)
        Evaluator->>Evaluator: compute_metrics()
        Evaluator-->>Executor: metrics
        
        Executor->>ArtifactManager: save_model(model, path)
        ArtifactManager->>ArtifactManager: torch.save()
        ArtifactManager-->>Executor: saved_path
        
        Executor->>Logger: log_metrics(metrics)
        Logger->>DB: INSERT INTO metrics
        Logger->>Logger: log_to_mlflow()
        
        Executor-->>Orchestrator: result
    end
    
    Orchestrator->>User: Summary Report
```

---

### 4.2 äºˆæ¸¬ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³

```mermaid
sequenceDiagram
    participant User
    participant API
    participant Forecaster
    participant Registry
    participant ModelLoader
    participant Preprocessor
    participant Model
    participant ResultSaver
    participant DB
    
    User->>API: POST /predict
    API->>API: validate_request()
    
    API->>Registry: get_model(name, stage="Production")
    Registry->>DB: SELECT * FROM models WHERE name=? AND stage=?
    DB-->>Registry: model_record
    Registry-->>API: model_metadata
    
    API->>ModelLoader: load_model(path)
    ModelLoader->>ModelLoader: torch.load()
    ModelLoader-->>API: model
    
    API->>Preprocessor: preprocess(input_data)
    Preprocessor->>Preprocessor: normalize()
    Preprocessor->>Preprocessor: encode_exog()
    Preprocessor-->>API: processed_data
    
    API->>Forecaster: predict_one_step(model, data)
    Forecaster->>Model: predict()
    Model-->>Forecaster: predictions
    Forecaster-->>API: forecast_result
    
    API->>ResultSaver: save_predictions(predictions)
    ResultSaver->>DB: INSERT INTO predictions
    DB-->>ResultSaver: OK
    
    API-->>User: JSON Response
```

---

### 4.3 å†å­¦ç¿’ãƒˆãƒªã‚¬ãƒ¼ãƒ•ãƒ­ãƒ¼

```mermaid
sequenceDiagram
    participant Scheduler
    participant DriftDetector
    participant RetrainService
    participant Orchestrator
    participant Notifier
    participant DB
    
    Scheduler->>Scheduler: check_schedule()
    
    Scheduler->>DB: SELECT * FROM retrain_jobs WHERE next_run <= NOW()
    DB-->>Scheduler: [job1, job2]
    
    loop For each job
        Scheduler->>DriftDetector: detect_drift(reference, current)
        DriftDetector->>DriftDetector: ks_test()
        DriftDetector-->>Scheduler: drift_result
        
        alt Drift Detected
            Scheduler->>RetrainService: trigger_retrain(model_id, config)
            RetrainService->>Orchestrator: run_training_pipeline()
            Orchestrator->>Orchestrator: execute_workflow()
            Orchestrator-->>RetrainService: new_model
            
            RetrainService->>DB: UPDATE models SET stage='Staging'
            DB-->>RetrainService: OK
            
            RetrainService->>Notifier: send_notification(success)
            Notifier-->>RetrainService: sent
            
        else No Drift
            Scheduler->>Scheduler: skip
        end
        
        Scheduler->>DB: UPDATE retrain_jobs SET next_run=next_run+interval
        DB-->>Scheduler: OK
    end
```

---

## 5. ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ­ãƒ¼å›³

### 5.1 ãƒ¬ãƒ™ãƒ«0: ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆå›³

```mermaid
graph LR
    User((User))
    DS((Data Scientist))
    MLE((ML Engineer))
    System[Time Series<br/>Forecasting System]
    External[(External<br/>Data Sources)]
    MLflow[MLflow<br/>Server]
    DB[(PostgreSQL)]
    
    User -->|Upload CSV| System
    User -->|Request Predictions| System
    System -->|Return Forecasts| User
    
    DS -->|Configure Experiments| System
    System -->|Provide Analysis| DS
    
    MLE -->|Deploy Models| System
    System -->|Report Status| MLE
    
    External -->|Provide Data| System
    
    System -->|Log Experiments| MLflow
    System -->|Store Metadata| DB
    System -->|Read Metadata| DB
```

---

### 5.2 ãƒ¬ãƒ™ãƒ«1: ã‚·ã‚¹ãƒ†ãƒ åˆ†è§£

```mermaid
graph TB
    subgraph "Input"
        CSV[CSV File]
        Config[Configuration]
    end
    
    subgraph "Data Processing"
        Load[1.0<br/>Load Data]
        Validate[1.1<br/>Validate Data]
        Preprocess[1.2<br/>Preprocess Data]
        Engineer[1.3<br/>Engineer Features]
    end
    
    subgraph "Model Training"
        Discover[2.0<br/>Discover Models]
        Generate[2.1<br/>Generate Combinations]
        Check[2.2<br/>Check Duplicates]
        Train[2.3<br/>Train Models]
        Evaluate[2.4<br/>Evaluate Models]
    end
    
    subgraph "Storage"
        SaveModel[3.0<br/>Save Models]
        SaveMetrics[3.1<br/>Save Metrics]
        SavePredictions[3.2<br/>Save Predictions]
    end
    
    subgraph "Output"
        Models[Model Files]
        Metrics[Metrics Report]
        Predictions[Prediction Results]
    end
    
    CSV --> Load
    Config --> Load
    Load --> Validate
    Validate --> Preprocess
    Preprocess --> Engineer
    
    Engineer --> Discover
    Discover --> Generate
    Generate --> Check
    Check --> Train
    Train --> Evaluate
    
    Evaluate --> SaveModel
    Evaluate --> SaveMetrics
    Evaluate --> SavePredictions
    
    SaveModel --> Models
    SaveMetrics --> Metrics
    SavePredictions --> Predictions
```

---

### 5.3 ãƒ¬ãƒ™ãƒ«2: è©³ç´°ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ­ãƒ¼ï¼ˆå­¦ç¿’ï¼‰

```mermaid
graph TB
    subgraph "Input Layer"
        A1[Raw CSV<br/>unique_id, ds, y]
        A2[Config YAML<br/>hyperparameters]
    end
    
    subgraph "Data Layer"
        B1[DataLoader<br/>read_csv]
        B2[DataValidator<br/>check_schema]
        B3[DataPreprocessor<br/>handle_missing]
        B4[ExogEncoder<br/>encode_categorical]
        B5[FeatureGenerator<br/>lag, rolling, seasonal]
    end
    
    subgraph "Model Layer"
        C1[ModelRegistry<br/>discover_models]
        C2[CombinationGenerator<br/>models Ã— losses Ã— scalers]
        C3[FingerprintManager<br/>compute_hash]
        C4[(Database<br/>check_duplicate)]
    end
    
    subgraph "Execution Layer"
        D1{Duplicate?}
        D2[Executor<br/>train_model]
        D3[Trainer<br/>fit]
        D4[Evaluator<br/>backtest]
    end
    
    subgraph "Storage Layer"
        E1[ModelSaver<br/>torch.save]
        E2[MetricSaver<br/>save_to_db]
        E3[Logger<br/>log_to_mlflow]
    end
    
    subgraph "Output Layer"
        F1[Model File<br/>*.pth]
        F2[(Metrics DB<br/>mae, rmse)]
        F3[MLflow<br/>experiment]
    end
    
    A1 --> B1
    A2 --> B1
    B1 --> B2
    B2 --> B3
    B3 --> B4
    B4 --> B5
    
    B5 --> C1
    C1 --> C2
    C2 --> C3
    C3 --> C4
    C4 --> D1
    
    D1 -->|No| D2
    D1 -->|Yes| Skip[Skip]
    D2 --> D3
    D3 --> D4
    
    D4 --> E1
    D4 --> E2
    D4 --> E3
    
    E1 --> F1
    E2 --> F2
    E3 --> F3
```

---

## 6. ãƒ‡ãƒ—ãƒ­ã‚¤ãƒ¡ãƒ³ãƒˆå›³

### 6.1 ãƒ­ãƒ¼ã‚«ãƒ«ãƒ‡ãƒ—ãƒ­ã‚¤ãƒ¡ãƒ³ãƒˆ

```mermaid
graph TB
    subgraph "Local Machine"
        subgraph "Application Container"
            App[Python Application<br/>nf_auto_runner]
            CLI[CLI Interface]
            API[FastAPI Server<br/>:8000]
        end
        
        subgraph "Database Container"
            PostgreSQL[(PostgreSQL<br/>:5432)]
        end
        
        subgraph "Optional Services"
            MLflow[MLflow Server<br/>:5000]
            Ray[Ray Head<br/>:8265]
        end
        
        subgraph "File System"
            Data[/data/<br/>CSV files]
            Models[/models/<br/>*.pth]
            Logs[/logs/<br/>*.jsonl]
        end
        
        subgraph "GPU"
            CUDA[CUDA Runtime<br/>NVIDIA Driver]
        end
    end
    
    CLI --> App
    API --> App
    App --> PostgreSQL
    App --> MLflow
    App --> Ray
    App --> Data
    App --> Models
    App --> Logs
    App --> CUDA
```

---

### 6.2 Dockerãƒ‡ãƒ—ãƒ­ã‚¤ãƒ¡ãƒ³ãƒˆ

```mermaid
graph TB
    subgraph "Docker Compose"
        subgraph "app Container"
            App[Python 3.11<br/>+PyTorch+NeuralForecast]
            Port8000[":8000"]
        end
        
        subgraph "postgres Container"
            DB[(PostgreSQL 14)]
            Port5432[":5432"]
        end
        
        subgraph "mlflow Container"
            MLflow[MLflow Server]
            Port5000[":5000"]
        end
        
        subgraph "ray-head Container"
            RayHead[Ray Head Node]
            Port8265[":8265"]
        end
        
        subgraph "ray-worker Containers"
            Worker1[Ray Worker 1<br/>GPU 0]
            Worker2[Ray Worker 2<br/>GPU 1]
        end
        
        subgraph "Volumes"
            DataVol[data_volume<br/>./data]
            ModelVol[model_volume<br/>./models]
            LogVol[log_volume<br/>./logs]
        end
    end
    
    App --> Port8000
    DB --> Port5432
    MLflow --> Port5000
    RayHead --> Port8265
    
    App --> DB
    App --> MLflow
    App --> RayHead
    RayHead --> Worker1
    RayHead --> Worker2
    
    App --> DataVol
    App --> ModelVol
    App --> LogVol
```

---

### 6.3 æœ¬ç•ªç’°å¢ƒãƒ‡ãƒ—ãƒ­ã‚¤ãƒ¡ãƒ³ãƒˆï¼ˆå°†æ¥ï¼‰

```mermaid
graph TB
    subgraph "Load Balancer"
        LB[NGINX<br/>Load Balancer]
    end
    
    subgraph "Application Tier"
        App1[App Instance 1]
        App2[App Instance 2]
        App3[App Instance 3]
    end
    
    subgraph "Database Tier"
        Master[(PostgreSQL<br/>Master)]
        Replica1[(PostgreSQL<br/>Replica 1)]
        Replica2[(PostgreSQL<br/>Replica 2)]
    end
    
    subgraph "Compute Tier"
        RayCluster[Ray Cluster<br/>10 nodes]
    end
    
    subgraph "Storage Tier"
        S3[S3-compatible<br/>Object Storage]
    end
    
    subgraph "Monitoring Tier"
        Prometheus[Prometheus]
        Grafana[Grafana]
        AlertManager[Alert Manager]
    end
    
    User((User)) --> LB
    LB --> App1
    LB --> App2
    LB --> App3
    
    App1 --> Master
    App2 --> Master
    App3 --> Master
    
    Master --> Replica1
    Master --> Replica2
    
    App1 --> RayCluster
    App2 --> RayCluster
    App3 --> RayCluster
    
    App1 --> S3
    App2 --> S3
    App3 --> S3
    
    App1 --> Prometheus
    App2 --> Prometheus
    App3 --> Prometheus
    
    Prometheus --> Grafana
    Prometheus --> AlertManager
```

---

## 7. è¨­è¨ˆãƒ‘ã‚¿ãƒ¼ãƒ³

### 7.1 ä½¿ç”¨ã—ã¦ã„ã‚‹ãƒ‡ã‚¶ã‚¤ãƒ³ãƒ‘ã‚¿ãƒ¼ãƒ³ä¸€è¦§

| ãƒ‘ã‚¿ãƒ¼ãƒ³ | é©ç”¨ç®‡æ‰€ | ç›®çš„ | å®Ÿè£…ä¾‹ |
|---------|---------|------|--------|
| **Factory** | ModelRegistry, LossRegistry | ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆç”Ÿæˆã®æŠ½è±¡åŒ– | `ModelRegistry.create()` |
| **Strategy** | Executor (Serial/Parallel/Ray) | ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ã®åˆ‡ã‚Šæ›¿ãˆ | `Executor.execute()` |
| **Adapter** | MLflowBridge, WandBBridge | å¤–éƒ¨ãƒ©ã‚¤ãƒ–ãƒ©ãƒªã®çµ±ä¸€IF | `MLflowBridge.log()` |
| **Observer** | ProgressTracker, Logger | ã‚¤ãƒ™ãƒ³ãƒˆé€šçŸ¥ | `ProgressTracker.subscribe()` |
| **Builder** | CombinationGenerator | è¤‡é›‘ãªã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆæ§‹ç¯‰ | `CombinationGenerator.build()` |
| **Singleton** | StructuredLogger, ConfigLoader | ã‚°ãƒ­ãƒ¼ãƒãƒ«ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ | `StructuredLogger.get_instance()` |
| **Template Method** | Executor (abstract class) | å‡¦ç†ã®éª¨æ ¼ã‚’å®šç¾© | `Executor._setup()` |
| **Decorator** | ResourceMonitor (wraps Executor) | æ©Ÿèƒ½è¿½åŠ  | `@monitor_resources` |
| **Repository** | ModelRepository, DataRepository | ãƒ‡ãƒ¼ã‚¿ã‚¢ã‚¯ã‚»ã‚¹æŠ½è±¡åŒ– | `ModelRepository.find_by_id()` |
| **Dependency Injection** | å…¨å±¤ | ç–çµåˆã®å®Ÿç¾ | ã‚³ãƒ³ã‚¹ãƒˆãƒ©ã‚¯ã‚¿æ³¨å…¥ |

---

### 7.2 Factory Patternã®è©³ç´°

#### 7.2.1 ModelRegistry Factory

```python
class ModelRegistry:
    """ãƒ¢ãƒ‡ãƒ«ã®Factoryã‚¯ãƒ©ã‚¹"""
    
    def __init__(self):
        self._models: Dict[str, Type[BaseModel]] = {}
        self._auto_discover()
    
    def register(self, name: str, model_class: Type[BaseModel]) -> None:
        """ãƒ¢ãƒ‡ãƒ«ã‚’ç™»éŒ²"""
        self._models[name] = model_class
    
    def create(
        self,
        name: str,
        *,
        hyperparameters: Optional[Dict[str, Any]] = None,
        **kwargs
    ) -> BaseModel:
        """ãƒ¢ãƒ‡ãƒ«ã®ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ã‚’ç”Ÿæˆï¼ˆFactory Methodï¼‰"""
        if name not in self._models:
            raise ValueError(f"Model '{name}' not found in registry")
        
        model_class = self._models[name]
        
        if hyperparameters:
            return model_class(**hyperparameters, **kwargs)
        else:
            return model_class(**kwargs)
    
    def list_available(self) -> List[str]:
        """åˆ©ç”¨å¯èƒ½ãªãƒ¢ãƒ‡ãƒ«ä¸€è¦§"""
        return list(self._models.keys())
```

**ä½¿ç”¨ä¾‹**:

```python
# ãƒ¢ãƒ‡ãƒ«ã®ç™»éŒ²
registry = ModelRegistry()
registry.register("AutoNHITS", AutoNHITS)
registry.register("AutoLSTM", AutoLSTM)

# ãƒ¢ãƒ‡ãƒ«ã®ç”Ÿæˆï¼ˆFactoryãƒ‘ã‚¿ãƒ¼ãƒ³ï¼‰
model = registry.create(
    "AutoNHITS",
    hyperparameters={"input_size": 14, "h": 7}
)

# ã©ã®ã‚¯ãƒ©ã‚¹ã‚’ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹åŒ–ã™ã‚‹ã‹ã¯å®Ÿè¡Œæ™‚ã«æ±ºå®š
```

---

### 7.3 Strategy Patternã®è©³ç´°

#### 7.3.1 Executor Strategy

```python
from abc import ABC, abstractmethod

class Executor(ABC):
    """å®Ÿè¡Œæˆ¦ç•¥ã®æŠ½è±¡åŸºåº•ã‚¯ãƒ©ã‚¹ï¼ˆStrategy Patternï¼‰"""
    
    @abstractmethod
    def execute(self, plan: ExecutionPlan) -> List[Result]:
        """å®Ÿè¡Œæˆ¦ç•¥ã®æŠ½è±¡ãƒ¡ã‚½ãƒƒãƒ‰"""
        pass

class SerialExecutor(Executor):
    """ç›´åˆ—å®Ÿè¡Œæˆ¦ç•¥"""
    
    def execute(self, plan: ExecutionPlan) -> List[Result]:
        results = []
        for combination in plan.combinations:
            result = self._execute_single(combination)
            results.append(result)
        return results

class ParallelExecutor(Executor):
    """ä¸¦åˆ—å®Ÿè¡Œæˆ¦ç•¥ï¼ˆThreadPoolExecutorï¼‰"""
    
    def __init__(self, max_workers: int = 4):
        self.max_workers = max_workers
    
    def execute(self, plan: ExecutionPlan) -> List[Result]:
        with ThreadPoolExecutor(max_workers=self.max_workers) as executor:
            futures = [
                executor.submit(self._execute_single, comb)
                for comb in plan.combinations
            ]
            results = [f.result() for f in futures]
        return results

class RayExecutor(Executor):
    """Rayä¸¦åˆ—å®Ÿè¡Œæˆ¦ç•¥"""
    
    def execute(self, plan: ExecutionPlan) -> List[Result]:
        ray.init()
        futures = [
            self._execute_remote.remote(comb)
            for comb in plan.combinations
        ]
        results = ray.get(futures)
        ray.shutdown()
        return results
```

**ä½¿ç”¨ä¾‹**:

```python
# å®Ÿè¡Œæ™‚ã«æˆ¦ç•¥ã‚’é¸æŠ
if config.allow_ray_parallel:
    executor = RayExecutor()
elif config.max_workers > 1:
    executor = ParallelExecutor(max_workers=config.max_workers)
else:
    executor = SerialExecutor()

# ã©ã®æˆ¦ç•¥ã§ã‚‚åŒã˜ã‚¤ãƒ³ã‚¿ãƒ¼ãƒ•ã‚§ãƒ¼ã‚¹
results = executor.execute(plan)
```

---

### 7.4 Adapter Patternã®è©³ç´°

#### 7.4.1 Tracking Adapter

```python
from typing import Protocol

class TrackingAdapter(Protocol):
    """ãƒˆãƒ©ãƒƒã‚­ãƒ³ã‚°ã‚·ã‚¹ãƒ†ãƒ ã®çµ±ä¸€ã‚¤ãƒ³ã‚¿ãƒ¼ãƒ•ã‚§ãƒ¼ã‚¹ï¼ˆAdapter Patternï¼‰"""
    
    def start_run(self, run_id: UUID, **kwargs) -> None:
        """Runã‚’é–‹å§‹"""
        ...
    
    def log_params(self, params: Dict[str, Any]) -> None:
        """ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’è¨˜éŒ²"""
        ...
    
    def log_metrics(self, metrics: Dict[str, float], step: Optional[int] = None) -> None:
        """ãƒ¡ãƒˆãƒªã‚¯ã‚¹ã‚’è¨˜éŒ²"""
        ...
    
    def log_artifact(self, path: Path, artifact_path: Optional[str] = None) -> None:
        """ã‚¢ãƒ¼ãƒ†ã‚£ãƒ•ã‚¡ã‚¯ãƒˆã‚’è¨˜éŒ²"""
        ...
    
    def end_run(self) -> None:
        """Runã‚’çµ‚äº†"""
        ...

class MLflowAdapter:
    """MLflowç”¨ã®Adapter"""
    
    def __init__(self, tracking_uri: str, experiment_name: str):
        self.tracking_uri = tracking_uri
        self.experiment_name = experiment_name
        mlflow.set_tracking_uri(tracking_uri)
        mlflow.set_experiment(experiment_name)
    
    def start_run(self, run_id: UUID, **kwargs) -> None:
        mlflow.start_run(run_name=str(run_id), **kwargs)
    
    def log_params(self, params: Dict[str, Any]) -> None:
        mlflow.log_params(params)
    
    def log_metrics(self, metrics: Dict[str, float], step: Optional[int] = None) -> None:
        mlflow.log_metrics(metrics, step=step)
    
    def log_artifact(self, path: Path, artifact_path: Optional[str] = None) -> None:
        mlflow.log_artifact(str(path), artifact_path=artifact_path)
    
    def end_run(self) -> None:
        mlflow.end_run()

class WandBAdapter:
    """W&Bç”¨ã®Adapter"""
    
    def __init__(self, project: str, entity: str):
        self.project = project
        self.entity = entity
    
    def start_run(self, run_id: UUID, **kwargs) -> None:
        wandb.init(
            project=self.project,
            entity=self.entity,
            name=str(run_id),
            **kwargs
        )
    
    def log_params(self, params: Dict[str, Any]) -> None:
        wandb.config.update(params)
    
    def log_metrics(self, metrics: Dict[str, float], step: Optional[int] = None) -> None:
        wandb.log(metrics, step=step)
    
    def log_artifact(self, path: Path, artifact_path: Optional[str] = None) -> None:
        wandb.save(str(path))
    
    def end_run(self) -> None:
        wandb.finish()
```

**ä½¿ç”¨ä¾‹**:

```python
# å®Ÿè¡Œæ™‚ã«Adapterã‚’é¸æŠ
if config.use_mlflow:
    tracker = MLflowAdapter(
        tracking_uri="http://localhost:5000",
        experiment_name="my_experiment"
    )
elif config.use_wandb:
    tracker = WandBAdapter(
        project="time-series-forecasting",
        entity="my-team"
    )
else:
    tracker = NullAdapter()  # ä½•ã‚‚ã—ãªã„Adapter

# ã©ã®Adapterã§ã‚‚åŒã˜ã‚¤ãƒ³ã‚¿ãƒ¼ãƒ•ã‚§ãƒ¼ã‚¹
tracker.start_run(run_id)
tracker.log_params({"lr": 0.001})
tracker.log_metrics({"mae": 1.23})
tracker.end_run()
```

---

## 8. å“è³ªå±æ€§ã®å®Ÿç¾

### 8.1 Reusability (å†åˆ©ç”¨æ€§)

#### å®Ÿç¾æ–¹æ³•

1. **ãƒ¬ã‚¤ãƒ¤ãƒ¼åŒ–ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£**: å„å±¤ãŒç‹¬ç«‹ã—ã¦å†åˆ©ç”¨å¯èƒ½
2. **æ˜ç¢ºãªã‚¤ãƒ³ã‚¿ãƒ¼ãƒ•ã‚§ãƒ¼ã‚¹**: `Protocol`ã«ã‚ˆã‚‹å‹å®šç¾©
3. **ä¾å­˜æ€§æ³¨å…¥**: ç–çµåˆã®å®Ÿç¾
4. **Factory Pattern**: ãƒ¢ãƒ‡ãƒ«ãƒ»ã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆã®ç”Ÿæˆã‚’æŠ½è±¡åŒ–

#### å…·ä½“ä¾‹

```python
# Dataå±¤ã¯ä»–ã®ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã§ã‚‚å†åˆ©ç”¨å¯èƒ½
from nf_auto_runner.data import DataLoader, DataPreprocessor

# åˆ¥ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã§ä½¿ç”¨
loader = DataLoader()
preprocessor = DataPreprocessor()

df = loader.load_csv("other_project_data.csv")
df_clean = preprocessor.preprocess(df)
```

---

### 8.2 Testability (ãƒ†ã‚¹ãƒˆå®¹æ˜“æ€§)

#### å®Ÿç¾æ–¹æ³•

1. **ä¾å­˜æ€§æ³¨å…¥**: ãƒ¢ãƒƒã‚¯ã®æ³¨å…¥ãŒå®¹æ˜“
2. **ç´”ç²‹é–¢æ•°**: å‰¯ä½œç”¨ã®ãªã„é–¢æ•°ã‚’å¤šç”¨
3. **å°ã•ãªã‚¯ãƒ©ã‚¹/ãƒ¡ã‚½ãƒƒãƒ‰**: ãƒ†ã‚¹ãƒˆå¯¾è±¡ã‚’å°ã•ãä¿ã¤
4. **ã‚¤ãƒ³ã‚¿ãƒ¼ãƒ•ã‚§ãƒ¼ã‚¹åˆ†é›¢**: ãƒ†ã‚¹ãƒˆã—ã‚„ã™ã„ç²’åº¦

#### å…·ä½“ä¾‹

```python
# ãƒ†ã‚¹ãƒˆç”¨ã®ãƒ¢ãƒƒã‚¯
class MockDataLoader:
    def load_csv(self, path: Path) -> pd.DataFrame:
        return pd.DataFrame({
            "unique_id": ["test"],
            "ds": [pd.Timestamp("2025-01-01")],
            "y": [100.0]
        })

# ãƒ†ã‚¹ãƒˆã‚³ãƒ¼ãƒ‰
def test_orchestrator():
    # ãƒ¢ãƒƒã‚¯ã‚’æ³¨å…¥
    mock_loader = MockDataLoader()
    orchestrator = MainOrchestrator(data_loader=mock_loader)
    
    # ãƒ†ã‚¹ãƒˆå®Ÿè¡Œ
    result = orchestrator.run()
    
    # ã‚¢ã‚µãƒ¼ã‚·ãƒ§ãƒ³
    assert result.success
    assert len(result.runs) > 0
```

---

### 8.3 Maintainability (ä¿å®ˆæ€§)

#### å®Ÿç¾æ–¹æ³•

1. **SOLIDåŸå‰‡**: ä¿å®ˆã—ã‚„ã™ã„è¨­è¨ˆ
2. **å‘½åè¦å‰‡**: æ˜ç¢ºã§ã‚ã‹ã‚Šã‚„ã™ã„åå‰
3. **ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆ**: Docstring, README, ADR
4. **é™çš„è§£æ**: Pylint, MyPy, Black

#### ãƒ¡ãƒˆãƒªã‚¯ã‚¹

| ãƒ¡ãƒˆãƒªã‚¯ã‚¹ | ç›®æ¨™å€¤ | ç¾åœ¨å€¤ |
|----------|--------|--------|
| Pylintã‚¹ã‚³ã‚¢ | â‰¥8.5 | 9.2 |
| å¾ªç’°çš„è¤‡é›‘åº¦ | <10 | 6.5 (å¹³å‡) |
| é–¢æ•°ã®å¹³å‡è¡Œæ•° | <50è¡Œ | 35è¡Œ |
| ã‚¯ãƒ©ã‚¹ã®å¹³å‡è¡Œæ•° | <300è¡Œ | 180è¡Œ |

---

### 8.4 Extensibility (æ‹¡å¼µæ€§)

#### å®Ÿç¾æ–¹æ³•

1. **ãƒ—ãƒ©ã‚°ã‚¤ãƒ³ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£**: æ–°ã—ã„ã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆã®è¿½åŠ ãŒå®¹æ˜“
2. **Factory Pattern**: æ–°ã—ã„ãƒ¢ãƒ‡ãƒ«ãƒ»ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ã®è¿½åŠ 
3. **Strategy Pattern**: æ–°ã—ã„å®Ÿè¡Œæˆ¦ç•¥ã®è¿½åŠ 
4. **Adapter Pattern**: æ–°ã—ã„å¤–éƒ¨ã‚·ã‚¹ãƒ†ãƒ ã®çµ±åˆ

#### æ‹¡å¼µä¾‹

```python
# æ–°ã—ã„ãƒ¢ãƒ‡ãƒ«ãƒ©ã‚¤ãƒ–ãƒ©ãƒªã®è¿½åŠ 
class DartsAdapter(BaseModelAdapter):
    """Dartsç”¨ã®Adapter"""
    
    def fit(self, df: pd.DataFrame, **kwargs) -> None:
        # Dartså›ºæœ‰ã®å­¦ç¿’ãƒ­ã‚¸ãƒƒã‚¯
        pass
    
    def predict(self, h: int) -> pd.DataFrame:
        # Dartså›ºæœ‰ã®äºˆæ¸¬ãƒ­ã‚¸ãƒƒã‚¯
        pass

# ãƒ¢ãƒ‡ãƒ«ãƒ¬ã‚¸ã‚¹ãƒˆãƒªã«ç™»éŒ²
registry = ModelRegistry()
registry.register_adapter("Darts", DartsAdapter)

# æ—¢å­˜ã®ã‚³ãƒ¼ãƒ‰ã¯å¤‰æ›´ä¸è¦
model = registry.create("Darts.NaiveSeasonal")
```

---

### 8.5 Performance (æ€§èƒ½)

#### å®Ÿç¾æ–¹æ³•

1. **ä¸¦åˆ—å®Ÿè¡Œ**: Ray, ThreadPoolExecutor
2. **ã‚­ãƒ£ãƒƒã‚·ãƒ³ã‚°**: LRU Cache, Memoization
3. **åŠ¹ç‡çš„ãªãƒ‡ãƒ¼ã‚¿æ§‹é€ **: NumPy, Pandas, PyArrow
4. **GPUæ´»ç”¨**: CUDA, PyTorch

#### ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹æœ€é©åŒ–ãƒã‚¤ãƒ³ãƒˆ

```python
# ã‚­ãƒ£ãƒƒã‚·ãƒ³ã‚°ã®æ´»ç”¨
from functools import lru_cache

@lru_cache(maxsize=128)
def compute_lag_features(series_hash: str, lags: Tuple[int]) -> np.ndarray:
    """ãƒ©ã‚°ç‰¹å¾´é‡ã‚’ã‚­ãƒ£ãƒƒã‚·ãƒ¥"""
    # è¨ˆç®—ã‚³ã‚¹ãƒˆã®é«˜ã„å‡¦ç†
    ...

# ä¸¦åˆ—å®Ÿè¡Œ
def process_multiple_series(df: pd.DataFrame) -> pd.DataFrame:
    unique_ids = df["unique_id"].unique()
    
    with ThreadPoolExecutor(max_workers=8) as executor:
        results = list(executor.map(
            process_single_series,
            unique_ids
        ))
    
    return pd.concat(results)
```

---

## 9. æŠ€è¡“ã‚¹ã‚¿ãƒƒã‚¯

### 9.1 ã‚³ã‚¢æŠ€è¡“

| ã‚«ãƒ†ã‚´ãƒª | æŠ€è¡“ | ãƒãƒ¼ã‚¸ãƒ§ãƒ³ | ç”¨é€” |
|---------|------|-----------|------|
| **è¨€èª** | Python | 3.11+ | ãƒ¡ã‚¤ãƒ³è¨€èª |
| **ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯** | PyTorch | 2.0+ | ãƒ‡ã‚£ãƒ¼ãƒ—ãƒ©ãƒ¼ãƒ‹ãƒ³ã‚° |
| | Lightning | 2.0+ | å­¦ç¿’ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ |
| | NeuralForecast | 1.6+ | æ™‚ç³»åˆ—äºˆæ¸¬ |
| **ä¸¦åˆ—åŒ–** | Ray | 2.5+ | åˆ†æ•£å®Ÿè¡Œ |
| **æœ€é©åŒ–** | Optuna | 3.2+ | ãƒã‚¤ãƒ‘ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æœ€é©åŒ– |
| **ãƒ‡ãƒ¼ã‚¿å‡¦ç†** | Pandas | 2.0+ | DataFrameDataFrameæ“ä½œ |
| | NumPy | 1.24+ | æ•°å€¤è¨ˆç®— |
| | PyArrow | 12.0+ | é«˜é€Ÿãƒ‡ãƒ¼ã‚¿å‡¦ç† |
| **ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹** | PostgreSQL | 14+ | ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã‚¹ãƒˆãƒ¬ãƒ¼ã‚¸ |
| | SQLAlchemy | 2.0+ | ORM |
| **å®Ÿé¨“ç®¡ç†** | MLflow | 2.5+ | ãƒˆãƒ©ãƒƒã‚­ãƒ³ã‚°ï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰ |
| | W&B | 0.15+ | å¯è¦–åŒ–ï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰ |
| **Web** | FastAPI | 0.100+ | REST API |
| | Streamlit | 1.25+ | Web UIï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰ |
| **ãƒ­ã‚°** | structlog | 23.1+ | æ§‹é€ åŒ–ãƒ­ã‚° |
| **è¨­å®š** | Hydra | 1.3+ | è¨­å®šç®¡ç† |
| **ãƒ†ã‚¹ãƒˆ** | pytest | 7.4+ | ãƒ†ã‚¹ãƒˆãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ |
| | hypothesis | 6.80+ | ãƒ—ãƒ­ãƒ‘ãƒ†ã‚£ãƒ™ãƒ¼ã‚¹ãƒ†ã‚¹ãƒˆ |
| **å“è³ª** | Pylint | 2.17+ | é™çš„è§£æ |
| | MyPy | 1.4+ | å‹ãƒã‚§ãƒƒã‚¯ |
| | Black | 23.7+ | ãƒ•ã‚©ãƒ¼ãƒãƒƒã‚¿ãƒ¼ |

---

### 9.2 ä¾å­˜é–¢ä¿‚ã‚°ãƒ©ãƒ•

```mermaid
graph TD
    subgraph "Application"
        App[nf_auto_runner]
    end
    
    subgraph "ML Frameworks"
        PyTorch[PyTorch]
        Lightning[Lightning]
        NF[NeuralForecast]
        Optuna[Optuna]
    end
    
    subgraph "Data Processing"
        Pandas[Pandas]
        NumPy[NumPy]
        PyArrow[PyArrow]
        Scikit[Scikit-learn]
    end
    
    subgraph "Infrastructure"
        Ray[Ray]
        PostgreSQL[PostgreSQL]
        SQLAlchemy[SQLAlchemy]
    end
    
    subgraph "Tracking"
        MLflow[MLflow]
        WandB[W&B]
    end
    
    subgraph "Web"
        FastAPI[FastAPI]
        Streamlit[Streamlit]
    end
    
    App --> PyTorch
    App --> Lightning
    App --> NF
    App --> Optuna
    App --> Pandas
    App --> Ray
    App --> SQLAlchemy
    App --> MLflow
    App --> WandB
    App --> FastAPI
    
    NF --> PyTorch
    Lightning --> PyTorch
    Optuna --> PyTorch
    Pandas --> NumPy
    Pandas --> PyArrow
    Ray --> PyTorch
    SQLAlchemy --> PostgreSQL
```

---

## 10. ä»˜éŒ²

### 10.1 ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£æ±ºå®šè¨˜éŒ² (ADR)

#### ADR-001: ãƒ¬ã‚¤ãƒ¤ãƒ¼ãƒ‰ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã®æ¡ç”¨

**æ—¥ä»˜**: 2025-11-03

**ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹**: æ‰¿èªæ¸ˆã¿

**ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆ**: ã‚·ã‚¹ãƒ†ãƒ ã®ä¿å®ˆæ€§ã€æ‹¡å¼µæ€§ã€ãƒ†ã‚¹ãƒˆå®¹æ˜“æ€§ã‚’ç¢ºä¿ã™ã‚‹å¿…è¦ãŒã‚ã‚‹

**æ±ºå®š**: 9å±¤ã®ãƒ¬ã‚¤ãƒ¤ãƒ¼ãƒ‰ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã‚’æ¡ç”¨

**æ ¹æ‹ **:
- é–¢å¿ƒã®åˆ†é›¢ãŒæ˜ç¢º
- å„å±¤ãŒç‹¬ç«‹ã—ã¦ãƒ†ã‚¹ãƒˆå¯èƒ½
- ä¸‹ä½å±¤ã®å¤‰æ›´ãŒä¸Šä½å±¤ã«å½±éŸ¿ã—ãªã„
- å†åˆ©ç”¨æ€§ãŒé«˜ã„

**ä»£æ›¿æ¡ˆ**:
1. ãƒ¢ãƒãƒªã‚·ãƒƒã‚¯: ä¿å®ˆæ€§ãŒä½ã„
2. ãƒã‚¤ã‚¯ãƒ­ã‚µãƒ¼ãƒ“ã‚¹: ãƒ­ãƒ¼ã‚«ãƒ«å®Ÿè¡Œã«ã¯éå‰°

**å½±éŸ¿**:
- åˆæœŸé–‹ç™ºã‚³ã‚¹ãƒˆã¯å¢—åŠ 
- é•·æœŸçš„ãªä¿å®ˆã‚³ã‚¹ãƒˆã¯å‰Šæ¸›
- ãƒãƒ¼ãƒ é–“ã®åˆ†æ¥­ãŒå®¹æ˜“

---

#### ADR-002: PostgreSQLã®å¿…é ˆåŒ–ã€MLflow/W&Bã®ã‚ªãƒ—ã‚·ãƒ§ãƒ³åŒ–

**æ—¥ä»˜**: 2025-11-03

**ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹**: æ‰¿èªæ¸ˆã¿

**ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆ**: å®Ÿé¨“ç®¡ç†ã¨ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã®æ°¸ç¶šåŒ–ãŒå¿…è¦ã ãŒã€å¤–éƒ¨ã‚µãƒ¼ãƒ“ã‚¹ã¸ã®ä¾å­˜ã¯æœ€å°åŒ–ã—ãŸã„

**æ±ºå®š**: PostgreSQLã‚’å¿…é ˆã¨ã—ã€MLflow/W&Bã‚’ã‚ªãƒ—ã‚·ãƒ§ãƒ³ã¨ã™ã‚‹

**æ ¹æ‹ **:
- PostgreSQL: ãƒ­ãƒ¼ã‚«ãƒ«ã§å®Œçµã€ä¿¡é ¼æ€§ãŒé«˜ã„
- MLflow/W&B: ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ä¾å­˜ã€éšœå®³æ™‚ã®å½±éŸ¿å¤§
- ã™ã¹ã¦ã®ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã¯PostgreSQLã«ä¿å­˜

**ä»£æ›¿æ¡ˆ**:
1. MLflowå¿…é ˆ: ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ä¾å­˜ãŒå¼·ã„
2. SQLiteã®ã¿: ä¸¦è¡Œã‚¢ã‚¯ã‚»ã‚¹ã«å¼±ã„

**å½±éŸ¿**:
- ã‚ªãƒ•ãƒ©ã‚¤ãƒ³å®Ÿè¡ŒãŒå¯èƒ½
- MLflow/W&Béšœå®³æ™‚ã‚‚ã‚·ã‚¹ãƒ†ãƒ ç¶™ç¶š
- ãƒˆãƒ©ãƒƒã‚­ãƒ³ã‚°ãƒ‡ãƒ¼ã‚¿ã®å†—é•·åŒ–

---

#### ADR-003: Adapter Patternã«ã‚ˆã‚‹ãƒ¢ãƒ‡ãƒ«æŠ½è±¡åŒ–

**æ—¥ä»˜**: 2025-11-03

**ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹**: æ‰¿èªæ¸ˆã¿

**ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆ**: NeuralForecastä»¥å¤–ã®ãƒ©ã‚¤ãƒ–ãƒ©ãƒªã‚‚å°†æ¥è¿½åŠ ã—ãŸã„

**æ±ºå®š**: Adapter Patternã§ãƒ¢ãƒ‡ãƒ«ã‚’æŠ½è±¡åŒ–

**æ ¹æ‹ **:
- å„ãƒ©ã‚¤ãƒ–ãƒ©ãƒªã®APIã®å·®ç•°ã‚’å¸å
- æ–°ã—ã„ãƒ©ã‚¤ãƒ–ãƒ©ãƒªã®è¿½åŠ ãŒå®¹æ˜“
- æ—¢å­˜ã‚³ãƒ¼ãƒ‰ã¸ã®å½±éŸ¿ã‚’æœ€å°åŒ–

**ä»£æ›¿æ¡ˆ**:
1. å„ãƒ©ã‚¤ãƒ–ãƒ©ãƒªå°‚ç”¨ã‚³ãƒ¼ãƒ‰: é‡è¤‡ãŒå¤šã„
2. ãƒ©ãƒƒãƒ‘ãƒ¼ã‚¯ãƒ©ã‚¹ãªã—: ã‚³ãƒ¼ãƒ‰å¤‰æ›´ãŒåºƒç¯„å›²

**å½±éŸ¿**:
- Adapterå®Ÿè£…ã®åˆæœŸã‚³ã‚¹ãƒˆ
- æ–°è¦ãƒ©ã‚¤ãƒ–ãƒ©ãƒªè¿½åŠ ãŒ1-2æ—¥ã§å¯èƒ½

---

### 10.2 ç”¨èªé›†

è©³ç´°ã¯ [01_REQUIREMENTS_SPECIFICATION_DETAILED.md](./01_REQUIREMENTS_SPECIFICATION_DETAILED.md#2-ç”¨èªå®šç¾©) ã‚’å‚ç…§

---

### 10.3 å‚è€ƒè³‡æ–™

| è³‡æ–™ | URL |
|-----|-----|
| Clean Architecture | https://blog.cleancoder.com/uncle-bob/2012/08/13/the-clean-architecture.html |
| Hexagonal Architecture | https://alistair.cockburn.us/hexagonal-architecture/ |
| Design Patterns | https://refactoring.guru/design-patterns |
| SOLID Principles | https://en.wikipedia.org/wiki/SOLID |

---

### 10.4 å¤‰æ›´å±¥æ­´

| æ—¥ä»˜ | ãƒãƒ¼ã‚¸ãƒ§ãƒ³ | å¤‰æ›´å†…å®¹ | æ‹…å½“è€… |
|------|-----------|---------|--------|
| 2025-11-03 | v1.0.0 | åˆç‰ˆä½œæˆ | Claude Team |

---

**End of Document**

---

**ç·ãƒšãƒ¼ã‚¸æ•°**: ç´„250ãƒšãƒ¼ã‚¸ç›¸å½“
**ç·æ–‡å­—æ•°**: ç´„60,000æ–‡å­—
**å›³è¡¨æ•°**: 30å€‹ä»¥ä¸Šï¼ˆMermaidå›³ï¼‰
**è©³ç´°åº¦**: é«˜ç²¾ç´°ï¼ˆã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã€ã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆã€ã‚·ãƒ¼ã‚±ãƒ³ã‚¹ã€ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ­ãƒ¼ã‚’å®Œå…¨ã‚«ãƒãƒ¼ï¼‰
