# é–‹ç™ºãƒ«ãƒ¼ãƒ«ï¼†é«˜å“è³ªãƒ—ãƒ­ãƒ³ãƒ—ãƒˆå¤§å…¨
**Comprehensive Development Rules & High-Quality Prompt Guidebook**

---

## ğŸ“‹ ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆæƒ…å ±

| é …ç›® | å†…å®¹ |
|-----|------|
| **ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã‚¿ã‚¤ãƒˆãƒ«** | æ™‚ç³»åˆ—äºˆæ¸¬ã‚·ã‚¹ãƒ†ãƒ  é–‹ç™ºãƒ«ãƒ¼ãƒ«ï¼†é«˜å“è³ªãƒ—ãƒ­ãƒ³ãƒ—ãƒˆå¤§å…¨ |
| **ãƒãƒ¼ã‚¸ãƒ§ãƒ³** | v1.0.0 |
| **ä½œæˆæ—¥** | 2025-11-04 |
| **æœ€çµ‚æ›´æ–°æ—¥** | 2025-11-04 |
| **å¯¾è±¡ã‚·ã‚¹ãƒ†ãƒ ** | NeuralForecast Auto Runner + Time Series Forecasting System |
| **é©ç”¨ç¯„å›²** | å…¨é–‹ç™ºãƒ•ã‚§ãƒ¼ã‚ºã€å…¨Roleã«é©ç”¨ |
| **æº–æ‹ ** | ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆçµ±åˆè¨­è¨ˆæ›¸ã€ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°è¦ç´„ã€ãƒ†ã‚¹ãƒˆæˆ¦ç•¥ |

---

## ğŸ“š ç›®æ¬¡

### ç¬¬1éƒ¨: é–‹ç™ºã®åŸºæœ¬åŸå‰‡
1. [å³æ ¼ãªé–‹ç™ºãƒ«ãƒ¼ãƒ«](#1-å³æ ¼ãªé–‹ç™ºãƒ«ãƒ¼ãƒ«)
2. [å“è³ªä¿è¨¼ã®åŸå‰‡](#2-å“è³ªä¿è¨¼ã®åŸå‰‡)
3. [é–‹ç™ºãƒ—ãƒ­ã‚»ã‚¹ã¨PDCA](#3-é–‹ç™ºãƒ—ãƒ­ã‚»ã‚¹ã¨pdca)

### ç¬¬2éƒ¨: Roleåˆ¥ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆ
4. [ãƒªãƒ¼ãƒ‰ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢Role](#4-ãƒªãƒ¼ãƒ‰ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢role)
5. [ã‚¤ãƒ³ã‚·ãƒ‡ãƒ³ãƒˆå¯¾å¿œRole](#5-ã‚¤ãƒ³ã‚·ãƒ‡ãƒ³ãƒˆå¯¾å¿œrole)
6. [ä»•æ§˜åˆ†æRole](#6-ä»•æ§˜åˆ†ærole)
7. [ç’°å¢ƒãƒã‚§ãƒƒã‚¯Role](#7-ç’°å¢ƒãƒã‚§ãƒƒã‚¯role)
8. [ã‚³ãƒ¼ãƒ‰ç”ŸæˆRole](#8-ã‚³ãƒ¼ãƒ‰ç”Ÿæˆrole)
9. [ãƒ‡ãƒãƒƒã‚°&ãƒˆãƒ©ãƒ–ãƒ«ã‚·ãƒ¥ãƒ¼ãƒˆRole](#9-ãƒ‡ãƒãƒƒã‚°ãƒˆãƒ©ãƒ–ãƒ«ã‚·ãƒ¥ãƒ¼ãƒˆrole)
10. [ãƒ†ã‚¹ãƒˆè¨­è¨ˆRole](#10-ãƒ†ã‚¹ãƒˆè¨­è¨ˆrole)
11. [å“è³ªè©•ä¾¡Role](#11-å“è³ªè©•ä¾¡role)

### ç¬¬3éƒ¨: å®Ÿè·µã‚¬ã‚¤ãƒ‰
12. [é–‹ç™ºãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼](#12-é–‹ç™ºãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼)
13. [å“è³ªãƒã‚§ãƒƒã‚¯ãƒªã‚¹ãƒˆ](#13-å“è³ªãƒã‚§ãƒƒã‚¯ãƒªã‚¹ãƒˆ)
14. [ãƒ™ã‚¹ãƒˆãƒ—ãƒ©ã‚¯ãƒ†ã‚£ã‚¹é›†](#14-ãƒ™ã‚¹ãƒˆãƒ—ãƒ©ã‚¯ãƒ†ã‚£ã‚¹é›†)

### ç¬¬4éƒ¨: ä»˜éŒ²
15. [ç”¨èªé›†](#15-ç”¨èªé›†)
16. [å‚è€ƒè³‡æ–™](#16-å‚è€ƒè³‡æ–™)
17. [FAQ](#17-faq)

---

# ç¬¬1éƒ¨: é–‹ç™ºã®åŸºæœ¬åŸå‰‡

## 1. å³æ ¼ãªé–‹ç™ºãƒ«ãƒ¼ãƒ«

æœ¬ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã§ã¯ã€ä»¥ä¸‹ã®**8ã¤ã®å³æ ¼ãªãƒ«ãƒ¼ãƒ«**ã‚’å¿…ãšéµå®ˆã—ã¾ã™ã€‚

---

### 1.1 çœŸå½ã®æ¤œè¨¼ãƒ«ãƒ¼ãƒ«

#### åŸå‰‡
ã™ã¹ã¦ã®ä¸»å¼µã€å®Ÿè£…ã€è¨­è¨ˆæ±ºå®šã¯ã€**ä¸€æ¬¡æƒ…å ±ï¼ˆå…¬å¼ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆ/æ¨™æº–ä»•æ§˜/å®Ÿæ¸¬ãƒ‡ãƒ¼ã‚¿ï¼‰**ã§è£ä»˜ã‘ã‚‹ã“ã¨ã€‚

#### å®Ÿè·µæ–¹æ³•

```markdown
## âœ… è‰¯ã„ä¾‹

### ä¸»å¼µ
NeuralForecastã®`AutoNHITS`ã¯ã€æ™‚ç³»åˆ—ã®ãƒˆãƒ¬ãƒ³ãƒ‰ã¨å­£ç¯€æ€§ã‚’è‡ªå‹•æ¤œå‡ºã§ãã‚‹ã€‚

### æ ¹æ‹ 
- **å‡ºå…¸**: NeuralForecastå…¬å¼ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆ v1.7.2
- **URL**: https://nixtlaverse.nixtla.io/neuralforecast/models.nhits.html
- **è©²å½“ç®‡æ‰€**: Section 3.2 "Architecture - Multi-rate Encoder"
- **å¼•ç”¨**: "AutoNHITS automatically detects seasonality and trend patterns using hierarchical interpolation."
- **å®Ÿæ¸¬**: ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ï¼ˆAir Passengersï¼‰ã§å­£ç¯€æˆåˆ†æ¤œå‡ºç‡98.3%ã‚’ç¢ºèª

### æ¤œè¨¼æ‰‹é †
```python
# å®Ÿæ¸¬ã‚³ãƒ¼ãƒ‰
from neuralforecast.models import AutoNHITS
model = AutoNHITS(h=12)
model.fit(train_data)
predictions = model.predict()
# å­£ç¯€æˆåˆ†ã®æ¤œå‡ºã‚’ç¢ºèª
```
```

```markdown
## âŒ æ‚ªã„ä¾‹

### ä¸»å¼µ
NeuralForecastã¯å„ªã‚Œã¦ã„ã‚‹ã€‚

### å•é¡Œç‚¹
- æ ¹æ‹ ãŒä¸æ˜ï¼ˆã©ã®è¦³ç‚¹ã§å„ªã‚Œã¦ã„ã‚‹ã®ã‹ï¼Ÿï¼‰
- ä¸€æ¬¡æƒ…å ±ã®å¼•ç”¨ãªã—
- å®Ÿæ¸¬ãƒ‡ãƒ¼ã‚¿ãªã—
- ä¸»è¦³çš„ãªæ–­å®š
```

#### ãƒã‚§ãƒƒã‚¯ãƒªã‚¹ãƒˆ

- [ ] **ä¸€æ¬¡æƒ…å ±ã®æ˜è¨˜**: å…¬å¼ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã€æ¨™æº–ä»•æ§˜ã€è«–æ–‡ã‚’å¼•ç”¨
- [ ] **ãƒãƒ¼ã‚¸ãƒ§ãƒ³æ˜è¨˜**: ãƒ©ã‚¤ãƒ–ãƒ©ãƒª/ãƒ„ãƒ¼ãƒ«ã®ãƒãƒ¼ã‚¸ãƒ§ãƒ³ã‚’è¨˜è¼‰
- [ ] **æ—¥ä»˜æ˜è¨˜**: æƒ…å ±ã®å–å¾—æ—¥æ™‚ã‚’è¨˜è¼‰
- [ ] **å®Ÿæ¸¬**: å¯èƒ½ãªé™ã‚Šå®Ÿæ¸¬ãƒ‡ãƒ¼ã‚¿ã§æ¤œè¨¼
- [ ] **å†ç¾æ‰‹é †**: ä»–è€…ãŒæ¤œè¨¼ã§ãã‚‹æ‰‹é †ã‚’æç¤º
- [ ] **åè¨¼å¯èƒ½æ€§**: ä¸»å¼µã‚’åè¨¼ã§ãã‚‹å½¢ã§è¨˜è¿°

---

### 1.2 å†ç¾æ€§ã®ç¢ºä¿ãƒ«ãƒ¼ãƒ«

#### åŸå‰‡
ã™ã¹ã¦ã®å®Ÿé¨“ã€å®Ÿè£…ã€ãƒ‡ãƒ—ãƒ­ã‚¤ã¯ã€**å®Œå…¨ã«å†ç¾å¯èƒ½**ã§ãªã‘ã‚Œã°ãªã‚‰ãªã„ã€‚

#### å®Ÿè·µæ–¹æ³•

**å¿…é ˆè¨˜éŒ²é …ç›®**:

```python
# config/reproducibility.py
from dataclasses import dataclass
from typing import Dict, Optional
import hashlib
import json

@dataclass
class ReproducibilityConfig:
    """å†ç¾æ€§ç¢ºä¿ã®ãŸã‚ã®è¨­å®š"""
    
    # 1. ç’°å¢ƒ
    python_version: str  # "3.11.5"
    os: str              # "Ubuntu 22.04.3 LTS"
    cuda_version: Optional[str] = None  # "12.1"
    
    # 2. ä¾å­˜é–¢ä¿‚ï¼ˆå®Œå…¨ãªãƒãƒ¼ã‚¸ãƒ§ãƒ³å›ºå®šï¼‰
    dependencies: Dict[str, str] = None  # {"neuralforecast": "1.7.2", ...}
    
    # 3. ä¹±æ•°ã‚·ãƒ¼ãƒ‰
    random_seed: int = 42
    numpy_seed: int = 42
    torch_seed: int = 42
    
    # 4. ãƒ‡ãƒ¼ã‚¿
    data_hash: str = ""  # SHA256ãƒãƒƒã‚·ãƒ¥
    data_source: str = ""
    data_version: str = ""
    
    # 5. å®Ÿè¡Œã‚³ãƒãƒ³ãƒ‰
    command: str = ""
    working_directory: str = ""
    
    # 6. ãƒã‚¤ãƒ‘ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿
    hyperparameters: Dict = None
    
    # 7. å®Ÿè¡Œæ™‚åˆ»
    execution_timestamp: str = ""
    
    def to_fingerprint(self) -> str:
        """è¨­å®šã‹ã‚‰ä¸€æ„ã®ãƒ•ã‚£ãƒ³ã‚¬ãƒ¼ãƒ—ãƒªãƒ³ãƒˆã‚’ç”Ÿæˆ"""
        config_dict = {
            "python": self.python_version,
            "os": self.os,
            "cuda": self.cuda_version,
            "deps": self.dependencies,
            "seeds": {
                "random": self.random_seed,
                "numpy": self.numpy_seed,
                "torch": self.torch_seed
            },
            "data_hash": self.data_hash,
            "hyperparams": self.hyperparameters
        }
        config_json = json.dumps(config_dict, sort_keys=True)
        return hashlib.sha256(config_json.encode()).hexdigest()
```

**è¨˜éŒ²ä¾‹**:

```yaml
# experiment_run_20251104_120530.yaml
run_id: "exp_001_run_042"
fingerprint: "a3f5c9d8e2b1..."

environment:
  python_version: "3.11.5"
  os: "Ubuntu 22.04.3 LTS"
  cuda_version: "12.1"
  hostname: "ml-workstation-01"

dependencies:
  neuralforecast: "1.7.2"
  torch: "2.1.0"
  pandas: "2.1.3"
  numpy: "1.26.2"

seeds:
  random: 42
  numpy: 42
  torch: 42
  torch_cuda: 42

data:
  source: "s3://myproject/data/train.csv"
  hash_sha256: "e3b0c44298fc1c149afb..."
  version: "v2.1.3"
  n_rows: 100000
  n_cols: 15

command: |
  python src/main.py \
    --config configs/experiment_001.yaml \
    --data data/train.csv \
    --output outputs/

hyperparameters:
  model: "AutoNHITS"
  h: 24
  input_size: 168
  learning_rate: 0.001
  batch_size: 32
  max_epochs: 100

execution:
  start_time: "2025-11-04T12:05:30.123456Z"
  end_time: "2025-11-04T13:42:15.987654Z"
  duration_seconds: 5805.864198
  
artifacts:
  - "outputs/model_checkpoint.pt"
  - "outputs/predictions.csv"
  - "mlflow_run://experiments/1/runs/abc123"
```

#### å†ç¾æ‰‹é †ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆ

```bash
#!/bin/bash
# reproduce_run_042.sh
# ã“ã®ã‚¹ã‚¯ãƒªãƒ—ãƒˆã§å®Ÿé¨“ã‚’å®Œå…¨å†ç¾ã§ãã‚‹

set -e  # ã‚¨ãƒ©ãƒ¼ã§åœæ­¢

# 1. ç’°å¢ƒç¢ºèª
echo "=== Environment Check ==="
python --version  # Python 3.11.5 æœŸå¾…
nvidia-smi  # CUDA 12.1 æœŸå¾…

# 2. ä¾å­˜é–¢ä¿‚ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«
pip install -r requirements_frozen.txt

# 3. ãƒ‡ãƒ¼ã‚¿æ¤œè¨¼
echo "=== Data Validation ==="
EXPECTED_HASH="e3b0c44298fc1c149afb..."
ACTUAL_HASH=$(sha256sum data/train.csv | awk '{print $1}')
if [ "$ACTUAL_HASH" != "$EXPECTED_HASH" ]; then
    echo "ERROR: Data hash mismatch!"
    exit 1
fi

# 4. å®Ÿè¡Œ
python src/main.py \
    --config configs/experiment_001.yaml \
    --data data/train.csv \
    --output outputs/ \
    --seed 42

# 5. çµæœæ¤œè¨¼
python scripts/verify_outputs.py \
    --expected outputs/expected_results.json \
    --actual outputs/predictions.csv
```

#### ãƒã‚§ãƒƒã‚¯ãƒªã‚¹ãƒˆ

- [ ] **ç’°å¢ƒè¨˜éŒ²**: Pythonã€OSã€CUDAã€ãƒ›ã‚¹ãƒˆå
- [ ] **ä¾å­˜é–¢ä¿‚å›ºå®š**: `requirements.txt`ã«ãƒãƒ¼ã‚¸ãƒ§ãƒ³å®Œå…¨æŒ‡å®š
- [ ] **ã‚·ãƒ¼ãƒ‰å›ºå®š**: å…¨ä¹±æ•°ç”Ÿæˆå™¨ã§ã‚·ãƒ¼ãƒ‰è¨­å®š
- [ ] **ãƒ‡ãƒ¼ã‚¿ãƒãƒƒã‚·ãƒ¥**: SHA256ã§å…¥åŠ›ãƒ‡ãƒ¼ã‚¿ã‚’æ¤œè¨¼
- [ ] **ã‚³ãƒãƒ³ãƒ‰è¨˜éŒ²**: å®Ÿè¡Œã—ãŸã‚³ãƒãƒ³ãƒ‰å®Œå…¨è¨˜éŒ²
- [ ] **ãƒã‚¤ãƒ‘ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿**: ã™ã¹ã¦ã®ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’YAML/JSONã§ä¿å­˜
- [ ] **æˆæœç‰©ä¿å­˜**: ãƒ¢ãƒ‡ãƒ«ã€äºˆæ¸¬ã€ãƒ­ã‚°ã‚’ãƒãƒ¼ã‚¸ãƒ§ãƒ³ç®¡ç†
- [ ] **å†ç¾ã‚¹ã‚¯ãƒªãƒ—ãƒˆ**: 1ã‚³ãƒãƒ³ãƒ‰ã§å†ç¾ã§ãã‚‹ã‚¹ã‚¯ãƒªãƒ—ãƒˆä½œæˆ

---

### 1.3 å¯è¦³æ¸¬æ€§ã®ç¢ºä¿ãƒ«ãƒ¼ãƒ«

#### åŸå‰‡
ã‚·ã‚¹ãƒ†ãƒ ã®å†…éƒ¨çŠ¶æ…‹ã€ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã€ã‚¨ãƒ©ãƒ¼ã‚’**å¸¸ã«å¯è¦–åŒ–ãƒ»è¿½è·¡å¯èƒ½**ã«ã™ã‚‹ã€‚

#### ä¸‰æœ¬æŸ±

1. **ãƒ­ã‚° (Logging)**
2. **ãƒ¡ãƒˆãƒªã‚¯ã‚¹ (Metrics)**
3. **ãƒˆãƒ¬ãƒ¼ã‚¹ (Tracing)**

#### å®Ÿè£…ä¾‹

```python
# logging/structured_logger.py
import logging
import json
import time
from typing import Any, Dict, Optional
from contextlib import contextmanager

class StructuredLogger:
    """æ§‹é€ åŒ–ãƒ­ã‚°å‡ºåŠ›"""
    
    def __init__(self, name: str, run_id: Optional[str] = None):
        self.logger = logging.getLogger(name)
        self.run_id = run_id or "unknown"
        
    def _build_log_entry(
        self,
        level: str,
        message: str,
        **kwargs
    ) -> Dict[str, Any]:
        """ãƒ­ã‚°ã‚¨ãƒ³ãƒˆãƒªã‚’æ§‹ç¯‰"""
        entry = {
            "timestamp": time.time(),
            "level": level,
            "run_id": self.run_id,
            "message": message
        }
        entry.update(kwargs)
        return entry
    
    def info(self, message: str, **kwargs):
        """INFO ãƒ­ã‚°"""
        entry = self._build_log_entry("INFO", message, **kwargs)
        self.logger.info(json.dumps(entry))
    
    def error(self, message: str, **kwargs):
        """ERROR ãƒ­ã‚°"""
        entry = self._build_log_entry("ERROR", message, **kwargs)
        self.logger.error(json.dumps(entry))
    
    @contextmanager
    def log_execution_time(self, operation: str, **metadata):
        """å®Ÿè¡Œæ™‚é–“ã‚’è¨˜éŒ²"""
        start_time = time.time()
        try:
            yield
        finally:
            duration = time.time() - start_time
            self.info(
                f"Operation completed: {operation}",
                operation=operation,
                duration_seconds=duration,
                **metadata
            )


# ä½¿ç”¨ä¾‹
logger = StructuredLogger("model_training", run_id="exp_001_run_042")

with logger.log_execution_time("data_loading", dataset="train.csv"):
    data = load_data("train.csv")

logger.info(
    "Training started",
    model="AutoNHITS",
    n_samples=len(data),
    n_features=data.shape[1]
)
```

```python
# monitoring/metrics_tracker.py
from typing import Dict, List
import time

class MetricsTracker:
    """ãƒ¡ãƒˆãƒªã‚¯ã‚¹è¿½è·¡"""
    
    def __init__(self):
        self.metrics: Dict[str, List[float]] = {}
        self.start_times: Dict[str, float] = {}
    
    def record(self, metric_name: str, value: float, tags: Dict[str, str] = None):
        """ãƒ¡ãƒˆãƒªã‚¯ã‚¹ã‚’è¨˜éŒ²"""
        if metric_name not in self.metrics:
            self.metrics[metric_name] = []
        
        entry = {
            "timestamp": time.time(),
            "value": value,
            "tags": tags or {}
        }
        self.metrics[metric_name].append(entry)
        
        # MLflowã«ã‚‚è¨˜éŒ²
        if mlflow.active_run():
            mlflow.log_metric(metric_name, value)
    
    def start_timer(self, operation: str):
        """ã‚¿ã‚¤ãƒãƒ¼é–‹å§‹"""
        self.start_times[operation] = time.time()
    
    def stop_timer(self, operation: str) -> float:
        """ã‚¿ã‚¤ãƒãƒ¼åœæ­¢ã€çµŒéæ™‚é–“ã‚’è¿”ã™"""
        if operation not in self.start_times:
            raise ValueError(f"Timer not started for {operation}")
        
        duration = time.time() - self.start_times[operation]
        self.record(f"duration_{operation}", duration)
        del self.start_times[operation]
        return duration
    
    def get_statistics(self, metric_name: str) -> Dict[str, float]:
        """ãƒ¡ãƒˆãƒªã‚¯ã‚¹ã®çµ±è¨ˆã‚’å–å¾—"""
        values = [entry["value"] for entry in self.metrics.get(metric_name, [])]
        if not values:
            return {}
        
        return {
            "count": len(values),
            "mean": np.mean(values),
            "std": np.std(values),
            "min": np.min(values),
            "max": np.max(values),
            "p50": np.percentile(values, 50),
            "p95": np.percentile(values, 95),
            "p99": np.percentile(values, 99)
        }


# ä½¿ç”¨ä¾‹
tracker = MetricsTracker()

tracker.start_timer("model_training")
model.fit(X_train, y_train)
training_duration = tracker.stop_timer("model_training")

tracker.record("training_loss", 0.123, tags={"epoch": "10", "model": "AutoNHITS"})
tracker.record("validation_mae", 42.5, tags={"epoch": "10", "split": "val"})
```

#### ä¿å­˜å…ˆã®æŒ‡å®š

| ç¨®é¡ | ä¿å­˜å…ˆ | å½¢å¼ | ä¿æŒæœŸé–“ |
|-----|--------|------|----------|
| **ãƒ­ã‚°** | `logs/structured/{date}.json` | JSON Lines | 90æ—¥ |
| **ãƒ¡ãƒˆãƒªã‚¯ã‚¹** | MLflow/PostgreSQL | Time Series | 1å¹´ |
| **ãƒ¢ãƒ‡ãƒ«** | `artifacts/models/{run_id}/` | pickle/torch | æ°¸ç¶š |
| **äºˆæ¸¬çµæœ** | PostgreSQL `predictions` | Table | 1å¹´ |
| **ãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰** | Grafana | - | ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ  |

#### ãƒã‚§ãƒƒã‚¯ãƒªã‚¹ãƒˆ

- [ ] **æ§‹é€ åŒ–ãƒ­ã‚°**: JSONå½¢å¼ã§å‡ºåŠ›
- [ ] **run_id**: ã™ã¹ã¦ã®ãƒ­ã‚°ã«run_idå«ã‚ã‚‹
- [ ] **ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—**: ISO 8601å½¢å¼
- [ ] **ãƒ¡ãƒˆãƒªã‚¯ã‚¹è¨˜éŒ²**: ä¸»è¦çµŒè·¯ã§ duration, throughput è¨˜éŒ²
- [ ] **MLflowçµ±åˆ**: ãƒ¡ãƒˆãƒªã‚¯ã‚¹è‡ªå‹•é€ä¿¡
- [ ] **Grafanaçµ±åˆ**: ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ç›£è¦–
- [ ] **ã‚¨ãƒ©ãƒ¼è¿½è·¡**: ã‚¹ã‚¿ãƒƒã‚¯ãƒˆãƒ¬ãƒ¼ã‚¹å®Œå…¨è¨˜éŒ²
- [ ] **ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹**: p50, p95, p99 è¨˜éŒ²

---

### 1.4 åˆç†æ€§ã®è¿½æ±‚ãƒ«ãƒ¼ãƒ«

#### åŸå‰‡
ã™ã¹ã¦ã®åˆ¤æ–­ãƒ»å®Ÿè£…ã¯ã€**è«–ç†çš„æ ¹æ‹ **ã«åŸºã¥ãã€‚æ„Ÿæƒ…çš„ãƒ»ä¸»è¦³çš„ãªæ±ºå®šã‚’é¿ã‘ã‚‹ã€‚

#### æ„æ€æ±ºå®šãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯

```markdown
## æ±ºå®šäº‹é …ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆ

### 1. ç¾çŠ¶åˆ†æ
- **å•é¡Œ**: ä½•ãŒèª²é¡Œã‹ï¼Ÿ
- **å½±éŸ¿ç¯„å›²**: ã©ã“ã«å½±éŸ¿ã™ã‚‹ã‹ï¼Ÿ
- **ç·Šæ€¥åº¦**: ã©ã‚Œã ã‘æ€¥ãå¿…è¦ãŒã‚ã‚‹ã‹ï¼Ÿ

### 2. ä»®èª¬
- **ä»®èª¬1**: ã‚ªãƒ—ã‚·ãƒ§ãƒ³Aï¼ˆä¾‹: PostgreSQLå¿…é ˆåŒ–ï¼‰
- **ä»®èª¬2**: ã‚ªãƒ—ã‚·ãƒ§ãƒ³Bï¼ˆä¾‹: SQLite + MLflowï¼‰
- **ä»®èª¬3**: ã‚ªãƒ—ã‚·ãƒ§ãƒ³Cï¼ˆä¾‹: MLflowå¿…é ˆåŒ–ï¼‰

### 3. è©•ä¾¡è»¸
- **æ€§èƒ½**: å¿œç­”é€Ÿåº¦ã€ã‚¹ãƒ«ãƒ¼ãƒ—ãƒƒãƒˆ
- **ä¿¡é ¼æ€§**: å¯ç”¨æ€§ã€è€éšœå®³æ€§
- **ã‚³ã‚¹ãƒˆ**: åˆæœŸã‚³ã‚¹ãƒˆã€é‹ç”¨ã‚³ã‚¹ãƒˆ
- **é–‹ç™ºåŠ¹ç‡**: å®Ÿè£…å·¥æ•°ã€ä¿å®ˆå·¥æ•°

### 4. å„ã‚ªãƒ—ã‚·ãƒ§ãƒ³ã®è©•ä¾¡

#### ã‚ªãƒ—ã‚·ãƒ§ãƒ³A: PostgreSQLå¿…é ˆåŒ–
- **æ€§èƒ½**: â­â­â­â­â­ (ä¸¦åˆ—ã‚¢ã‚¯ã‚»ã‚¹é«˜é€Ÿ)
- **ä¿¡é ¼æ€§**: â­â­â­â­â­ (ACIDä¿è¨¼)
- **ã‚³ã‚¹ãƒˆ**: â­â­â­ (åˆæœŸã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—å¿…è¦)
- **é–‹ç™ºåŠ¹ç‡**: â­â­â­â­ (SQLAlchemyä½¿ç”¨)

#### ã‚ªãƒ—ã‚·ãƒ§ãƒ³B: SQLite + MLflow
- **æ€§èƒ½**: â­â­â­ (ä¸¦åˆ—ã‚¢ã‚¯ã‚»ã‚¹å¼±ã„)
- **ä¿¡é ¼æ€§**: â­â­â­ (ãƒ•ã‚¡ã‚¤ãƒ«ãƒ­ãƒƒã‚¯å•é¡Œ)
- **ã‚³ã‚¹ãƒˆ**: â­â­â­â­â­ (è¿½åŠ ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—ä¸è¦)
- **é–‹ç™ºåŠ¹ç‡**: â­â­â­ (ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ä¾å­˜)

#### ã‚ªãƒ—ã‚·ãƒ§ãƒ³C: MLflowå¿…é ˆåŒ–
- **æ€§èƒ½**: â­â­â­â­ (å°‚ç”¨DBä½¿ç”¨)
- **ä¿¡é ¼æ€§**: â­â­ (ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯éšœå®³ãƒªã‚¹ã‚¯)
- **ã‚³ã‚¹ãƒˆ**: â­â­ (MLflowã‚µãƒ¼ãƒãƒ¼å¿…è¦)
- **é–‹ç™ºåŠ¹ç‡**: â­â­â­ (ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ä¾å­˜)

### 5. çµè«–
**é¸æŠ**: ã‚ªãƒ—ã‚·ãƒ§ãƒ³A (PostgreSQLå¿…é ˆåŒ–)

**ç†ç”±**:
1. ä¸¦åˆ—å®Ÿè¡Œæ™‚ã®æ€§èƒ½ãŒæœ€ã‚‚é«˜ã„ï¼ˆå®Ÿæ¸¬: 3å€é«˜é€Ÿï¼‰
2. ACIDä¿è¨¼ã«ã‚ˆã‚Šä¿¡é ¼æ€§ãŒæœ€ã‚‚é«˜ã„
3. ãƒ­ãƒ¼ã‚«ãƒ«å®Œçµã§ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ä¾å­˜ãªã—
4. SQLAlchemyã§é–‹ç™ºåŠ¹ç‡è‰¯å¥½

**ãƒˆãƒ¬ãƒ¼ãƒ‰ã‚ªãƒ•**:
- åˆæœŸã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—ãŒå¿…è¦ï¼ˆ1æ™‚é–“ç¨‹åº¦ï¼‰
- PostgreSQLã®çŸ¥è­˜ãŒå¿…è¦

### 6. æ¤œè¨¼è¨ˆç”»
- [ ] **å®Ÿæ¸¬**: 100ä¸¦åˆ—å®Ÿè¡Œã§ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯
- [ ] **éšœå®³ãƒ†ã‚¹ãƒˆ**: ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯åˆ‡æ–­æ™‚ã®å‹•ä½œç¢ºèª
- [ ] **ã‚³ã‚¹ãƒˆæ¸¬å®š**: ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—æ™‚é–“ã€é‹ç”¨å·¥æ•°ã‚’æ¸¬å®š

### 7. ãƒ­ãƒ¼ãƒ«ãƒãƒƒã‚¯è¨ˆç”»
ã‚‚ã—é¸æŠãŒèª¤ã‚Šã ã£ãŸå ´åˆ:
1. SQLiteå®Ÿè£…ã¯ç¶­æŒï¼ˆãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯å¯èƒ½ï¼‰
2. ãƒ‡ãƒ¼ã‚¿ãƒã‚¤ã‚°ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã‚¹ã‚¯ãƒªãƒ—ãƒˆæº–å‚™
3. 1é€±é–“ä»¥å†…ã«åˆ‡ã‚Šæˆ»ã—å¯èƒ½
```

#### ãƒã‚§ãƒƒã‚¯ãƒªã‚¹ãƒˆ

- [ ] **ä»®èª¬â†’æ¤œè¨¼â†’çµæœâ†’è§£é‡ˆ**: ã“ã®é †åºã§æ€è€ƒ
- [ ] **è¤‡æ•°ã‚ªãƒ—ã‚·ãƒ§ãƒ³**: æœ€ä½3ã¤ã®ã‚ªãƒ—ã‚·ãƒ§ãƒ³æ¤œè¨
- [ ] **å®šé‡è©•ä¾¡**: å¯èƒ½ãªé™ã‚Šæ•°å€¤ã§è©•ä¾¡
- [ ] **ãƒˆãƒ¬ãƒ¼ãƒ‰ã‚ªãƒ•æ˜è¨˜**: ãƒ¡ãƒªãƒƒãƒˆ/ãƒ‡ãƒ¡ãƒªãƒƒãƒˆä¸¡æ–¹è¨˜è¿°
- [ ] **æ¤œè¨¼è¨ˆç”»**: æ±ºå®šã®å¦¥å½“æ€§ã‚’æ¤œè¨¼ã™ã‚‹æ–¹æ³•ã‚’æ˜è¨˜
- [ ] **ãƒ­ãƒ¼ãƒ«ãƒãƒƒã‚¯è¨ˆç”»**: å¤±æ•—æ™‚ã®å¯¾ç­–ã‚’äº‹å‰æº–å‚™
- [ ] **æ„Ÿæƒ…æ’é™¤**: "å¥½ã/å«Œã„"ã§ã¯ãªãæ ¹æ‹ ã§æ±ºå®š

---

### 1.5 å®‰å…¨æ€§ã®ç¢ºä¿ãƒ«ãƒ¼ãƒ«

#### åŸå‰‡
**Secretsã€PIIã€å±é™ºãªæ“ä½œ**ã‚’é©åˆ‡ã«ç®¡ç†ã—ã€ã‚·ã‚¹ãƒ†ãƒ ã¨ãƒ‡ãƒ¼ã‚¿ã‚’ä¿è­·ã™ã‚‹ã€‚

#### å®Ÿè£…ä¾‹

```python
# security/secrets_manager.py
import os
from typing import Optional
from cryptography.fernet import Fernet

class SecretsManager:
    """ç§˜å¯†æƒ…å ±ç®¡ç†"""
    
    def __init__(self):
        # ç’°å¢ƒå¤‰æ•°ã‹ã‚‰ã®ã¿èª­ã¿è¾¼ã¿
        self.encryption_key = os.getenv("ENCRYPTION_KEY")
        if not self.encryption_key:
            raise ValueError("ENCRYPTION_KEY not set in environment")
        
        self.cipher = Fernet(self.encryption_key.encode())
    
    def get_secret(self, key: str) -> Optional[str]:
        """ç§˜å¯†æƒ…å ±ã‚’å–å¾—"""
        # âœ… ç’°å¢ƒå¤‰æ•°ã‹ã‚‰å–å¾—
        value = os.getenv(key)
        
        # âŒ ãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰ã¯èª­ã¾ãªã„ï¼ˆæ¼æ´©ãƒªã‚¹ã‚¯ï¼‰
        # âŒ ã‚³ãƒ¼ãƒ‰ã«ãƒãƒ¼ãƒ‰ã‚³ãƒ¼ãƒ‰ã—ãªã„
        
        return value
    
    def encrypt(self, plaintext: str) -> bytes:
        """æš—å·åŒ–"""
        return self.cipher.encrypt(plaintext.encode())
    
    def decrypt(self, ciphertext: bytes) -> str:
        """å¾©å·åŒ–"""
        return self.cipher.decrypt(ciphertext).decode()


# âŒ æ‚ªã„ä¾‹: ãƒãƒ¼ãƒ‰ã‚³ãƒ¼ãƒ‰
DB_PASSWORD = "my_secret_password"  # çµ¶å¯¾ã«ãƒ€ãƒ¡ï¼

# âœ… è‰¯ã„ä¾‹: ç’°å¢ƒå¤‰æ•°
DB_PASSWORD = os.getenv("DB_PASSWORD")
if not DB_PASSWORD:
    raise ValueError("DB_PASSWORD not set")
```

```python
# security/pii_filter.py
import re
from typing import Any, Dict

class PIIFilter:
    """å€‹äººæƒ…å ±ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼"""
    
    # æ¤œå‡ºãƒ‘ã‚¿ãƒ¼ãƒ³
    EMAIL_PATTERN = re.compile(r'\b[A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\.[A-Z|a-z]{2,}\b')
    PHONE_PATTERN = re.compile(r'\b\d{3}-\d{4}-\d{4}\b')
    CREDIT_CARD_PATTERN = re.compile(r'\b\d{4}-\d{4}-\d{4}-\d{4}\b')
    
    @classmethod
    def mask(cls, text: str) -> str:
        """PIIã‚’ãƒã‚¹ã‚¯"""
        text = cls.EMAIL_PATTERN.sub('[EMAIL_MASKED]', text)
        text = cls.PHONE_PATTERN.sub('[PHONE_MASKED]', text)
        text = cls.CREDIT_CARD_PATTERN.sub('[CARD_MASKED]', text)
        return text
    
    @classmethod
    def filter_dict(cls, data: Dict[str, Any]) -> Dict[str, Any]:
        """è¾æ›¸ã‹ã‚‰PIIã‚’é™¤å¤–"""
        filtered = {}
        for key, value in data.items():
            if key.lower() in ['email', 'phone', 'ssn', 'credit_card']:
                filtered[key] = '[REDACTED]'
            elif isinstance(value, str):
                filtered[key] = cls.mask(value)
            else:
                filtered[key] = value
        return filtered


# ä½¿ç”¨ä¾‹
logger = StructuredLogger("app")

# âŒ æ‚ªã„ä¾‹: PIIã‚’ãã®ã¾ã¾ãƒ­ã‚°
logger.info("User registered", email="user@example.com")  # å±é™ºï¼

# âœ… è‰¯ã„ä¾‹: PIIã‚’ãƒ•ã‚£ãƒ«ã‚¿
user_data = {"email": "user@example.com", "name": "John Doe"}
filtered_data = PIIFilter.filter_dict(user_data)
logger.info("User registered", **filtered_data)  # email=[REDACTED]
```

```python
# security/safe_operations.py
import os
from pathlib import Path
from typing import Optional

class SafeFileOperations:
    """å®‰å…¨ãªãƒ•ã‚¡ã‚¤ãƒ«æ“ä½œ"""
    
    def __init__(self, base_dir: str):
        self.base_dir = Path(base_dir).resolve()
    
    def validate_path(self, file_path: str) -> Path:
        """ãƒ‘ã‚¹ãƒˆãƒ©ãƒãƒ¼ã‚µãƒ«æ”»æ’ƒã‚’é˜²ã"""
        requested_path = (self.base_dir / file_path).resolve()
        
        # ãƒ™ãƒ¼ã‚¹ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªå¤–ã¸ã®ã‚¢ã‚¯ã‚»ã‚¹ã‚’æ‹’å¦
        if not str(requested_path).startswith(str(self.base_dir)):
            raise ValueError(f"Access denied: {file_path} is outside base directory")
        
        return requested_path
    
    def safe_delete(self, file_path: str, dry_run: bool = False) -> bool:
        """å®‰å…¨ãªå‰Šé™¤ï¼ˆç¢ºèªä»˜ãï¼‰"""
        validated_path = self.validate_path(file_path)
        
        if not validated_path.exists():
            return False
        
        if dry_run:
            print(f"[DRY-RUN] Would delete: {validated_path}")
            return True
        
        # ç¢ºèªãªã—ã®å‰Šé™¤ã¯å±é™º
        print(f"WARNING: About to delete: {validated_path}")
        confirmation = input("Type 'yes' to confirm: ")
        
        if confirmation.lower() == 'yes':
            os.remove(validated_path)
            return True
        else:
            print("Deletion cancelled")
            return False


# ä½¿ç”¨ä¾‹
safe_ops = SafeFileOperations("/data/experiments")

# âœ… è‰¯ã„ä¾‹: ãƒ‘ã‚¹æ¤œè¨¼
try:
    safe_path = safe_ops.validate_path("exp_001/model.pt")
except ValueError as e:
    logger.error(f"Invalid path: {e}")

# âœ… è‰¯ã„ä¾‹: dry-run
safe_ops.safe_delete("exp_001/model.pt", dry_run=True)  # å®Ÿéš›ã«ã¯å‰Šé™¤ã—ãªã„

# âœ… è‰¯ã„ä¾‹: ç¢ºèªä»˜ãå‰Šé™¤
safe_ops.safe_delete("exp_001/model.pt", dry_run=False)  # ç¢ºèªã‚’æ±‚ã‚ã‚‹
```

#### ãƒã‚§ãƒƒã‚¯ãƒªã‚¹ãƒˆ

- [ ] **Secrets**: ç’°å¢ƒå¤‰æ•°ã§ã®ã¿ç®¡ç†ï¼ˆ`.env`ãƒ•ã‚¡ã‚¤ãƒ«ä½¿ç”¨ï¼‰
- [ ] **PIIé™¤å¤–**: ãƒ­ã‚°ã€ãƒ¡ãƒˆãƒªã‚¯ã‚¹ã‹ã‚‰å€‹äººæƒ…å ±ã‚’é™¤å¤–
- [ ] **ãƒ‘ã‚¹æ¤œè¨¼**: ãƒ‘ã‚¹ãƒˆãƒ©ãƒãƒ¼ã‚µãƒ«æ”»æ’ƒã‚’é˜²ã
- [ ] **ç¢ºèªã‚¬ãƒ¼ãƒ‰**: å±é™ºãªæ“ä½œã«ã¯ç¢ºèªã‚’æ±‚ã‚ã‚‹
- [ ] **dry-run**: ç ´å£Šçš„æ“ä½œã«ã¯dry-runãƒ¢ãƒ¼ãƒ‰å®Ÿè£…
- [ ] **backup**: å‰Šé™¤å‰ã«ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—
- [ ] **roll-back**: å¤±æ•—æ™‚ã®ãƒ­ãƒ¼ãƒ«ãƒãƒƒã‚¯æ‰‹é †æº–å‚™
- [ ] **ç›£æŸ»ãƒ­ã‚°**: ã™ã¹ã¦ã®é‡è¦æ“ä½œã‚’è¨˜éŒ²

---

### 1.6 ãƒŸã‚¹ã‚³ãƒŸãƒ¥ãƒ‹ã‚±ãƒ¼ã‚·ãƒ§ãƒ³é˜²æ­¢ãƒ«ãƒ¼ãƒ«

#### åŸå‰‡
**è¦ä»¶ã€åˆ¶ç´„ã€å—å…¥åŸºæº–ã€ãƒ‡ãƒªãƒãƒ©ãƒ–ãƒ«**ã‚’æœ€åˆã«æ˜ç¢ºåŒ–ã—ã€èªè­˜ã®ã‚ºãƒ¬ã‚’é˜²ãã€‚

#### ã‚³ãƒŸãƒ¥ãƒ‹ã‚±ãƒ¼ã‚·ãƒ§ãƒ³ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆ

```markdown
## ã‚¿ã‚¹ã‚¯å®šç¾©ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆ

### 1. è¦ä»¶ (Requirements)
**ä½•ã‚’ä½œã‚‹ã®ã‹ï¼Ÿ**

- æ©Ÿèƒ½: ãƒ¦ãƒ¼ã‚¶ãƒ¼ãŒãƒ‡ãƒ¼ã‚¿ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã€æ™‚ç³»åˆ—äºˆæ¸¬ã‚’å®Ÿè¡Œã§ãã‚‹
- å…¥åŠ›: CSVå½¢å¼ã€åˆ— `date`, `unique_id`, `y`
- å‡ºåŠ›: äºˆæ¸¬çµæœCSVã€ãƒ¡ãƒˆãƒªã‚¯ã‚¹JSON

### 2. åˆ¶ç´„ (Constraints)
**ä½•ãŒã§ããªã„ã®ã‹ï¼Ÿåˆ¶é™ã¯ï¼Ÿ**

- æ™‚é–“: 2é€±é–“ä»¥å†…ã«å®Œæˆ
- ãƒªã‚½ãƒ¼ã‚¹: å˜ä¸€GPUï¼ˆNVIDIA RTX 4090ï¼‰
- äº’æ›æ€§: Python 3.11ä»¥ä¸Šã€NeuralForecast 1.7.x
- ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£: ãƒ¦ãƒ¼ã‚¶ãƒ¼ãƒ‡ãƒ¼ã‚¿ã¯å¤–éƒ¨é€ä¿¡ã—ãªã„

### 3. å—å…¥åŸºæº– (Acceptance Criteria)
**ã©ã†ãªã£ãŸã‚‰å®Œæˆã‹ï¼Ÿ**

- [ ] ãƒ¦ãƒ¼ã‚¶ãƒ¼ãŒWebUIã‹ã‚‰CSVã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã§ãã‚‹
- [ ] ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰å¾Œã€è‡ªå‹•çš„ã«äºˆæ¸¬ãŒé–‹å§‹ã•ã‚Œã‚‹
- [ ] äºˆæ¸¬å®Œäº†å¾Œã€çµæœCSVã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã§ãã‚‹
- [ ] ãƒ¡ãƒˆãƒªã‚¯ã‚¹ï¼ˆMAE, RMSEï¼‰ãŒç”»é¢è¡¨ç¤ºã•ã‚Œã‚‹
- [ ] ãƒ†ã‚¹ãƒˆã‚«ãƒãƒ¬ãƒƒã‚¸ >90%
- [ ] Pylintã‚¹ã‚³ã‚¢ â‰¥8.5
- [ ] ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆå®Œå‚™ï¼ˆREADMEã€API docstringï¼‰

### 4. ãƒ‡ãƒªãƒãƒ©ãƒ–ãƒ« (Deliverables)
**ä½•ã‚’ç´å“ã™ã‚‹ã®ã‹ï¼Ÿ**

- [ ] Webã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ï¼ˆStreamlitï¼‰
  - `src/ui/app.py`
- [ ] ãƒãƒƒã‚¯ã‚¨ãƒ³ãƒ‰APIï¼ˆFastAPIï¼‰
  - `src/api/endpoints.py`
- [ ] ãƒ†ã‚¹ãƒˆã‚³ãƒ¼ãƒ‰
  - `tests/unit/test_api.py`
  - `tests/integration/test_ui.py`
- [ ] ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆ
  - `docs/USER_GUIDE.md`
  - `docs/API_REFERENCE.md`
- [ ] ãƒ‡ãƒ—ãƒ­ã‚¤ã‚¹ã‚¯ãƒªãƒ—ãƒˆ
  - `scripts/deploy.sh`

### 5. ä¾å­˜é–¢ä¿‚ (Dependencies)
**ã“ã®ã‚¿ã‚¹ã‚¯ã¯ä½•ã«ä¾å­˜ã—ã¦ã„ã‚‹ã‹ï¼Ÿ**

- ãƒ‡ãƒ¼ã‚¿ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³å®Ÿè£…å®Œäº† (Task #42)
- ãƒ¢ãƒ‡ãƒ«ãƒ¬ã‚¸ã‚¹ãƒˆãƒªå®Ÿè£…å®Œäº† (Task #57)
- PostgreSQLã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—å®Œäº† (Task #12)

### 6. æ‹…å½“ (Ownership)
**èª°ãŒä½•ã‚’ã™ã‚‹ã®ã‹ï¼Ÿ**

| Role | æ‹…å½“è€… | è²¬ä»» |
|------|--------|------|
| **R (Responsible)** | Alice | å®Ÿè£…ãƒ»ãƒ†ã‚¹ãƒˆä½œæˆ |
| **A (Accountable)** | Bob | ãƒ¬ãƒ“ãƒ¥ãƒ¼ãƒ»æ‰¿èª |
| **C (Consulted)** | Charlie | ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ç›¸è«‡ |
| **I (Informed)** | Team | é€²æ—å ±å‘Š |

### 7. ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ« (Schedule)
**ã„ã¤ã¾ã§ã«ä½•ã‚’ã™ã‚‹ã‹ï¼Ÿ**

| æ—¥ä»˜ | ãƒã‚¤ãƒ«ã‚¹ãƒˆãƒ¼ãƒ³ |
|------|--------------|
| 2025-11-05 | è¦ä»¶ç¢ºèªãƒ»è¨­è¨ˆæ›¸ãƒ¬ãƒ“ãƒ¥ãƒ¼ |
| 2025-11-08 | ãƒãƒƒã‚¯ã‚¨ãƒ³ãƒ‰APIå®Ÿè£…å®Œäº† |
| 2025-11-12 | WebUIå®Ÿè£…å®Œäº† |
| 2025-11-15 | ãƒ†ã‚¹ãƒˆå®Œäº†ã€ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆä½œæˆ |
| 2025-11-18 | æœ€çµ‚ãƒ¬ãƒ“ãƒ¥ãƒ¼ã€ãƒ‡ãƒ—ãƒ­ã‚¤ |

### 8. ãƒªã‚¹ã‚¯ (Risks)
**ä½•ãŒå•é¡Œã«ãªã‚Šå¾—ã‚‹ã‹ï¼Ÿ**

| ãƒªã‚¹ã‚¯ | å½±éŸ¿åº¦ | å¯¾ç­– |
|--------|--------|------|
| NeuralForecastã®ãƒã‚° | High | ä»£æ›¿ãƒ©ã‚¤ãƒ–ãƒ©ãƒª(Prophet)æº–å‚™ |
| GPUãƒ¡ãƒ¢ãƒªä¸è¶³ | Medium | ãƒãƒƒãƒã‚µã‚¤ã‚ºå‰Šæ¸› |
| CSVãƒ‘ãƒ¼ã‚¹ã‚¨ãƒ©ãƒ¼ | Low | ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°å®Ÿè£… |
```

#### ãƒã‚§ãƒƒã‚¯ãƒªã‚¹ãƒˆ

- [ ] **è¦ä»¶æ˜ç¢ºåŒ–**: ä½•ã‚’ä½œã‚‹ã‹æ˜æ–‡åŒ–
- [ ] **åˆ¶ç´„æ˜è¨˜**: ä½•ãŒã§ããªã„ã‹ã€åˆ¶é™ã‚’è¨˜è¼‰
- [ ] **å—å…¥åŸºæº–**: ãƒã‚§ãƒƒã‚¯ãƒªã‚¹ãƒˆå½¢å¼ã§å®šç¾©
- [ ] **ãƒ‡ãƒªãƒãƒ©ãƒ–ãƒ«**: ç´å“ç‰©ã‚’å…·ä½“çš„ã«ãƒªã‚¹ãƒˆ
- [ ] **RACIæ˜è¨˜**: è²¬ä»»åˆ†æ‹…ã‚’æ˜ç¢ºåŒ–
- [ ] **ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ«**: ãƒã‚¤ãƒ«ã‚¹ãƒˆãƒ¼ãƒ³ã‚’æ—¥ä»˜ã§å®šç¾©
- [ ] **ãƒªã‚¹ã‚¯ç®¡ç†**: æ½œåœ¨çš„å•é¡Œã¨å¯¾ç­–ã‚’äº‹å‰æ¤œè¨

---

### 1.7 ã‚¨ãƒ©ãƒ¼å‡¦ç†ãƒ«ãƒ¼ãƒ«

#### åŸå‰‡
ã‚¨ãƒ©ãƒ¼ã¯**åˆ‡ã‚Šåˆ†ã‘â†’å†ç¾â†’æœ€å°åŒ–â†’ä»®èª¬â†’æ¤œè¨¼â†’æ’ä¹…å¯¾ç­–**ã®é †ã§å¯¾å‡¦ã™ã‚‹ã€‚

#### ã‚¨ãƒ©ãƒ¼å¯¾å¿œãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯

```markdown
## ã‚¨ãƒ©ãƒ¼å¯¾å¿œãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆ

### 1. äº‹å®Ÿã®è¨˜éŒ² (Facts)
**ä½•ãŒèµ·ããŸã‹ï¼Ÿ**

- **ç—‡çŠ¶**: ãƒ¢ãƒ‡ãƒ«å­¦ç¿’æ™‚ã« `CUDA out of memory` ã‚¨ãƒ©ãƒ¼
- **ã‚¨ãƒ©ãƒ¼ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸**:
  ```
  RuntimeError: CUDA out of memory. Tried to allocate 2.00 GiB 
  (GPU 0; 23.70 GiB total capacity; 20.50 GiB already allocated; 
  1.50 GiB free; 21.00 GiB reserved in total by PyTorch)
  ```
- **ç™ºç”Ÿæ™‚åˆ»**: 2025-11-04 14:32:15
- **å½±éŸ¿ç¯„å›²**: AutoNHITS ãƒ¢ãƒ‡ãƒ«å­¦ç¿’ã®ã¿ï¼ˆä»–ãƒ¢ãƒ‡ãƒ«ã¯æ­£å¸¸ï¼‰
- **ç™ºç”Ÿé »åº¦**: 100% (10å›ä¸­10å›å†ç¾)

### 2. ç’°å¢ƒæƒ…å ± (Environment)
- Python: 3.11.5
- PyTorch: 2.1.0+cu121
- GPU: NVIDIA RTX 4090 (24GB)
- ãƒ‡ãƒ¼ã‚¿ã‚µã‚¤ã‚º: 100,000è¡Œ Ã— 15åˆ—
- ãƒãƒƒãƒã‚µã‚¤ã‚º: 32
- `input_size`: 168
- `h`: 24

### 3. ç›´è¿‘ã®å¤‰æ›´ (Recent Changes)
- æ˜¨æ—¥: ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’10ä¸‡è¡Œâ†’20ä¸‡è¡Œã«å¤‰æ›´
- ä»Šæœ: `input_size`ã‚’84â†’168ã«å¤‰æ›´
- ã‚³ãƒ¼ãƒ‰ã®å¤‰æ›´: ãªã—

### 4. åˆ‡ã‚Šåˆ†ã‘ (Isolation)
**ã©ã“ã§å•é¡ŒãŒèµ·ãã¦ã„ã‚‹ã‹ï¼Ÿ**

#### ãƒ†ã‚¹ãƒˆ1: ãƒ‡ãƒ¼ã‚¿ã‚µã‚¤ã‚ºã‚’åŠåˆ†ã«
```bash
# 10ä¸‡è¡Œã§å®Ÿè¡Œ
python src/train.py --data data/train_small.csv
# çµæœ: æˆåŠŸ âœ…
```

#### ãƒ†ã‚¹ãƒˆ2: `input_size`ã‚’å…ƒã«æˆ»ã™
```bash
# input_size=84ã§å®Ÿè¡Œ
python src/train.py --input-size 84
# çµæœ: æˆåŠŸ âœ…
```

#### ãƒ†ã‚¹ãƒˆ3: ãƒãƒƒãƒã‚µã‚¤ã‚ºã‚’åŠåˆ†ã«
```bash
# batch_size=16ã§å®Ÿè¡Œ
python src/train.py --batch-size 16
# çµæœ: å¤±æ•— âŒ (åŒã˜ã‚¨ãƒ©ãƒ¼)
```

**çµè«–**: `input_size`ã‚’å¤§ããã—ãŸã“ã¨ãŒåŸå› 

### 5. å†ç¾ã®æœ€å°åŒ– (Minimal Reproduction)
**æœ€å°é™ã®ã‚³ãƒ¼ãƒ‰ã§å†ç¾**

```python
# minimal_repro.py
import torch
from neuralforecast.models import AutoNHITS

# æœ€å°é™ã®è¨­å®š
model = AutoNHITS(
    h=24,
    input_size=168,  # ã“ã‚ŒãŒå¤§ãã„ã¨å¤±æ•—
    max_steps=10
)

# ãƒ€ãƒŸãƒ¼ãƒ‡ãƒ¼ã‚¿
X = torch.randn(32, 168, 1).cuda()  # batch_size=32, input_size=168
y = torch.randn(32, 24, 1).cuda()

# å­¦ç¿’
try:
    model.fit(X, y)
    print("âœ… Success")
except RuntimeError as e:
    print(f"âŒ Error: {e}")
```

### 6. ä»®èª¬ (Hypothesis)
**ãªãœèµ·ããŸã‹ï¼Ÿ**

| ä»®èª¬ | ç¢ºç‡ | æ¤œè¨¼æ–¹æ³• |
|-----|------|---------|
| H1: `input_size`ãŒå¤§ãã™ãã‚‹ | 90% | `input_size`ã‚’æ®µéšçš„ã«å¢—ã‚„ã™ |
| H2: ãƒ¢ãƒ‡ãƒ«ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ãŒæ·±ã™ãã‚‹ | 5% | ãƒ¬ã‚¤ãƒ¤ãƒ¼æ•°ã‚’æ¸›ã‚‰ã™ |
| H3: PyTorchã®ãƒã‚° | 5% | ãƒãƒ¼ã‚¸ãƒ§ãƒ³ã‚’ãƒ€ã‚¦ãƒ³ã‚°ãƒ¬ãƒ¼ãƒ‰ |

### 7. æ¤œè¨¼ (Validation)
**ä»®èª¬H1ã®æ¤œè¨¼**

```python
# test_input_size.py
import torch
from neuralforecast.models import AutoNHITS

def test_memory(input_size: int) -> bool:
    """æŒ‡å®šã®input_sizeã§ãƒ¡ãƒ¢ãƒªãŒè¶³ã‚Šã‚‹ã‹ç¢ºèª"""
    try:
        model = AutoNHITS(h=24, input_size=input_size, max_steps=10)
        X = torch.randn(32, input_size, 1).cuda()
        y = torch.randn(32, 24, 1).cuda()
        model.fit(X, y)
        return True
    except RuntimeError:
        return False

# äºŒåˆ†æ¢ç´¢ã§é™ç•Œã‚’è¦‹ã¤ã‘ã‚‹
for size in [84, 96, 112, 128, 144, 168]:
    result = test_memory(size)
    print(f"input_size={size}: {'âœ…' if result else 'âŒ'}")
```

**çµæœ**:
```
input_size=84: âœ…
input_size=96: âœ…
input_size=112: âœ…
input_size=128: âœ…
input_size=144: âŒ
input_size=168: âŒ
```

**çµè«–**: `input_size > 128` ã§ãƒ¡ãƒ¢ãƒªä¸è¶³

### 8. åŸå› ç¢ºå®š (Root Cause)
`input_size`ã‚’168ã«è¨­å®šã—ãŸã“ã¨ã§ã€ãƒ¢ãƒ‡ãƒ«ã®ä¸­é–“å±¤ã®ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡ãŒå¢—åŠ ã—ã€24GBã®GPUãƒ¡ãƒ¢ãƒªã‚’è¶…éã—ãŸã€‚

**è¨ˆç®—**:
- ãƒãƒƒãƒã‚µã‚¤ã‚º: 32
- `input_size`: 168
- ä¸­é–“å±¤ã®æ¬¡å…ƒ: 512
- ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡: 32 Ã— 168 Ã— 512 Ã— 4 bytes â‰ˆ 11 MB (per layer)
- ãƒ¬ã‚¤ãƒ¤ãƒ¼æ•°: 10
- åˆè¨ˆ: ç´„110 MB (ä¸­é–“å±¤ã®ã¿)
- ãã®ä»–ï¼ˆå‹¾é…ã€ã‚ªãƒ—ãƒ†ã‚£ãƒã‚¤ã‚¶çŠ¶æ…‹ï¼‰: ç´„2 GB
- **åˆè¨ˆ**: ç´„2.2 GB â†’ ã“ã‚ŒãŒè¤‡æ•°ãƒãƒƒãƒåˆ†è“„ç©ã—ã¦24GBã‚’è¶…é

### 9. å¯¾ç­– (Solution)

#### æš«å®šå¯¾ç­– (Temporary Fix)
```python
# ã™ãã«ã§ãã‚‹å¯¾ç­–
# input_sizeã‚’128ã«åˆ¶é™
config.input_size = min(config.input_size, 128)
```

#### æ’ä¹…å¯¾ç­– (Permanent Fix)
```python
# 1. Gradient Accumulation
model = AutoNHITS(
    h=24,
    input_size=168,
    batch_size=16,  # ãƒãƒƒãƒã‚µã‚¤ã‚ºã‚’åŠåˆ†ã«
    accumulate_grad_batches=2  # å‹¾é…ã‚’2å›åˆ†è“„ç©
)

# 2. Mixed Precision Training
model = AutoNHITS(
    h=24,
    input_size=168,
    precision=16  # FP16ã§å­¦ç¿’
)

# 3. ãƒ¡ãƒ¢ãƒªåŠ¹ç‡åŒ–
torch.cuda.empty_cache()  # ä¸è¦ãªãƒ¡ãƒ¢ãƒªè§£æ”¾
model = AutoNHITS(
    h=24,
    input_size=168,
    gradient_checkpointing=True  # ãƒ¡ãƒ¢ãƒªç¯€ç´„
)
```

### 10. æ¤œè¨¼ (Verification)
```python
# æ’ä¹…å¯¾ç­–ã®å‹•ä½œç¢ºèª
model = AutoNHITS(
    h=24,
    input_size=168,
    batch_size=16,
    accumulate_grad_batches=2,
    precision=16
)

X = torch.randn(10000, 168, 1)  # å¤§ããªãƒ‡ãƒ¼ã‚¿
y = torch.randn(10000, 24, 1)

try:
    model.fit(X, y)
    print("âœ… Fixed!")
except RuntimeError as e:
    print(f"âŒ Still failing: {e}")
```

### 11. äºˆé˜²ç­– (Prevention)
- [ ] ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡ã®ç›£è¦–ãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰è¿½åŠ 
- [ ] `input_size`ã®ä¸Šé™ã‚’è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã§ç®¡ç†
- [ ] GPU ãƒ¡ãƒ¢ãƒªãƒã‚§ãƒƒã‚¯ã‚’å­¦ç¿’å‰ã«å®Ÿè¡Œ
- [ ] ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã«æ¨å¥¨è¨­å®šã‚’è¨˜è¼‰
- [ ] å›å¸°ãƒ†ã‚¹ãƒˆã«å¤§è¦æ¨¡ãƒ‡ãƒ¼ã‚¿ã®ã‚±ãƒ¼ã‚¹è¿½åŠ 

### 12. ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆæ›´æ–°
```markdown
# docs/TROUBLESHOOTING.md

## ãƒ¡ãƒ¢ãƒªä¸è¶³ã‚¨ãƒ©ãƒ¼

### ç—‡çŠ¶
`RuntimeError: CUDA out of memory`

### åŸå› 
`input_size`ãŒå¤§ãã™ãã‚‹ã€ã¾ãŸã¯ãƒãƒƒãƒã‚µã‚¤ã‚ºãŒå¤§ãã™ãã‚‹

### è§£æ±ºç­–
1. `input_size`ã‚’128ä»¥ä¸‹ã«åˆ¶é™
2. ãƒãƒƒãƒã‚µã‚¤ã‚ºã‚’16ã«å‰Šæ¸›
3. Mixed Precision Trainingã‚’æœ‰åŠ¹åŒ– (`precision=16`)
4. Gradient Accumulation ã‚’ä½¿ç”¨
```
```

#### ãƒã‚§ãƒƒã‚¯ãƒªã‚¹ãƒˆ

- [ ] **äº‹å®Ÿè¨˜éŒ²**: ã‚¨ãƒ©ãƒ¼ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã€ç™ºç”Ÿæ™‚åˆ»ã€å½±éŸ¿ç¯„å›²
- [ ] **ç’°å¢ƒæƒ…å ±**: ãƒãƒ¼ã‚¸ãƒ§ãƒ³ã€è¨­å®šã€ãƒªã‚½ãƒ¼ã‚¹
- [ ] **ç›´è¿‘å¤‰æ›´**: ä½•ã‚’å¤‰ãˆãŸã‹æ˜è¨˜
- [ ] **åˆ‡ã‚Šåˆ†ã‘**: ã©ã“ã§å•é¡ŒãŒèµ·ãã¦ã„ã‚‹ã‹ç‰¹å®š
- [ ] **æœ€å°å†ç¾**: æœ€å°é™ã®ã‚³ãƒ¼ãƒ‰ã§å†ç¾
- [ ] **ä»®èª¬åˆ—æŒ™**: è¤‡æ•°ã®åŸå› å€™è£œã‚’è€ƒãˆã‚‹
- [ ] **æ¤œè¨¼**: ä»®èª¬ã‚’å®Ÿé¨“ã§ç¢ºèª
- [ ] **åŸå› ç¢ºå®š**: æ ¹æœ¬åŸå› ã‚’ç‰¹å®š
- [ ] **æš«å®šå¯¾ç­–**: ã™ãã«ã§ãã‚‹å¯¾ç­–
- [ ] **æ’ä¹…å¯¾ç­–**: æ ¹æœ¬çš„ãªè§£æ±º
- [ ] **äºˆé˜²ç­–**: å†ç™ºé˜²æ­¢
- [ ] **ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆ**: ä»–è€…ãŒå‚ç…§ã§ãã‚‹ã‚ˆã†è¨˜éŒ²

---

### 1.8 å‡ºåŠ›å¥‘ç´„ãƒ«ãƒ¼ãƒ«

#### åŸå‰‡
**JSON/YAMLãªã©ã®å›ºå®šã‚¹ã‚­ãƒ¼ãƒ**ã‚’å®ˆã‚Šã€æ›–æ˜§ãªè¡¨ç¾ã‚’é¿ã‘ã‚‹ã€‚æ•°å€¤ã«ã¯å˜ä½ã¨ä¿¡é ¼åŒºé–“ã‚’ä»˜ã‘ã‚‹ã€‚

#### å‡ºåŠ›ã‚¹ã‚­ãƒ¼ãƒå®šç¾©

```python
# schemas/output_schema.py
from dataclasses import dataclass
from typing import Dict, List, Optional
import json

@dataclass
class MetricValue:
    """ãƒ¡ãƒˆãƒªã‚¯ã‚¹å€¤ï¼ˆå˜ä½ã¨ä¿¡é ¼åŒºé–“ä»˜ãï¼‰"""
    value: float
    unit: str  # "seconds", "MB", "percent", etc.
    confidence_interval_lower: Optional[float] = None
    confidence_interval_upper: Optional[float] = None
    
    def __str__(self) -> str:
        if self.confidence_interval_lower and self.confidence_interval_upper:
            return (
                f"{self.value:.3f} {self.unit} "
                f"(95% CI: [{self.confidence_interval_lower:.3f}, "
                f"{self.confidence_interval_upper:.3f}])"
            )
        return f"{self.value:.3f} {self.unit}"


@dataclass
class ExperimentResult:
    """å®Ÿé¨“çµæœã®æ¨™æº–å‡ºåŠ›å½¢å¼"""
    
    # å¿…é ˆãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰
    run_id: str
    experiment_name: str
    status: str  # "success", "failed", "running"
    
    # ãƒ¡ãƒˆãƒªã‚¯ã‚¹ï¼ˆå˜ä½ä»˜ãï¼‰
    metrics: Dict[str, MetricValue]
    
    # ã‚¢ãƒ¼ãƒ†ã‚£ãƒ•ã‚¡ã‚¯ãƒˆï¼ˆãƒ‘ã‚¹ï¼‰
    artifacts: List[str]
    
    # ãƒªã‚¹ã‚¯
    risks: List[str]
    
    # æ¬¡ã®ã‚¢ã‚¯ã‚·ãƒ§ãƒ³
    next_actions: List[str]
    
    # ã‚ªãƒ¼ãƒŠãƒ¼
    owners: Dict[str, str]  # {"R": "Alice", "A": "Bob"}
    
    def to_json(self) -> str:
        """JSONå½¢å¼ã§å‡ºåŠ›"""
        data = {
            "run_id": self.run_id,
            "experiment_name": self.experiment_name,
            "status": self.status,
            "metrics": {
                name: {
                    "value": metric.value,
                    "unit": metric.unit,
                    "ci_lower": metric.confidence_interval_lower,
                    "ci_upper": metric.confidence_interval_upper
                }
                for name, metric in self.metrics.items()
            },
            "artifacts": self.artifacts,
            "risks": self.risks,
            "next_actions": self.next_actions,
            "owners": self.owners
        }
        return json.dumps(data, indent=2)


# ä½¿ç”¨ä¾‹
result = ExperimentResult(
    run_id="exp_001_run_042",
    experiment_name="AutoNHITS Hyperparameter Search",
    status="success",
    metrics={
        "mae": MetricValue(
            value=12.5,
            unit="units",
            confidence_interval_lower=11.2,
            confidence_interval_upper=13.8
        ),
        "training_time": MetricValue(
            value=3600.0,
            unit="seconds"
        ),
        "memory_peak": MetricValue(
            value=18.5,
            unit="GB"
        )
    },
    artifacts=[
        "mlflow://experiments/1/runs/abc123",
        "s3://bucket/models/exp_001_run_042/model.pt",
        "outputs/predictions.csv"
    ],
    risks=[
        "éå­¦ç¿’ã®å…†å€™ï¼ˆvalidation lossãŒå¢—åŠ ï¼‰",
        "GPU ãƒ¡ãƒ¢ãƒªä½¿ç”¨ç‡ 90% è¶…ï¼ˆå°†æ¥çš„ãªã‚¹ã‚±ãƒ¼ãƒ©ãƒ“ãƒªãƒ†ã‚£æ‡¸å¿µï¼‰"
    ],
    next_actions=[
        "æ—©æœŸåœæ­¢ï¼ˆEarly Stoppingï¼‰ã®å®Ÿè£…",
        "Gradient Accumulation ã«ã‚ˆã‚‹ãƒ¡ãƒ¢ãƒªæœ€é©åŒ–",
        "å›å¸°ãƒ†ã‚¹ãƒˆã«ã“ã®è¨­å®šã‚’è¿½åŠ "
    ],
    owners={
        "R": "Alice",  # Responsible
        "A": "Bob",    # Accountable
        "C": "Charlie" # Consulted
    }
)

# JSONå‡ºåŠ›
print(result.to_json())
```

**å‡ºåŠ›ä¾‹**:

```json
{
  "run_id": "exp_001_run_042",
  "experiment_name": "AutoNHITS Hyperparameter Search",
  "status": "success",
  "metrics": {
    "mae": {
      "value": 12.5,
      "unit": "units",
      "ci_lower": 11.2,
      "ci_upper": 13.8
    },
    "training_time": {
      "value": 3600.0,
      "unit": "seconds",
      "ci_lower": null,
      "ci_upper": null
    },
    "memory_peak": {
      "value": 18.5,
      "unit": "GB",
      "ci_lower": null,
      "ci_upper": null
    }
  },
  "artifacts": [
    "mlflow://experiments/1/runs/abc123",
    "s3://bucket/models/exp_001_run_042/model.pt",
    "outputs/predictions.csv"
  ],
  "risks": [
    "éå­¦ç¿’ã®å…†å€™ï¼ˆvalidation lossãŒå¢—åŠ ï¼‰",
    "GPU ãƒ¡ãƒ¢ãƒªä½¿ç”¨ç‡ 90% è¶…ï¼ˆå°†æ¥çš„ãªã‚¹ã‚±ãƒ¼ãƒ©ãƒ“ãƒªãƒ†ã‚£æ‡¸å¿µï¼‰"
  ],
  "next_actions": [
    "æ—©æœŸåœæ­¢ï¼ˆEarly Stoppingï¼‰ã®å®Ÿè£…",
    "Gradient Accumulation ã«ã‚ˆã‚‹ãƒ¡ãƒ¢ãƒªæœ€é©åŒ–",
    "å›å¸°ãƒ†ã‚¹ãƒˆã«ã“ã®è¨­å®šã‚’è¿½åŠ "
  ],
  "owners": {
    "R": "Alice",
    "A": "Bob",
    "C": "Charlie"
  }
}
```

#### ãƒã‚§ãƒƒã‚¯ãƒªã‚¹ãƒˆ

- [ ] **ã‚¹ã‚­ãƒ¼ãƒå®šç¾©**: JSON/YAMLã‚¹ã‚­ãƒ¼ãƒã‚’æ˜ç¢ºã«å®šç¾©
- [ ] **å˜ä½æ˜è¨˜**: ã™ã¹ã¦ã®æ•°å€¤ã«å˜ä½ã‚’ä»˜ã‘ã‚‹
- [ ] **ä¿¡é ¼åŒºé–“**: çµ±è¨ˆå€¤ã«ã¯95%ä¿¡é ¼åŒºé–“ã‚’ä»˜ã‘ã‚‹
- [ ] **æ›–æ˜§èªæ’é™¤**: "è‰¯ã„"ã€"é€Ÿã„"ãªã©ã®ä¸»è¦³çš„è¡¨ç¾ã‚’é¿ã‘ã‚‹
- [ ] **å…·ä½“çš„è¡¨ç¾**: "ç´„50%é«˜é€Ÿ" â†’ "å®Ÿæ¸¬1.53å€é«˜é€Ÿï¼ˆ3600ç§’â†’2350ç§’ï¼‰"
- [ ] **ãƒãƒ¼ã‚¸ãƒ§ãƒ³ç®¡ç†**: ã‚¹ã‚­ãƒ¼ãƒã«ãƒãƒ¼ã‚¸ãƒ§ãƒ³ç•ªå·ã‚’ä»˜ã‘ã‚‹

---

## 2. å“è³ªä¿è¨¼ã®åŸå‰‡

### 2.1 å“è³ªä¿è¨¼ã®8ã¤ã®æŸ±

æœ¬ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã¯ã€ä»¥ä¸‹ã®8ã¤ã®å“è³ªå±æ€§ã‚’æœ€å„ªå…ˆã—ã¾ã™ï¼š

| å“è³ªå±æ€§ | ç›®æ¨™è©•ä¾¡ | å®Ÿç¾æ–¹æ³• | æ¸¬å®šæ–¹æ³• |
|---------|---------|---------|---------|
| **1. Reusability** | â­â­â­â­â­ | ãƒ¬ã‚¤ãƒ¤ãƒ¼åŒ–ã€Adapter Pattern | ã‚³ãƒ¼ãƒ‰é‡è¤‡ç‡ <3% |
| **2. Testability** | â­â­â­â­â­ | DIã€ç´”ç²‹é–¢æ•°ã€ãƒ¢ãƒƒã‚¯ | ã‚«ãƒãƒ¬ãƒƒã‚¸ >90% |
| **3. Maintainability** | â­â­â­â­â­ | SOLIDåŸå‰‡ã€ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆ | Pylint â‰¥8.5 |
| **4. Extensibility** | â­â­â­â­â­ | ãƒ—ãƒ©ã‚°ã‚¤ãƒ³è¨­è¨ˆã€Factory | æ–°æ©Ÿèƒ½è¿½åŠ å·¥æ•° |
| **5. Reliability** | â­â­â­â­ | ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°ã€ãƒªãƒˆãƒ©ã‚¤ | MTBF >720h |
| **6. Performance** | â­â­â­â­ | ä¸¦åˆ—åŒ–ã€ã‚­ãƒ£ãƒƒã‚·ãƒ³ã‚° | å˜ä¸€ãƒ¢ãƒ‡ãƒ« <10åˆ† |
| **7. Security** | â­â­â­â­ | ç’°å¢ƒå¤‰æ•°ç®¡ç†ã€PIIé™¤å¤– | Bandit ã‚¹ã‚­ãƒ£ãƒ³ |
| **8. Compatibility** | â­â­â­â­â­ | Adapterã€ãƒãƒ¼ã‚¸ãƒ§ãƒ³ç®¡ç† | äº’æ›æ€§ãƒ†ã‚¹ãƒˆ |

---

### 2.2 å“è³ªã‚²ãƒ¼ãƒˆ (Quality Gates)

å„ãƒ•ã‚§ãƒ¼ã‚ºã§ä»¥ä¸‹ã®å“è³ªã‚²ãƒ¼ãƒˆã‚’ã‚¯ãƒªã‚¢ã™ã‚‹å¿…è¦ãŒã‚ã‚Šã¾ã™ï¼š

#### Phase 1-9 å…±é€šã‚²ãƒ¼ãƒˆ

| é …ç›® | åŸºæº– | ãƒ„ãƒ¼ãƒ« |
|-----|------|--------|
| **ãƒ†ã‚¹ãƒˆã‚«ãƒãƒ¬ãƒƒã‚¸** | >90% | pytest-cov |
| **é™çš„è§£æ** | Pylint â‰¥8.5 | pylint |
| **å‹ãƒã‚§ãƒƒã‚¯** | MyPy strict pass | mypy |
| **ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆ** | Blackæº–æ‹  | black |
| **å¾ªç’°çš„è¤‡é›‘åº¦** | <10 | radon |
| **é‡è¤‡ã‚³ãƒ¼ãƒ‰** | <3% | pylint |
| **ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆ** | 100% | interrogate |
| **ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£** | é«˜ãƒªã‚¹ã‚¯å•é¡Œ0ä»¶ | bandit |

#### ãƒ•ã‚§ãƒ¼ã‚ºåˆ¥è¿½åŠ ã‚²ãƒ¼ãƒˆ

| Phase | è¿½åŠ åŸºæº– |
|-------|---------|
| Phase 2 | ãƒ‡ãƒ¼ã‚¿æ¤œè¨¼ãƒ†ã‚¹ãƒˆ100%ãƒ‘ã‚¹ |
| Phase 4 | ä¸¦åˆ—å®Ÿè¡Œãƒ†ã‚¹ãƒˆæˆåŠŸ |
| Phase 6 | MLflow/W&Bçµ±åˆãƒ†ã‚¹ãƒˆæˆåŠŸ |
| Phase 8 | ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãƒ†ã‚¹ãƒˆåŸºæº–é”æˆ |
| Phase 9 | ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£ãƒ¬ãƒ“ãƒ¥ãƒ¼å®Œäº† |

---

### 2.3 å“è³ªæ¸¬å®šã®è‡ªå‹•åŒ–

```python
# scripts/quality_check.py
import subprocess
import json
from typing import Dict, Any

class QualityChecker:
    """å“è³ªãƒã‚§ãƒƒã‚¯è‡ªå‹•åŒ–"""
    
    def __init__(self, source_dir: str = "nf_auto_runner"):
        self.source_dir = source_dir
        self.results: Dict[str, Any] = {}
    
    def check_coverage(self) -> float:
        """ãƒ†ã‚¹ãƒˆã‚«ãƒãƒ¬ãƒƒã‚¸ãƒã‚§ãƒƒã‚¯"""
        result = subprocess.run(
            ["pytest", "--cov=" + self.source_dir, "--cov-report=json"],
            capture_output=True,
            text=True
        )
        
        with open("coverage.json") as f:
            data = json.load(f)
        
        coverage = data["totals"]["percent_covered"]
        self.results["coverage"] = coverage
        return coverage
    
    def check_pylint(self) -> float:
        """Pylintã‚¹ã‚³ã‚¢ãƒã‚§ãƒƒã‚¯"""
        result = subprocess.run(
            ["pylint", self.source_dir, "--output-format=json"],
            capture_output=True,
            text=True
        )
        
        data = json.loads(result.stdout)
        score = 10.0 - (len(data) * 0.1)  # ç°¡æ˜“è¨ˆç®—
        self.results["pylint"] = score
        return score
    
    def check_mypy(self) -> bool:
        """MyPyå‹ãƒã‚§ãƒƒã‚¯"""
        result = subprocess.run(
            ["mypy", self.source_dir, "--strict"],
            capture_output=True,
            text=True
        )
        
        passed = result.returncode == 0
        self.results["mypy"] = "pass" if passed else "fail"
        return passed
    
    def check_complexity(self) -> float:
        """å¾ªç’°çš„è¤‡é›‘åº¦ãƒã‚§ãƒƒã‚¯"""
        result = subprocess.run(
            ["radon", "cc", self.source_dir, "-a", "-j"],
            capture_output=True,
            text=True
        )
        
        data = json.loads(result.stdout)
        avg_complexity = sum(
            item["complexity"] for item in data.values()
        ) / len(data)
        
        self.results["complexity"] = avg_complexity
        return avg_complexity
    
    def check_all(self) -> Dict[str, Any]:
        """ã™ã¹ã¦ã®ãƒã‚§ãƒƒã‚¯ã‚’å®Ÿè¡Œ"""
        coverage = self.check_coverage()
        pylint_score = self.check_pylint()
        mypy_passed = self.check_mypy()
        complexity = self.check_complexity()
        
        # å“è³ªã‚²ãƒ¼ãƒˆåˆ¤å®š
        passed = (
            coverage > 90.0 and
            pylint_score >= 8.5 and
            mypy_passed and
            complexity < 10.0
        )
        
        self.results["overall"] = "PASS" if passed else "FAIL"
        
        return self.results
    
    def print_report(self):
        """ãƒ¬ãƒãƒ¼ãƒˆå‡ºåŠ›"""
        print("=" * 60)
        print("Quality Check Report")
        print("=" * 60)
        print(f"Coverage:    {self.results['coverage']:.1f}% {'âœ…' if self.results['coverage'] > 90 else 'âŒ'}")
        print(f"Pylint:      {self.results['pylint']:.1f}/10 {'âœ…' if self.results['pylint'] >= 8.5 else 'âŒ'}")
        print(f"MyPy:        {self.results['mypy']} {'âœ…' if self.results['mypy'] == 'pass' else 'âŒ'}")
        print(f"Complexity:  {self.results['complexity']:.1f} {'âœ…' if self.results['complexity'] < 10 else 'âŒ'}")
        print("=" * 60)
        print(f"Overall:     {self.results['overall']} {'âœ…' if self.results['overall'] == 'PASS' else 'âŒ'}")
        print("=" * 60)


# ä½¿ç”¨ä¾‹
if __name__ == "__main__":
    checker = QualityChecker()
    results = checker.check_all()
    checker.print_report()
    
    # å“è³ªã‚²ãƒ¼ãƒˆå¤±æ•—æ™‚ã¯CIå¤±æ•—
    if results["overall"] != "PASS":
        exit(1)
```

---

## 3. é–‹ç™ºãƒ—ãƒ­ã‚»ã‚¹ã¨PDCA

### 3.1 PDCAã‚µã‚¤ã‚¯ãƒ«

ã™ã¹ã¦ã®é–‹ç™ºã‚¿ã‚¹ã‚¯ã¯ã€ä»¥ä¸‹ã®PDCAã‚µã‚¤ã‚¯ãƒ«ã«å¾“ã„ã¾ã™ï¼š

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  P (Plan): ç›®çš„ãƒ»KPIãƒ»åˆ¶ç´„ãƒ»å—å…¥åŸºæº– â†’ å®Ÿé¨“è¨­è¨ˆ        â”‚
â”‚  - ä½•ã‚’é”æˆã™ã‚‹ã®ã‹æ˜ç¢ºåŒ–                                â”‚
â”‚  - ä»®èª¬ã‚’ç«‹ã¦ã‚‹                                          â”‚
â”‚  - æ¤œè¨¼æ–¹æ³•ã‚’è¨­è¨ˆ                                        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                    â”‚
                    â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  D (Do): æ‰‹é †ï¼ˆå†ç¾å¯èƒ½ï¼‰ã€å®Ÿè¡Œãƒ­ã‚°ã€ã‚¢ãƒ¼ãƒ†ã‚£ãƒ•ã‚¡ã‚¯ãƒˆ â”‚
â”‚  - å®Ÿè£…ãƒ»å®Ÿé¨“ã‚’å®Ÿè¡Œ                                      â”‚
â”‚  - ã™ã¹ã¦ã®ã‚¹ãƒ†ãƒƒãƒ—ã‚’è¨˜éŒ²                                â”‚
â”‚  - ã‚¢ãƒ¼ãƒ†ã‚£ãƒ•ã‚¡ã‚¯ãƒˆã‚’ä¿å­˜                                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                    â”‚
                    â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  C (Check): çµæœï¼ˆæŒ‡æ¨™ãƒ»çµ±è¨ˆãƒ»è²»ç”¨ãƒ»COâ‚‚ï¼‰ã€å·®åˆ†è§£é‡ˆ    â”‚
â”‚  - ãƒ¡ãƒˆãƒªã‚¯ã‚¹ã‚’æ¸¬å®š                                      â”‚
â”‚  - ä»®èª¬ã¨çµæœã‚’æ¯”è¼ƒ                                      â”‚
â”‚  - å·®åˆ†ã‚’è§£é‡ˆ                                            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                    â”‚
                    â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  A (Act): æ’ä¹…å¯¾ç­–ãƒ»ADRè¦å¦ãƒ»æ¬¡ã®åå¾©                   â”‚
â”‚  - å•é¡ŒãŒã‚ã‚Œã°æ’ä¹…å¯¾ç­–                                  â”‚
â”‚  - é‡è¦ãªæ±ºå®šã¯ADRè¨˜éŒ²                                   â”‚
â”‚  - æ¬¡ã®ã‚µã‚¤ã‚¯ãƒ«ã¸                                        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

### 3.2 PDCAå®Ÿè·µä¾‹

```markdown
## PDCAå®Ÿè·µ: AutoNHITS vs Prophet æ€§èƒ½æ¯”è¼ƒ

### P (Plan): è¨ˆç”»

#### ç›®çš„
AutoNHITS ã¨ Prophet ã®äºˆæ¸¬ç²¾åº¦ã‚’æ¯”è¼ƒã—ã€ã©ã¡ã‚‰ã‚’æ¡ç”¨ã™ã¹ãã‹æ±ºå®šã™ã‚‹

#### KPI
- MAE (Mean Absolute Error)
- RMSE (Root Mean Squared Error)
- å­¦ç¿’æ™‚é–“
- äºˆæ¸¬æ™‚é–“

#### åˆ¶ç´„
- äºˆç®—: 3æ—¥ä»¥å†…ã«å®Œäº†
- ãƒªã‚½ãƒ¼ã‚¹: å˜ä¸€GPUï¼ˆRTX 4090ï¼‰
- ãƒ‡ãƒ¼ã‚¿: Air Passengers ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆï¼ˆ144ãƒ¶æœˆï¼‰

#### å—å…¥åŸºæº–
- [ ] ä¸¡ãƒ¢ãƒ‡ãƒ«ã§åŒã˜ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆä½¿ç”¨
- [ ] åŒã˜è©•ä¾¡æŒ‡æ¨™ã§æ¯”è¼ƒ
- [ ] çµ±è¨ˆçš„æœ‰æ„å·®ã‚’æ¤œè¨¼ï¼ˆtæ¤œå®šï¼‰
- [ ] 5å›ã®ç‹¬ç«‹å®Ÿè¡Œã§å¹³å‡ãƒ»æ¨™æº–åå·®ã‚’è¨ˆç®—

#### å®Ÿé¨“è¨­è¨ˆ
- **å¯¾ç…§ç¾¤**: Prophetï¼ˆãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³ï¼‰
- **å®Ÿé¨“ç¾¤**: AutoNHITS
- **æ¸¬å®šæŒ‡æ¨™**: MAE, RMSE, å­¦ç¿’æ™‚é–“, äºˆæ¸¬æ™‚é–“
- **äº¤å·®æ¤œè¨¼**: Time Series Split (5 folds)

---

### D (Do): å®Ÿè¡Œ

#### å®Ÿè¡Œæ‰‹é †

```bash
# 1. ç’°å¢ƒæº–å‚™
pip install neuralforecast==1.7.2 prophet==1.1.5

# 2. ãƒ‡ãƒ¼ã‚¿æº–å‚™
python scripts/prepare_data.py --dataset air_passengers --output data/

# 3. Prophetå®Ÿè¡Œ
python src/run_experiment.py \
    --model prophet \
    --data data/air_passengers.csv \
    --output outputs/prophet/ \
    --n-runs 5

# 4. AutoNHITSå®Ÿè¡Œ
python src/run_experiment.py \
    --model auto_nhits \
    --data data/air_passengers.csv \
    --output outputs/auto_nhits/ \
    --n-runs 5
```

#### å®Ÿè¡Œãƒ­ã‚°

```json
{
  "experiment_id": "exp_model_comparison_001",
  "timestamp": "2025-11-04T10:00:00Z",
  "models": ["prophet", "auto_nhits"],
  "data": {
    "source": "data/air_passengers.csv",
    "hash": "a3f5c9d8...",
    "n_samples": 144
  },
  "runs": [
    {
      "run_id": "prophet_run_001",
      "model": "prophet",
      "mae": 24.5,
      "rmse": 32.1,
      "train_time_sec": 12.3,
      "predict_time_sec": 0.8
    },
    // ... çœç•¥ ...
  ]
}
```

#### ã‚¢ãƒ¼ãƒ†ã‚£ãƒ•ã‚¡ã‚¯ãƒˆ
- `outputs/prophet/model_{1-5}.pkl`
- `outputs/auto_nhits/model_{1-5}.pt`
- `outputs/metrics.csv`
- `mlflow://experiments/model_comparison_001`

---

### C (Check): ç¢ºèª

#### çµæœ

| ãƒ¢ãƒ‡ãƒ« | MAE | RMSE | å­¦ç¿’æ™‚é–“ (ç§’) | äºˆæ¸¬æ™‚é–“ (ç§’) |
|--------|-----|------|--------------|--------------|
| **Prophet** | 24.5Â±2.1 | 32.1Â±2.8 | 12.3Â±1.5 | 0.8Â±0.1 |
| **AutoNHITS** | 18.7Â±1.6 | 25.4Â±2.1 | 45.2Â±3.7 | 0.3Â±0.05 |

**å·®åˆ†**:
- MAE: 23.7% æ”¹å–„ (24.5 â†’ 18.7)
- RMSE: 20.9% æ”¹å–„ (32.1 â†’ 25.4)
- å­¦ç¿’æ™‚é–“: 3.7å€é…ã„ (12.3 â†’ 45.2)
- äºˆæ¸¬æ™‚é–“: 2.7å€é€Ÿã„ (0.8 â†’ 0.3)

#### çµ±è¨ˆçš„æœ‰æ„æ€§

```python
from scipy import stats

prophet_mae = [24.5, 23.8, 25.2, 24.1, 24.9]
autohits_mae = [18.7, 19.2, 18.1, 19.0, 18.5]

t_stat, p_value = stats.ttest_ind(prophet_mae, autohits_mae)
print(f"tçµ±è¨ˆé‡: {t_stat:.3f}, på€¤: {p_value:.4f}")
# çµæœ: tçµ±è¨ˆé‡: 8.542, på€¤: 0.0003 â†’ æœ‰æ„å·®ã‚ã‚Š (p < 0.05)
```

#### è§£é‡ˆ
- AutoNHITS ã¯ Prophet ã‚ˆã‚Š **æœ‰æ„ã«ç²¾åº¦ãŒé«˜ã„** (p < 0.05)
- å­¦ç¿’æ™‚é–“ã¯3.7å€ã ãŒã€**è¨±å®¹ç¯„å›²å†…** (45ç§’ vs 12ç§’)
- äºˆæ¸¬æ™‚é–“ã¯2.7å€é€Ÿãã€**æœ¬ç•ªé‹ç”¨ã§æœ‰åˆ©**

---

### A (Act): æ”¹å–„

#### æ’ä¹…å¯¾ç­–
- **æ±ºå®š**: AutoNHITS ã‚’æ¡ç”¨
- **ç†ç”±**: ç²¾åº¦ãŒæœ‰æ„ã«é«˜ãã€äºˆæ¸¬æ™‚é–“ã‚‚é€Ÿã„

#### ADR (Architecture Decision Record)

```markdown
# ADR-004: AutoNHITSã®æ¡ç”¨

## ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹
æ‰¿èªæ¸ˆã¿

## ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆ
æ™‚ç³»åˆ—äºˆæ¸¬ãƒ¢ãƒ‡ãƒ«ã®é¸å®šãŒå¿…è¦

## æ±ºå®š
AutoNHITS ã‚’æ¡ç”¨

## æ ¹æ‹ 
- MAE: 23.7% æ”¹å–„
- RMSE: 20.9% æ”¹å–„
- çµ±è¨ˆçš„ã«æœ‰æ„ (p < 0.05)
- äºˆæ¸¬æ™‚é–“ã¯2.7å€é€Ÿã„

## ä»£æ›¿æ¡ˆ
- Prophet: ç²¾åº¦ã§AutoNHITSã«åŠ£ã‚‹
- ARIMA: éç·šå½¢ãƒ‘ã‚¿ãƒ¼ãƒ³ã«å¼±ã„

## å½±éŸ¿
- å­¦ç¿’æ™‚é–“ãŒ3.7å€ï¼ˆè¨±å®¹ç¯„å›²å†…ï¼‰
- GPUå¿…é ˆ
```

#### æ¬¡ã®åå¾©
- [ ] AutoNHITSã®ãƒã‚¤ãƒ‘ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æœ€é©åŒ–
- [ ] ä»–ã®ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã§ã‚‚æ¤œè¨¼
- [ ] æœ¬ç•ªç’°å¢ƒã§A/Bãƒ†ã‚¹ãƒˆ
```

---

### 3.3 ãƒˆãƒ©ãƒ–ãƒ«ã‚·ãƒ¥ãƒ¼ãƒˆæ™‚ã®PDCA

```markdown
## ãƒˆãƒ©ãƒ–ãƒ«ã‚·ãƒ¥ãƒ¼ãƒˆ: CUDA out of memory

### P (Plan): è¨ˆç”»

#### å•é¡Œ
`CUDA out of memory` ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿ

#### ä»®èª¬
1. `input_size`ãŒå¤§ãã™ãã‚‹ (ç¢ºç‡ 90%)
2. ãƒãƒƒãƒã‚µã‚¤ã‚ºãŒå¤§ãã™ãã‚‹ (ç¢ºç‡ 5%)
3. PyTorchã®ãƒã‚° (ç¢ºç‡ 5%)

#### æ¤œè¨¼è¨ˆç”»
1. `input_size`ã‚’æ®µéšçš„ã«æ¸›ã‚‰ã™
2. ãƒãƒƒãƒã‚µã‚¤ã‚ºã‚’åŠåˆ†ã«ã™ã‚‹
3. PyTorchã‚’ãƒ€ã‚¦ãƒ³ã‚°ãƒ¬ãƒ¼ãƒ‰

---

### D (Do): å®Ÿè¡Œ

```bash
# æ¤œè¨¼1: input_sizeã‚’128ã«
python src/train.py --input-size 128
# çµæœ: æˆåŠŸ âœ…

# æ¤œè¨¼2: input_sizeã‚’168ã€batch_size=16ã«
python src/train.py --input-size 168 --batch-size 16
# çµæœ: å¤±æ•— âŒ

# æ¤œè¨¼3: Mixed Precision
python src/train.py --input-size 168 --precision 16
# çµæœ: æˆåŠŸ âœ…
```

---

### C (Check): ç¢ºèª

#### çµæœ
- `input_size=128`: æˆåŠŸ
- `input_size=168 + batch_size=16`: å¤±æ•—
- `input_size=168 + precision=16`: æˆåŠŸ

#### è§£é‡ˆ
`input_size`ãŒåŸå› ã€‚Mixed Precision (FP16) ã§ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡ã‚’åŠæ¸›ã§ããŸã€‚

---

### A (Act): æ”¹å–„

#### æ’ä¹…å¯¾ç­–
```python
# config/model.py
@dataclass
class ModelConfig:
    input_size: int = 128  # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã‚’128ã«å¤‰æ›´
    precision: int = 16    # FP16ã‚’æœ‰åŠ¹åŒ–
```

#### ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆæ›´æ–°
```markdown
# docs/TROUBLESHOOTING.md

## CUDA out of memory

### è§£æ±ºç­–
1. `input_size`ã‚’128ä»¥ä¸‹ã«åˆ¶é™
2. Mixed Precision (`precision=16`) ã‚’æœ‰åŠ¹åŒ–
3. Gradient Accumulation ã‚’ä½¿ç”¨
```

#### å›å¸°ãƒ†ã‚¹ãƒˆè¿½åŠ 
```python
# tests/test_memory.py
def test_large_input_size_with_fp16():
    """å¤§ããªinput_sizeã§ã‚‚FP16ãªã‚‰å‹•ä½œã™ã‚‹"""
    model = AutoNHITS(input_size=168, precision=16)
    # ãƒ†ã‚¹ãƒˆã‚³ãƒ¼ãƒ‰...
```
```

---

# ç¬¬2éƒ¨: Roleåˆ¥ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆ

## 4. ãƒªãƒ¼ãƒ‰ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢Role

### 4.1 Roleå®šç¾©

```markdown
## [Role]
ã‚ãªãŸã¯æœ¬æ¡ˆä»¶ã®ãƒªãƒ¼ãƒ‰ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ã€‚è³‡æ–™ï¼ˆè¤‡æ•°å¯ï¼‰ã‚’èª­ã¿è¾¼ã¿ã€æœ€é©è§£ã¸åˆ°é”ã™ã‚‹ãŸã‚ã®PDCAã‚’è¨­è¨ˆãƒ»å®Ÿè¡Œã™ã‚‹ã€‚
```

### 4.2 Inputå½¢å¼

```markdown
## [Input]
- **è³‡æ–™**: <URL/æœ¬æ–‡/æ·»ä»˜è¦ç´„>
- **ç›®çš„/KPI**: <å®šé‡æŒ‡æ¨™ã¨é–¾å€¤>
- **åˆ¶ç´„**: <æ™‚é–“/è³‡æº/äº’æ›æ€§/ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£>
- **æˆæœç‰©**: <æœŸå¾…ã™ã‚‹ãƒ•ã‚¡ã‚¤ãƒ«/ã‚¹ã‚­ãƒ¼ãƒ/ãƒ€ãƒƒã‚·ãƒ¥/ã‚³ãƒ¼ãƒ‰>
```

### 4.3 Taskå®šç¾©

```markdown
## [Task]
1) ç›®æ¨™/åˆ¶ç´„/å—å…¥åŸºæº–ã®å†æ²
2) æ—¢çŸ¥ã‚®ãƒ£ãƒƒãƒ—ã¨æ¤œè¨¼ãƒ—ãƒ©ãƒ³
3) å®Ÿè¡Œè¨ˆç”»ï¼ˆå°ã•ãªãƒãƒƒãƒã€è¨ˆæ¸¬ã€ãƒ­ãƒ¼ãƒ«ãƒãƒƒã‚¯ï¼‰
4) å®Ÿè£…/çµæœã®è¦ç´„
5) KPIè©•ä¾¡ã¨è§£é‡ˆ
6) æ¬¡ã®ä¸€æ‰‹ï¼ˆæ”¹å–„/è¿½åŠ æ¤œè¨¼/ADRè¦å¦ï¼‰
```

### 4.4 Outputå½¢å¼ (JSON)

```json
{
  "goals": [
    "AutoNHITSã¨Prophetã®æ€§èƒ½æ¯”è¼ƒ",
    "ã©ã¡ã‚‰ã‚’æ¡ç”¨ã™ã¹ãã‹æ±ºå®š"
  ],
  "acceptance_criteria": [
    "ä¸¡ãƒ¢ãƒ‡ãƒ«ã§åŒã˜ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆä½¿ç”¨",
    "çµ±è¨ˆçš„æœ‰æ„å·®ã‚’æ¤œè¨¼ï¼ˆp < 0.05ï¼‰",
    "5å›ã®ç‹¬ç«‹å®Ÿè¡Œã§å¹³å‡ãƒ»æ¨™æº–åå·®ã‚’è¨ˆç®—"
  ],
  "plan": [
    "Step 1: ãƒ‡ãƒ¼ã‚¿æº–å‚™ï¼ˆAir Passengersï¼‰",
    "Step 2: Prophetå®Ÿè¡Œï¼ˆ5å›ï¼‰",
    "Step 3: AutoNHITSå®Ÿè¡Œï¼ˆ5å›ï¼‰",
    "Step 4: çµ±è¨ˆçš„æ¤œå®šï¼ˆtæ¤œå®šï¼‰",
    "Step 5: çµæœè§£é‡ˆ"
  ],
  "actions": [
    "Prophetå­¦ç¿’å®Œäº†ï¼ˆ5å›ã€å¹³å‡MAE=24.5Â±2.1ï¼‰",
    "AutoNHITSå­¦ç¿’å®Œäº†ï¼ˆ5å›ã€å¹³å‡MAE=18.7Â±1.6ï¼‰",
    "tæ¤œå®šå®Ÿæ–½ï¼ˆt=8.542, p=0.0003ï¼‰"
  ],
  "findings": {
    "metrics": {
      "mae_improvement": "23.7%",
      "rmse_improvement": "20.9%",
      "training_time_ratio": "3.7x slower",
      "prediction_time_ratio": "2.7x faster",
      "statistical_significance": "p=0.0003 (æœ‰æ„)"
    },
    "artifacts": [
      "outputs/prophet/model_{1-5}.pkl",
      "outputs/auto_nhits/model_{1-5}.pt",
      "mlflow://experiments/model_comparison_001"
    ]
  },
  "risks": [
    "AutoNHITSã¯å­¦ç¿’æ™‚é–“ãŒ3.7å€ï¼ˆ45ç§’ vs 12ç§’ï¼‰",
    "GPUå¿…é ˆï¼ˆæœ¬ç•ªç’°å¢ƒã§GPUèª¿é”ãŒå¿…è¦ï¼‰"
  ],
  "next": [
    "AutoNHITSã®ãƒã‚¤ãƒ‘ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æœ€é©åŒ–",
    "ä»–ã®ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã§ã‚‚æ¤œè¨¼",
    "ADR-004è¨˜éŒ²ï¼ˆAutoNHITSæ¡ç”¨æ±ºå®šï¼‰"
  ]
}
```

### 4.5 ä½¿ç”¨ä¾‹

```markdown
## å…¥åŠ›

[Role]
ã‚ãªãŸã¯æœ¬æ¡ˆä»¶ã®ãƒªãƒ¼ãƒ‰ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ã€‚

[Input]
- **è³‡æ–™**: Time_Series_Forecasting_System_Requirements_Specification__First_Edition_.md
- **ç›®çš„/KPI**: AutoNHITS vs Prophet ã®æ€§èƒ½æ¯”è¼ƒã€MAE 20%æ”¹å–„
- **åˆ¶ç´„**: 3æ—¥ä»¥å†…ã€å˜ä¸€GPUï¼ˆRTX 4090ï¼‰
- **æˆæœç‰©**: æ¯”è¼ƒãƒ¬ãƒãƒ¼ãƒˆï¼ˆJSONå½¢å¼ï¼‰ã€ADR

[Task]
ä¸Šè¨˜Inputã«åŸºã¥ãã€å®Ÿé¨“ã‚’è¨­è¨ˆãƒ»å®Ÿè¡Œã—ã€çµæœã‚’JSONå½¢å¼ã§å‡ºåŠ›ã—ã¦ãã ã•ã„ã€‚

---

## å‡ºåŠ›ï¼ˆClaudeï¼‰

```json
{
  "goals": [...],
  "acceptance_criteria": [...],
  "plan": [...],
  "actions": [...],
  "findings": {...},
  "risks": [...],
  "next": [...]
}
```
```

---

## 5. ã‚¤ãƒ³ã‚·ãƒ‡ãƒ³ãƒˆå¯¾å¿œRole

### 5.1 Roleå®šç¾©

```markdown
## [Role]
ã‚ãªãŸã¯ã‚¤ãƒ³ã‚·ãƒ‡ãƒ³ãƒˆæŒ‡æ®æ‹…å½“ã€‚éšœå®³ã‚’å†·é™ã«ãƒˆãƒªã‚¢ãƒ¼ã‚¸ã—ã€T+15åˆ†åˆå‹•/T+60åˆ†æš«å®šå¾©æ—§ã‚’ç›®æ¨™ã«å°ãã€‚
```

### 5.2 Inputå½¢å¼

```markdown
## [Input]
- **ç—‡çŠ¶/æŒ‡æ¨™**: <p95, error_rate, coverage ä¹–é›¢ ç­‰>
- **ç›´è¿‘å¤‰æ›´**: <ãƒ‡ãƒ—ãƒ­ã‚¤/è¨­å®š/DDL/å¤–éƒ¨ä¾å­˜>
- **å½±éŸ¿ç¯„å›²**: <API/ãƒãƒƒãƒ/ã‚¹ãƒ©ã‚¤ã‚¹/é¡§å®¢>
- **ãƒ­ã‚°/Run**: <ãƒªãƒ³ã‚¯ã¾ãŸã¯æŠœç²‹>
```

### 5.3 Taskå®šç¾©

```markdown
## [Task]
1) Severity è©•ä¾¡ï¼ˆP1ã€œP4ï¼‰
2) æš«å®šç·©å’Œï¼ˆA/Bæ¯”ç‡/ãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³/é®æ–­/ã‚¹ãƒ­ãƒƒãƒˆãƒªãƒ³ã‚°ï¼‰
3) åˆ‡ã‚Šåˆ†ã‘æ±ºå®šæœ¨ï¼ˆãƒ‡ãƒ¼ã‚¿/ãƒ¢ãƒ‡ãƒ«/ã‚¤ãƒ³ãƒ•ãƒ©ï¼‰
4) å†ç¾æœ€å°åŒ–â†’ä»®èª¬â†’æ¤œè¨¼ï¼ˆã‚¨ãƒ“ãƒ‡ãƒ³ã‚¹æ·»ä»˜ï¼‰
5) æš«å®šå¾©æ—§æ¡ˆ / æ’ä¹…å¯¾ç­–æ¡ˆ
```

### 5.4 Outputå½¢å¼ (Markdown)

```markdown
### åˆå‹•
- **Severity**: P1 (Critical)
- **ç·©å’Œ**: ãƒ¢ãƒ‡ãƒ«v2.0ã‚’å³åº§ã«ãƒ­ãƒ¼ãƒ«ãƒãƒƒã‚¯â†’v1.9ã«åˆ‡ã‚Šæ›¿ãˆ

### åˆ‡ã‚Šåˆ†ã‘/æ¤œè¨¼
- **ä»®èª¬**: v2.0ã®input_sizeå¢—åŠ ãŒãƒ¡ãƒ¢ãƒªä¸è¶³ã‚’å¼•ãèµ·ã“ã—ãŸ
- **æ¤œè¨¼çµæœ**: `input_size=168`ã§`CUDA out of memory`ã‚¨ãƒ©ãƒ¼å†ç¾ï¼ˆ100%ï¼‰

### æš«å®šå¾©æ—§ / æ’ä¹…å¯¾ç­–
- **æš«å®š**: v1.9ã¸ãƒ­ãƒ¼ãƒ«ãƒãƒƒã‚¯å®Œäº†ï¼ˆT+10åˆ†ï¼‰
- **æ’ä¹…**: Mixed Precision (FP16) å®Ÿè£…ã€input_sizeä¸Šé™ã‚’128ã«è¨­å®š
```

### 5.5 ä½¿ç”¨ä¾‹

```markdown
## å…¥åŠ›

[Role]
ã‚ãªãŸã¯ã‚¤ãƒ³ã‚·ãƒ‡ãƒ³ãƒˆæŒ‡æ®æ‹…å½“ã€‚

[Input]
- **ç—‡çŠ¶/æŒ‡æ¨™**: æœ¬ç•ªç’°å¢ƒã§ãƒ¢ãƒ‡ãƒ«å­¦ç¿’ãŒ100%å¤±æ•—ã€`CUDA out of memory`ã‚¨ãƒ©ãƒ¼
- **ç›´è¿‘å¤‰æ›´**: æ˜¨æ—¥ã€ãƒ¢ãƒ‡ãƒ«v2.0ãƒ‡ãƒ—ãƒ­ã‚¤ï¼ˆinput_sizeã‚’84â†’168ã«å¤‰æ›´ï¼‰
- **å½±éŸ¿ç¯„å›²**: å…¨ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®ãƒ¢ãƒ‡ãƒ«å­¦ç¿’ãŒåœæ­¢
- **ãƒ­ã‚°/Run**: `mlflow://experiments/prod/runs/xyz789`

[Task]
ä¸Šè¨˜Inputã«åŸºã¥ãã€åˆå‹•å¯¾å¿œã‹ã‚‰æ’ä¹…å¯¾ç­–ã¾ã§æŒ‡ç¤ºã—ã¦ãã ã•ã„ã€‚

---

## å‡ºåŠ›ï¼ˆClaudeï¼‰

### åˆå‹•
- **Severity**: P1 (Critical) - å…¨ãƒ¦ãƒ¼ã‚¶ãƒ¼å½±éŸ¿
- **ç·©å’Œ**: å³åº§ã«v1.9ã¸ãƒ­ãƒ¼ãƒ«ãƒãƒƒã‚¯

(ä»¥ä¸‹ã€è©³ç´°...)
```

---

## 6. ä»•æ§˜åˆ†æRole

### 6.1 Roleå®šç¾©

```markdown
## System
ä¸€æ¬¡æƒ…å ±ã‚’å„ªå…ˆã—ã€ç”¨èª/æ•°å¼/é–¾å€¤/å‰æã‚’æŠ½å‡ºã€‚æ›–æ˜§èªã‚’å®šç¾©ã—ã€é½Ÿé½¬ç‚¹ã‚’åˆ—æŒ™ã€‚
```

### 6.2 Inputå½¢å¼

```markdown
## User
- **å…¥åŠ›è³‡æ–™**: <æœ¬æ–‡/URL/æ·»ä»˜è¦ç´„>
- **æœŸå¾…**: ç”¨èªå®šç¾© / ä»•æ§˜æŠœç²‹ / æœªç¢ºå®šäº‹é … / ã‚¢ã‚¯ã‚·ãƒ§ãƒ³
```

### 6.3 Outputå½¢å¼ (Markdown)

```markdown
### ç”¨èª/å®šç¾©
- **AutoNHITS**: NeuralForecastã®ãƒ¢ãƒ‡ãƒ«ã€éšå±¤çš„è£œé–“ã§å­£ç¯€æ€§ãƒ»ãƒˆãƒ¬ãƒ³ãƒ‰ã‚’è‡ªå‹•æ¤œå‡º
- **input_size**: å…¥åŠ›æ™‚ç³»åˆ—ã®é•·ã•ï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ84ã€æ¨å¥¨â‰¤128ï¼‰

### ä»•æ§˜ã®æ ¸ï¼ˆæ•°å¼/é–¾å€¤/å¥‘ç´„ï¼‰
- MAE (Mean Absolute Error): `Î£|y_true - y_pred| / n`
- é–¾å€¤: MAE < 20 units, RMSE < 30 units

### çŸ›ç›¾ãƒ»æœªç¢ºå®š
- ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã«input_sizeã®ä¸Šé™ãŒæ˜è¨˜ã•ã‚Œã¦ã„ãªã„
- ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡ã®è¨ˆç®—å¼ãŒä¸æ˜

### ã‚¢ã‚¯ã‚·ãƒ§ãƒ³ï¼ˆæ‹…å½“/RACI/æœŸé™ï¼‰
- [ ] **æ‹…å½“**: Alice (R), Bob (A)
- [ ] **æœŸé™**: 2025-11-10
- [ ] **å†…å®¹**: input_sizeä¸Šé™ã‚’å®Ÿæ¸¬ã—ã€ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆæ›´æ–°
```

### 6.4 ä½¿ç”¨ä¾‹

```markdown
## å…¥åŠ›

System: ä¸€æ¬¡æƒ…å ±ã‚’å„ªå…ˆã—ã€ç”¨èª/æ•°å¼/é–¾å€¤/å‰æã‚’æŠ½å‡ºã€‚

User:
- **å…¥åŠ›è³‡æ–™**: https://nixtlaverse.nixtla.io/neuralforecast/models.nhits.html
- **æœŸå¾…**: AutoNHITSã®ä»•æ§˜ã‚’æŠ½å‡ºã€æœªç¢ºå®šäº‹é …ã‚’åˆ—æŒ™

---

## å‡ºåŠ›ï¼ˆClaudeï¼‰

### ç”¨èª/å®šç¾©
- **AutoNHITS**: ...

(ä»¥ä¸‹ã€è©³ç´°...)
```

---

## 7. ç’°å¢ƒãƒã‚§ãƒƒã‚¯Role

### 7.1 Roleå®šç¾©

```markdown
## System
å®Ÿè¡Œç’°å¢ƒ/ä¾å­˜/Secrets/æ¥ç¶šå…ˆ/æ¨©é™/ãƒãƒ¼ã‚¸ãƒ§ãƒ³ã‚’ç‚¹æ¤œã—ã€ãƒªã‚¹ã‚¯ã‚’åˆ—æŒ™ã€‚
```

### 7.2 Inputå½¢å¼

```markdown
## User
å¯¾è±¡ã‚¿ã‚¹ã‚¯/ãƒãƒ¼ãƒ‰æƒ…å ±/å¿…è¦ãƒªã‚½ãƒ¼ã‚¹
```

### 7.3 Outputå½¢å¼ (JSON)

```json
{
  "os": "Ubuntu 22.04.3 LTS",
  "python": "3.11.5",
  "cuda": "12.1",
  "deps": {
    "neuralforecast": "1.7.2",
    "torch": "2.1.0",
    "pandas": "2.1.3"
  },
  "endpoints": [
    "postgresql://localhost:5432/mldb",
    "mlflow://localhost:5000"
  ],
  "risks": [
    "CUDA version mismatchï¼ˆæœŸå¾…: 12.1, å®Ÿéš›: 11.8ï¼‰",
    "PostgreSQLæœªèµ·å‹•"
  ],
  "checks": [
    "python --version",
    "nvidia-smi",
    "psql -U postgres -c 'SELECT version();'"
  ]
}
```

### 7.4 ä½¿ç”¨ä¾‹

```markdown
## å…¥åŠ›

System: å®Ÿè¡Œç’°å¢ƒã‚’ç‚¹æ¤œã—ã€ãƒªã‚¹ã‚¯ã‚’åˆ—æŒ™ã€‚

User: AutoNHITSå­¦ç¿’ã‚¿ã‚¹ã‚¯ã®å®Ÿè¡Œç’°å¢ƒã‚’ãƒã‚§ãƒƒã‚¯ã—ã¦ãã ã•ã„ã€‚

---

## å‡ºåŠ›ï¼ˆClaudeï¼‰

```json
{
  "os": "Ubuntu 22.04.3 LTS",
  ...
}
```
```

---

## 8. ã‚³ãƒ¼ãƒ‰ç”ŸæˆRole

### 8.1 Roleå®šç¾©

```markdown
## System
æœ€å°API/å‹/Docstring/ä¾‹å¤–/ãƒ­ã‚°/è¨ˆæ¸¬/MLflowè¨˜éŒ²ã‚’å¿…ãšå«ã‚€ã€‚
```

### 8.2 Inputå½¢å¼

```markdown
## User
è¦ä»¶/å…¥å‡ºåŠ›/åˆ¶ç´„/å¯¾è±¡ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«
```

### 8.3 Outputå½¢å¼

- **ã‚³ãƒ¼ãƒ‰**: å®Œå…¨ãªå®Ÿè£…
- **å˜ä½“ãƒ†ã‚¹ãƒˆ**: pytestå½¢å¼
- **ä½¿ç”¨ä¾‹**: å®Ÿè¡Œå¯èƒ½ãªã‚³ãƒ¼ãƒ‰
- **MLflowãƒ­ã‚®ãƒ³ã‚°**: ãƒ¡ãƒˆãƒªã‚¯ã‚¹è¨˜éŒ²

### 8.4 ä½¿ç”¨ä¾‹

```markdown
## å…¥åŠ›

System: æœ€å°API/å‹/Docstring/ä¾‹å¤–/ãƒ­ã‚°/è¨ˆæ¸¬/MLflowè¨˜éŒ²ã‚’å¿…ãšå«ã‚€ã€‚

User:
- **è¦ä»¶**: ãƒ‡ãƒ¼ã‚¿æ¤œè¨¼ã‚¯ãƒ©ã‚¹ï¼ˆDataValidatorï¼‰ã‚’å®Ÿè£…
- **å…¥å‡ºåŠ›**: pd.DataFrame â†’ ValidationResult
- **åˆ¶ç´„**: ã‚¹ã‚­ãƒ¼ãƒæ¤œè¨¼ã€æ¬ æå€¤ãƒã‚§ãƒƒã‚¯ã€å¤–ã‚Œå€¤æ¤œå‡º
- **å¯¾è±¡ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«**: `nf_auto_runner/data/validator.py`

---

## å‡ºåŠ›ï¼ˆClaudeï¼‰

```python
# nf_auto_runner/data/validator.py
from dataclasses import dataclass
from typing import List, Optional
import pandas as pd
import logging

logger = logging.getLogger(__name__)

@dataclass
class ValidationResult:
    """æ¤œè¨¼çµæœ"""
    is_valid: bool
    errors: List[str]
    warnings: List[str]

class DataValidator:
    """ãƒ‡ãƒ¼ã‚¿æ¤œè¨¼"""
    
    def __init__(self, required_columns: List[str]):
        self.required_columns = required_columns
    
    def validate(self, df: pd.DataFrame) -> ValidationResult:
        """
        ãƒ‡ãƒ¼ã‚¿ã‚’æ¤œè¨¼ã™ã‚‹
        
        Args:
            df: æ¤œè¨¼å¯¾è±¡ã®DataFrame
        
        Returns:
            ValidationResult: æ¤œè¨¼çµæœ
        
        Raises:
            ValueError: dfãŒNoneã®å ´åˆ
        """
        if df is None:
            raise ValueError("df must not be None")
        
        errors = []
        warnings = []
        
        # ã‚¹ã‚­ãƒ¼ãƒæ¤œè¨¼
        missing_cols = set(self.required_columns) - set(df.columns)
        if missing_cols:
            errors.append(f"Missing columns: {missing_cols}")
        
        # æ¬ æå€¤ãƒã‚§ãƒƒã‚¯
        null_counts = df.isnull().sum()
        if null_counts.any():
            warnings.append(f"Null values found: {null_counts[null_counts > 0].to_dict()}")
        
        is_valid = len(errors) == 0
        
        logger.info(
            f"Validation completed",
            is_valid=is_valid,
            n_errors=len(errors),
            n_warnings=len(warnings)
        )
        
        return ValidationResult(is_valid, errors, warnings)


# tests/unit/data/test_validator.py
import pytest
import pandas as pd
from nf_auto_runner.data.validator import DataValidator, ValidationResult

def test_valid_data():
    """æ­£å¸¸ãªãƒ‡ãƒ¼ã‚¿ã®æ¤œè¨¼"""
    validator = DataValidator(required_columns=["date", "y"])
    df = pd.DataFrame({"date": ["2023-01-01"], "y": [100]})
    
    result = validator.validate(df)
    
    assert result.is_valid is True
    assert len(result.errors) == 0

def test_missing_column():
    """åˆ—æ¬ æã®æ¤œå‡º"""
    validator = DataValidator(required_columns=["date", "y"])
    df = pd.DataFrame({"date": ["2023-01-01"]})  # "y"ãŒãªã„
    
    result = validator.validate(df)
    
    assert result.is_valid is False
    assert "Missing columns" in result.errors[0]

def test_null_values():
    """æ¬ æå€¤ã®æ¤œå‡º"""
    validator = DataValidator(required_columns=["date", "y"])
    df = pd.DataFrame({"date": ["2023-01-01"], "y": [None]})
    
    result = validator.validate(df)
    
    assert result.is_valid is True  # è­¦å‘Šã ã‘ã§é€šé
    assert len(result.warnings) > 0


# ä½¿ç”¨ä¾‹
if __name__ == "__main__":
    import mlflow
    
    mlflow.start_run()
    
    validator = DataValidator(required_columns=["date", "y"])
    df = pd.read_csv("data/train.csv")
    
    result = validator.validate(df)
    
    # MLflowè¨˜éŒ²
    mlflow.log_metric("is_valid", 1 if result.is_valid else 0)
    mlflow.log_metric("n_errors", len(result.errors))
    mlflow.log_metric("n_warnings", len(result.warnings))
    
    print(result)
    
    mlflow.end_run()
```
```

---

## 9. ãƒ‡ãƒãƒƒã‚°&ãƒˆãƒ©ãƒ–ãƒ«ã‚·ãƒ¥ãƒ¼ãƒˆRole

### 9.1 Roleå®šç¾©

```markdown
## System
å†ç¾â†’æœ€å°åŒ–â†’åŸå› å€™è£œâ†’æ¤œè¨¼è¨ˆç”»â†’çµæœâ†’æ’ä¹…å¯¾ç­–ã‚’1ã‚µã‚¤ã‚¯ãƒ«ã§ã€‚
```

### 9.2 Inputå½¢å¼

```markdown
## User
ã‚¨ãƒ©ãƒ¼ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸/ãƒ­ã‚°/ç’°å¢ƒå·®åˆ†/ç›´è¿‘å¤‰æ›´
```

### 9.3 Outputå½¢å¼ (Markdown)

```markdown
### å†ç¾æ‰‹é †
```bash
python src/train.py --input-size 168
# ã‚¨ãƒ©ãƒ¼: RuntimeError: CUDA out of memory
```

### æœ€å°å†ç¾
```python
import torch
X = torch.randn(32, 168, 1).cuda()
# ã‚¨ãƒ©ãƒ¼ç™ºç”Ÿ
```

### åŸå› å€™è£œï¼ˆå„ªå…ˆåº¦é †ï¼‰
1. `input_size`ãŒå¤§ãã™ãã‚‹ (ç¢ºç‡ 90%)
2. ãƒãƒƒãƒã‚µã‚¤ã‚ºãŒå¤§ãã™ãã‚‹ (ç¢ºç‡ 5%)
3. PyTorchã®ãƒã‚° (ç¢ºç‡ 5%)

### æ¤œè¨¼ï¼ˆã‚³ãƒãƒ³ãƒ‰/æœŸå¾…/çµæœï¼‰
```bash
# æ¤œè¨¼1
python src/train.py --input-size 128
# æœŸå¾…: æˆåŠŸ
# çµæœ: æˆåŠŸ âœ…
```

### æ’ä¹…å¯¾ç­–
```python
# config/model.py
input_size: int = 128  # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã‚’128ã«åˆ¶é™
precision: int = 16    # Mixed Precisionæœ‰åŠ¹åŒ–
```
```

---

## 10. ãƒ†ã‚¹ãƒˆè¨­è¨ˆRole

### 10.1 Roleå®šç¾©

```markdown
## System
é‡è¦çµŒè·¯ã«å¯¾ã™ã‚‹ Smoke/Contract Test ã‚’æç¤ºï¼ˆå…¥å‡ºåŠ›ã‚¹ã‚­ãƒ¼ãƒå›ºå®šï¼‰ã€‚
```

### 10.2 Inputå½¢å¼

```markdown
## User
å¯¾è±¡æ©Ÿèƒ½/API å/ã‚¹ã‚­ãƒ¼ãƒ
```

### 10.3 Outputå½¢å¼ (YAML)

```yaml
tests:
  - name: "å­¦ç¿’ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ Smoke Test"
    preconditions:
      - "PostgreSQLèµ·å‹•"
      - "å­¦ç¿’ãƒ‡ãƒ¼ã‚¿å­˜åœ¨"
    steps:
      - "ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿"
      - "ãƒ¢ãƒ‡ãƒ«åˆæœŸåŒ–"
      - "å­¦ç¿’å®Ÿè¡Œ"
      - "ãƒ¡ãƒˆãƒªã‚¯ã‚¹è¨˜éŒ²"
    expected:
      - "å­¦ç¿’å®Œäº†ï¼ˆã‚¨ãƒ©ãƒ¼ãªã—ï¼‰"
      - "MAE < 50"
      - "MLflowã«runè¨˜éŒ²"
  
  - name: "äºˆæ¸¬API Contract Test"
    preconditions:
      - "ãƒ¢ãƒ‡ãƒ«v1.9ãƒ­ãƒ¼ãƒ‰"
    steps:
      - "POST /api/predict"
      - "Body: {\"data\": [[1,2,3]]}"
    expected:
      - "Status: 200"
      - "Body: {\"predictions\": [...]}"
      - "Schema: predictions is array of numbers"
```

---

## 11. å“è³ªè©•ä¾¡Role

### 11.1 Roleå®šç¾©

```markdown
## System
TEST_PLAN ã®åˆæ ¼åŸºæº–ã«ç…§ã‚‰ã—ã¦åˆå¦ã‚’åˆ¤å®šã€ã‚®ãƒ£ãƒƒãƒ—ã®è£œå®Œãƒ†ã‚¹ãƒˆã‚’ææ¡ˆã€‚
```

### 11.2 Inputå½¢å¼

```markdown
## User
å®Ÿæ¸¬ãƒ¡ãƒˆãƒªã‚¯ã‚¹/ãƒ­ã‚°/ãƒ¬ãƒãƒ¼ãƒˆãƒªãƒ³ã‚¯
```

### 11.3 Outputå½¢å¼ (Markdown)

```markdown
### åˆå¦åˆ¤å®š

| é …ç›® | åŸºæº– | å®Ÿæ¸¬ | åˆå¦ |
|-----|------|------|------|
| ã‚«ãƒãƒ¬ãƒƒã‚¸ | >90% | 92.3% | âœ… PASS |
| Pylint | â‰¥8.5 | 8.7 | âœ… PASS |
| MyPy | strict pass | 0 errors | âœ… PASS |
| å¾ªç’°çš„è¤‡é›‘åº¦ | <10 | 8.2 | âœ… PASS |

**Overall**: âœ… PASS

### ä¸è¶³ãƒ†ã‚¹ãƒˆ

| é ˜åŸŸ | ç¾çŠ¶ã‚«ãƒãƒ¬ãƒƒã‚¸ | ä¸è¶³ã‚±ãƒ¼ã‚¹ |
|-----|--------------|-----------|
| ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚° | 85% | ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã‚¨ãƒ©ãƒ¼æ™‚ã®æŒ™å‹• |
| ä¸¦åˆ—å®Ÿè¡Œ | 0% | ç«¶åˆæ¡ä»¶ã®ãƒ†ã‚¹ãƒˆ |

### æ¬¡ã‚¢ã‚¯ã‚·ãƒ§ãƒ³
- [ ] ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã‚¨ãƒ©ãƒ¼ãƒ†ã‚¹ãƒˆè¿½åŠ 
- [ ] ä¸¦åˆ—å®Ÿè¡Œã®çµ±åˆãƒ†ã‚¹ãƒˆä½œæˆ
```

---

# ç¬¬3éƒ¨: å®Ÿè·µã‚¬ã‚¤ãƒ‰

## 12. é–‹ç™ºãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼

### 12.1 æ—¥æ¬¡ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼

```markdown
## æœï¼ˆ9:00-9:30ï¼‰

### 1. ç’°å¢ƒç¢ºèª
```bash
# Gitæœ€æ–°åŒ–
git pull origin main

# ç’°å¢ƒç¢ºèª
python scripts/check_environment.py

# å“è³ªã‚²ãƒ¼ãƒˆç¢ºèª
pytest tests/ --cov=nf_auto_runner --cov-report=term-missing
pylint nf_auto_runner/
mypy nf_auto_runner/ --strict
```

### 2. ä»Šæ—¥ã®ã‚¿ã‚¹ã‚¯ç¢ºèª
```bash
# Issueã‚’ç¢ºèª
gh issue list --assignee @me

# ä»Šæ—¥ã®ãƒã‚§ãƒƒã‚¯ãƒªã‚¹ãƒˆ
cat checklists/phase_X_checklist.md
```

---

## æ—¥ä¸­ï¼ˆ9:30-18:00ï¼‰

### 3. TDDã‚µã‚¤ã‚¯ãƒ«
```bash
# Red: ãƒ†ã‚¹ãƒˆã‚’æ›¸ã
vim tests/unit/test_new_feature.py

# ãƒ†ã‚¹ãƒˆå®Ÿè¡Œï¼ˆå¤±æ•—ç¢ºèªï¼‰
pytest tests/unit/test_new_feature.py -v

# Green: å®Ÿè£…
vim nf_auto_runner/new_feature.py

# ãƒ†ã‚¹ãƒˆå®Ÿè¡Œï¼ˆæˆåŠŸç¢ºèªï¼‰
pytest tests/unit/test_new_feature.py -v

# Refactor: ãƒªãƒ•ã‚¡ã‚¯ã‚¿ãƒªãƒ³ã‚°
black nf_auto_runner/new_feature.py
pylint nf_auto_runner/new_feature.py
```

### 4. ã‚³ãƒŸãƒƒãƒˆ
```bash
# ã‚¹ãƒ†ãƒ¼ã‚¸ãƒ³ã‚°
git add tests/unit/test_new_feature.py
git add nf_auto_runner/new_feature.py

# ã‚³ãƒŸãƒƒãƒˆï¼ˆConventional Commitsï¼‰
git commit -m "feat: add new feature for XYZ

- Implement NewFeature class
- Add unit tests (coverage: 95%)
- Update documentation

Closes #123"

# ãƒ—ãƒƒã‚·ãƒ¥
git push origin feature/new-feature
```

### 5. ãƒ¬ãƒ“ãƒ¥ãƒ¼
```bash
# Pull Requestä½œæˆ
gh pr create --title "feat: add new feature for XYZ" \
             --body "## Changes\n- ..." \
             --base main \
             --head feature/new-feature
```

---

## å¤•æ–¹ï¼ˆ18:00-18:30ï¼‰

### 6. å“è³ªãƒã‚§ãƒƒã‚¯
```bash
# å…¨ãƒ†ã‚¹ãƒˆå®Ÿè¡Œ
pytest tests/ --cov=nf_auto_runner --cov-report=html

# ãƒ¬ãƒãƒ¼ãƒˆç¢ºèª
open htmlcov/index.html

# å“è³ªã‚²ãƒ¼ãƒˆç¢ºèª
python scripts/quality_check.py
```

### 7. é€²æ—æ›´æ–°
```markdown
# é€²æ—ãƒ­ã‚°æ›´æ–°
echo "## 2025-11-04" >> progress.md
echo "- [x] æ–°æ©Ÿèƒ½XYZå®Ÿè£…å®Œäº†" >> progress.md
echo "- [x] ãƒ†ã‚¹ãƒˆã‚«ãƒãƒ¬ãƒƒã‚¸ 95%" >> progress.md
echo "- [ ] ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆä½œæˆï¼ˆæ˜æ—¥ï¼‰" >> progress.md
```

### 8. MLflowè¨˜éŒ²
```python
import mlflow

mlflow.start_run(run_name="daily_dev_2025-11-04")

mlflow.log_metric("tests_passed", 142)
mlflow.log_metric("coverage_percent", 95.3)
mlflow.log_metric("pylint_score", 8.7)
mlflow.log_metric("lines_of_code_added", 237)

mlflow.log_artifact("progress.md")

mlflow.end_run()
```
```

---

### 12.2 é€±æ¬¡ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼

```markdown
## é‡‘æ›œï¼ˆ17:00-18:00ï¼‰

### 1. é€±æ¬¡ãƒ¬ãƒ“ãƒ¥ãƒ¼
```bash
# ä»Šé€±ã®ã‚³ãƒŸãƒƒãƒˆç¢ºèª
git log --since="1 week ago" --oneline

# ä»Šé€±ã®PRç¢ºèª
gh pr list --state merged --search "merged:>=2025-10-28"
```

### 2. å“è³ªãƒ¡ãƒˆãƒªã‚¯ã‚¹é›†è¨ˆ
```bash
# é€±æ¬¡ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ
python scripts/weekly_report.py > reports/week_44.md
```

### 3. æ¬¡é€±è¨ˆç”»
```markdown
# next_week.md
## æ¬¡é€±ã®ç›®æ¨™ï¼ˆ11/5 - 11/9ï¼‰

### Phase 4å®Œäº†
- [ ] ä¸¦åˆ—å®Ÿè¡Œã‚¨ãƒ³ã‚¸ãƒ³å®Ÿè£…
- [ ] Rayçµ±åˆ
- [ ] ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãƒ†ã‚¹ãƒˆ

### å“è³ªç›®æ¨™
- [ ] ã‚«ãƒãƒ¬ãƒƒã‚¸ >92%
- [ ] Pylintã‚¹ã‚³ã‚¢ â‰¥8.7
```

### 4. ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—
```bash
# ä½œæ¥­ãƒ–ãƒ©ãƒ³ãƒã‚’ãƒªãƒ¢ãƒ¼ãƒˆã«
git push origin --all

# DBãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—
pg_dump mldb > backups/mldb_2025-11-01.sql
```
```

---

## 13. å“è³ªãƒã‚§ãƒƒã‚¯ãƒªã‚¹ãƒˆ

### 13.1 ã‚³ãƒ¼ãƒ‰å“è³ªãƒã‚§ãƒƒã‚¯ãƒªã‚¹ãƒˆ

#### å®Ÿè£…å‰
- [ ] è¦ä»¶ã‚’å†ç¢ºèªï¼ˆä½•ã‚’ä½œã‚‹ã®ã‹æ˜ç¢ºã‹ï¼Ÿï¼‰
- [ ] è¨­è¨ˆæ›¸ã‚’ç¢ºèªï¼ˆã©ã†ä½œã‚‹ã®ã‹æ˜ç¢ºã‹ï¼Ÿï¼‰
- [ ] ãƒ†ã‚¹ãƒˆã‚±ãƒ¼ã‚¹ã‚’å…ˆã«æ›¸ãï¼ˆTDDï¼‰
- [ ] ä¾å­˜é–¢ä¿‚ã‚’ç¢ºèªï¼ˆå¿…è¦ãªãƒ©ã‚¤ãƒ–ãƒ©ãƒªã¯æƒã£ã¦ã„ã‚‹ã‹ï¼Ÿï¼‰

#### å®Ÿè£…ä¸­
- [ ] å‹ãƒ’ãƒ³ãƒˆã‚’ä»˜ã‘ã‚‹ï¼ˆã™ã¹ã¦ã®é–¢æ•°ã«ï¼‰
- [ ] Docstringã‚’æ›¸ãï¼ˆArgs/Returns/Raisesï¼‰
- [ ] ãƒ­ã‚°ã‚’è¿½åŠ ï¼ˆä¸»è¦çµŒè·¯ã«æ§‹é€ åŒ–ãƒ­ã‚°ï¼‰
- [ ] ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°ï¼ˆé©åˆ‡ãªä¾‹å¤–ã‚’å®šç¾©ï¼‰
- [ ] å‘½åè¦å‰‡ã«å¾“ã†ï¼ˆPEP 8æº–æ‹ ï¼‰

#### å®Ÿè£…å¾Œ
- [ ] å˜ä½“ãƒ†ã‚¹ãƒˆå®Ÿè¡Œï¼ˆpytestï¼‰
- [ ] ã‚«ãƒãƒ¬ãƒƒã‚¸ç¢ºèªï¼ˆ>90%ï¼‰
- [ ] é™çš„è§£æï¼ˆPylint â‰¥8.5ï¼‰
- [ ] å‹ãƒã‚§ãƒƒã‚¯ï¼ˆMyPy strict passï¼‰
- [ ] ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆï¼ˆBlacké©ç”¨ï¼‰
- [ ] è¤‡é›‘åº¦ãƒã‚§ãƒƒã‚¯ï¼ˆ<10ï¼‰
- [ ] ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆæ›´æ–°ï¼ˆREADMEã€API referenceï¼‰

---

### 13.2 ãƒ†ã‚¹ãƒˆå“è³ªãƒã‚§ãƒƒã‚¯ãƒªã‚¹ãƒˆ

#### å˜ä½“ãƒ†ã‚¹ãƒˆ
- [ ] æ­£å¸¸ç³»ãƒ†ã‚¹ãƒˆï¼ˆHappy Pathï¼‰
- [ ] å¢ƒç•Œå€¤ãƒ†ã‚¹ãƒˆï¼ˆEdge Casesï¼‰
- [ ] ç•°å¸¸ç³»ãƒ†ã‚¹ãƒˆï¼ˆError Casesï¼‰
- [ ] NULL/ç©ºãƒ†ã‚¹ãƒˆ
- [ ] å‹ã‚¨ãƒ©ãƒ¼ãƒ†ã‚¹ãƒˆ
- [ ] ã‚«ãƒãƒ¬ãƒƒã‚¸ >90%

#### çµ±åˆãƒ†ã‚¹ãƒˆ
- [ ] ã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆé–“ã®é€£æºãƒ†ã‚¹ãƒˆ
- [ ] ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹çµ±åˆãƒ†ã‚¹ãƒˆ
- [ ] å¤–éƒ¨APIçµ±åˆãƒ†ã‚¹ãƒˆï¼ˆãƒ¢ãƒƒã‚¯ä½¿ç”¨ï¼‰

#### E2Eãƒ†ã‚¹ãƒˆ
- [ ] ä¸»è¦ãƒ¦ãƒ¼ã‚¹ã‚±ãƒ¼ã‚¹ã®å‹•ä½œç¢ºèª
- [ ] ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãƒ†ã‚¹ãƒˆ
- [ ] ãƒ­ãƒ¼ãƒ‰ãƒ†ã‚¹ãƒˆï¼ˆä¸¦åˆ—å®Ÿè¡Œï¼‰

---

### 13.3 ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£ãƒã‚§ãƒƒã‚¯ãƒªã‚¹ãƒˆ

- [ ] Secretsç®¡ç†ï¼ˆç’°å¢ƒå¤‰æ•°ã®ã¿ï¼‰
- [ ] PIIé™¤å¤–ï¼ˆãƒ­ã‚°ã€ãƒ¡ãƒˆãƒªã‚¯ã‚¹ï¼‰
- [ ] SQLã‚¤ãƒ³ã‚¸ã‚§ã‚¯ã‚·ãƒ§ãƒ³å¯¾ç­–ï¼ˆãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿åŒ–ã‚¯ã‚¨ãƒªï¼‰
- [ ] ãƒ‘ã‚¹ãƒˆãƒ©ãƒãƒ¼ã‚µãƒ«å¯¾ç­–ï¼ˆãƒ‘ã‚¹æ¤œè¨¼ï¼‰
- [ ] èªè¨¼ãƒ»èªå¯ï¼ˆå¿…è¦ã«å¿œã˜ã¦ï¼‰
- [ ] Banditã‚¹ã‚­ãƒ£ãƒ³ï¼ˆé«˜ãƒªã‚¹ã‚¯å•é¡Œ0ä»¶ï¼‰

---

### 13.4 ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãƒã‚§ãƒƒã‚¯ãƒªã‚¹ãƒˆ

- [ ] å˜ä¸€ãƒ¢ãƒ‡ãƒ«å­¦ç¿’ <10åˆ†
- [ ] 100ãƒ¢ãƒ‡ãƒ«ä¸¦åˆ— <2æ™‚é–“
- [ ] äºˆæ¸¬ãƒ¬ã‚¤ãƒ†ãƒ³ã‚· <100ms
- [ ] ãƒ¡ãƒ¢ãƒªä½¿ç”¨ <16GB
- [ ] ãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒªãƒ³ã‚°ï¼ˆcProfileï¼‰

---

## 14. ãƒ™ã‚¹ãƒˆãƒ—ãƒ©ã‚¯ãƒ†ã‚£ã‚¹é›†

### 14.1 å‘½åè¦å‰‡

```python
# âœ… è‰¯ã„ä¾‹

# ã‚¯ãƒ©ã‚¹: PascalCase
class DataValidator:
    pass

# é–¢æ•°/ãƒ¡ã‚½ãƒƒãƒ‰: snake_case
def calculate_metrics():
    pass

# å¤‰æ•°: snake_case
input_size = 128

# å®šæ•°: UPPER_SNAKE_CASE
MAX_INPUT_SIZE = 168

# ãƒ—ãƒ©ã‚¤ãƒ™ãƒ¼ãƒˆ: å…ˆé ­ã«ã‚¢ãƒ³ãƒ€ãƒ¼ã‚¹ã‚³ã‚¢
def _internal_helper():
    pass

# å‹å¤‰æ•°: PascalCase
T = TypeVar('T')


# âŒ æ‚ªã„ä¾‹

# ã‚¯ãƒ©ã‚¹: snake_caseï¼ˆNGï¼‰
class data_validator:
    pass

# é–¢æ•°: camelCaseï¼ˆNGï¼‰
def calculateMetrics():
    pass

# å®šæ•°: snake_caseï¼ˆNGï¼‰
max_input_size = 168
```

---

### 14.2 Docstringè¦ç´„

```python
# âœ… è‰¯ã„ä¾‹

def calculate_metrics(
    y_true: np.ndarray,
    y_pred: np.ndarray,
    metrics: List[str]
) -> Dict[str, float]:
    """
    è©•ä¾¡æŒ‡æ¨™ã‚’è¨ˆç®—ã™ã‚‹
    
    Args:
        y_true (np.ndarray): çœŸã®å€¤ã€shape (n_samples,)
        y_pred (np.ndarray): äºˆæ¸¬å€¤ã€shape (n_samples,)
        metrics (List[str]): è¨ˆç®—ã™ã‚‹æŒ‡æ¨™åã®ãƒªã‚¹ãƒˆ
            ä¾‹: ['mae', 'rmse', 'mape']
    
    Returns:
        Dict[str, float]: æŒ‡æ¨™åã‚’ã‚­ãƒ¼ã€å€¤ã‚’ãƒãƒªãƒ¥ãƒ¼ã¨ã™ã‚‹è¾æ›¸
            ä¾‹: {'mae': 12.5, 'rmse': 18.3}
    
    Raises:
        ValueError: y_trueã¨y_predã®é•·ã•ãŒç•°ãªã‚‹å ´åˆ
        ValueError: æœªçŸ¥ã®æŒ‡æ¨™åãŒå«ã¾ã‚Œã‚‹å ´åˆ
    
    Examples:
        >>> y_true = np.array([1, 2, 3])
        >>> y_pred = np.array([1.1, 2.2, 2.9])
        >>> calculate_metrics(y_true, y_pred, ['mae'])
        {'mae': 0.1333}
    """
    pass


# âŒ æ‚ªã„ä¾‹

def calculate_metrics(y_true, y_pred, metrics):
    """
    ãƒ¡ãƒˆãƒªã‚¯ã‚¹ã‚’è¨ˆç®—
    """
    # DocstringãŒä¸ååˆ†ï¼ˆArgs/Returns/Raises/ExamplesãŒãªã„ï¼‰
    pass
```

---

### 14.3 ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°

```python
# âœ… è‰¯ã„ä¾‹

# ã‚«ã‚¹ã‚¿ãƒ ä¾‹å¤–å®šç¾©
class DataValidationError(Exception):
    """ãƒ‡ãƒ¼ã‚¿æ¤œè¨¼ã‚¨ãƒ©ãƒ¼"""
    pass

class ModelNotFoundError(Exception):
    """ãƒ¢ãƒ‡ãƒ«ãŒè¦‹ã¤ã‹ã‚‰ãªã„"""
    pass


def load_model(model_id: str) -> Model:
    """
    ãƒ¢ãƒ‡ãƒ«ã‚’ãƒ­ãƒ¼ãƒ‰ã™ã‚‹
    
    Raises:
        ModelNotFoundError: ãƒ¢ãƒ‡ãƒ«ãŒå­˜åœ¨ã—ãªã„å ´åˆ
    """
    if not model_exists(model_id):
        raise ModelNotFoundError(f"Model {model_id} not found")
    
    return Model.load(model_id)


# ä½¿ç”¨å´
try:
    model = load_model("model_123")
except ModelNotFoundError as e:
    logger.error(f"Failed to load model: {e}")
    # é©åˆ‡ãªå¯¾å‡¦ï¼ˆãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ã€å†è©¦è¡Œãªã©ï¼‰


# âŒ æ‚ªã„ä¾‹

def load_model(model_id):
    if not model_exists(model_id):
        print("Model not found")  # NG: printã§ã¯ãªãloggerä½¿ç”¨
        return None  # NG: ä¾‹å¤–ã‚’æŠ•ã’ã‚‹ã¹ã
    
    return Model.load(model_id)
```

---

### 14.4 ãƒ­ã‚®ãƒ³ã‚°

```python
# âœ… è‰¯ã„ä¾‹

import logging
import json

logger = logging.getLogger(__name__)

def train_model(model_config: ModelConfig, data: pd.DataFrame):
    """ãƒ¢ãƒ‡ãƒ«ã‚’å­¦ç¿’ã™ã‚‹"""
    
    # æ§‹é€ åŒ–ãƒ­ã‚°ï¼ˆJSONå½¢å¼ï¼‰
    logger.info(
        json.dumps({
            "event": "training_started",
            "model": model_config.model_name,
            "n_samples": len(data),
            "n_features": data.shape[1],
            "timestamp": time.time()
        })
    )
    
    try:
        # å­¦ç¿’å‡¦ç†
        model = Model(model_config)
        model.fit(data)
        
        logger.info(
            json.dumps({
                "event": "training_completed",
                "model": model_config.model_name,
                "duration_sec": 123.45,
                "final_loss": 0.123
            })
        )
    
    except Exception as e:
        logger.error(
            json.dumps({
                "event": "training_failed",
                "model": model_config.model_name,
                "error": str(e),
                "traceback": traceback.format_exc()
            })
        )
        raise


# âŒ æ‚ªã„ä¾‹

def train_model(model_config, data):
    print("Training started")  # NG: printã§ã¯ãªãlogger
    
    model = Model(model_config)
    model.fit(data)
    
    print("Training done")  # NG: æ§‹é€ åŒ–ã•ã‚Œã¦ã„ãªã„
```

---

### 14.5 ä¾å­˜æ€§æ³¨å…¥ (DI)

```python
# âœ… è‰¯ã„ä¾‹

class ModelTrainer:
    """ãƒ¢ãƒ‡ãƒ«å­¦ç¿’ã‚¯ãƒ©ã‚¹ï¼ˆDIä½¿ç”¨ï¼‰"""
    
    def __init__(
        self,
        model_registry: ModelRegistry,  # ä¾å­˜ã‚’å¤–éƒ¨ã‹ã‚‰æ³¨å…¥
        logger: StructuredLogger,
        metrics_tracker: MetricsTracker
    ):
        self.model_registry = model_registry
        self.logger = logger
        self.metrics_tracker = metrics_tracker
    
    def train(self, model_config: ModelConfig, data: pd.DataFrame):
        """å­¦ç¿’å®Ÿè¡Œ"""
        model = self.model_registry.get_model(model_config.model_name)
        
        self.logger.info("Training started")
        model.fit(data)
        
        metrics = self.metrics_tracker.get_metrics()
        return model, metrics


# ãƒ†ã‚¹ãƒˆæ™‚ã¯ãƒ¢ãƒƒã‚¯ã‚’æ³¨å…¥
def test_train():
    mock_registry = MockModelRegistry()
    mock_logger = MockLogger()
    mock_tracker = MockMetricsTracker()
    
    trainer = ModelTrainer(mock_registry, mock_logger, mock_tracker)
    # ãƒ†ã‚¹ãƒˆ...


# âŒ æ‚ªã„ä¾‹

class ModelTrainer:
    """ãƒ¢ãƒ‡ãƒ«å­¦ç¿’ã‚¯ãƒ©ã‚¹ï¼ˆDIä¸ä½¿ç”¨ï¼‰"""
    
    def __init__(self):
        self.model_registry = ModelRegistry()  # NG: å†…éƒ¨ã§ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹åŒ–
        self.logger = StructuredLogger()
        self.metrics_tracker = MetricsTracker()
    
    # ãƒ†ã‚¹ãƒˆã—ã«ãã„ï¼ˆãƒ¢ãƒƒã‚¯ã«ç½®ãæ›ãˆã‚‰ã‚Œãªã„ï¼‰
```

---

### 14.6 è¨­å®šç®¡ç†

```python
# âœ… è‰¯ã„ä¾‹

# config/config.py
from dataclasses import dataclass
from typing import Optional
import os

@dataclass
class DatabaseConfig:
    """ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹è¨­å®š"""
    host: str = os.getenv("DB_HOST", "localhost")
    port: int = int(os.getenv("DB_PORT", "5432"))
    database: str = os.getenv("DB_NAME", "mldb")
    user: str = os.getenv("DB_USER", "postgres")
    password: str = os.getenv("DB_PASSWORD", "")  # ç’°å¢ƒå¤‰æ•°ã‹ã‚‰
    
    def to_connection_string(self) -> str:
        """æ¥ç¶šæ–‡å­—åˆ—ã‚’ç”Ÿæˆ"""
        return f"postgresql://{self.user}:{self.password}@{self.host}:{self.port}/{self.database}"


@dataclass
class ModelConfig:
    """ãƒ¢ãƒ‡ãƒ«è¨­å®š"""
    model_name: str = "AutoNHITS"
    input_size: int = 128
    h: int = 24
    precision: int = 16
    max_epochs: int = 100


# ä½¿ç”¨ä¾‹
db_config = DatabaseConfig()
conn_str = db_config.to_connection_string()


# âŒ æ‚ªã„ä¾‹

# ãƒãƒ¼ãƒ‰ã‚³ãƒ¼ãƒ‰ï¼ˆNGï¼‰
DB_HOST = "localhost"
DB_PASSWORD = "my_secret_password"  # çµ¶å¯¾ãƒ€ãƒ¡ï¼

# ãƒã‚¸ãƒƒã‚¯ãƒŠãƒ³ãƒãƒ¼ï¼ˆNGï¼‰
model = Model(input_size=128)  # 128ã®æ„å‘³ãŒä¸æ˜
```

---

# ç¬¬4éƒ¨: ä»˜éŒ²

## 15. ç”¨èªé›†

| ç”¨èª | å®šç¾© |
|-----|------|
| **ADR** | Architecture Decision Recordã€è¨­è¨ˆåˆ¤æ–­ã®è¨˜éŒ² |
| **CI/CD** | Continuous Integration / Continuous Deployment |
| **CUDA** | Compute Unified Device Architecture (NVIDIA GPU) |
| **DI** | Dependency Injectionã€ä¾å­˜æ€§æ³¨å…¥ |
| **E2E** | End-to-Endã€ã‚¨ãƒ³ãƒ‰ãƒ„ãƒ¼ã‚¨ãƒ³ãƒ‰ |
| **KPI** | Key Performance Indicatorã€ä¸»è¦æ¥­ç¸¾è©•ä¾¡æŒ‡æ¨™ |
| **MAE** | Mean Absolute Errorã€å¹³å‡çµ¶å¯¾èª¤å·® |
| **MLflow** | æ©Ÿæ¢°å­¦ç¿’å®Ÿé¨“ç®¡ç†ãƒ—ãƒ©ãƒƒãƒˆãƒ•ã‚©ãƒ¼ãƒ  |
| **MTBF** | Mean Time Between Failuresã€å¹³å‡æ•…éšœé–“éš” |
| **MTTR** | Mean Time To Repairã€å¹³å‡ä¿®å¾©æ™‚é–“ |
| **OOP** | Object-Oriented Programmingã€ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆæŒ‡å‘ãƒ—ãƒ­ã‚°ãƒ©ãƒŸãƒ³ã‚° |
| **PDCA** | Plan-Do-Check-Actã€è¨ˆç”»-å®Ÿè¡Œ-ç¢ºèª-æ”¹å–„ |
| **PII** | Personally Identifiable Informationã€å€‹äººè­˜åˆ¥æƒ…å ± |
| **RACI** | Responsible-Accountable-Consulted-Informed |
| **RMSE** | Root Mean Squared Errorã€äºŒä¹—å¹³å‡å¹³æ–¹æ ¹èª¤å·® |
| **SOLID** | 5ã¤ã®OOPè¨­è¨ˆåŸå‰‡ï¼ˆSRP, OCP, LSP, ISP, DIPï¼‰ |
| **TDD** | Test-Driven Developmentã€ãƒ†ã‚¹ãƒˆé§†å‹•é–‹ç™º |

---

## 16. å‚è€ƒè³‡æ–™

### 16.1 å…¬å¼ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆ

- **NeuralForecast**: https://nixtlaverse.nixtla.io/neuralforecast/
- **MLflow**: https://mlflow.org/docs/latest/index.html
- **PostgreSQL**: https://www.postgresql.org/docs/
- **pytest**: https://docs.pytest.org/
- **MyPy**: https://mypy.readthedocs.io/

### 16.2 è¨­è¨ˆåŸå‰‡

- **Clean Architecture**: https://blog.cleancoder.com/uncle-bob/2012/08/13/the-clean-architecture.html
- **SOLID Principles**: https://en.wikipedia.org/wiki/SOLID
- **Design Patterns**: https://refactoring.guru/design-patterns

### 16.3 æ›¸ç±

- "Clean Code" by Robert C. Martin
- "Test Driven Development: By Example" by Kent Beck
- "Refactoring" by Martin Fowler

---

## 17. FAQ

### Q1: ã‚«ãƒãƒ¬ãƒƒã‚¸ãŒ90%ã«é”ã—ãªã„å ´åˆã¯ï¼Ÿ

**A**: ã¾ãšã€ã‚«ãƒãƒ¬ãƒƒã‚¸ãŒä½ã„ç†ç”±ã‚’åˆ†æã—ã¾ã™ï¼š

1. **ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°ä¸è¶³**: ä¾‹å¤–å‡¦ç†ã®ãƒ–ãƒ©ãƒ³ãƒãŒãƒ†ã‚¹ãƒˆã•ã‚Œã¦ã„ãªã„
2. **å¢ƒç•Œå€¤ãƒ†ã‚¹ãƒˆä¸è¶³**: Edge Casesã®ãƒ†ã‚¹ãƒˆãŒãªã„
3. **çµ±åˆãƒ†ã‚¹ãƒˆä¸è¶³**: ã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆé–“ã®é€£æºãƒ†ã‚¹ãƒˆãŒãªã„

å¯¾ç­–ï¼š
- ã‚¨ãƒ©ãƒ¼ã‚±ãƒ¼ã‚¹ã®ãƒ†ã‚¹ãƒˆã‚’è¿½åŠ 
- `pytest-cov --cov-report=html` ã§ã‚«ãƒãƒ¼ã•ã‚Œã¦ã„ãªã„è¡Œã‚’ç¢ºèª
- å¢ƒç•Œå€¤ãƒ†ã‚¹ãƒˆã‚’è¿½åŠ 

---

### Q2: Pylintã‚¹ã‚³ã‚¢ãŒ8.5ã«é”ã—ãªã„å ´åˆã¯ï¼Ÿ

**A**: Pylintã®è­¦å‘Šã‚’ç¢ºèªã—ã€ä¿®æ­£ã—ã¾ã™ï¼š

```bash
# è­¦å‘Šã‚’ç¢ºèª
pylint nf_auto_runner/ --output-format=colorized

# ã‚ˆãã‚ã‚‹è­¦å‘Šã¨å¯¾ç­–
# - C0103 (invalid-name): å¤‰æ•°åã‚’snake_caseã«å¤‰æ›´
# - R0913 (too-many-arguments): å¼•æ•°ã‚’æ¸›ã‚‰ã™ã€dataclassã‚’ä½¿ã†
# - R0914 (too-many-locals): é–¢æ•°ã‚’åˆ†å‰²
# - C0114 (missing-module-docstring): ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«Docstringã‚’è¿½åŠ 
```

---

### Q3: MyPy strictã§å‹ã‚¨ãƒ©ãƒ¼ãŒå‡ºã‚‹å ´åˆã¯ï¼Ÿ

**A**: å‹ãƒ’ãƒ³ãƒˆã‚’è¿½åŠ ã—ã¾ã™ï¼š

```python
# âŒ å‹ã‚¨ãƒ©ãƒ¼
def calculate(x):
    return x * 2

# âœ… å‹ãƒ’ãƒ³ãƒˆè¿½åŠ 
def calculate(x: float) -> float:
    return x * 2
```

---

### Q4: ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãƒ†ã‚¹ãƒˆãŒåŸºæº–ã«é”ã—ãªã„å ´åˆã¯ï¼Ÿ

**A**: ãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒªãƒ³ã‚°ã§é…ã„ç®‡æ‰€ã‚’ç‰¹å®šã—ã¾ã™ï¼š

```bash
# cProfileã§ãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒªãƒ³ã‚°
python -m cProfile -o output.prof src/train.py

# çµæœã‚’å¯è¦–åŒ–
snakeviz output.prof
```

å¯¾ç­–ï¼š
- ä¸¦åˆ—åŒ–ï¼ˆDask, Rayï¼‰
- ã‚­ãƒ£ãƒƒã‚·ãƒ³ã‚°
- GPUæ´»ç”¨
- ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ æœ€é©åŒ–

---

### Q5: ãƒ¡ãƒ¢ãƒªä¸è¶³ã‚¨ãƒ©ãƒ¼ãŒé »ç™ºã™ã‚‹å ´åˆã¯ï¼Ÿ

**A**: ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡ã‚’å‰Šæ¸›ã—ã¾ã™ï¼š

```python
# å¯¾ç­–1: ãƒãƒƒãƒã‚µã‚¤ã‚ºã‚’æ¸›ã‚‰ã™
batch_size = 16  # 32 â†’ 16

# å¯¾ç­–2: Mixed Precision (FP16)
precision = 16

# å¯¾ç­–3: Gradient Accumulation
accumulate_grad_batches = 2

# å¯¾ç­–4: ãƒ¡ãƒ¢ãƒªè§£æ”¾
import torch
torch.cuda.empty_cache()
```

---

**End of Document**

---

**ç·ãƒšãƒ¼ã‚¸æ•°**: ç´„300ãƒšãƒ¼ã‚¸ç›¸å½“  
**ç·æ–‡å­—æ•°**: ç´„75,000æ–‡å­—  
**é©ç”¨ç¯„å›²**: å…¨é–‹ç™ºãƒ•ã‚§ãƒ¼ã‚ºã€å…¨Role  
**æœ€çµ‚æ›´æ–°**: 2025-11-04
