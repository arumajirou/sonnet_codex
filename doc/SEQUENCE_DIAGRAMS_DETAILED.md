# æ™‚ç³»åˆ—äºˆæ¸¬ã‚·ã‚¹ãƒ†ãƒ  - è©³ç´°ã‚·ãƒ¼ã‚±ãƒ³ã‚¹å›³é›†

## ğŸ“‹ ç›®æ¬¡

1. [Configurationèª­ã¿è¾¼ã¿](#1-configurationèª­ã¿è¾¼ã¿)
2. [ãƒ‡ãƒ¼ã‚¿ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³](#2-ãƒ‡ãƒ¼ã‚¿ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³)
3. [ãƒ¢ãƒ‡ãƒ«æ¤œå‡ºãƒ•ãƒ­ãƒ¼](#3-ãƒ¢ãƒ‡ãƒ«æ¤œå‡ºãƒ•ãƒ­ãƒ¼)
4. [å®Ÿè¡Œè¨ˆç”»ç”Ÿæˆ](#4-å®Ÿè¡Œè¨ˆç”»ç”Ÿæˆ)
5. [ä¸¦åˆ—å®Ÿè¡Œãƒ•ãƒ­ãƒ¼](#5-ä¸¦åˆ—å®Ÿè¡Œãƒ•ãƒ­ãƒ¼)
6. [ãƒ­ã‚®ãƒ³ã‚°ãƒ•ãƒ­ãƒ¼](#6-ãƒ­ã‚®ãƒ³ã‚°ãƒ•ãƒ­ãƒ¼)
7. [å®Œå…¨ãªå­¦ç¿’ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³](#7-å®Œå…¨ãªå­¦ç¿’ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³)
8. [äºˆæ¸¬ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³](#8-äºˆæ¸¬ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³)
9. [å†å­¦ç¿’ãƒˆãƒªã‚¬ãƒ¼ãƒ•ãƒ­ãƒ¼](#9-å†å­¦ç¿’ãƒˆãƒªã‚¬ãƒ¼ãƒ•ãƒ­ãƒ¼)
10. [ãƒã‚¤ãƒ‘ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æ¢ç´¢](#10-ãƒã‚¤ãƒ‘ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æ¢ç´¢)
11. [ã‚¢ãƒ¼ãƒ†ã‚£ãƒ•ã‚¡ã‚¯ãƒˆç®¡ç†](#11-ã‚¢ãƒ¼ãƒ†ã‚£ãƒ•ã‚¡ã‚¯ãƒˆç®¡ç†)
12. [ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°](#12-ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°)

---

## 1. Configurationèª­ã¿è¾¼ã¿

### 1.1 ç’°å¢ƒå¤‰æ•°ã‹ã‚‰ã®è¨­å®šèª­ã¿è¾¼ã¿

```mermaid
sequenceDiagram
    participant App as Application
    participant CL as ConfigLoader
    participant PC as PathConfig
    participant EC as ExecutionConfig
    participant MC as ModelSelectionConfig
    participant Env as Environment Variables
    participant FS as File System
    
    App->>CL: load_all()
    
    Note over CL: Configurationèª­ã¿è¾¼ã¿é–‹å§‹
    
    %% PathConfigèª­ã¿è¾¼ã¿
    CL->>PC: from_env()
    PC->>Env: getenv("NF_DATA_CSV")
    Env-->>PC: "./data/input.csv"
    PC->>Env: getenv("NF_OUTPUT_DIR")
    Env-->>PC: "./outputs"
    PC->>Env: getenv("NF_MODELS_DIR")
    Env-->>PC: "./models"
    PC->>Env: getenv("NF_LOGS_DIR")
    Env-->>PC: "./logs"
    
    PC->>PC: validate()
    alt ãƒ‡ãƒ¼ã‚¿ãƒ‘ã‚¹ãŒå­˜åœ¨ã—ãªã„
        PC-->>CL: ValidationError
        CL-->>App: Error: Data file not found
    else ãƒ‘ã‚¹æ¤œè¨¼æˆåŠŸ
        PC->>FS: mkdir(outputs_dir)
        PC->>FS: mkdir(models_dir)
        PC->>FS: mkdir(logs_dir)
        FS-->>PC: Directories created
        PC-->>CL: PathConfig
    end
    
    %% ExecutionConfigèª­ã¿è¾¼ã¿
    CL->>EC: from_env()
    EC->>Env: getenv("NF_RANDOM_STATE")
    Env-->>EC: "42"
    EC->>Env: getenv("NF_MAX_WORKERS")
    Env-->>EC: "4"
    EC->>Env: getenv("NF_ALLOW_RAY_PARALLEL")
    Env-->>EC: "false"
    EC->>Env: getenv("NF_TRIAL_NUM_SAMPLES")
    Env-->>EC: "10"
    
    EC->>EC: validate()
    alt max_workers ãŒ CPUæ•°ã‚’è¶…ãˆã‚‹
        EC->>EC: max_workers = min(max_workers, cpu_count)
    end
    EC-->>CL: ExecutionConfig
    
    %% ModelSelectionConfigèª­ã¿è¾¼ã¿
    CL->>MC: from_env()
    MC->>Env: getenv("NF_MODELS")
    Env-->>MC: "AutoNBEATS,AutoLSTM"
    MC->>Env: getenv("NF_BACKENDS")
    Env-->>MC: "pytorch_lightning"
    MC->>Env: getenv("NF_SEARCH_ALGS")
    Env-->>MC: "optuna"
    MC->>Env: getenv("NF_LOSSES")
    Env-->>MC: "auto"
    
    MC->>MC: parse_list_values()
    MC->>MC: validate()
    alt ãƒ¢ãƒ‡ãƒ«ãƒªã‚¹ãƒˆãŒç©º
        MC-->>CL: ValidationError
        CL-->>App: Error: No models specified
    else æ¤œè¨¼æˆåŠŸ
        MC-->>CL: ModelSelectionConfig
    end
    
    %% å…¨è¨­å®šã‚’çµ±åˆ
    CL->>CL: combine_configs()
    CL-->>App: Dict[str, Config]
    
    Note over App: è¨­å®šèª­ã¿è¾¼ã¿å®Œäº†
```

---

## 2. ãƒ‡ãƒ¼ã‚¿ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³

### 2.1 ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿ã‹ã‚‰å‰å‡¦ç†ã¾ã§

```mermaid
sequenceDiagram
    participant App as Application
    participant DL as DataLoader
    participant DP as DataPreprocessor
    participant FI as FrequencyInferrer
    participant EE as ExogeneousEncoder
    participant DV as DataValidator
    participant DF as DataFrame
    
    App->>DL: load(data_path)
    
    %% ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿
    DL->>DL: detect_file_format()
    alt CSVå½¢å¼
        DL->>DF: pd.read_csv(data_path)
    else Parquetå½¢å¼
        DL->>DF: pd.read_parquet(data_path)
    else Excelå½¢å¼
        DL->>DF: pd.read_excel(data_path)
    end
    DF-->>DL: raw_df
    
    %% åˆæœŸæ¤œè¨¼
    DL->>DV: validate_schema(raw_df)
    DV->>DV: check_required_columns()
    alt å¿…é ˆã‚«ãƒ©ãƒ ä¸è¶³
        DV-->>DL: ValidationError
        DL-->>App: Error: Missing columns
    else ã‚¹ã‚­ãƒ¼ãƒæ¤œè¨¼æˆåŠŸ
        DV-->>DL: OK
    end
    
    %% ã‚«ãƒ©ãƒ æ¨™æº–åŒ–
    DL->>DP: standardize_columns(raw_df)
    DP->>DP: detect_id_column()
    DP->>DP: detect_date_column()
    DP->>DP: detect_target_column()
    DP->>DP: rename_columns()
    Note over DP: unique_id, ds, y ã«æ¨™æº–åŒ–
    DP-->>DL: standardized_df
    
    %% æ—¥ä»˜è§£æ
    DL->>DP: parse_dates(standardized_df)
    DP->>DP: to_datetime(ds_column)
    alt æ—¥ä»˜ãƒ‘ãƒ¼ã‚¹å¤±æ•—
        DP-->>DL: ValueError
        DL-->>App: Error: Invalid date format
    else æ—¥ä»˜ãƒ‘ãƒ¼ã‚¹æˆåŠŸ
        DP-->>DL: df_with_dates
    end
    
    %% å¤–ç”Ÿå¤‰æ•°ã®æ¤œå‡ºã¨åˆ†é¡
    DL->>EE: detect_exogenous(df_with_dates)
    EE->>EE: identify_futr_columns()
    EE->>EE: identify_hist_columns()
    EE->>EE: identify_stat_columns()
    EE-->>DL: exog_metadata
    
    %% å‘¨æœŸæ€§æ¨å®š
    DL->>FI: infer_frequency(df_with_dates)
    FI->>FI: group_by_unique_id()
    loop å„æ™‚ç³»åˆ—
        FI->>FI: pd.infer_freq(dates)
        alt é »åº¦æ¨å®šæˆåŠŸ
            FI->>FI: record_frequency()
        else æ¨å®šå¤±æ•—
            FI->>FI: calculate_median_diff()
            FI->>FI: map_to_pandas_freq()
        end
    end
    FI->>FI: determine_dominant_freq()
    FI-->>DL: frequency_info
    
    %% æ¬ æå€¤å‡¦ç†
    DL->>DP: handle_missing(df_with_dates)
    DP->>DP: detect_missing_patterns()
    loop å„ã‚«ãƒ©ãƒ 
        alt æ•°å€¤ã‚«ãƒ©ãƒ 
            DP->>DP: forward_fill()
            DP->>DP: interpolate()
        else ã‚«ãƒ†ã‚´ãƒªã‚«ãƒ©ãƒ 
            DP->>DP: mode_fill()
        end
    end
    DP-->>DL: df_no_missing
    
    %% å¤–ã‚Œå€¤æ¤œå‡º
    DL->>DV: detect_outliers(df_no_missing)
    DV->>DV: calculate_zscore()
    DV->>DV: calculate_iqr()
    DV->>DV: flag_outliers()
    DV-->>DL: outlier_info
    
    %% å¤–ç”Ÿå¤‰æ•°ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°
    DL->>EE: encode_exogenous(df_no_missing)
    loop å„ã‚«ãƒ†ã‚´ãƒªã‚«ãƒ«å¤‰æ•°
        EE->>EE: label_encode()
        EE->>EE: store_mapping()
    end
    EE-->>DL: df_encoded
    
    %% æœ€çµ‚æ¤œè¨¼
    DL->>DV: validate_processed(df_encoded)
    DV->>DV: check_data_integrity()
    DV->>DV: verify_time_series_continuity()
    DV->>DV: validate_value_ranges()
    alt æ¤œè¨¼å¤±æ•—
        DV-->>DL: ValidationError
        DL-->>App: Error: Data validation failed
    else æ¤œè¨¼æˆåŠŸ
        DV-->>DL: OK
        DL-->>App: ProcessedData
    end
    
    Note over App: ãƒ‡ãƒ¼ã‚¿ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³å®Œäº†
```

---

## 3. ãƒ¢ãƒ‡ãƒ«æ¤œå‡ºãƒ•ãƒ­ãƒ¼

### 3.1 Autoãƒ¢ãƒ‡ãƒ«ã¨ãƒãƒƒã‚¯ã‚¨ãƒ³ãƒ‰ã®æ¤œå‡º

```mermaid
sequenceDiagram
    participant App as Application
    participant MR as ModelRegistry
    participant MC as ModelCapabilityAnalyzer
    participant BD as BackendDetector
    participant MV as ModelValidator
    participant Sys as System
    
    App->>MR: discover_models()
    
    %% ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«æ¸ˆã¿ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«æ¤œå‡º
    MR->>Sys: scan_installed_packages()
    Sys-->>MR: package_list
    
    %% ãƒ¢ãƒ‡ãƒ«æ¤œå‡º
    MR->>MR: detect_auto_models()
    loop NeuralForecastãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«å†…
        MR->>MR: inspect_module(neuralforecast)
        alt Autoã§å§‹ã¾ã‚‹ã‚¯ãƒ©ã‚¹ç™ºè¦‹
            MR->>MR: import_class()
            MR->>MC: analyze_capabilities(model_class)
            
            %% ãƒ¢ãƒ‡ãƒ«èƒ½åŠ›åˆ†æ
            MC->>MC: check_exog_support()
            MC->>MC: check_static_features()
            MC->>MC: check_val_size_support()
            MC->>MC: extract_required_params()
            MC-->>MR: capability_info
            
            MR->>MR: register_model(model_class, capability_info)
        end
    end
    
    %% ãƒãƒƒã‚¯ã‚¨ãƒ³ãƒ‰æ¤œå‡º
    MR->>BD: detect_backends()
    
    BD->>Sys: check_pytorch_lightning()
    alt PyTorch Lightningåˆ©ç”¨å¯èƒ½
        BD->>Sys: check_cuda_availability()
        alt CUDAåˆ©ç”¨å¯èƒ½
            BD->>Sys: get_cuda_version()
            Sys-->>BD: cuda_version
            BD->>BD: register_backend("pytorch_lightning", gpu=True)
        else CPUã®ã¿
            BD->>BD: register_backend("pytorch_lightning", gpu=False)
        end
    end
    
    BD->>Sys: check_pytorch()
    alt PyTorchåˆ©ç”¨å¯èƒ½
        BD->>BD: register_backend("pytorch")
    end
    
    BD->>Sys: check_ray()
    alt Rayåˆ©ç”¨å¯èƒ½
        BD->>Sys: check_ray_cluster()
        alt Rayã‚¯ãƒ©ã‚¹ã‚¿å®Ÿè¡Œä¸­
            BD->>BD: register_backend("ray", distributed=True)
        else ãƒ­ãƒ¼ã‚«ãƒ«å®Ÿè¡Œ
            BD->>BD: register_backend("ray", distributed=False)
        end
    end
    
    BD-->>MR: backend_info
    
    %% æå¤±é–¢æ•°æ¤œå‡º
    MR->>MR: detect_loss_functions()
    loop NeuralForecastæå¤±ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«
        MR->>MR: import_loss_class()
        MR->>MR: register_loss(loss_class)
    end
    
    %% ã‚¹ã‚±ãƒ¼ãƒ©ãƒ¼æ¤œå‡º
    MR->>MR: detect_scalers()
    loop æ¨™æº–ã‚¹ã‚±ãƒ¼ãƒ©ãƒ¼
        MR->>MR: register_scaler(scaler_class)
    end
    
    %% æ¢ç´¢ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ æ¤œå‡º
    MR->>MR: detect_search_algorithms()
    
    MR->>Sys: check_optuna()
    alt Optunaåˆ©ç”¨å¯èƒ½
        MR->>MR: register_search_algo("optuna")
    end
    
    MR->>Sys: check_ray_tune()
    alt Ray Tuneåˆ©ç”¨å¯èƒ½
        MR->>MR: register_search_algo("ray_tune")
    end
    
    %% äº’æ›æ€§æ¤œè¨¼
    MR->>MV: validate_combinations(registry)
    
    loop å„ãƒ¢ãƒ‡ãƒ«Ã—ãƒãƒƒã‚¯ã‚¨ãƒ³ãƒ‰ã®çµ„ã¿åˆã‚ã›
        MV->>MV: check_backend_compatibility()
        MV->>MV: check_loss_compatibility()
        MV->>MV: check_search_algo_compatibility()
        alt éäº’æ›
            MV->>MV: mark_incompatible()
        end
    end
    
    MV-->>MR: validation_results
    
    %% ãƒ¬ã‚¸ã‚¹ãƒˆãƒªå®Œæˆ
    MR->>MR: finalize_registry()
    MR-->>App: ModelRegistry
    
    Note over App: ãƒ¢ãƒ‡ãƒ«æ¤œå‡ºå®Œäº†
```

---

## 4. å®Ÿè¡Œè¨ˆç”»ç”Ÿæˆ

### 4.1 çµ„ã¿åˆã‚ã›ç”Ÿæˆã¨é‡è¤‡æ’é™¤

```mermaid
sequenceDiagram
    participant App as Application
    participant CG as CombinationGenerator
    participant EP as ExecutionPlan
    participant DD as DuplicateDetector
    participant RE as ResourceEstimator
    participant Config as Configuration
    participant Data as ProcessedData
    
    App->>CG: generate_combinations(config, data, registry)
    
    %% å±•é–‹è»¸ã®æ±ºå®š
    CG->>Config: get_expand_axes()
    Config-->>CG: ["model", "backend", "search_alg", "loss"]
    
    CG->>Config: get_combo_depth()
    Config-->>CG: depth=3
    
    %% å®‰å…¨ãªhã®è¨ˆç®—
    CG->>Data: get_min_series_length()
    Data-->>CG: min_length=100
    
    CG->>Config: get_h_config()
    Config-->>CG: h_config={h: 24, h_ratio: 0.2}
    
    CG->>CG: calculate_safe_h()
    Note over CG: h = min(24, floor(100 * 0.2))
    CG->>CG: safe_h = 20
    
    %% å±•é–‹è»¸ã”ã¨ã®å€¤ç”Ÿæˆ
    CG->>CG: expand_models()
    loop å„ãƒ¢ãƒ‡ãƒ«
        alt ãƒ¢ãƒ‡ãƒ«ãŒæœ‰åŠ¹
            CG->>CG: add_to_axis(model)
        end
    end
    
    CG->>CG: expand_backends()
    CG->>CG: expand_search_algos()
    CG->>CG: expand_losses()
    CG->>CG: expand_scalers()
    CG->>CG: expand_early_stops()
    
    %% ç›´ç©è¨ˆç®—
    CG->>CG: cartesian_product(axes, depth)
    Note over CG: çµ„ã¿åˆã‚ã›ã®ç·æ•°ã‚’è¨ˆç®—
    
    %% ãƒ•ã‚£ãƒ³ã‚¬ãƒ¼ãƒ—ãƒªãƒ³ãƒˆç”Ÿæˆ
    loop å„çµ„ã¿åˆã‚ã›
        CG->>DD: generate_fingerprint(combination)
        
        DD->>DD: serialize_params()
        DD->>DD: calculate_sha256()
        DD-->>CG: fingerprint
        
        %% é‡è¤‡ãƒã‚§ãƒƒã‚¯
        CG->>DD: check_duplicate(fingerprint)
        DD->>DD: lookup_in_database()
        alt é‡è¤‡ã‚ã‚Š
            DD-->>CG: duplicate=True
            CG->>CG: skip_combination()
        else æ–°è¦
            DD-->>CG: duplicate=False
            
            %% ãƒªã‚½ãƒ¼ã‚¹è¦‹ç©ã‚‚ã‚Š
            CG->>RE: estimate_resources(combination, data)
            
            RE->>RE: estimate_memory()
            Note over RE: æ™‚ç³»åˆ—æ•° Ã— ãƒ¢ãƒ‡ãƒ«ã‚µã‚¤ã‚º Ã— ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æ•°
            
            RE->>RE: estimate_training_time()
            Note over RE: ãƒ‡ãƒ¼ã‚¿é‡ Ã— ãƒ¢ãƒ‡ãƒ«è¤‡é›‘åº¦ Ã— ã‚¨ãƒãƒƒã‚¯æ•°
            
            RE->>RE: estimate_gpu_memory()
            alt GPUãƒ¢ãƒ‡ãƒ«
                RE->>RE: calculate_vram_usage()
            end
            
            RE-->>CG: resource_estimate
            
            %% å®Ÿè¡Œè¨ˆç”»ã‚¨ãƒ³ãƒˆãƒªä½œæˆ
            CG->>EP: create_execution_entry()
            EP->>EP: assign_run_id()
            EP->>EP: set_parameters(combination)
            EP->>EP: set_safe_h(safe_h)
            EP->>EP: set_resource_estimate(resource_estimate)
            EP->>EP: set_fingerprint(fingerprint)
            EP-->>CG: execution_entry
            
            CG->>CG: add_to_plan(execution_entry)
        end
    end
    
    %% è¨ˆç”»ã®æœ€é©åŒ–
    CG->>EP: optimize_plan()
    
    EP->>EP: sort_by_priority()
    Note over EP: GPUå„ªå…ˆã€è»½é‡ãƒ¢ãƒ‡ãƒ«å„ªå…ˆãªã©
    
    EP->>EP: group_by_resource_type()
    Note over EP: GPU/CPUã‚°ãƒ«ãƒ¼ãƒ—ã«åˆ†å‰²
    
    EP->>RE: validate_resource_constraints()
    alt ãƒªã‚½ãƒ¼ã‚¹è¶…é
        RE->>EP: split_into_batches()
    end
    
    EP-->>CG: optimized_plan
    
    %% å®Ÿè¡Œè¨ˆç”»ã®æ°¸ç¶šåŒ–
    CG->>EP: save_to_database()
    EP->>EP: serialize_plan()
    EP->>DB: insert(execution_plan)
    DB-->>EP: plan_id
    
    EP-->>CG: persisted_plan
    CG-->>App: ExecutionPlan
    
    Note over App: å®Ÿè¡Œè¨ˆç”»ç”Ÿæˆå®Œäº†<br/>çµ„ã¿åˆã‚ã›æ•°: N<br/>æ¨å®šæ™‚é–“: Xæ™‚é–“
```

---

## 5. ä¸¦åˆ—å®Ÿè¡Œãƒ•ãƒ­ãƒ¼

### 5.1 ThreadPoolExecutorã«ã‚ˆã‚‹ä¸¦åˆ—å®Ÿè¡Œ

```mermaid
sequenceDiagram
    participant App as Application
    participant PE as ParallelExecutor
    participant RM as ResourceMonitor
    participant SE as SerialExecutor
    participant Worker as Worker Thread
    participant Model as NeuralForecast Model
    participant AS as ArtifactSaver
    participant Logger as StructuredLogger
    
    App->>PE: execute_plan(execution_plan, max_workers=4)
    
    %% ãƒªã‚½ãƒ¼ã‚¹ãƒ¢ãƒ‹ã‚¿èµ·å‹•
    PE->>RM: start_monitoring()
    RM->>RM: spawn_monitor_thread()
    loop ç›£è¦–ãƒ«ãƒ¼ãƒ—
        RM->>System: get_cpu_usage()
        RM->>System: get_memory_usage()
        RM->>System: get_gpu_usage()
        RM->>Logger: log_metrics()
    end
    
    %% å®Ÿè¡Œè¨ˆç”»ã®åˆ†å‰²
    PE->>PE: split_by_backend(execution_plan)
    PE->>PE: gpu_tasks = filter(backend="pytorch_lightning")
    PE->>PE: cpu_tasks = filter(backend!="pytorch_lightning")
    
    %% ThreadPoolExecutoråˆæœŸåŒ–
    PE->>PE: create_executor(max_workers=4)
    
    %% é€²æ—ãƒˆãƒ©ãƒƒã‚«ãƒ¼åˆæœŸåŒ–
    PE->>Logger: init_progress(total_tasks)
    Logger->>Logger: create_tqdm_bar()
    
    %% Rayã‚¿ã‚¹ã‚¯ã®å®‰å…¨æ€§ãƒã‚§ãƒƒã‚¯
    alt Rayãƒãƒƒã‚¯ã‚¨ãƒ³ãƒ‰å«ã‚€ AND allow_ray_parallel=False
        PE->>Logger: warn("Ray tasks will run serially")
        PE->>SE: execute_ray_tasks_serially(ray_tasks)
        loop å„Rayã‚¿ã‚¹ã‚¯
            SE->>SE: execute_single(task)
        end
    end
    
    %% ä¸¦åˆ—å®Ÿè¡Œé–‹å§‹
    PE->>PE: submit_tasks(cpu_tasks)
    
    par Worker 1
        PE->>Worker: execute_task(task_1)
        Worker->>Worker: setup_environment()
        Worker->>Worker: set_random_seed(task_1.seed)
        
        %% ãƒ¢ãƒ‡ãƒ«åˆæœŸåŒ–
        Worker->>Model: initialize(task_1.params)
        Model->>Model: load_hyperparameters()
        Model->>Model: setup_backend()
        Model-->>Worker: model_instance
        
        %% å­¦ç¿’å®Ÿè¡Œ
        Worker->>Model: fit(train_data)
        Model->>Model: run_training_loop()
        loop ã‚¨ãƒãƒƒã‚¯ã”ã¨
            Model->>Model: forward_pass()
            Model->>Model: calculate_loss()
            Model->>Model: backward_pass()
            Model->>Model: update_weights()
            Model->>Logger: log_epoch_metrics()
        end
        Model-->>Worker: trained_model
        
        %% äºˆæ¸¬
        Worker->>Model: predict(test_data)
        Model-->>Worker: predictions
        
        %% ãƒ¡ãƒˆãƒªã‚¯ã‚¹è¨ˆç®—
        Worker->>Worker: calculate_metrics(predictions)
        
        %% ã‚¢ãƒ¼ãƒ†ã‚£ãƒ•ã‚¡ã‚¯ãƒˆä¿å­˜
        Worker->>AS: save_model(trained_model)
        Worker->>AS: save_predictions(predictions)
        Worker->>AS: save_metrics(metrics)
        
        %% é€²æ—æ›´æ–°
        Worker->>Logger: update_progress()
        Worker->>Logger: log_completion(task_1)
        
    and Worker 2
        PE->>Worker: execute_task(task_2)
        Note over Worker: åŒæ§˜ã®å‡¦ç†
        
    and Worker 3
        PE->>Worker: execute_task(task_3)
        Note over Worker: åŒæ§˜ã®å‡¦ç†
        
    and Worker 4
        PE->>Worker: execute_task(task_4)
        Note over Worker: åŒæ§˜ã®å‡¦ç†
    end
    
    %% ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°
    alt ã‚¿ã‚¹ã‚¯å®Ÿè¡Œä¸­ã«ã‚¨ãƒ©ãƒ¼
        Worker->>Worker: catch_exception()
        Worker->>Logger: log_error(exception)
        Worker->>AS: save_error_metadata()
        Worker->>Worker: extract_traceback()
        Worker->>PE: return_error_result()
    end
    
    %% ã™ã¹ã¦ã®ã‚¿ã‚¹ã‚¯å®Œäº†å¾…ã¡
    PE->>PE: wait_for_completion()
    
    %% çµæœé›†ç´„
    PE->>PE: collect_results()
    loop å„Workerçµæœ
        PE->>PE: aggregate_metrics()
        PE->>PE: check_for_errors()
    end
    
    %% ãƒªã‚½ãƒ¼ã‚¹ãƒ¢ãƒ‹ã‚¿åœæ­¢
    PE->>RM: stop_monitoring()
    RM->>RM: save_final_metrics()
    RM->>Logger: log_resource_summary()
    
    %% ExecutorPoolçµ‚äº†
    PE->>PE: shutdown_executor(wait=True)
    
    %% æœ€çµ‚ãƒ¬ãƒãƒ¼ãƒˆ
    PE->>Logger: log_execution_summary()
    Note over Logger: æˆåŠŸ: Xä»¶<br/>å¤±æ•—: Yä»¶<br/>ç·æ™‚é–“: Zç§’
    
    PE-->>App: ExecutionResults
    
    Note over App: ä¸¦åˆ—å®Ÿè¡Œå®Œäº†
```

---

## 6. ãƒ­ã‚®ãƒ³ã‚°ãƒ•ãƒ­ãƒ¼

### 6.1 æ§‹é€ åŒ–ãƒ­ã‚°ã¨ãƒ¡ãƒˆãƒªã‚¯ã‚¹ãƒˆãƒ©ãƒƒã‚­ãƒ³ã‚°

```mermaid
sequenceDiagram
    participant App as Application
    participant SL as StructuredLogger
    participant PT as ProgressTracker
    participant MB as MLflowBridge
    participant WB as WandBBridge
    participant FS as File System
    participant Console as Console Output
    
    App->>SL: initialize(config)
    
    %% ãƒ­ã‚¬ãƒ¼è¨­å®š
    SL->>SL: setup_structlog()
    SL->>SL: configure_processors()
    Note over SL: JSON formatter<br/>Timestamp<br/>Log level<br/>Context
    
    SL->>FS: create_log_file(log_path)
    FS-->>SL: file_handle
    
    %% MLflowåˆæœŸåŒ–ï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰
    alt MLflowæœ‰åŠ¹
        SL->>MB: initialize(tracking_uri)
        MB->>MB: create_experiment()
        MB-->>SL: experiment_id
    end
    
    %% W&BåˆæœŸåŒ–ï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰
    alt W&Bæœ‰åŠ¹
        SL->>WB: initialize(project_name)
        WB->>WB: create_run()
        WB-->>SL: run_id
    end
    
    %% å®Ÿè¡Œé–‹å§‹ãƒ­ã‚°
    App->>SL: log_execution_start(config)
    SL->>SL: create_log_entry()
    SL->>SL: add_context(run_id, timestamp)
    SL->>FS: write_log(entry)
    SL->>Console: print_info()
    
    alt MLflowæœ‰åŠ¹
        SL->>MB: log_params(config)
    end
    
    alt W&Bæœ‰åŠ¹
        SL->>WB: log_config(config)
    end
    
    %% é€²æ—ãƒˆãƒ©ãƒƒã‚­ãƒ³ã‚°é–‹å§‹
    App->>PT: start_tracking(total_tasks)
    PT->>PT: initialize_tqdm(total_tasks)
    PT->>PT: create_progress_bar()
    
    %% ã‚¿ã‚¹ã‚¯å®Ÿè¡Œä¸­ã®ãƒ­ã‚°
    loop å„ã‚¿ã‚¹ã‚¯
        App->>SL: log_task_start(task_id)
        SL->>FS: write_log(task_start)
        SL->>Console: print_task_info()
        
        %% ã‚¨ãƒãƒƒã‚¯ã”ã¨ã®ãƒ¡ãƒˆãƒªã‚¯ã‚¹
        loop å„ã‚¨ãƒãƒƒã‚¯
            App->>SL: log_metrics(epoch, metrics)
            SL->>SL: format_metrics()
            
            SL->>FS: write_log(metrics)
            
            alt MLflowæœ‰åŠ¹
                SL->>MB: log_metrics(metrics, step=epoch)
            end
            
            alt W&Bæœ‰åŠ¹
                SL->>WB: log(metrics, step=epoch)
            end
            
            %% é€²æ—æ›´æ–°
            App->>PT: update(1)
            PT->>PT: increment_progress()
            PT->>Console: update_bar()
        end
        
        %% ã‚¿ã‚¹ã‚¯å®Œäº†ãƒ­ã‚°
        App->>SL: log_task_complete(task_id, results)
        SL->>SL: calculate_task_duration()
        SL->>SL: extract_final_metrics()
        
        SL->>FS: write_log(task_complete)
        SL->>Console: print_task_summary()
        
        alt MLflowæœ‰åŠ¹
            SL->>MB: log_metrics(final_metrics)
            SL->>MB: log_artifact(model_path)
        end
        
        alt W&Bæœ‰åŠ¹
            SL->>WB: log_summary(final_metrics)
            SL->>WB: log_model(model_path)
        end
        
        %% ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°
        alt ã‚¿ã‚¹ã‚¯å¤±æ•—
            App->>SL: log_error(task_id, exception)
            SL->>SL: extract_traceback()
            SL->>SL: extract_error_metadata()
            
            SL->>FS: write_error_log()
            SL->>Console: print_error()
            
            alt MLflowæœ‰åŠ¹
                SL->>MB: log_error_artifact()
            end
            
            alt W&Bæœ‰åŠ¹
                SL->>WB: log_error()
            end
        end
    end
    
    %% é€²æ—å®Œäº†
    PT->>PT: close_progress_bar()
    PT->>Console: clear_bar()
    
    %% å®Ÿè¡Œå®Œäº†ãƒ­ã‚°
    App->>SL: log_execution_complete(summary)
    SL->>SL: calculate_total_duration()
    SL->>SL: aggregate_metrics()
    SL->>SL: generate_summary()
    
    SL->>FS: write_summary_log()
    SL->>Console: print_summary()
    
    Note over Console: ===== Execution Summary =====<br/>Total Tasks: X<br/>Successful: Y<br/>Failed: Z<br/>Total Time: T seconds
    
    alt MLflowæœ‰åŠ¹
        SL->>MB: log_final_summary()
        SL->>MB: end_run()
    end
    
    alt W&Bæœ‰åŠ¹
        SL->>WB: log_final_summary()
        SL->>WB: finish_run()
    end
    
    %% ãƒ­ã‚°ãƒ•ã‚¡ã‚¤ãƒ«ã‚¯ãƒ­ãƒ¼ã‚º
    SL->>FS: close_log_file()
    
    SL-->>App: LoggingComplete
    
    Note over App: ãƒ­ã‚®ãƒ³ã‚°å®Œäº†
```

---

## 7. å®Œå…¨ãªå­¦ç¿’ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³

### 7.1 ã‚¨ãƒ³ãƒ‰ãƒ„ãƒ¼ã‚¨ãƒ³ãƒ‰ã®å­¦ç¿’ãƒ•ãƒ­ãƒ¼

```mermaid
sequenceDiagram
    participant User as User/CLI
    participant Orch as MainOrchestrator
    participant CL as ConfigLoader
    participant DL as DataLoader
    participant MR as ModelRegistry
    participant CG as CombinationGenerator
    participant PE as ParallelExecutor
    participant Model as NeuralForecast
    participant AS as ArtifactSaver
    participant DB as Database
    participant Logger as StructuredLogger
    
    %% 1. åˆæœŸåŒ–ãƒ•ã‚§ãƒ¼ã‚º
    User->>Orch: run_training(cli_args)
    
    Note over Orch: === Phase 1: Initialization ===
    
    Orch->>Logger: initialize_logging()
    Logger-->>Orch: logger_ready
    
    Orch->>CL: load_all_configs(cli_args)
    CL->>CL: merge_env_and_cli()
    CL->>CL: validate_configs()
    CL-->>Orch: configs
    
    Orch->>Logger: log_config(configs)
    
    %% 2. ãƒ‡ãƒ¼ã‚¿æº–å‚™ãƒ•ã‚§ãƒ¼ã‚º
    Note over Orch: === Phase 2: Data Preparation ===
    
    Orch->>DL: load_and_preprocess(data_path)
    
    DL->>DL: load_csv()
    DL->>DL: standardize_columns()
    DL->>DL: parse_dates()
    DL->>DL: infer_frequency()
    DL->>DL: handle_missing()
    DL->>DL: encode_exogenous()
    DL->>DL: validate_data()
    
    DL-->>Orch: processed_data
    
    Orch->>Logger: log_data_info(processed_data)
    Orch->>DB: save_dataset_metadata(processed_data)
    
    %% 3. ãƒ¢ãƒ‡ãƒ«æ¤œå‡ºãƒ•ã‚§ãƒ¼ã‚º
    Note over Orch: === Phase 3: Model Discovery ===
    
    Orch->>MR: discover_all()
    
    MR->>MR: detect_auto_models()
    MR->>MR: detect_backends()
    MR->>MR: detect_losses()
    MR->>MR: detect_scalers()
    MR->>MR: detect_search_algos()
    MR->>MR: validate_combinations()
    
    MR-->>Orch: registry
    
    Orch->>Logger: log_registry_info(registry)
    
    %% 4. å®Ÿè¡Œè¨ˆç”»ç”Ÿæˆãƒ•ã‚§ãƒ¼ã‚º
    Note over Orch: === Phase 4: Execution Planning ===
    
    Orch->>CG: generate_plan(configs, processed_data, registry)
    
    CG->>CG: calculate_safe_h()
    CG->>CG: expand_axes()
    CG->>CG: cartesian_product()
    CG->>CG: generate_fingerprints()
    CG->>CG: filter_duplicates()
    CG->>CG: estimate_resources()
    CG->>CG: optimize_plan()
    
    CG-->>Orch: execution_plan
    
    Orch->>Logger: log_plan_summary(execution_plan)
    Orch->>DB: save_execution_plan(execution_plan)
    
    %% 5. å®Ÿè¡Œãƒ•ã‚§ãƒ¼ã‚º
    Note over Orch: === Phase 5: Execution ===
    
    Orch->>PE: execute_plan(execution_plan)
    
    PE->>PE: start_resource_monitor()
    PE->>PE: create_thread_pool()
    
    loop å„çµ„ã¿åˆã‚ã›
        PE->>PE: assign_to_worker()
        
        par Worker Thread
            PE->>PE: setup_environment()
            PE->>PE: set_random_seed()
            
            %% ãƒ¢ãƒ‡ãƒ«åˆæœŸåŒ–
            PE->>Model: initialize(params)
            Model->>Model: setup_backend()
            Model->>Model: configure_hyperparams()
            Model-->>PE: model_instance
            
            %% å­¦ç¿’
            PE->>Model: fit(train_data, val_data)
            
            loop ã‚¨ãƒãƒƒã‚¯
                Model->>Model: train_epoch()
                Model->>Model: validate()
                Model->>Logger: log_metrics()
                
                alt Early Stoppingæ¡ä»¶
                    Model->>Model: stop_training()
                end
            end
            
            Model-->>PE: trained_model
            
            %% è©•ä¾¡
            PE->>Model: predict(test_data)
            Model-->>PE: predictions
            
            PE->>PE: calculate_metrics(predictions)
            
            %% ã‚¢ãƒ¼ãƒ†ã‚£ãƒ•ã‚¡ã‚¯ãƒˆä¿å­˜
            PE->>AS: save_model(trained_model)
            AS->>AS: generate_model_path()
            AS->>FS: write_model()
            AS-->>PE: model_path
            
            PE->>AS: save_predictions(predictions)
            AS->>FS: write_predictions()
            AS-->>PE: predictions_path
            
            PE->>AS: save_metadata(run_info)
            AS->>FS: write_metadata()
            AS-->>PE: metadata_path
            
            %% ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹è¨˜éŒ²
            PE->>DB: insert_run(run_info)
            PE->>DB: insert_metrics(metrics)
            PE->>DB: insert_artifacts(paths)
            
            PE->>Logger: log_run_complete()
            PE->>Logger: update_progress()
            
            alt ã‚¨ãƒ©ãƒ¼ç™ºç”Ÿ
                PE->>Logger: log_error(exception)
                PE->>DB: insert_error(error_info)
                PE->>AS: save_error_metadata()
            end
        end
    end
    
    PE->>PE: wait_all_workers()
    PE->>PE: stop_resource_monitor()
    PE->>PE: shutdown_thread_pool()
    
    PE-->>Orch: execution_results
    
    %% 6. é›†ç´„ãƒ•ã‚§ãƒ¼ã‚º
    Note over Orch: === Phase 6: Aggregation ===
    
    Orch->>Orch: aggregate_results(execution_results)
    Orch->>Orch: calculate_summary_stats()
    Orch->>Orch: identify_best_models()
    
    Orch->>Logger: log_final_summary()
    Orch->>DB: save_experiment_summary()
    
    %% 7. ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—ãƒ•ã‚§ãƒ¼ã‚º
    Note over Orch: === Phase 7: Cleanup ===
    
    Orch->>Logger: flush_logs()
    Orch->>Logger: close_handlers()
    
    Orch-->>User: TrainingComplete
    
    Note over User: å­¦ç¿’å®Œäº†<br/>æˆåŠŸ: Xä»¶<br/>å¤±æ•—: Yä»¶<br/>ç·æ™‚é–“: Z
```

---

## 8. äºˆæ¸¬ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³

### 8.1 ãƒ¢ãƒ‡ãƒ«èª­ã¿è¾¼ã¿ã‹ã‚‰äºˆæ¸¬ã¾ã§

```mermaid
sequenceDiagram
    participant User as User/API
    participant FC as Forecaster
    participant MLoader as ModelLoader
    participant DL as DataLoader
    participant DP as DataPreprocessor
    participant Model as LoadedModel
    participant PP as PostProcessor
    participant AS as ArtifactSaver
    participant DB as Database
    
    %% 1. äºˆæ¸¬ãƒªã‚¯ã‚¨ã‚¹ãƒˆ
    User->>FC: predict(model_id, input_data)
    
    %% 2. ãƒ¢ãƒ‡ãƒ«èª­ã¿è¾¼ã¿
    FC->>MLoader: load_model(model_id)
    
    MLoader->>DB: get_model_metadata(model_id)
    DB-->>MLoader: metadata
    
    MLoader->>MLoader: validate_metadata()
    
    MLoader->>FS: read_model_file(model_path)
    FS-->>MLoader: model_bytes
    
    MLoader->>MLoader: deserialize_model()
    MLoader->>Model: restore_state()
    
    Model->>Model: load_weights()
    Model->>Model: load_hyperparameters()
    Model->>Model: setup_backend()
    
    Model-->>MLoader: loaded_model
    MLoader-->>FC: model_instance
    
    %% 3. ãƒ‡ãƒ¼ã‚¿æº–å‚™
    FC->>DL: load_input(input_data)
    DL->>DL: validate_format()
    DL->>DL: parse_dates()
    DL-->>FC: raw_data
    
    FC->>DP: preprocess(raw_data, metadata)
    
    DP->>DP: standardize_columns()
    DP->>DP: infer_frequency()
    DP->>DP: align_with_training()
    
    alt å¤–ç”Ÿå¤‰æ•°ã‚ã‚Š
        DP->>DP: load_encoders(metadata)
        DP->>DP: encode_exogenous()
    end
    
    DP->>DP: validate_input()
    DP-->>FC: preprocessed_data
    
    %% 4. äºˆæ¸¬å®Ÿè¡Œ
    FC->>FC: setup_prediction_context()
    FC->>FC: set_random_seed()
    
    FC->>Model: predict(preprocessed_data, h)
    
    Model->>Model: prepare_input()
    Model->>Model: forward_pass()
    Model->>Model: generate_forecast()
    
    alt ç¢ºç‡äºˆæ¸¬
        Model->>Model: compute_quantiles()
    end
    
    Model-->>FC: raw_predictions
    
    %% 5. å¾Œå‡¦ç†
    FC->>PP: postprocess(raw_predictions, metadata)
    
    PP->>PP: denormalize()
    
    alt ã‚¹ã‚±ãƒ¼ãƒ©ãƒ¼ä½¿ç”¨
        PP->>PP: inverse_transform()
    end
    
    PP->>PP: format_output()
    PP->>PP: add_timestamps()
    PP->>PP: add_confidence_intervals()
    
    PP-->>FC: formatted_predictions
    
    %% 6. ä¿å­˜
    FC->>AS: save_predictions(formatted_predictions)
    AS->>AS: generate_prediction_path()
    AS->>FS: write_csv(formatted_predictions)
    AS-->>FC: predictions_path
    
    FC->>DB: insert_prediction_record()
    DB-->>FC: prediction_id
    
    %% 7. å¿œç­”
    FC-->>User: PredictionResult
    
    Note over User: äºˆæ¸¬å®Œäº†<br/>Horizon: h<br/>Series: N
```

---

## 9. å†å­¦ç¿’ãƒˆãƒªã‚¬ãƒ¼ãƒ•ãƒ­ãƒ¼

### 9.1 ãƒ‰ãƒªãƒ•ãƒˆæ¤œå‡ºã‹ã‚‰å†å­¦ç¿’ã¾ã§

```mermaid
sequenceDiagram
    participant Scheduler as Scheduler/Cron
    participant RT as RetrainTrigger
    participant DD as DriftDetector
    participant MLoader as ModelLoader
    participant Orch as MainOrchestrator
    participant DB as Database
    participant Logger as StructuredLogger
    participant Alert as AlertSystem
    
    %% 1. ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ«èµ·å‹•
    Scheduler->>RT: trigger_check()
    
    RT->>Logger: log_check_start()
    
    %% 2. ãƒˆãƒªã‚¬ãƒ¼æ¡ä»¶ãƒã‚§ãƒƒã‚¯
    RT->>DB: get_last_training_time()
    DB-->>RT: last_training_time
    
    RT->>RT: check_time_threshold()
    Note over RT: æœ€çµ‚å­¦ç¿’ã‹ã‚‰7æ—¥ä»¥ä¸Š?
    
    alt æ™‚é–“é–¾å€¤æœªé”
        RT-->>Scheduler: No action needed
    end
    
    %% 3. ãƒ‰ãƒªãƒ•ãƒˆæ¤œå‡º
    RT->>DD: detect_drift(model_id)
    
    DD->>MLoader: load_model(model_id)
    MLoader-->>DD: model_instance
    
    DD->>DB: get_training_data()
    DB-->>DD: training_data
    
    DD->>DB: get_recent_data()
    DB-->>DD: recent_data
    
    %% çµ±è¨ˆçš„ãƒ‰ãƒªãƒ•ãƒˆæ¤œå‡º
    DD->>DD: compute_statistics(training_data)
    DD->>DD: compute_statistics(recent_data)
    
    DD->>DD: kolmogorov_smirnov_test()
    DD->>DD: chi_square_test()
    DD->>DD: population_stability_index()
    
    %% ãƒ¢ãƒ‡ãƒ«æ€§èƒ½ãƒ‰ãƒªãƒ•ãƒˆ
    DD->>DD: compute_model_performance(training_data)
    DD->>DD: compute_model_performance(recent_data)
    DD->>DD: compare_metrics()
    
    %% ãƒ‡ãƒ¼ã‚¿åˆ†å¸ƒãƒ‰ãƒªãƒ•ãƒˆ
    DD->>DD: jensen_shannon_divergence()
    DD->>DD: wasserstein_distance()
    
    DD->>DD: aggregate_drift_scores()
    
    alt ãƒ‰ãƒªãƒ•ãƒˆæ¤œå‡º
        DD->>Logger: log_drift_detected(scores)
        DD-->>RT: drift_detected=True, scores
    else ãƒ‰ãƒªãƒ•ãƒˆãªã—
        DD->>Logger: log_no_drift()
        DD-->>RT: drift_detected=False
        RT-->>Scheduler: No retraining needed
    end
    
    %% 4. å†å­¦ç¿’åˆ¤å®š
    RT->>RT: evaluate_retrain_criteria()
    
    alt é«˜ãƒ‰ãƒªãƒ•ãƒˆï¼ˆã‚¹ã‚³ã‚¢ > 0.8ï¼‰
        RT->>RT: priority=HIGH
    else ä¸­ãƒ‰ãƒªãƒ•ãƒˆï¼ˆã‚¹ã‚³ã‚¢ > 0.5ï¼‰
        RT->>RT: priority=MEDIUM
    else ä½ãƒ‰ãƒªãƒ•ãƒˆï¼ˆã‚¹ã‚³ã‚¢ > 0.3ï¼‰
        RT->>RT: priority=LOW
    end
    
    %% 5. ã‚¢ãƒ©ãƒ¼ãƒˆé€ä¿¡
    RT->>Alert: send_alert(drift_info)
    Alert->>Alert: format_message()
    Alert->>Email: send_email(stakeholders)
    Alert->>Slack: post_message(channel)
    
    %% 6. å†å­¦ç¿’è¨ˆç”»ä½œæˆ
    RT->>DB: get_model_config(model_id)
    DB-->>RT: config
    
    RT->>RT: prepare_retrain_config()
    RT->>RT: update_hyperparams()
    RT->>RT: set_data_window()
    
    %% 7. å†å­¦ç¿’å®Ÿè¡Œ
    RT->>Orch: trigger_retraining(retrain_config)
    
    Orch->>Logger: log_retrain_start()
    
    %% ãƒ‡ãƒ¼ã‚¿æº–å‚™
    Orch->>DB: get_updated_data()
    DB-->>Orch: updated_data
    
    %% å­¦ç¿’å®Ÿè¡Œ
    Orch->>Orch: run_training(retrain_config, updated_data)
    Note over Orch: é€šå¸¸ã®å­¦ç¿’ãƒ•ãƒ­ãƒ¼å®Ÿè¡Œ
    
    %% æ–°æ—§ãƒ¢ãƒ‡ãƒ«æ¯”è¼ƒ
    Orch->>Orch: compare_models(old_model, new_model)
    
    alt æ–°ãƒ¢ãƒ‡ãƒ«ãŒå„ªã‚Œã¦ã„ã‚‹
        Orch->>DB: promote_model(new_model_id)
        Orch->>DB: archive_model(old_model_id)
        Orch->>Logger: log_model_promotion()
    else æ—§ãƒ¢ãƒ‡ãƒ«ã®æ–¹ãŒè‰¯ã„
        Orch->>DB: keep_current_model()
        Orch->>Logger: log_keep_current()
    end
    
    Orch-->>RT: retrain_result
    
    %% 8. è¨˜éŒ²ã¨é€šçŸ¥
    RT->>DB: insert_retrain_record()
    RT->>Logger: log_retrain_complete()
    RT->>Alert: send_completion_notification()
    
    RT-->>Scheduler: Retrain complete
    
    Note over Scheduler: æ¬¡å›ãƒã‚§ãƒƒã‚¯: 7æ—¥å¾Œ
```

---

## 10. ãƒã‚¤ãƒ‘ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æ¢ç´¢

### 10.1 Optunaã‚’ä½¿ã£ãŸæ¢ç´¢ãƒ•ãƒ­ãƒ¼

```mermaid
sequenceDiagram
    participant App as Application
    participant SM as SearchManager
    participant Study as Optuna Study
    participant Trial as Trial
    participant Model as NeuralForecast
    participant Eval as Evaluator
    participant DB as Database
    
    %% 1. æ¢ç´¢åˆæœŸåŒ–
    App->>SM: run_hyperparameter_search(config)
    
    SM->>SM: parse_search_space(config)
    SM->>SM: define_objective_function()
    
    SM->>Study: create_study()
    Study->>Study: set_direction("minimize")
    Study->>Study: set_sampler(TPESampler())
    Study->>Study: set_pruner(MedianPruner())
    
    %% 2. æ¢ç´¢ãƒ«ãƒ¼ãƒ—
    SM->>Study: optimize(objective, n_trials=100)
    
    loop Trial 1 to 100
        Study->>Trial: create_trial()
        
        %% ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚µã‚¸ã‚§ã‚¹ãƒˆ
        Trial->>Trial: suggest_int("hidden_size", 32, 256)
        Trial->>Trial: suggest_float("learning_rate", 1e-5, 1e-2, log=True)
        Trial->>Trial: suggest_categorical("optimizer", ["Adam", "SGD"])
        Trial->>Trial: suggest_int("n_layers", 1, 4)
        Trial->>Trial: suggest_float("dropout", 0.0, 0.5)
        
        Trial-->>SM: trial_params
        
        %% ãƒ¢ãƒ‡ãƒ«åˆæœŸåŒ–
        SM->>Model: initialize(trial_params)
        Model->>Model: setup_architecture()
        Model->>Model: configure_optimizer()
        Model-->>SM: model_instance
        
        %% å­¦ç¿’
        SM->>Model: fit(train_data, val_data)
        
        loop Epoch
            Model->>Model: train_epoch()
            Model->>Model: validate()
            
            Model->>Eval: calculate_metrics(val_predictions)
            Eval-->>Model: val_loss
            
            %% ä¸­é–“å€¤å ±å‘Š
            Model->>Trial: report(val_loss, step=epoch)
            
            %% Pruningåˆ¤å®š
            Trial->>Trial: should_prune()
            alt Pruningæ¡ä»¶æº€ãŸã™
                Trial->>SM: TrialPruned
                Note over SM: ã“ã®è©¦è¡Œã‚’æ‰“ã¡åˆ‡ã‚Š
            end
        end
        
        Model-->>SM: final_val_loss
        
        %% è©¦è¡Œè¨˜éŒ²
        SM->>DB: save_trial(trial_params, final_val_loss)
        SM->>Trial: set_user_attrs(custom_metrics)
        
        Trial-->>Study: trial_result
        
        %% æœ€è‰¯ãƒ¢ãƒ‡ãƒ«æ›´æ–°
        alt æ–°ã—ã„ãƒ™ã‚¹ãƒˆã‚¹ã‚³ã‚¢
            Study->>Study: update_best_trial()
            SM->>DB: save_best_model(model_instance)
        end
    end
    
    %% 3. æ¢ç´¢å®Œäº†
    Study-->>SM: study_results
    
    SM->>SM: analyze_results(study_results)
    SM->>SM: get_best_params()
    SM->>SM: generate_importance_plot()
    SM->>SM: generate_optimization_history()
    
    SM->>DB: save_study_summary()
    
    SM-->>App: SearchResults
    
    Note over App: æ¢ç´¢å®Œäº†<br/>Best params found<br/>Best score: X
```

---

## 11. ã‚¢ãƒ¼ãƒ†ã‚£ãƒ•ã‚¡ã‚¯ãƒˆç®¡ç†

### 11.1 ãƒ¢ãƒ‡ãƒ«ä¿å­˜ã¨ãƒãƒ¼ã‚¸ãƒ§ãƒ‹ãƒ³ã‚°

```mermaid
sequenceDiagram
    participant App as Application
    participant AM as ArtifactManager
    participant MS as ModelSaver
    participant PS as PredictionSaver
    participant MM as MetadataManager
    participant FS as File System
    participant DB as Database
    participant Hash as HashCalculator
    
    %% 1. ãƒ¢ãƒ‡ãƒ«ä¿å­˜é–‹å§‹
    App->>AM: save_run_artifacts(run_info, model, predictions)
    
    AM->>AM: generate_run_id()
    AM->>AM: create_artifact_structure()
    
    %% 2. ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªãƒ‘ã‚¹ç”Ÿæˆ
    AM->>AM: encode_params_to_path(run_info.params)
    
    loop å„ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿
        AM->>AM: format_param_name(key, value)
        alt å€¤ãŒé•·ã„ï¼ˆ> 50æ–‡å­—ï¼‰
            AM->>Hash: calculate_sha256_short(value)
            Hash-->>AM: hash_value
            AM->>AM: append(f"{key}={hash_value}")
        else å€¤ãŒçŸ­ã„
            AM->>AM: append(f"{key}={value}")
        end
    end
    
    AM->>AM: check_path_length()
    alt ãƒ‘ã‚¹ãŒé•·ã™ãã‚‹ï¼ˆ> 255æ–‡å­—ï¼‰
        AM->>AM: truncate_path()
        AM->>Hash: calculate_dir_hash()
        Hash-->>AM: dir_hash
        AM->>AM: append_hash_suffix(dir_hash)
    end
    
    AM->>FS: mkdir(artifact_path)
    FS-->>AM: path_created
    
    %% 3. ãƒ¢ãƒ‡ãƒ«ä¿å­˜
    AM->>MS: save_model(model, artifact_path)
    
    MS->>MS: serialize_model(model)
    MS->>MS: extract_model_metadata()
    
    MS->>FS: write(model_path, model_bytes)
    FS-->>MS: model_file_path
    
    MS->>Hash: calculate_file_hash(model_file_path)
    Hash-->>MS: model_hash
    
    MS->>MM: record_model_info(model_hash, model_metadata)
    
    MS-->>AM: model_saved
    
    %% 4. äºˆæ¸¬çµæœä¿å­˜
    AM->>PS: save_predictions(predictions, artifact_path)
    
    PS->>PS: format_predictions_df(predictions)
    PS->>PS: add_metadata_columns()
    
    PS->>FS: write_csv(predictions_path, predictions_df)
    FS-->>PS: predictions_file_path
    
    PS->>Hash: calculate_file_hash(predictions_file_path)
    Hash-->>PS: predictions_hash
    
    PS-->>AM: predictions_saved
    
    %% 5. ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ä¿å­˜
    AM->>MM: save_metadata(run_info, artifact_path)
    
    MM->>MM: create_metadata_dict()
    MM->>MM: add_run_info(run_info)
    MM->>MM: add_model_hash(model_hash)
    MM->>MM: add_predictions_hash(predictions_hash)
    MM->>MM: add_timestamps()
    MM->>MM: add_environment_info()
    
    MM->>FS: write_json(metadata_path, metadata_dict)
    FS-->>MM: metadata_file_path
    
    MM-->>AM: metadata_saved
    
    %% 6. ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹è¨˜éŒ²
    AM->>DB: insert_run_record()
    DB-->>AM: run_id
    
    AM->>DB: insert_artifact_paths()
    DB-->>AM: artifact_id
    
    AM->>DB: insert_hashes()
    DB-->>AM: hash_id
    
    %% 7. ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹æ›´æ–°
    AM->>DB: update_run_index()
    AM->>FS: create_symlink(latest_run)
    
    %% 8. ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—ï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰
    alt å¤ã„ã‚¢ãƒ¼ãƒ†ã‚£ãƒ•ã‚¡ã‚¯ãƒˆå‰Šé™¤ãŒæœ‰åŠ¹
        AM->>DB: get_old_runs(retention_days)
        DB-->>AM: old_run_ids
        
        loop å„å¤ã„Run
            AM->>FS: delete_directory(old_artifact_path)
            AM->>DB: mark_as_archived(old_run_id)
        end
    end
    
    AM-->>App: ArtifactsSaved
    
    Note over App: ã‚¢ãƒ¼ãƒ†ã‚£ãƒ•ã‚¡ã‚¯ãƒˆä¿å­˜å®Œäº†<br/>Run ID: XXX<br/>Path: /outputs/...
```

---

## 12. ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°

### 12.1 ä¾‹å¤–å‡¦ç†ã¨ãƒªãƒˆãƒ©ã‚¤

```mermaid
sequenceDiagram
    participant App as Application
    participant EH as ErrorHandler
    participant Retry as RetryManager
    participant Logger as StructuredLogger
    participant Model as NeuralForecast
    participant DB as Database
    participant Alert as AlertSystem
    
    %% 1. ã‚¿ã‚¹ã‚¯å®Ÿè¡Œé–‹å§‹
    App->>EH: execute_with_error_handling(task)
    
    EH->>EH: wrap_task(task)
    EH->>Retry: init_retry_policy(max_retries=3)
    
    loop è©¦è¡Œå›æ•°ï¼ˆæœ€å¤§3å›ï¼‰
        EH->>EH: try_execute(task)
        
        alt å®Ÿè¡ŒæˆåŠŸ
            EH-->>App: task_result
        else ã‚¨ãƒ©ãƒ¼ç™ºç”Ÿ
            Model->>Model: raise_exception(error)
            Model-->>EH: exception
            
            %% 2. ã‚¨ãƒ©ãƒ¼åˆ†é¡
            EH->>EH: classify_error(exception)
            
            alt ãƒ‡ãƒ¼ã‚¿ã‚¨ãƒ©ãƒ¼
                EH->>EH: error_type = "DATA_ERROR"
                EH->>EH: recoverable = False
                
            else ãƒ¡ãƒ¢ãƒªã‚¨ãƒ©ãƒ¼
                EH->>EH: error_type = "MEMORY_ERROR"
                EH->>EH: recoverable = True
                EH->>EH: suggest_reduce_batch_size()
                
            else GPUã‚¨ãƒ©ãƒ¼
                EH->>EH: error_type = "GPU_ERROR"
                EH->>EH: recoverable = True
                EH->>EH: suggest_use_cpu()
                
            else ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã‚¨ãƒ©ãƒ¼
                EH->>EH: error_type = "NETWORK_ERROR"
                EH->>EH: recoverable = True
                
            else ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆ
                EH->>EH: error_type = "TIMEOUT"
                EH->>EH: recoverable = True
                EH->>EH: suggest_increase_timeout()
                
            else ãã®ä»–
                EH->>EH: error_type = "UNKNOWN_ERROR"
                EH->>EH: recoverable = True
            end
            
            %% 3. ãƒ­ã‚°è¨˜éŒ²
            EH->>Logger: log_error(error_info)
            Logger->>Logger: format_error_message()
            Logger->>Logger: extract_traceback()
            Logger->>Logger: add_context(task_info)
            Logger->>FS: write_error_log()
            
            %% 4. ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ä¿å­˜
            EH->>EH: extract_error_metadata()
            EH->>DB: insert_error_record(error_metadata)
            
            %% 5. ãƒªãƒˆãƒ©ã‚¤åˆ¤å®š
            alt recoverable AND retries_left > 0
                EH->>Retry: should_retry(error_type, attempt)
                Retry-->>EH: retry=True
                
                Retry->>Retry: calculate_backoff(attempt)
                Note over Retry: Exponential backoff:<br/>2^attempt seconds
                
                Retry->>Retry: sleep(backoff_time)
                
                EH->>Logger: log_retry_attempt(attempt)
                
                %% ãƒªãƒˆãƒ©ã‚¤å‰ã®ä¿®æ­£
                alt ãƒ¡ãƒ¢ãƒªã‚¨ãƒ©ãƒ¼
                    EH->>EH: reduce_batch_size()
                else GPUã‚¨ãƒ©ãƒ¼
                    EH->>EH: switch_to_cpu()
                end
                
                Note over EH: æ¬¡ã®è©¦è¡Œã¸
                
            else å›å¾©ä¸èƒ½ OR ãƒªãƒˆãƒ©ã‚¤ä¸Šé™
                Retry-->>EH: retry=False
                
                %% 6. æœ€çµ‚ã‚¨ãƒ©ãƒ¼å‡¦ç†
                EH->>EH: handle_final_failure()
                
                %% ã‚¢ãƒ©ãƒ¼ãƒˆé€ä¿¡
                EH->>Alert: send_alert(critical_error)
                Alert->>Email: send_error_notification()
                Alert->>Slack: post_error_message()
                
                %% ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯æˆ¦ç•¥
                alt ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ã‚ã‚Š
                    EH->>EH: execute_fallback_strategy()
                    EH->>Logger: log_fallback_execution()
                else ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ãªã—
                    EH->>Logger: log_final_failure()
                    EH->>DB: mark_task_failed()
                    EH-->>App: TaskFailedError
                end
            end
        end
    end
    
    %% 7. çµ±è¨ˆæ›´æ–°
    EH->>DB: update_error_statistics()
    EH->>DB: update_task_statistics()
    
    Note over App: ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°å®Œäº†
```

---

## ğŸ“Š ã‚·ãƒ¼ã‚±ãƒ³ã‚¹å›³ã®èª­ã¿æ–¹

### è¨˜å·ã®èª¬æ˜

- **â†’**: åŒæœŸå‘¼ã³å‡ºã—ï¼ˆãƒ¬ã‚¹ãƒãƒ³ã‚¹å¾…ã¡ï¼‰
- **--â†’**: éåŒæœŸãƒ¬ã‚¹ãƒãƒ³ã‚¹
- **Note**: è£œè¶³èª¬æ˜
- **alt/else/end**: æ¡ä»¶åˆ†å²
- **loop/end**: ç¹°ã‚Šè¿”ã—
- **par/and/end**: ä¸¦åˆ—å‡¦ç†

### è‰²åˆ†ã‘ã®æ„å‘³ï¼ˆå®Ÿè£…æ™‚ï¼‰

- **é’**: æ­£å¸¸ãƒ•ãƒ­ãƒ¼
- **èµ¤**: ã‚¨ãƒ©ãƒ¼ãƒ‘ã‚¹
- **é»„**: è­¦å‘Šãƒ»æ³¨æ„
- **ç·‘**: æˆåŠŸ

---

## ğŸ¯ ä½¿ç”¨æ–¹æ³•

### Mermaidãƒ¬ãƒ³ãƒ€ãƒªãƒ³ã‚°

ã“ã‚Œã‚‰ã®ã‚·ãƒ¼ã‚±ãƒ³ã‚¹å›³ã¯ã€Mermaidå¯¾å¿œã®ãƒãƒ¼ã‚¯ãƒ€ã‚¦ãƒ³ãƒ“ãƒ¥ãƒ¼ã‚¢ã§è¡¨ç¤ºã§ãã¾ã™ï¼š

1. **GitHub/GitLab**: è‡ªå‹•ãƒ¬ãƒ³ãƒ€ãƒªãƒ³ã‚°
2. **VS Code**: Mermaid Previewæ‹¡å¼µæ©Ÿèƒ½
3. **Mermaid Live Editor**: https://mermaid.live
4. **Confluence/Notion**: Mermaidãƒ—ãƒ©ã‚°ã‚¤ãƒ³

### ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆç”Ÿæˆ

```bash
# Mermaid CLIã‚’ä½¿ã£ã¦PNG/SVGç”Ÿæˆ
mmdc -i SEQUENCE_DIAGRAMS_DETAILED.md -o output/
```

---

## ğŸ“š é–¢é€£ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆ

- **00_INTEGRATED_DESIGN_OVERVIEW.md**: ã‚·ã‚¹ãƒ†ãƒ å…¨ä½“è¨­è¨ˆ
- **03_ARCHITECTURE_DESIGN_DETAILED.md**: ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£è©³ç´°
- **04_CLASS_DESIGN_DETAILED.md**: ã‚¯ãƒ©ã‚¹è¨­è¨ˆè©³ç´°
- **07_IMPLEMENTATION_GUIDE.md**: å®Ÿè£…ã‚¬ã‚¤ãƒ‰

---

**ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆãƒãƒ¼ã‚¸ãƒ§ãƒ³**: 1.0  
**æœ€çµ‚æ›´æ–°æ—¥**: 2025-11-04  
**ä½œæˆè€…**: System Architect  
**ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹**: Complete
