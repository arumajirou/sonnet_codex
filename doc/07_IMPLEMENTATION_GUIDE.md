# è©³ç´°å®Ÿè£…ã‚¬ã‚¤ãƒ‰
**Detailed Implementation Guide for Time Series Forecasting System**

---

## ğŸ“‹ ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆæƒ…å ±

| é …ç›® | å†…å®¹ |
|-----|------|
| **ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã‚¿ã‚¤ãƒˆãƒ«** | æ™‚ç³»åˆ—äºˆæ¸¬ã‚·ã‚¹ãƒ†ãƒ  è©³ç´°å®Ÿè£…ã‚¬ã‚¤ãƒ‰ |
| **ãƒãƒ¼ã‚¸ãƒ§ãƒ³** | v1.0.0 |
| **ä½œæˆæ—¥** | 2025-11-03 |
| **æœ€çµ‚æ›´æ–°æ—¥** | 2025-11-03 |
| **å¯¾è±¡ã‚·ã‚¹ãƒ†ãƒ ** | NeuralForecast Auto Runner + Time Series Forecasting System |
| **å¯¾è±¡èª­è€…** | é–‹ç™ºè€…ã€MLã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ |

---

## ç›®æ¬¡

1. [é–‹ç™ºç’°å¢ƒã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—](#1-é–‹ç™ºç’°å¢ƒã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—)
2. [ãƒ•ã‚§ãƒ¼ã‚ºåˆ¥å®Ÿè£…æ‰‹é †](#2-ãƒ•ã‚§ãƒ¼ã‚ºåˆ¥å®Ÿè£…æ‰‹é †)
3. [ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°è¦ç´„](#3-ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°è¦ç´„)
4. [ãƒ™ã‚¹ãƒˆãƒ—ãƒ©ã‚¯ãƒ†ã‚£ã‚¹](#4-ãƒ™ã‚¹ãƒˆãƒ—ãƒ©ã‚¯ãƒ†ã‚£ã‚¹)
5. [TDDå®Ÿè·µã‚¬ã‚¤ãƒ‰](#5-tddå®Ÿè·µã‚¬ã‚¤ãƒ‰)
6. [CI/CDè¨­å®š](#6-cicdè¨­å®š)
7. [ã‚³ãƒ¼ãƒ‰ãƒ¬ãƒ“ãƒ¥ãƒ¼ã‚¬ã‚¤ãƒ‰ãƒ©ã‚¤ãƒ³](#7-ã‚³ãƒ¼ãƒ‰ãƒ¬ãƒ“ãƒ¥ãƒ¼ã‚¬ã‚¤ãƒ‰ãƒ©ã‚¤ãƒ³)
8. [ãƒˆãƒ©ãƒ–ãƒ«ã‚·ãƒ¥ãƒ¼ãƒ†ã‚£ãƒ³ã‚°](#8-ãƒˆãƒ©ãƒ–ãƒ«ã‚·ãƒ¥ãƒ¼ãƒ†ã‚£ãƒ³ã‚°)
9. [ä»˜éŒ²](#9-ä»˜éŒ²)

---

## 1. é–‹ç™ºç’°å¢ƒã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—

### 1.1 å¿…è¦ãªã‚½ãƒ•ãƒˆã‚¦ã‚§ã‚¢

#### 1.1.1 åŸºæœ¬ãƒ„ãƒ¼ãƒ«

```bash
# Python 3.11ã®ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ï¼ˆpyenvæ¨å¥¨ï¼‰
pyenv install 3.11.6
pyenv local 3.11.6

# ãƒ‘ãƒƒã‚±ãƒ¼ã‚¸ãƒãƒãƒ¼ã‚¸ãƒ£ãƒ¼
pip install --upgrade pip setuptools wheel

# é–‹ç™ºãƒ„ãƒ¼ãƒ«
pip install poetry  # ã¾ãŸã¯ pipenv
pip install pre-commit
pip install black isort flake8 mypy pylint
```

**ãƒãƒ¼ã‚¸ãƒ§ãƒ³è¦ä»¶**:

| ãƒ„ãƒ¼ãƒ« | ãƒãƒ¼ã‚¸ãƒ§ãƒ³ | å¿…é ˆ |
|-------|-----------|------|
| Python | 3.11+ | âœ… |
| PostgreSQL | 14+ | âœ… |
| Git | 2.30+ | âœ… |
| Docker | 20.10+ | æ¨å¥¨ |
| Make | 4.0+ | æ¨å¥¨ |
| CUDA | 11.0+ | GPUä½¿ç”¨æ™‚ |

---

#### 1.1.2 IDE/ã‚¨ãƒ‡ã‚£ã‚¿è¨­å®š

**VS Codeæ¨å¥¨è¨­å®š** (`.vscode/settings.json`):

```json
{
  "python.defaultInterpreterPath": "${workspaceFolder}/.venv/bin/python",
  "python.linting.enabled": true,
  "python.linting.pylintEnabled": true,
  "python.linting.flake8Enabled": true,
  "python.linting.mypyEnabled": true,
  "python.formatting.provider": "black",
  "python.formatting.blackArgs": ["--line-length", "100"],
  "editor.formatOnSave": true,
  "editor.codeActionsOnSave": {
    "source.organizeImports": true
  },
  "python.testing.pytestEnabled": true,
  "python.testing.pytestArgs": [
    "tests",
    "-v",
    "--cov=src",
    "--cov-report=html"
  ],
  "[python]": {
    "editor.rulers": [100],
    "editor.tabSize": 4
  }
}
```

**PyCharmæ¨å¥¨è¨­å®š**:

- ã‚¤ãƒ³ã‚¿ãƒ¼ãƒ—ãƒªã‚¿: ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆä»®æƒ³ç’°å¢ƒ
- ã‚³ãƒ¼ãƒ‰ã‚¹ã‚¿ã‚¤ãƒ«: Black
- ã‚¤ãƒ³ã‚¹ãƒšã‚¯ã‚·ãƒ§ãƒ³: ã™ã¹ã¦æœ‰åŠ¹åŒ–
- Type checking: Strict mode

---

### 1.2 ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—

#### 1.2.1 ãƒªãƒã‚¸ãƒˆãƒªã‚¯ãƒ­ãƒ¼ãƒ³

```bash
# ãƒªãƒã‚¸ãƒˆãƒªã‚¯ãƒ­ãƒ¼ãƒ³
git clone https://github.com/your-org/time-series-forecasting-system.git
cd time-series-forecasting-system

# ãƒ–ãƒ©ãƒ³ãƒæˆ¦ç•¥ç¢ºèª
git checkout develop
```

---

#### 1.2.2 ä»®æƒ³ç’°å¢ƒä½œæˆ

**æ–¹æ³•1: venvï¼ˆæ¨™æº–ï¼‰**:

```bash
python3.11 -m venv .venv
source .venv/bin/activate  # Linux/Mac
# ã¾ãŸã¯
.venv\Scripts\activate  # Windows

# ä¾å­˜é–¢ä¿‚ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«
pip install -r requirements-dev.txt
pip install -e .  # é–‹ç™ºãƒ¢ãƒ¼ãƒ‰ã§ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«
```

**æ–¹æ³•2: Poetryï¼ˆæ¨å¥¨ï¼‰**:

```bash
# Poetryã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«
curl -sSL https://install.python-poetry.org | python3 -

# ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—
poetry install
poetry shell  # ä»®æƒ³ç’°å¢ƒæœ‰åŠ¹åŒ–
```

---

#### 1.2.3 ç’°å¢ƒå¤‰æ•°è¨­å®š

```bash
# .envãƒ•ã‚¡ã‚¤ãƒ«ä½œæˆ
cp .env.example .env

# å¿…è¦ãªç’°å¢ƒå¤‰æ•°ã‚’è¨­å®š
cat > .env << 'EOF'
# Database
DATABASE_URL=postgresql://postgres:password@localhost:5432/ts_forecast_system
DATABASE_POOL_SIZE=10
DATABASE_MAX_OVERFLOW=20

# Paths
DATA_DIR=/path/to/data
MODEL_DIR=/path/to/models
OUTPUT_DIR=/path/to/outputs
LOG_DIR=/path/to/logs

# Execution
MAX_PARALLEL_RUNS=10
DEFAULT_BACKEND=cuda  # ã¾ãŸã¯ cpu, mps

# Tracking
MLFLOW_TRACKING_URI=http://localhost:5000
ENABLE_WANDB=false
WANDB_API_KEY=your_wandb_key

# Logging
LOG_LEVEL=INFO
LOG_FORMAT=json

# Security
SECRET_KEY=your-secret-key-here
JWT_ALGORITHM=HS256
ACCESS_TOKEN_EXPIRE_MINUTES=60
EOF

# ç’°å¢ƒå¤‰æ•°èª­ã¿è¾¼ã¿
source .env  # ã¾ãŸã¯ export $(cat .env | xargs)
```

---

#### 1.2.4 ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹åˆæœŸåŒ–

```bash
# PostgreSQLèµ·å‹•ï¼ˆDockerä½¿ç”¨ã®å ´åˆï¼‰
docker-compose up -d postgres

# ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ä½œæˆ
psql -U postgres -c "CREATE DATABASE ts_forecast_system;"

# ãƒã‚¤ã‚°ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³å®Ÿè¡Œ
alembic upgrade head

# åˆæœŸãƒ‡ãƒ¼ã‚¿æŠ•å…¥
python scripts/setup/seed_data.py
```

---

#### 1.2.5 pre-commitãƒ•ãƒƒã‚¯ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—

```bash
# pre-commitã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«
pip install pre-commit

# ãƒ•ãƒƒã‚¯è¨­å®š
pre-commit install

# å…¨ãƒ•ã‚¡ã‚¤ãƒ«ã§å®Ÿè¡Œï¼ˆåˆå›ï¼‰
pre-commit run --all-files
```

**`.pre-commit-config.yaml`**:

```yaml
repos:
  - repo: https://github.com/pre-commit/pre-commit-hooks
    rev: v4.5.0
    hooks:
      - id: trailing-whitespace
      - id: end-of-file-fixer
      - id: check-yaml
      - id: check-json
      - id: check-added-large-files
        args: ['--maxkb=1000']
      - id: check-merge-conflict
      - id: debug-statements

  - repo: https://github.com/psf/black
    rev: 23.11.0
    hooks:
      - id: black
        language_version: python3.11
        args: ['--line-length=100']

  - repo: https://github.com/pycqa/isort
    rev: 5.12.0
    hooks:
      - id: isort
        args: ['--profile=black', '--line-length=100']

  - repo: https://github.com/pycqa/flake8
    rev: 6.1.0
    hooks:
      - id: flake8
        args: ['--max-line-length=100', '--extend-ignore=E203,W503']

  - repo: https://github.com/pre-commit/mirrors-mypy
    rev: v1.7.0
    hooks:
      - id: mypy
        additional_dependencies: [types-all]
        args: ['--strict', '--ignore-missing-imports']

  - repo: https://github.com/pycqa/pylint
    rev: v3.0.2
    hooks:
      - id: pylint
        args: ['--rcfile=.pylintrc']
```

---

### 1.3 å‹•ä½œç¢ºèª

```bash
# 1. Pythonãƒãƒ¼ã‚¸ãƒ§ãƒ³ç¢ºèª
python --version  # 3.11.x

# 2. ãƒ‘ãƒƒã‚±ãƒ¼ã‚¸ç¢ºèª
pip list

# 3. ãƒ†ã‚¹ãƒˆå®Ÿè¡Œ
pytest tests/ -v

# 4. é™çš„è§£æ
make lint

# 5. ã‚«ãƒãƒ¬ãƒƒã‚¸ç¢ºèª
make coverage

# 6. å‹ãƒã‚§ãƒƒã‚¯
make typecheck

# 7. ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆç”Ÿæˆ
make docs
```

---

## 2. ãƒ•ã‚§ãƒ¼ã‚ºåˆ¥å®Ÿè£…æ‰‹é †

### 2.1 é–‹ç™ºãƒ—ãƒ­ã‚»ã‚¹å…¨ä½“åƒ

```mermaid
graph LR
    A[Phase 1: Config] --> B[Phase 2: Data]
    B --> C[Phase 3: Model Discovery]
    C --> D[Phase 4: Hyperparameter]
    D --> E[Phase 5: Execution Plan]
    E --> F[Phase 6: Execution]
    F --> G[Phase 7: Artifact]
    G --> H[Phase 8: Logging]
    H --> I[Phase 9: Application]
    
    style A fill:#e1f5e1
    style B fill:#e1f5e1
    style C fill:#ffe1e1
    style D fill:#ffe1e1
    style E fill:#ffe1e1
    style F fill:#ffe1e1
    style G fill:#fff4e1
    style H fill:#fff4e1
    style I fill:#e1f0ff
```

---

### 2.2 Phase 1: Configurationå±¤ï¼ˆ1é€±é–“ï¼‰

#### 2.2.1 ç›®æ¨™

- ã‚·ã‚¹ãƒ†ãƒ å…¨ä½“ã®è¨­å®šç®¡ç†æ©Ÿèƒ½ã‚’å®Ÿè£…
- ç’°å¢ƒå¤‰æ•°ã€YAMLã€JSONã‹ã‚‰ã®è¨­å®šèª­ã¿è¾¼ã¿
- è¨­å®šã®æ¤œè¨¼ã¨ä¸å¤‰æ€§ä¿è¨¼

---

#### 2.2.2 å®Ÿè£…ã‚¿ã‚¹ã‚¯

**Task 1.1: ConfigåŸºåº•ã‚¯ãƒ©ã‚¹å®Ÿè£…**

```python
"""
src/nf_auto_runner/config/base.py

Configurationå±¤ã®åŸºåº•ã‚¯ãƒ©ã‚¹
"""
from dataclasses import dataclass, field, asdict
from abc import ABC, abstractmethod
from typing import Dict, Any, Optional, TypeVar, Type
from pathlib import Path
import json
import os

T = TypeVar('T', bound='Config')


@dataclass(frozen=True)
class Config(ABC):
    """
    è¨­å®šåŸºåº•ã‚¯ãƒ©ã‚¹
    
    ã™ã¹ã¦ã®è¨­å®šã‚¯ãƒ©ã‚¹ã¯ã“ã®ã‚¯ãƒ©ã‚¹ã‚’ç¶™æ‰¿ã™ã‚‹ã€‚
    frozen=Trueã§ä¸å¤‰æ€§ã‚’ä¿è¨¼ã€‚
    
    Attributes:
        æ´¾ç”Ÿã‚¯ãƒ©ã‚¹ã§å®šç¾©
    
    Example:
        >>> @dataclass(frozen=True)
        ... class MyConfig(Config):
        ...     value: int
        ...     
        ...     @classmethod
        ...     def from_env(cls) -> 'MyConfig':
        ...         return cls(value=int(os.getenv('VALUE', '42')))
        >>> 
        >>> config = MyConfig.from_env()
        >>> config.value
        42
    """
    
    @classmethod
    @abstractmethod
    def from_env(cls: Type[T]) -> T:
        """
        ç’°å¢ƒå¤‰æ•°ã‹ã‚‰è¨­å®šã‚’æ§‹ç¯‰
        
        Returns:
            è¨­å®šã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹
            
        Raises:
            EnvironmentError: å¿…é ˆç’°å¢ƒå¤‰æ•°ãŒå­˜åœ¨ã—ãªã„
            ValueError: ç’°å¢ƒå¤‰æ•°ã®å€¤ãŒä¸æ­£
        """
        pass
    
    @classmethod
    def from_dict(cls: Type[T], data: Dict[str, Any]) -> T:
        """
        è¾æ›¸ã‹ã‚‰è¨­å®šã‚’æ§‹ç¯‰
        
        Args:
            data: è¨­å®šãƒ‡ãƒ¼ã‚¿ã®è¾æ›¸
            
        Returns:
            è¨­å®šã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹
        """
        # Pathã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã®å¤‰æ›
        converted_data = {}
        for key, value in data.items():
            if isinstance(value, str) and key.endswith(('_path', '_dir')):
                converted_data[key] = Path(value)
            else:
                converted_data[key] = value
        
        return cls(**converted_data)
    
    def validate(self) -> None:
        """
        è¨­å®šã®å¦¥å½“æ€§æ¤œè¨¼
        
        Raises:
            ValueError: è¨­å®šå€¤ãŒä¸æ­£
        """
        pass
    
    def to_dict(self) -> Dict[str, Any]:
        """
        è¾æ›¸ã«å¤‰æ›
        
        Returns:
            è¨­å®šã®è¾æ›¸è¡¨ç¾
        """
        result = {}
        for key, value in asdict(self).items():
            if isinstance(value, Path):
                result[key] = str(value)
            else:
                result[key] = value
        return result


# ãƒ†ã‚¹ãƒˆä½œæˆ
"""
tests/unit/config/test_base.py
"""
import pytest
from pathlib import Path
from dataclasses import dataclass

from nf_auto_runner.config.base import Config


@dataclass(frozen=True)
class TestConfig(Config):
    """ãƒ†ã‚¹ãƒˆç”¨è¨­å®šã‚¯ãƒ©ã‚¹"""
    value: int
    name: str = "test"
    
    @classmethod
    def from_env(cls) -> 'TestConfig':
        return cls(
            value=int(os.getenv('TEST_VALUE', '0')),
            name=os.getenv('TEST_NAME', 'test')
        )


class TestConfigBase:
    """ConfigåŸºåº•ã‚¯ãƒ©ã‚¹ã®ãƒ†ã‚¹ãƒˆã‚¹ã‚¤ãƒ¼ãƒˆ"""
    
    def test_from_dict(self):
        """è¾æ›¸ã‹ã‚‰ã®ä½œæˆ"""
        data = {"value": 100, "name": "test"}
        config = TestConfig.from_dict(data)
        assert config.value == 100
        assert config.name == "test"
    
    def test_to_dict(self):
        """è¾æ›¸ã¸ã®å¤‰æ›"""
        config = TestConfig(value=100, name="test")
        data = config.to_dict()
        assert data == {"value": 100, "name": "test"}
    
    def test_immutability(self):
        """ä¸å¤‰æ€§ã®ç¢ºèª"""
        config = TestConfig(value=100)
        with pytest.raises(Exception):  # FrozenInstanceError
            config.value = 200
    
    def test_from_env(self, monkeypatch):
        """ç’°å¢ƒå¤‰æ•°ã‹ã‚‰ã®ä½œæˆ"""
        monkeypatch.setenv('TEST_VALUE', '42')
        monkeypatch.setenv('TEST_NAME', 'production')
        config = TestConfig.from_env()
        assert config.value == 42
        assert config.name == 'production'
```

---

**Task 1.2: PathConfigå®Ÿè£…**

```python
"""
src/nf_auto_runner/config/path_config.py
"""
from dataclasses import dataclass
from pathlib import Path
import os

from .base import Config


@dataclass(frozen=True)
class PathConfig(Config):
    """
    ãƒ‘ã‚¹è¨­å®šã‚¯ãƒ©ã‚¹
    
    Attributes:
        project_root: ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒ«ãƒ¼ãƒˆ
        data_dir: ãƒ‡ãƒ¼ã‚¿ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª
        model_dir: ãƒ¢ãƒ‡ãƒ«ä¿å­˜ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª
        output_dir: å‡ºåŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª
        log_dir: ãƒ­ã‚°ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª
    """
    
    project_root: Path
    data_dir: Path
    model_dir: Path
    output_dir: Path
    log_dir: Path
    
    @classmethod
    def from_env(cls) -> 'PathConfig':
        """ç’°å¢ƒå¤‰æ•°ã‹ã‚‰è¨­å®šã‚’æ§‹ç¯‰"""
        project_root = Path(os.getenv('PROJECT_ROOT', Path.cwd()))
        
        return cls(
            project_root=project_root,
            data_dir=Path(os.getenv('DATA_DIR', project_root / 'data')),
            model_dir=Path(os.getenv('MODEL_DIR', project_root / 'models')),
            output_dir=Path(os.getenv('OUTPUT_DIR', project_root / 'outputs')),
            log_dir=Path(os.getenv('LOG_DIR', project_root / 'logs'))
        )
    
    def validate(self) -> None:
        """ãƒ‘ã‚¹ã®å¦¥å½“æ€§æ¤œè¨¼"""
        # ãƒ«ãƒ¼ãƒˆãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã®å­˜åœ¨ç¢ºèª
        if not self.project_root.exists():
            raise ValueError(f"Project root does not exist: {self.project_root}")
        
        # å¿…è¦ãªãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’ä½œæˆ
        for path_name in ['data_dir', 'model_dir', 'output_dir', 'log_dir']:
            path = getattr(self, path_name)
            path.mkdir(parents=True, exist_ok=True)
    
    def get_data_path(self, filename: str) -> Path:
        """ãƒ‡ãƒ¼ã‚¿ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹ã‚’å–å¾—"""
        return self.data_dir / filename
    
    def get_model_path(self, filename: str) -> Path:
        """ãƒ¢ãƒ‡ãƒ«ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹ã‚’å–å¾—"""
        return self.model_dir / filename


# ãƒ†ã‚¹ãƒˆ
"""
tests/unit/config/test_path_config.py
"""
import pytest
from pathlib import Path
import tempfile

from nf_auto_runner.config.path_config import PathConfig


class TestPathConfig:
    """PathConfigã®ãƒ†ã‚¹ãƒˆã‚¹ã‚¤ãƒ¼ãƒˆ"""
    
    def test_from_env_default(self, monkeypatch, tmp_path):
        """ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå€¤ã§ã®ä½œæˆ"""
        monkeypatch.setenv('PROJECT_ROOT', str(tmp_path))
        config = PathConfig.from_env()
        
        assert config.project_root == tmp_path
        assert config.data_dir == tmp_path / 'data'
        assert config.model_dir == tmp_path / 'models'
    
    def test_validate_creates_directories(self, tmp_path):
        """validateã§ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªãŒä½œæˆã•ã‚Œã‚‹"""
        config = PathConfig(
            project_root=tmp_path,
            data_dir=tmp_path / 'data',
            model_dir=tmp_path / 'models',
            output_dir=tmp_path / 'outputs',
            log_dir=tmp_path / 'logs'
        )
        config.validate()
        
        assert (tmp_path / 'data').exists()
        assert (tmp_path / 'models').exists()
        assert (tmp_path / 'outputs').exists()
        assert (tmp_path / 'logs').exists()
    
    def test_get_data_path(self, tmp_path):
        """ãƒ‡ãƒ¼ã‚¿ãƒ‘ã‚¹å–å¾—"""
        config = PathConfig(
            project_root=tmp_path,
            data_dir=tmp_path / 'data',
            model_dir=tmp_path / 'models',
            output_dir=tmp_path / 'outputs',
            log_dir=tmp_path / 'logs'
        )
        path = config.get_data_path('test.csv')
        assert path == tmp_path / 'data' / 'test.csv'
```

---

**Task 1.3: ãã®ä»–ã®Configå®Ÿè£…**

åŒæ§˜ã«ä»¥ä¸‹ã‚’å®Ÿè£…ï¼š
- `ExecutionConfig`: å®Ÿè¡Œè¨­å®š
- `ModelSelectionConfig`: ãƒ¢ãƒ‡ãƒ«é¸æŠè¨­å®š
- `TrackingConfig`: ãƒˆãƒ©ãƒƒã‚­ãƒ³ã‚°è¨­å®š

---

#### 2.2.3 å“è³ªã‚²ãƒ¼ãƒˆ

```bash
# ãƒ†ã‚¹ãƒˆå®Ÿè¡Œ
pytest tests/unit/config/ -v --cov=src/nf_auto_runner/config --cov-report=term-missing

# ã‚«ãƒãƒ¬ãƒƒã‚¸ç¢ºèªï¼ˆ>95%å¿…é ˆï¼‰
coverage report

# é™çš„è§£æ
pylint src/nf_auto_runner/config/ --rcfile=.pylintrc
mypy src/nf_auto_runner/config/ --strict

# ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆç”Ÿæˆ
interrogate src/nf_auto_runner/config/ --verbose
```

**åˆæ ¼åŸºæº–**:
- âœ… ãƒ†ã‚¹ãƒˆã‚«ãƒãƒ¬ãƒƒã‚¸ > 95%
- âœ… Pylintã‚¹ã‚³ã‚¢ â‰¥ 8.5/10
- âœ… MyPy strict mode ã§ã‚¨ãƒ©ãƒ¼ãªã—
- âœ… ã™ã¹ã¦ã®ã‚¯ãƒ©ã‚¹ãƒ»ãƒ¡ã‚½ãƒƒãƒ‰ã«docstring

---

### 2.3 Phase 2: Dataå±¤ï¼ˆ1é€±é–“ï¼‰

#### 2.3.1 ç›®æ¨™

- ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿ã€å‰å‡¦ç†ã€æ¤œè¨¼æ©Ÿèƒ½ã‚’å®Ÿè£…
- CSVãƒ•ã‚¡ã‚¤ãƒ«ã®èª­ã¿è¾¼ã¿ã¨æ­£è¦åŒ–
- æ™‚ç³»åˆ—ãƒ‡ãƒ¼ã‚¿ã®æ¤œè¨¼ã¨ã‚¯ãƒªãƒ¼ãƒ‹ãƒ³ã‚°

---

#### 2.3.2 å®Ÿè£…ã‚¿ã‚¹ã‚¯

**Task 2.1: DataLoaderå®Ÿè£…**

```python
"""
src/nf_auto_runner/data/data_loader.py
"""
from pathlib import Path
from typing import Optional, List
import pandas as pd
from dataclasses import dataclass

from ..config.path_config import PathConfig


@dataclass
class DataLoadResult:
    """ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿çµæœ"""
    data: pd.DataFrame
    file_path: Path
    num_rows: int
    num_columns: int
    unique_ids: List[str]
    date_range: tuple[pd.Timestamp, pd.Timestamp]


class DataLoader:
    """
    ãƒ‡ãƒ¼ã‚¿ãƒ­ãƒ¼ãƒ€ãƒ¼ã‚¯ãƒ©ã‚¹
    
    CSVãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã¿ã€æ¨™æº–ã‚¹ã‚­ãƒ¼ãƒã«å¤‰æ›ã™ã‚‹ã€‚
    
    Attributes:
        path_config: ãƒ‘ã‚¹è¨­å®š
        
    Example:
        >>> loader = DataLoader(path_config)
        >>> result = loader.load_csv('sales_data.csv')
        >>> print(f"Loaded {result.num_rows} rows")
    """
    
    def __init__(self, path_config: PathConfig):
        """
        åˆæœŸåŒ–
        
        Args:
            path_config: ãƒ‘ã‚¹è¨­å®š
        """
        self.path_config = path_config
    
    def load_csv(
        self,
        file_path: str | Path,
        encoding: str = 'utf-8',
        date_column: str = 'ds',
        target_column: str = 'y',
        id_column: str = 'unique_id'
    ) -> DataLoadResult:
        """
        CSVãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã‚€
        
        Args:
            file_path: ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹
            encoding: æ–‡å­—ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°
            date_column: æ—¥ä»˜ã‚«ãƒ©ãƒ å
            target_column: ç›®çš„å¤‰æ•°ã‚«ãƒ©ãƒ å
            id_column: ID ã‚«ãƒ©ãƒ å
            
        Returns:
            èª­ã¿è¾¼ã¿çµæœ
            
        Raises:
            FileNotFoundError: ãƒ•ã‚¡ã‚¤ãƒ«ãŒå­˜åœ¨ã—ãªã„
            ValueError: å¿…é ˆã‚«ãƒ©ãƒ ãŒå­˜åœ¨ã—ãªã„
        """
        # ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹è§£æ±º
        if isinstance(file_path, str):
            file_path = Path(file_path)
        
        if not file_path.is_absolute():
            file_path = self.path_config.get_data_path(str(file_path))
        
        # ãƒ•ã‚¡ã‚¤ãƒ«å­˜åœ¨ç¢ºèª
        if not file_path.exists():
            raise FileNotFoundError(f"File not found: {file_path}")
        
        # CSVèª­ã¿è¾¼ã¿
        df = pd.read_csv(file_path, encoding=encoding)
        
        # å¿…é ˆã‚«ãƒ©ãƒ ç¢ºèª
        required_columns = {id_column, date_column, target_column}
        missing_columns = required_columns - set(df.columns)
        if missing_columns:
            raise ValueError(f"Missing required columns: {missing_columns}")
        
        # æ—¥ä»˜ã‚«ãƒ©ãƒ ã‚’datetimeå‹ã«å¤‰æ›
        df[date_column] = pd.to_datetime(df[date_column])
        
        # ã‚½ãƒ¼ãƒˆ
        df = df.sort_values([id_column, date_column]).reset_index(drop=True)
        
        # çµ±è¨ˆæƒ…å ±è¨ˆç®—
        unique_ids = df[id_column].unique().tolist()
        date_range = (df[date_column].min(), df[date_column].max())
        
        return DataLoadResult(
            data=df,
            file_path=file_path,
            num_rows=len(df),
            num_columns=len(df.columns),
            unique_ids=unique_ids,
            date_range=date_range
        )
    
    def validate_schema(self, df: pd.DataFrame) -> bool:
        """
        ã‚¹ã‚­ãƒ¼ãƒæ¤œè¨¼
        
        Args:
            df: ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ 
            
        Returns:
            æ¤œè¨¼çµæœ
        """
        # å¿…é ˆã‚«ãƒ©ãƒ ã®å­˜åœ¨ç¢ºèª
        required_columns = {'unique_id', 'ds', 'y'}
        if not required_columns.issubset(df.columns):
            return False
        
        # ãƒ‡ãƒ¼ã‚¿å‹ã®ç¢ºèª
        if df['ds'].dtype not in ['datetime64[ns]']:
            return False
        
        if not pd.api.types.is_numeric_dtype(df['y']):
            return False
        
        return True


# ãƒ†ã‚¹ãƒˆ
"""
tests/unit/data/test_data_loader.py
"""
import pytest
import pandas as pd
from pathlib import Path

from nf_auto_runner.data.data_loader import DataLoader
from nf_auto_runner.config.path_config import PathConfig


@pytest.fixture
def sample_csv(tmp_path):
    """ã‚µãƒ³ãƒ—ãƒ«CSVãƒ•ã‚¡ã‚¤ãƒ«ä½œæˆ"""
    csv_path = tmp_path / 'data' / 'sample.csv'
    csv_path.parent.mkdir(parents=True)
    
    df = pd.DataFrame({
        'unique_id': ['A', 'A', 'B', 'B'],
        'ds': ['2025-01-01', '2025-01-02', '2025-01-01', '2025-01-02'],
        'y': [100, 110, 200, 210]
    })
    df.to_csv(csv_path, index=False)
    
    return csv_path


class TestDataLoader:
    """DataLoaderã®ãƒ†ã‚¹ãƒˆã‚¹ã‚¤ãƒ¼ãƒˆ"""
    
    def test_load_csv_success(self, tmp_path, sample_csv):
        """æ­£å¸¸ãªCSVèª­ã¿è¾¼ã¿"""
        path_config = PathConfig(
            project_root=tmp_path,
            data_dir=tmp_path / 'data',
            model_dir=tmp_path / 'models',
            output_dir=tmp_path / 'outputs',
            log_dir=tmp_path / 'logs'
        )
        
        loader = DataLoader(path_config)
        result = loader.load_csv(sample_csv)
        
        assert result.num_rows == 4
        assert result.num_columns == 3
        assert len(result.unique_ids) == 2
        assert result.data['ds'].dtype == 'datetime64[ns]'
    
    def test_load_csv_file_not_found(self, tmp_path):
        """ãƒ•ã‚¡ã‚¤ãƒ«ãŒå­˜åœ¨ã—ãªã„å ´åˆ"""
        path_config = PathConfig(
            project_root=tmp_path,
            data_dir=tmp_path / 'data',
            model_dir=tmp_path / 'models',
            output_dir=tmp_path / 'outputs',
            log_dir=tmp_path / 'logs'
        )
        
        loader = DataLoader(path_config)
        with pytest.raises(FileNotFoundError):
            loader.load_csv('nonexistent.csv')
    
    def test_validate_schema(self, tmp_path):
        """ã‚¹ã‚­ãƒ¼ãƒæ¤œè¨¼"""
        path_config = PathConfig(
            project_root=tmp_path,
            data_dir=tmp_path / 'data',
            model_dir=tmp_path / 'models',
            output_dir=tmp_path / 'outputs',
            log_dir=tmp_path / 'logs'
        )
        
        loader = DataLoader(path_config)
        
        # æ­£å¸¸ãªãƒ‡ãƒ¼ã‚¿
        valid_df = pd.DataFrame({
            'unique_id': ['A'],
            'ds': pd.to_datetime(['2025-01-01']),
            'y': [100]
        })
        assert loader.validate_schema(valid_df)
        
        # ä¸æ­£ãªãƒ‡ãƒ¼ã‚¿ï¼ˆå¿…é ˆã‚«ãƒ©ãƒ ãªã—ï¼‰
        invalid_df = pd.DataFrame({
            'unique_id': ['A'],
            'ds': pd.to_datetime(['2025-01-01'])
        })
        assert not loader.validate_schema(invalid_df)
```

---

**Task 2.2: DataPreprocessorå®Ÿè£…**

åŒæ§˜ã®ãƒ‘ã‚¿ãƒ¼ãƒ³ã§å®Ÿè£…ï¼š
- ãƒ‡ãƒ¼ã‚¿ã®ã‚¯ãƒªãƒ¼ãƒ‹ãƒ³ã‚°
- æ¬ æå€¤å‡¦ç†
- å¤–ã‚Œå€¤æ¤œå‡º

---

#### 2.3.3 å“è³ªã‚²ãƒ¼ãƒˆ

```bash
pytest tests/unit/data/ -v --cov=src/nf_auto_runner/data --cov-report=html
pylint src/nf_auto_runner/data/ --rcfile=.pylintrc
mypy src/nf_auto_runner/data/ --strict
```

**åˆæ ¼åŸºæº–**: Phase 1ã¨åŒæ§˜

---

### 2.4 Phase 3-9: åŒæ§˜ã®ãƒ‘ã‚¿ãƒ¼ãƒ³

å„Phaseã§ä»¥ä¸‹ã‚’ç¹°ã‚Šè¿”ã™ï¼š

1. **è¨­è¨ˆç¢ºèª**: ã‚¯ãƒ©ã‚¹è¨­è¨ˆæ›¸ã‚’èª­ã‚€
2. **ãƒ†ã‚¹ãƒˆãƒ•ã‚¡ãƒ¼ã‚¹ãƒˆ**: ãƒ†ã‚¹ãƒˆã‚’å…ˆã«æ›¸ã
3. **å®Ÿè£…**: å®Ÿéš›ã®ã‚³ãƒ¼ãƒ‰ã‚’æ›¸ã
4. **å“è³ªã‚²ãƒ¼ãƒˆ**: ãƒ†ã‚¹ãƒˆãƒ»é™çš„è§£æã‚’å®Ÿè¡Œ
5. **ãƒ¬ãƒ“ãƒ¥ãƒ¼**: ãƒ—ãƒ«ãƒªã‚¯ã‚¨ã‚¹ãƒˆä½œæˆ
6. **çµ±åˆ**: developãƒ–ãƒ©ãƒ³ãƒã«ãƒãƒ¼ã‚¸

---

## 3. ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°è¦ç´„

### 3.1 Python ã‚¹ã‚¿ã‚¤ãƒ«ã‚¬ã‚¤ãƒ‰

#### 3.1.1 åŸºæœ¬ãƒ«ãƒ¼ãƒ«

- **PEP 8æº–æ‹ **: Pythonã®æ¨™æº–ã‚¹ã‚¿ã‚¤ãƒ«ã‚¬ã‚¤ãƒ‰
- **è¡Œã®é•·ã•**: 100æ–‡å­—ä»¥å†…
- **ã‚¤ãƒ³ãƒ‡ãƒ³ãƒˆ**: ã‚¹ãƒšãƒ¼ã‚¹4ã¤
- **å¼•ç”¨ç¬¦**: ã‚·ãƒ³ã‚°ãƒ«ã‚¯ã‚©ãƒ¼ãƒˆ`'`ã‚’ä½¿ç”¨ï¼ˆdocstringã¯`"""`ï¼‰
- **ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°**: UTF-8

---

#### 3.1.2 å‘½åè¦å‰‡

```python
# ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ãƒ»ãƒ‘ãƒƒã‚±ãƒ¼ã‚¸: lowercase_with_underscores
my_module.py
my_package/

# ã‚¯ãƒ©ã‚¹: PascalCase
class DataLoader:
    pass

# é–¢æ•°ãƒ»ãƒ¡ã‚½ãƒƒãƒ‰: lowercase_with_underscores
def load_data():
    pass

# å¤‰æ•°: lowercase_with_underscores
my_variable = 10

# å®šæ•°: UPPERCASE_WITH_UNDERSCORES
MAX_BATCH_SIZE = 128

# ãƒ—ãƒ©ã‚¤ãƒ™ãƒ¼ãƒˆ: å…ˆé ­ã«ã‚¢ãƒ³ãƒ€ãƒ¼ã‚¹ã‚³ã‚¢
_internal_function()
_private_variable = 10

# å‹å¤‰æ•°: PascalCase
T = TypeVar('T')
ModelType = TypeVar('ModelType', bound='BaseModel')
```

---

#### 3.1.3 ã‚¤ãƒ³ãƒãƒ¼ãƒˆé †åº

```python
"""
1. æ¨™æº–ãƒ©ã‚¤ãƒ–ãƒ©ãƒª
2. ã‚µãƒ¼ãƒ‰ãƒ‘ãƒ¼ãƒ†ã‚£ãƒ©ã‚¤ãƒ–ãƒ©ãƒª
3. ãƒ­ãƒ¼ã‚«ãƒ«ãƒ©ã‚¤ãƒ–ãƒ©ãƒª
"""

# æ¨™æº–ãƒ©ã‚¤ãƒ–ãƒ©ãƒª
import os
import sys
from pathlib import Path
from typing import Optional, List, Dict, Any

# ã‚µãƒ¼ãƒ‰ãƒ‘ãƒ¼ãƒ†ã‚£ãƒ©ã‚¤ãƒ–ãƒ©ãƒª
import pandas as pd
import numpy as np
from pydantic import BaseModel, Field

# ãƒ­ãƒ¼ã‚«ãƒ«ãƒ©ã‚¤ãƒ–ãƒ©ãƒª
from nf_auto_runner.config import PathConfig
from nf_auto_runner.data import DataLoader
```

---

### 3.2 å‹ãƒ’ãƒ³ãƒˆ

#### 3.2.1 åŸºæœ¬çš„ãªå‹ãƒ’ãƒ³ãƒˆ

```python
from typing import Optional, List, Dict, Any, Union, Tuple

def process_data(
    data: pd.DataFrame,
    column_name: str,
    threshold: float = 0.5,
    options: Optional[Dict[str, Any]] = None
) -> Tuple[pd.DataFrame, int]:
    """
    ãƒ‡ãƒ¼ã‚¿ã‚’å‡¦ç†ã™ã‚‹
    
    Args:
        data: å…¥åŠ›ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ 
        column_name: å‡¦ç†å¯¾è±¡ã‚«ãƒ©ãƒ å
        threshold: é–¾å€¤
        options: ã‚ªãƒ—ã‚·ãƒ§ãƒ³è¨­å®š
        
    Returns:
        å‡¦ç†å¾Œã®ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ ã¨å‡¦ç†ä»¶æ•°ã®ã‚¿ãƒ—ãƒ«
    """
    if options is None:
        options = {}
    
    # å‡¦ç†
    processed_data = data.copy()
    count = len(processed_data)
    
    return processed_data, count
```

---

#### 3.2.2 é«˜åº¦ãªå‹ãƒ’ãƒ³ãƒˆ

```python
from typing import TypeVar, Generic, Protocol, Literal

# TypeVar
T = TypeVar('T')

class Container(Generic[T]):
    """ã‚¸ã‚§ãƒãƒªãƒƒã‚¯ã‚³ãƒ³ãƒ†ãƒŠ"""
    def __init__(self, value: T):
        self.value = value
    
    def get(self) -> T:
        return self.value

# Protocol
class Saveable(Protocol):
    """ä¿å­˜å¯èƒ½ãªã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã®ãƒ—ãƒ­ãƒˆã‚³ãƒ«"""
    def save(self, path: Path) -> None:
        ...

# Literal
def set_mode(mode: Literal['train', 'test', 'predict']) -> None:
    """ãƒ¢ãƒ¼ãƒ‰è¨­å®š"""
    pass
```

---

### 3.3 Docstring

#### 3.3.1 Google Style

```python
def calculate_metrics(
    y_true: np.ndarray,
    y_pred: np.ndarray,
    metrics: List[str]
) -> Dict[str, float]:
    """
    è©•ä¾¡æŒ‡æ¨™ã‚’è¨ˆç®—ã™ã‚‹
    
    Args:
        y_true: çœŸå€¤ã®é…åˆ—
        y_pred: äºˆæ¸¬å€¤ã®é…åˆ—
        metrics: è¨ˆç®—ã™ã‚‹æŒ‡æ¨™ã®ãƒªã‚¹ãƒˆï¼ˆ'mae', 'rmse', 'smape'ï¼‰
        
    Returns:
        æŒ‡æ¨™åã¨å€¤ã®è¾æ›¸
        
    Raises:
        ValueError: é…åˆ—ã®å½¢çŠ¶ãŒä¸€è‡´ã—ãªã„å ´åˆ
        ValueError: ã‚µãƒãƒ¼ãƒˆã•ã‚Œã¦ã„ãªã„æŒ‡æ¨™ãŒå«ã¾ã‚Œã‚‹å ´åˆ
        
    Example:
        >>> y_true = np.array([1, 2, 3])
        >>> y_pred = np.array([1.1, 2.1, 2.9])
        >>> metrics = calculate_metrics(y_true, y_pred, ['mae', 'rmse'])
        >>> print(metrics)
        {'mae': 0.1, 'rmse': 0.1}
        
    Note:
        å¤§é‡ã®ãƒ‡ãƒ¼ã‚¿ã«å¯¾ã—ã¦ã¯ã€ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡ã«æ³¨æ„ã—ã¦ãã ã•ã„ã€‚
    """
    if y_true.shape != y_pred.shape:
        raise ValueError("Shape mismatch")
    
    results = {}
    for metric in metrics:
        if metric == 'mae':
            results['mae'] = np.mean(np.abs(y_true - y_pred))
        elif metric == 'rmse':
            results['rmse'] = np.sqrt(np.mean((y_true - y_pred) ** 2))
        else:
            raise ValueError(f"Unsupported metric: {metric}")
    
    return results
```

---

#### 3.3.2 ã‚¯ãƒ©ã‚¹ã®docstring

```python
class ModelRegistry:
    """
    ãƒ¢ãƒ‡ãƒ«ãƒ¬ã‚¸ã‚¹ãƒˆãƒªã‚¯ãƒ©ã‚¹
    
    å­¦ç¿’æ¸ˆã¿ãƒ¢ãƒ‡ãƒ«ã®ç™»éŒ²ã€æ¤œç´¢ã€ç®¡ç†ã‚’è¡Œã†ã€‚
    
    Attributes:
        models: ç™»éŒ²æ¸ˆã¿ãƒ¢ãƒ‡ãƒ«ã®è¾æ›¸
        storage_path: ãƒ¢ãƒ‡ãƒ«ä¿å­˜ãƒ‘ã‚¹
        
    Example:
        >>> registry = ModelRegistry(storage_path='/models')
        >>> registry.register('my_model', model)
        >>> loaded_model = registry.load('my_model')
        
    Note:
        ã“ã®ã‚¯ãƒ©ã‚¹ã¯ã‚¹ãƒ¬ãƒƒãƒ‰ã‚»ãƒ¼ãƒ•ã§ã¯ã‚ã‚Šã¾ã›ã‚“ã€‚
        ä¸¦è¡Œã‚¢ã‚¯ã‚»ã‚¹ãŒå¿…è¦ãªå ´åˆã¯ãƒ­ãƒƒã‚¯ã‚’ä½¿ç”¨ã—ã¦ãã ã•ã„ã€‚
    """
    
    def __init__(self, storage_path: Path):
        """
        åˆæœŸåŒ–
        
        Args:
            storage_path: ãƒ¢ãƒ‡ãƒ«ä¿å­˜ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª
        """
        self.storage_path = storage_path
        self.models: Dict[str, Any] = {}
```

---

### 3.4 ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°

#### 3.4.1 ä¾‹å¤–ã®ä½¿ç”¨

```python
# ã‚«ã‚¹ã‚¿ãƒ ä¾‹å¤–å®šç¾©
class DataValidationError(Exception):
    """ãƒ‡ãƒ¼ã‚¿æ¤œè¨¼ã‚¨ãƒ©ãƒ¼"""
    pass


class ModelNotFoundError(Exception):
    """ãƒ¢ãƒ‡ãƒ«æœªç™ºè¦‹ã‚¨ãƒ©ãƒ¼"""
    pass


# ä¾‹å¤–ã®ä½¿ç”¨
def validate_data(df: pd.DataFrame) -> None:
    """
    ãƒ‡ãƒ¼ã‚¿ã‚’æ¤œè¨¼ã™ã‚‹
    
    Raises:
        DataValidationError: ãƒ‡ãƒ¼ã‚¿ãŒä¸æ­£ãªå ´åˆ
    """
    if df.empty:
        raise DataValidationError("DataFrame is empty")
    
    if 'unique_id' not in df.columns:
        raise DataValidationError("Missing 'unique_id' column")


# ä¾‹å¤–ã®ã‚­ãƒ£ãƒƒãƒ
def safe_load_model(model_id: int) -> Optional[Model]:
    """
    ãƒ¢ãƒ‡ãƒ«ã‚’å®‰å…¨ã«èª­ã¿è¾¼ã‚€
    
    Args:
        model_id: ãƒ¢ãƒ‡ãƒ«ID
        
    Returns:
        ãƒ¢ãƒ‡ãƒ«ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã€èª­ã¿è¾¼ã‚ãªã„å ´åˆã¯None
    """
    try:
        model = load_model(model_id)
        return model
    except ModelNotFoundError as e:
        logger.warning(f"Model not found: {e}")
        return None
    except Exception as e:
        logger.error(f"Unexpected error: {e}")
        raise
```

---

### 3.5 ãƒ­ã‚®ãƒ³ã‚°

#### 3.5.1 structlogä½¿ç”¨

```python
import structlog

# ãƒ­ã‚¬ãƒ¼è¨­å®š
logger = structlog.get_logger()


class DataLoader:
    """ãƒ‡ãƒ¼ã‚¿ãƒ­ãƒ¼ãƒ€ãƒ¼"""
    
    def load_csv(self, file_path: Path) -> pd.DataFrame:
        """CSVãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã‚€"""
        logger.info(
            "loading_csv",
            file_path=str(file_path),
            operation="load"
        )
        
        try:
            df = pd.read_csv(file_path)
            logger.info(
                "csv_loaded",
                file_path=str(file_path),
                num_rows=len(df),
                num_columns=len(df.columns)
            )
            return df
        except Exception as e:
            logger.error(
                "csv_load_failed",
                file_path=str(file_path),
                error=str(e),
                exc_info=True
            )
            raise
```

---

## 4. ãƒ™ã‚¹ãƒˆãƒ—ãƒ©ã‚¯ãƒ†ã‚£ã‚¹

### 4.1 SOLIDåŸå‰‡

#### 4.1.1 Single Responsibility Principleï¼ˆå˜ä¸€è²¬ä»»ã®åŸå‰‡ï¼‰

**æ‚ªã„ä¾‹**:

```python
class DataProcessor:
    """ãƒ‡ãƒ¼ã‚¿å‡¦ç†ã‚¯ãƒ©ã‚¹ï¼ˆè²¬å‹™ãŒå¤šã™ãã‚‹ï¼‰"""
    
    def load_data(self, path: Path) -> pd.DataFrame:
        """ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿"""
        pass
    
    def clean_data(self, df: pd.DataFrame) -> pd.DataFrame:
        """ãƒ‡ãƒ¼ã‚¿ã‚¯ãƒªãƒ¼ãƒ‹ãƒ³ã‚°"""
        pass
    
    def save_data(self, df: pd.DataFrame, path: Path) -> None:
        """ãƒ‡ãƒ¼ã‚¿ä¿å­˜"""
        pass
    
    def train_model(self, df: pd.DataFrame) -> Model:
        """ãƒ¢ãƒ‡ãƒ«å­¦ç¿’"""
        pass
```

**è‰¯ã„ä¾‹**:

```python
class DataLoader:
    """ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿å°‚ç”¨ã‚¯ãƒ©ã‚¹"""
    def load(self, path: Path) -> pd.DataFrame:
        pass


class DataCleaner:
    """ãƒ‡ãƒ¼ã‚¿ã‚¯ãƒªãƒ¼ãƒ‹ãƒ³ã‚°å°‚ç”¨ã‚¯ãƒ©ã‚¹"""
    def clean(self, df: pd.DataFrame) -> pd.DataFrame:
        pass


class DataSaver:
    """ãƒ‡ãƒ¼ã‚¿ä¿å­˜å°‚ç”¨ã‚¯ãƒ©ã‚¹"""
    def save(self, df: pd.DataFrame, path: Path) -> None:
        pass


class ModelTrainer:
    """ãƒ¢ãƒ‡ãƒ«å­¦ç¿’å°‚ç”¨ã‚¯ãƒ©ã‚¹"""
    def train(self, df: pd.DataFrame) -> Model:
        pass
```

---

#### 4.1.2 Open/Closed Principleï¼ˆé–‹æ”¾/é–‰é–ã®åŸå‰‡ï¼‰

```python
from abc import ABC, abstractmethod

# æ‹¡å¼µã«é–‹ã„ã¦ã„ã‚‹
class Metric(ABC):
    """è©•ä¾¡æŒ‡æ¨™ã®åŸºåº•ã‚¯ãƒ©ã‚¹"""
    
    @abstractmethod
    def calculate(self, y_true: np.ndarray, y_pred: np.ndarray) -> float:
        """æŒ‡æ¨™ã‚’è¨ˆç®—"""
        pass


class MAE(Metric):
    """Mean Absolute Error"""
    def calculate(self, y_true: np.ndarray, y_pred: np.ndarray) -> float:
        return np.mean(np.abs(y_true - y_pred))


class RMSE(Metric):
    """Root Mean Squared Error"""
    def calculate(self, y_true: np.ndarray, y_pred: np.ndarray) -> float:
        return np.sqrt(np.mean((y_true - y_pred) ** 2))


# æ–°ã—ã„æŒ‡æ¨™ã‚’è¿½åŠ ï¼ˆæ—¢å­˜ã‚³ãƒ¼ãƒ‰ã‚’å¤‰æ›´ã›ãšã«ï¼‰
class SMAPE(Metric):
    """Symmetric Mean Absolute Percentage Error"""
    def calculate(self, y_true: np.ndarray, y_pred: np.ndarray) -> float:
        denominator = (np.abs(y_true) + np.abs(y_pred)) / 2
        return np.mean(np.abs(y_true - y_pred) / denominator) * 100
```

---

#### 4.1.3 Dependency Inversion Principleï¼ˆä¾å­˜æ€§é€†è»¢ã®åŸå‰‡ï¼‰

```python
from typing import Protocol

# æŠ½è±¡ã«ä¾å­˜
class DataSource(Protocol):
    """ãƒ‡ãƒ¼ã‚¿ã‚½ãƒ¼ã‚¹ã®ãƒ—ãƒ­ãƒˆã‚³ãƒ«"""
    def read(self) -> pd.DataFrame:
        ...


class CSVDataSource:
    """CSVå®Ÿè£…"""
    def __init__(self, path: Path):
        self.path = path
    
    def read(self) -> pd.DataFrame:
        return pd.read_csv(self.path)


class ParquetDataSource:
    """Parquetå®Ÿè£…"""
    def __init__(self, path: Path):
        self.path = path
    
    def read(self) -> pd.DataFrame:
        return pd.read_parquet(self.path)


class DataPipeline:
    """ãƒ‡ãƒ¼ã‚¿ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ï¼ˆæŠ½è±¡ã«ä¾å­˜ï¼‰"""
    
    def __init__(self, data_source: DataSource):
        self.data_source = data_source
    
    def process(self) -> pd.DataFrame:
        data = self.data_source.read()
        # å‡¦ç†
        return data


# ä½¿ç”¨ä¾‹ï¼ˆå®Ÿè£…ã‚’ç°¡å˜ã«åˆ‡ã‚Šæ›¿ãˆå¯èƒ½ï¼‰
csv_pipeline = DataPipeline(CSVDataSource(Path('data.csv')))
parquet_pipeline = DataPipeline(ParquetDataSource(Path('data.parquet')))
```

---

### 4.2 ãƒ‡ã‚¶ã‚¤ãƒ³ãƒ‘ã‚¿ãƒ¼ãƒ³

#### 4.2.1 Factory Pattern

```python
from enum import Enum
from typing import Dict, Type

class ModelType(Enum):
    """ãƒ¢ãƒ‡ãƒ«ã‚¿ã‚¤ãƒ—"""
    NHITS = "nhits"
    LSTM = "lstm"
    TFT = "tft"


class ModelFactory:
    """ãƒ¢ãƒ‡ãƒ«ãƒ•ã‚¡ã‚¯ãƒˆãƒªãƒ¼"""
    
    _registry: Dict[ModelType, Type[BaseModel]] = {}
    
    @classmethod
    def register(cls, model_type: ModelType, model_class: Type[BaseModel]) -> None:
        """ãƒ¢ãƒ‡ãƒ«ã‚¯ãƒ©ã‚¹ã‚’ç™»éŒ²"""
        cls._registry[model_type] = model_class
    
    @classmethod
    def create(cls, model_type: ModelType, **kwargs) -> BaseModel:
        """ãƒ¢ãƒ‡ãƒ«ã‚’ä½œæˆ"""
        if model_type not in cls._registry:
            raise ValueError(f"Unknown model type: {model_type}")
        
        model_class = cls._registry[model_type]
        return model_class(**kwargs)


# ä½¿ç”¨ä¾‹
ModelFactory.register(ModelType.NHITS, NHITSModel)
ModelFactory.register(ModelType.LSTM, LSTMModel)

model = ModelFactory.create(ModelType.NHITS, input_size=30, h=7)
```

---

#### 4.2.2 Strategy Pattern

```python
class OptimizationStrategy(ABC):
    """æœ€é©åŒ–æˆ¦ç•¥ã®åŸºåº•ã‚¯ãƒ©ã‚¹"""
    
    @abstractmethod
    def optimize(self, objective_func, search_space) -> Dict[str, Any]:
        """æœ€é©åŒ–ã‚’å®Ÿè¡Œ"""
        pass


class OptunaStrategy(OptimizationStrategy):
    """Optunaæˆ¦ç•¥"""
    def optimize(self, objective_func, search_space) -> Dict[str, Any]:
        import optuna
        study = optuna.create_study()
        study.optimize(objective_func, n_trials=100)
        return study.best_params


class GridSearchStrategy(OptimizationStrategy):
    """ã‚°ãƒªãƒƒãƒ‰ã‚µãƒ¼ãƒæˆ¦ç•¥"""
    def optimize(self, objective_func, search_space) -> Dict[str, Any]:
        from sklearn.model_selection import GridSearchCV
        # å®Ÿè£…
        pass


class HyperparameterOptimizer:
    """ãƒã‚¤ãƒ‘ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æœ€é©åŒ–"""
    
    def __init__(self, strategy: OptimizationStrategy):
        self.strategy = strategy
    
    def run(self, objective_func, search_space) -> Dict[str, Any]:
        return self.strategy.optimize(objective_func, search_space)


# ä½¿ç”¨ä¾‹ï¼ˆæˆ¦ç•¥ã‚’ç°¡å˜ã«åˆ‡ã‚Šæ›¿ãˆï¼‰
optimizer = HyperparameterOptimizer(OptunaStrategy())
best_params = optimizer.run(objective_func, search_space)
```

---

## 5. TDDå®Ÿè·µã‚¬ã‚¤ãƒ‰

### 5.1 TDDã‚µã‚¤ã‚¯ãƒ«

```
1. Red: ãƒ†ã‚¹ãƒˆã‚’æ›¸ãï¼ˆå¤±æ•—ã™ã‚‹ï¼‰
2. Green: æœ€å°é™ã®ã‚³ãƒ¼ãƒ‰ã‚’æ›¸ãï¼ˆãƒ†ã‚¹ãƒˆã‚’é€šã™ï¼‰
3. Refactor: ã‚³ãƒ¼ãƒ‰ã‚’ãƒªãƒ•ã‚¡ã‚¯ã‚¿ãƒªãƒ³ã‚°
```

---

### 5.2 pyteståŸºæœ¬

#### 5.2.1 åŸºæœ¬çš„ãªãƒ†ã‚¹ãƒˆ

```python
"""
tests/unit/data/test_data_loader.py
"""
import pytest
import pandas as pd
from pathlib import Path

from nf_auto_runner.data.data_loader import DataLoader


class TestDataLoader:
    """DataLoaderã®ãƒ†ã‚¹ãƒˆã‚¯ãƒ©ã‚¹"""
    
    def test_load_csv_success(self, sample_csv):
        """æ­£å¸¸ç³»: CSVèª­ã¿è¾¼ã¿æˆåŠŸ"""
        loader = DataLoader()
        result = loader.load_csv(sample_csv)
        
        assert result is not None
        assert isinstance(result.data, pd.DataFrame)
        assert result.num_rows > 0
    
    def test_load_csv_file_not_found(self):
        """ç•°å¸¸ç³»: ãƒ•ã‚¡ã‚¤ãƒ«ãŒå­˜åœ¨ã—ãªã„"""
        loader = DataLoader()
        
        with pytest.raises(FileNotFoundError):
            loader.load_csv('nonexistent.csv')
    
    def test_load_csv_invalid_schema(self, invalid_csv):
        """ç•°å¸¸ç³»: ã‚¹ã‚­ãƒ¼ãƒãŒä¸æ­£"""
        loader = DataLoader()
        
        with pytest.raises(ValueError, match="Missing required columns"):
            loader.load_csv(invalid_csv)
```

---

#### 5.2.2 Fixture

```python
import pytest
import pandas as pd
from pathlib import Path


@pytest.fixture
def tmp_data_dir(tmp_path):
    """ä¸€æ™‚ãƒ‡ãƒ¼ã‚¿ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª"""
    data_dir = tmp_path / 'data'
    data_dir.mkdir()
    return data_dir


@pytest.fixture
def sample_csv(tmp_data_dir):
    """ã‚µãƒ³ãƒ—ãƒ«CSVãƒ•ã‚¡ã‚¤ãƒ«"""
    csv_path = tmp_data_dir / 'sample.csv'
    
    df = pd.DataFrame({
        'unique_id': ['A', 'A', 'B', 'B'],
        'ds': ['2025-01-01', '2025-01-02', '2025-01-01', '2025-01-02'],
        'y': [100, 110, 200, 210]
    })
    df.to_csv(csv_path, index=False)
    
    return csv_path


@pytest.fixture
def sample_dataframe():
    """ã‚µãƒ³ãƒ—ãƒ«ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ """
    return pd.DataFrame({
        'unique_id': ['A'] * 10,
        'ds': pd.date_range('2025-01-01', periods=10),
        'y': range(100, 110)
    })


@pytest.fixture(scope='session')
def database_connection():
    """ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹æ¥ç¶šï¼ˆã‚»ãƒƒã‚·ãƒ§ãƒ³ã‚¹ã‚³ãƒ¼ãƒ—ï¼‰"""
    # ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—
    conn = create_connection()
    
    yield conn
    
    # ãƒ†ã‚£ã‚¢ãƒ€ã‚¦ãƒ³
    conn.close()
```

---

#### 5.2.3 ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿åŒ–ãƒ†ã‚¹ãƒˆ

```python
import pytest


@pytest.mark.parametrize(
    "input_value,expected",
    [
        (0, 0),
        (1, 1),
        (2, 4),
        (3, 9),
        (4, 16),
    ]
)
def test_square(input_value, expected):
    """äºŒä¹—è¨ˆç®—ã®ãƒ†ã‚¹ãƒˆ"""
    assert input_value ** 2 == expected


@pytest.mark.parametrize(
    "y_true,y_pred,expected_mae",
    [
        ([1, 2, 3], [1, 2, 3], 0.0),
        ([1, 2, 3], [2, 3, 4], 1.0),
        ([0, 0, 0], [1, 1, 1], 1.0),
    ]
)
def test_mae_calculation(y_true, y_pred, expected_mae):
    """MAEè¨ˆç®—ã®ãƒ†ã‚¹ãƒˆ"""
    result = calculate_mae(y_true, y_pred)
    assert result == pytest.approx(expected_mae)
```

---

#### 5.2.4 ãƒ¢ãƒƒã‚¯ã¨ã‚¹ãƒ‘ã‚¤

```python
from unittest.mock import Mock, patch, MagicMock
import pytest


class TestModelTrainer:
    """ModelTrainerã®ãƒ†ã‚¹ãƒˆ"""
    
    def test_train_with_mock(self):
        """ãƒ¢ãƒ‡ãƒ«å­¦ç¿’ã®ãƒ†ã‚¹ãƒˆï¼ˆãƒ¢ãƒƒã‚¯ä½¿ç”¨ï¼‰"""
        # ãƒ¢ãƒƒã‚¯ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆä½œæˆ
        mock_model = Mock()
        mock_model.fit.return_value = None
        mock_model.score.return_value = 0.95
        
        trainer = ModelTrainer(mock_model)
        trainer.train(X_train, y_train)
        
        # ãƒ¢ãƒƒã‚¯ãŒå‘¼ã°ã‚ŒãŸã“ã¨ã‚’ç¢ºèª
        mock_model.fit.assert_called_once_with(X_train, y_train)
    
    @patch('nf_auto_runner.data.data_loader.pd.read_csv')
    def test_load_with_patch(self, mock_read_csv):
        """ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿ã®ãƒ†ã‚¹ãƒˆï¼ˆãƒ‘ãƒƒãƒä½¿ç”¨ï¼‰"""
        # ãƒ¢ãƒƒã‚¯ã®æˆ»ã‚Šå€¤è¨­å®š
        mock_df = pd.DataFrame({'col1': [1, 2, 3]})
        mock_read_csv.return_value = mock_df
        
        loader = DataLoader()
        result = loader.load_csv('dummy.csv')
        
        # ãƒ‘ãƒƒãƒãŒå‘¼ã°ã‚ŒãŸã“ã¨ã‚’ç¢ºèª
        mock_read_csv.assert_called_once_with('dummy.csv', encoding='utf-8')
        assert result.num_rows == 3
```

---

### 5.3 ã‚«ãƒãƒ¬ãƒƒã‚¸

```bash
# ã‚«ãƒãƒ¬ãƒƒã‚¸æ¸¬å®š
pytest tests/ --cov=src/nf_auto_runner --cov-report=html --cov-report=term

# ã‚«ãƒãƒ¬ãƒƒã‚¸ãƒ¬ãƒãƒ¼ãƒˆç¢ºèª
open htmlcov/index.html

# ã‚«ãƒãƒ¬ãƒƒã‚¸ç›®æ¨™
# - å…¨ä½“: >90%
# - å„ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«: >85%
# - ã‚¯ãƒªãƒ†ã‚£ã‚«ãƒ«ãƒ‘ã‚¹: 100%
```

**`.coveragerc`**:

```ini
[run]
source = src/nf_auto_runner
omit =
    */tests/*
    */test_*.py
    */__pycache__/*
    */site-packages/*
    */venv/*

[report]
precision = 2
exclude_lines =
    pragma: no cover
    def __repr__
    raise AssertionError
    raise NotImplementedError
    if __name__ == .__main__.:
    if TYPE_CHECKING:
    @abstractmethod
```

---

### 5.4 ãƒ†ã‚¹ãƒˆã®æ§‹é€ åŒ–

```
tests/
â”œâ”€â”€ unit/                      # ãƒ¦ãƒ‹ãƒƒãƒˆãƒ†ã‚¹ãƒˆ
â”‚   â”œâ”€â”€ config/
â”‚   â”‚   â”œâ”€â”€ test_base.py
â”‚   â”‚   â””â”€â”€ test_path_config.py
â”‚   â”œâ”€â”€ data/
â”‚   â”‚   â”œâ”€â”€ test_data_loader.py
â”‚   â”‚   â””â”€â”€ test_preprocessor.py
â”‚   â””â”€â”€ model/
â”‚       â””â”€â”€ test_registry.py
â”œâ”€â”€ integration/               # çµ±åˆãƒ†ã‚¹ãƒˆ
â”‚   â”œâ”€â”€ test_data_pipeline.py
â”‚   â””â”€â”€ test_training_flow.py
â”œâ”€â”€ e2e/                       # E2Eãƒ†ã‚¹ãƒˆ
â”‚   â””â”€â”€ test_full_workflow.py
â”œâ”€â”€ fixtures/                  # å…±æœ‰ãƒ•ã‚£ã‚¯ã‚¹ãƒãƒ£
â”‚   â”œâ”€â”€ sample_data/
â”‚   â””â”€â”€ conftest.py
â””â”€â”€ conftest.py                # ã‚°ãƒ­ãƒ¼ãƒãƒ«è¨­å®š
```

---

## 6. CI/CDè¨­å®š

### 6.1 GitHub Actions

#### 6.1.1 åŸºæœ¬ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼

**`.github/workflows/ci.yml`**:

```yaml
name: CI

on:
  push:
    branches: [ main, develop ]
  pull_request:
    branches: [ main, develop ]

jobs:
  test:
    runs-on: ubuntu-latest
    strategy:
      matrix:
        python-version: ['3.11']
    
    services:
      postgres:
        image: postgres:14
        env:
          POSTGRES_PASSWORD: postgres
          POSTGRES_DB: ts_forecast_test
        options: >-
          --health-cmd pg_isready
          --health-interval 10s
          --health-timeout 5s
          --health-retries 5
        ports:
          - 5432:5432
    
    steps:
      - uses: actions/checkout@v3
      
      - name: Set up Python ${{ matrix.python-version }}
        uses: actions/setup-python@v4
        with:
          python-version: ${{ matrix.python-version }}
      
      - name: Cache dependencies
        uses: actions/cache@v3
        with:
          path: ~/.cache/pip
          key: ${{ runner.os }}-pip-${{ hashFiles('**/requirements.txt') }}
          restore-keys: |
            ${{ runner.os }}-pip-
      
      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements-dev.txt
          pip install -e .
      
      - name: Lint with flake8
        run: |
          flake8 src/ --count --select=E9,F63,F7,F82 --show-source --statistics
          flake8 src/ --count --max-line-length=100 --statistics
      
      - name: Type check with mypy
        run: |
          mypy src/ --strict --ignore-missing-imports
      
      - name: Test with pytest
        env:
          DATABASE_URL: postgresql://postgres:postgres@localhost:5432/ts_forecast_test
        run: |
          pytest tests/ -v --cov=src --cov-report=xml --cov-report=term
      
      - name: Upload coverage to Codecov
        uses: codecov/codecov-action@v3
        with:
          files: ./coverage.xml
          flags: unittests
          name: codecov-umbrella
      
      - name: Check coverage threshold
        run: |
          coverage report --fail-under=90

  quality:
    runs-on: ubuntu-latest
    
    steps:
      - uses: actions/checkout@v3
      
      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.11'
      
      - name: Install dependencies
        run: |
          pip install pylint black isort
      
      - name: Check code formatting with black
        run: |
          black --check src/ tests/
      
      - name: Check import sorting with isort
        run: |
          isort --check-only src/ tests/
      
      - name: Lint with pylint
        run: |
          pylint src/ --rcfile=.pylintrc --fail-under=8.5
```

---

#### 6.1.2 ãƒªãƒªãƒ¼ã‚¹ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼

**`.github/workflows/release.yml`**:

```yaml
name: Release

on:
  push:
    tags:
      - 'v*'

jobs:
  build:
    runs-on: ubuntu-latest
    
    steps:
      - uses: actions/checkout@v3
      
      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.11'
      
      - name: Install build dependencies
        run: |
          pip install build twine
      
      - name: Build package
        run: |
          python -m build
      
      - name: Publish to PyPI
        env:
          TWINE_USERNAME: __token__
          TWINE_PASSWORD: ${{ secrets.PYPI_TOKEN }}
        run: |
          twine upload dist/*
      
      - name: Create GitHub Release
        uses: actions/create-release@v1
        env:
          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
        with:
          tag_name: ${{ github.ref }}
          release_name: Release ${{ github.ref }}
          draft: false
          prerelease: false
```

---

### 6.2 å“è³ªã‚²ãƒ¼ãƒˆ

#### 6.2.1 å“è³ªåŸºæº–

| ãƒ¡ãƒˆãƒªã‚¯ã‚¹ | ç›®æ¨™å€¤ | è¨±å®¹å€¤ | åˆ¤å®š |
|----------|--------|--------|------|
| ãƒ†ã‚¹ãƒˆã‚«ãƒãƒ¬ãƒƒã‚¸ | >95% | >90% | å¿…é ˆ |
| Pylintã‚¹ã‚³ã‚¢ | â‰¥9.0 | â‰¥8.5 | å¿…é ˆ |
| è¤‡é›‘åº¦ | <10 | <15 | æ¨å¥¨ |
| é‡è¤‡ç‡ | <3% | <5% | æ¨å¥¨ |
| ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆç‡ | 100% | >95% | å¿…é ˆ |

---

#### 6.2.2 å“è³ªãƒã‚§ãƒƒã‚¯ã‚¹ã‚¯ãƒªãƒ—ãƒˆ

**`scripts/quality_check.sh`**:

```bash
#!/bin/bash
set -e

echo "=== Running Quality Checks ==="

# ãƒ†ã‚¹ãƒˆã‚«ãƒãƒ¬ãƒƒã‚¸
echo "1. Testing with coverage..."
pytest tests/ --cov=src --cov-report=term --cov-report=html --cov-fail-under=90

# é™çš„è§£æ
echo "2. Running static analysis..."
pylint src/ --rcfile=.pylintrc --fail-under=8.5

# å‹ãƒã‚§ãƒƒã‚¯
echo "3. Type checking..."
mypy src/ --strict --ignore-missing-imports

# ã‚³ãƒ¼ãƒ‰å“è³ª
echo "4. Checking code quality..."
radon cc src/ -a -nb

# é‡è¤‡ã‚³ãƒ¼ãƒ‰æ¤œå‡º
echo "5. Detecting duplicate code..."
pylint src/ --disable=all --enable=duplicate-code

# ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆç‡
echo "6. Checking documentation..."
interrogate src/ --fail-under=95 -v

# ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£ãƒã‚§ãƒƒã‚¯
echo "7. Security check..."
bandit -r src/ -ll

echo "=== All Quality Checks Passed ==="
```

---

### 6.3 Makefile

**`Makefile`**:

```makefile
.PHONY: help install test lint format typecheck coverage docs clean

help:  ## ã“ã®ãƒ˜ãƒ«ãƒ—ã‚’è¡¨ç¤º
	@grep -E '^[a-zA-Z_-]+:.*?## .*$$' $(MAKEFILE_LIST) | sort | awk 'BEGIN {FS = ":.*?## "}; {printf "\033[36m%-20s\033[0m %s\n", $$1, $$2}'

install:  ## ä¾å­˜é–¢ä¿‚ã‚’ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«
	pip install -r requirements-dev.txt
	pip install -e .
	pre-commit install

test:  ## ãƒ†ã‚¹ãƒˆã‚’å®Ÿè¡Œ
	pytest tests/ -v

test-unit:  ## ãƒ¦ãƒ‹ãƒƒãƒˆãƒ†ã‚¹ãƒˆã®ã¿å®Ÿè¡Œ
	pytest tests/unit/ -v

test-integration:  ## çµ±åˆãƒ†ã‚¹ãƒˆã®ã¿å®Ÿè¡Œ
	pytest tests/integration/ -v

test-e2e:  ## E2Eãƒ†ã‚¹ãƒˆã®ã¿å®Ÿè¡Œ
	pytest tests/e2e/ -v

lint:  ## ãƒªãƒ³ãƒˆå®Ÿè¡Œ
	flake8 src/ tests/
	pylint src/ --rcfile=.pylintrc
	black --check src/ tests/
	isort --check-only src/ tests/

format:  ## ã‚³ãƒ¼ãƒ‰æ•´å½¢
	black src/ tests/
	isort src/ tests/

typecheck:  ## å‹ãƒã‚§ãƒƒã‚¯
	mypy src/ --strict --ignore-missing-imports

coverage:  ## ã‚«ãƒãƒ¬ãƒƒã‚¸æ¸¬å®š
	pytest tests/ --cov=src --cov-report=html --cov-report=term
	@echo "Opening coverage report..."
	@open htmlcov/index.html || xdg-open htmlcov/index.html

quality:  ## å“è³ªãƒã‚§ãƒƒã‚¯
	./scripts/quality_check.sh

docs:  ## ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆç”Ÿæˆ
	cd docs && make html
	@echo "Opening documentation..."
	@open docs/_build/html/index.html || xdg-open docs/_build/html/index.html

clean:  ## ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—
	find . -type d -name __pycache__ -exec rm -rf {} +
	find . -type f -name '*.pyc' -delete
	find . -type f -name '*.pyo' -delete
	find . -type f -name '*~' -delete
	rm -rf .pytest_cache
	rm -rf .mypy_cache
	rm -rf htmlcov
	rm -rf .coverage
	rm -rf dist
	rm -rf build
	rm -rf *.egg-info

setup-db:  ## ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹åˆæœŸåŒ–
	python scripts/setup/init_db.py

migrate:  ## ãƒã‚¤ã‚°ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³å®Ÿè¡Œ
	alembic upgrade head

migrate-rollback:  ## ãƒã‚¤ã‚°ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ãƒ­ãƒ¼ãƒ«ãƒãƒƒã‚¯
	alembic downgrade -1

run:  ## ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³å®Ÿè¡Œ
	python -m nf_auto_runner.app.main

dev:  ## é–‹ç™ºã‚µãƒ¼ãƒãƒ¼èµ·å‹•
	uvicorn nf_auto_runner.app.api:app --reload --port 8000
```

---

## 7. ã‚³ãƒ¼ãƒ‰ãƒ¬ãƒ“ãƒ¥ãƒ¼ã‚¬ã‚¤ãƒ‰ãƒ©ã‚¤ãƒ³

### 7.1 ãƒ¬ãƒ“ãƒ¥ãƒ¼ãƒã‚§ãƒƒã‚¯ãƒªã‚¹ãƒˆ

#### 7.1.1 ã‚³ãƒ¼ãƒ‰å“è³ª

- [ ] ã‚³ãƒ¼ãƒ‰ãŒPEP 8ã«æº–æ‹ ã—ã¦ã„ã‚‹
- [ ] é©åˆ‡ãªå‘½åè¦å‰‡ãŒä½¿ã‚ã‚Œã¦ã„ã‚‹
- [ ] é–¢æ•°ãƒ»ã‚¯ãƒ©ã‚¹ãŒå˜ä¸€è²¬ä»»ã‚’æŒã£ã¦ã„ã‚‹
- [ ] é©åˆ‡ãªæŠ½è±¡åŒ–ãƒ¬ãƒ™ãƒ«ã«ãªã£ã¦ã„ã‚‹
- [ ] é‡è¤‡ã‚³ãƒ¼ãƒ‰ãŒãªã„ï¼ˆDRYåŸå‰‡ï¼‰
- [ ] ãƒã‚¸ãƒƒã‚¯ãƒŠãƒ³ãƒãƒ¼ãŒå®šæ•°åŒ–ã•ã‚Œã¦ã„ã‚‹

---

#### 7.1.2 ãƒ†ã‚¹ãƒˆ

- [ ] æ–°æ©Ÿèƒ½ã«å¯¾ã™ã‚‹ãƒ†ã‚¹ãƒˆãŒè¿½åŠ ã•ã‚Œã¦ã„ã‚‹
- [ ] ãƒ†ã‚¹ãƒˆã‚«ãƒãƒ¬ãƒƒã‚¸ãŒ90%ä»¥ä¸Š
- [ ] ã‚¨ãƒƒã‚¸ã‚±ãƒ¼ã‚¹ãŒã‚«ãƒãƒ¼ã•ã‚Œã¦ã„ã‚‹
- [ ] ç•°å¸¸ç³»ã®ãƒ†ã‚¹ãƒˆãŒã‚ã‚‹
- [ ] ãƒ†ã‚¹ãƒˆãŒç‹¬ç«‹ã—ã¦ã„ã‚‹ï¼ˆé †åºä¾å­˜ãªã—ï¼‰

---

#### 7.1.3 ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆ

- [ ] ã™ã¹ã¦ã®ã‚¯ãƒ©ã‚¹ãƒ»é–¢æ•°ã«docstringãŒã‚ã‚‹
- [ ] docstringãŒGoogle Styleã«æº–æ‹ 
- [ ] ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã¨æˆ»ã‚Šå€¤ãŒæ˜è¨˜ã•ã‚Œã¦ã„ã‚‹
- [ ] ä¾‹å¤–ãŒæ˜è¨˜ã•ã‚Œã¦ã„ã‚‹
- [ ] å¿…è¦ã«å¿œã˜ã¦ä½¿ç”¨ä¾‹ãŒã‚ã‚‹

---

#### 7.1.4 ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£

- [ ] SQLã‚¤ãƒ³ã‚¸ã‚§ã‚¯ã‚·ãƒ§ãƒ³å¯¾ç­–
- [ ] XSSå¯¾ç­–
- [ ] ãƒ‘ã‚¹ãƒ¯ãƒ¼ãƒ‰ãƒ»ãƒˆãƒ¼ã‚¯ãƒ³ãŒãƒãƒ¼ãƒ‰ã‚³ãƒ¼ãƒ‰ã•ã‚Œã¦ã„ãªã„
- [ ] é©åˆ‡ãªãƒãƒªãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³ãŒã‚ã‚‹
- [ ] æ©Ÿå¯†æƒ…å ±ãŒãƒ­ã‚°ã«å‡ºåŠ›ã•ã‚Œã¦ã„ãªã„

---

### 7.2 ãƒ—ãƒ«ãƒªã‚¯ã‚¨ã‚¹ãƒˆãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆ

**`.github/pull_request_template.md`**:

```markdown
## å¤‰æ›´å†…å®¹

<!-- ä½•ã‚’å¤‰æ›´ã—ãŸã‹ç°¡æ½”ã«èª¬æ˜ -->

## å¤‰æ›´ã®ç¨®é¡

- [ ] ãƒã‚°ãƒ•ã‚£ãƒƒã‚¯ã‚¹
- [ ] æ–°æ©Ÿèƒ½
- [ ] ãƒªãƒ•ã‚¡ã‚¯ã‚¿ãƒªãƒ³ã‚°
- [ ] ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆæ›´æ–°
- [ ] ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹æ”¹å–„
- [ ] ãƒ†ã‚¹ãƒˆè¿½åŠ 

## é–¢é€£Issue

Closes #

## ãƒ†ã‚¹ãƒˆ

- [ ] ãƒ¦ãƒ‹ãƒƒãƒˆãƒ†ã‚¹ãƒˆã‚’è¿½åŠ ãƒ»æ›´æ–°
- [ ] çµ±åˆãƒ†ã‚¹ãƒˆã‚’è¿½åŠ ãƒ»æ›´æ–°
- [ ] ã™ã¹ã¦ã®ãƒ†ã‚¹ãƒˆãŒãƒ‘ã‚¹
- [ ] ã‚«ãƒãƒ¬ãƒƒã‚¸ãŒ90%ä»¥ä¸Š

## ãƒã‚§ãƒƒã‚¯ãƒªã‚¹ãƒˆ

- [ ] ã‚³ãƒ¼ãƒ‰ãŒPEP 8ã«æº–æ‹ 
- [ ] å‹ãƒ’ãƒ³ãƒˆã‚’è¿½åŠ 
- [ ] docstringã‚’è¿½åŠ 
- [ ] pre-commit ãƒã‚§ãƒƒã‚¯ãŒãƒ‘ã‚¹
- [ ] CI/CDãŒãƒ‘ã‚¹
- [ ] ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã‚’æ›´æ–°

## ã‚¹ã‚¯ãƒªãƒ¼ãƒ³ã‚·ãƒ§ãƒƒãƒˆï¼ˆå¿…è¦ãªå ´åˆï¼‰

## ãƒ¬ãƒ“ãƒ¥ã‚¢ãƒ¼ã¸ã®æ³¨æ„äº‹é …
```

---

## 8. ãƒˆãƒ©ãƒ–ãƒ«ã‚·ãƒ¥ãƒ¼ãƒ†ã‚£ãƒ³ã‚°

### 8.1 ã‚ˆãã‚ã‚‹å•é¡Œ

#### 8.1.1 ã‚¤ãƒ³ãƒãƒ¼ãƒˆã‚¨ãƒ©ãƒ¼

**å•é¡Œ**:
```
ModuleNotFoundError: No module named 'nf_auto_runner'
```

**è§£æ±ºç­–**:
```bash
# é–‹ç™ºãƒ¢ãƒ¼ãƒ‰ã§ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«
pip install -e .

# ã¾ãŸã¯
export PYTHONPATH="${PYTHONPATH}:$(pwd)/src"
```

---

#### 8.1.2 ãƒ†ã‚¹ãƒˆå¤±æ•—

**å•é¡Œ**:
```
pytest tests/test_data.py
FAILED tests/test_data.py::test_load_csv - FileNotFoundError
```

**è§£æ±ºç­–**:
```python
# ãƒ•ã‚£ã‚¯ã‚¹ãƒãƒ£ã‚’ä½¿ç”¨
@pytest.fixture
def sample_csv(tmp_path):
    csv_path = tmp_path / 'sample.csv'
    # CSVãƒ•ã‚¡ã‚¤ãƒ«ä½œæˆ
    return csv_path

def test_load_csv(sample_csv):
    # ãƒ†ã‚¹ãƒˆ
    pass
```

---

#### 8.1.3 ã‚«ãƒãƒ¬ãƒƒã‚¸ãŒä¸ŠãŒã‚‰ãªã„

**å•é¡Œ**:
ã‚«ãƒãƒ¬ãƒƒã‚¸ãŒç›®æ¨™ã«é”ã—ãªã„

**è§£æ±ºç­–**:
```bash
# ã‚«ãƒãƒ¬ãƒƒã‚¸ãƒ¬ãƒãƒ¼ãƒˆç¢ºèª
pytest --cov=src --cov-report=html
open htmlcov/index.html

# æœªã‚«ãƒãƒ¼è¡Œã‚’ç¢ºèªã—ã¦è¿½åŠ ãƒ†ã‚¹ãƒˆä½œæˆ
```

---

### 8.2 ãƒ‡ãƒãƒƒã‚° Tips

#### 8.2.1 pytest ãƒ‡ãƒãƒƒã‚°

```bash
# è©³ç´°å‡ºåŠ›
pytest tests/ -vv

# å¤±æ•—ã—ãŸãƒ†ã‚¹ãƒˆã®ã¿å†å®Ÿè¡Œ
pytest --lf

# æœ€åˆã®å¤±æ•—ã§åœæ­¢
pytest -x

# pdbã§ãƒ‡ãƒãƒƒã‚°
pytest --pdb

# ç‰¹å®šã®ãƒ†ã‚¹ãƒˆã®ã¿å®Ÿè¡Œ
pytest tests/unit/data/test_loader.py::TestDataLoader::test_load_csv
```

---

#### 8.2.2 ãƒ­ã‚°å‡ºåŠ›

```python
import logging

# ãƒ­ã‚¬ãƒ¼è¨­å®š
logging.basicConfig(
    level=logging.DEBUG,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

# ãƒ‡ãƒãƒƒã‚°ãƒ­ã‚°
logger.debug(f"Processing data: {data.shape}")
```

---

## 9. ä»˜éŒ²

### 9.1 è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆ

#### 9.1.1 pyproject.toml

```toml
[tool.poetry]
name = "nf-auto-runner"
version = "1.0.0"
description = "NeuralForecast Auto Runner"
authors = ["Your Name <you@example.com>"]

[tool.poetry.dependencies]
python = "^3.11"
pandas = "^2.0.0"
numpy = "^1.24.0"
scikit-learn = "^1.3.0"
neuralforecast = "^1.6.0"
pytorch = "^2.0.0"
lightning = "^2.0.0"

[tool.poetry.dev-dependencies]
pytest = "^7.4.0"
pytest-cov = "^4.1.0"
black = "^23.11.0"
isort = "^5.12.0"
mypy = "^1.7.0"
pylint = "^3.0.0"

[tool.black]
line-length = 100
target-version = ['py311']

[tool.isort]
profile = "black"
line_length = 100

[tool.mypy]
python_version = "3.11"
strict = true
ignore_missing_imports = true

[tool.pytest.ini_options]
testpaths = ["tests"]
python_files = ["test_*.py"]
python_classes = ["Test*"]
python_functions = ["test_*"]
```

---

#### 9.1.2 .pylintrc

```ini
[MASTER]
ignore=CVS,.git,__pycache__
jobs=4

[MESSAGES CONTROL]
disable=
    C0111,  # missing-docstring
    R0903,  # too-few-public-methods
    R0913,  # too-many-arguments

[FORMAT]
max-line-length=100
indent-string='    '

[DESIGN]
max-args=7
max-locals=15
max-returns=6
max-branches=12
max-statements=50
```

---

### 9.2 ãƒãƒ¼ãƒˆã‚·ãƒ¼ãƒˆ

#### 9.2.1 Git ã‚³ãƒãƒ³ãƒ‰

```bash
# ãƒ–ãƒ©ãƒ³ãƒä½œæˆ
git checkout -b feature/phase-1-config

# å¤‰æ›´ã‚’ã‚³ãƒŸãƒƒãƒˆ
git add .
git commit -m "feat: implement Config base class"

# ãƒ—ãƒƒã‚·ãƒ¥
git push origin feature/phase-1-config

# ãƒãƒ¼ã‚¸
git checkout develop
git merge feature/phase-1-config
```

---

#### 9.2.2 pytest ã‚³ãƒãƒ³ãƒ‰

```bash
# ã™ã¹ã¦ã®ãƒ†ã‚¹ãƒˆå®Ÿè¡Œ
pytest

# ç‰¹å®šã®ãƒ•ã‚¡ã‚¤ãƒ«
pytest tests/unit/config/test_base.py

# ç‰¹å®šã®ã‚¯ãƒ©ã‚¹
pytest tests/unit/config/test_base.py::TestConfig

# ç‰¹å®šã®ãƒ¡ã‚½ãƒƒãƒ‰
pytest tests/unit/config/test_base.py::TestConfig::test_from_dict

# ã‚«ãƒãƒ¬ãƒƒã‚¸ä»˜ã
pytest --cov=src --cov-report=html

# ä¸¦åˆ—å®Ÿè¡Œ
pytest -n auto
```

---

### 9.3 å‚è€ƒè³‡æ–™

- [PEP 8 -- Style Guide for Python Code](https://peps.python.org/pep-0008/)
- [Google Python Style Guide](https://google.github.io/styleguide/pyguide.html)
- [pytest Documentation](https://docs.pytest.org/)
- [Type Hints Documentation](https://docs.python.org/3/library/typing.html)
- [SOLID Principles](https://en.wikipedia.org/wiki/SOLID)

---

**End of Document**
