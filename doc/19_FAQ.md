# FAQï¼ˆã‚ˆãã‚ã‚‹è³ªå•ï¼‰
**Frequently Asked Questions for Time Series Forecasting System**

---

## ğŸ“‹ ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆæƒ…å ±

| é …ç›® | å†…å®¹ |
|-----|------|
| **ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã‚¿ã‚¤ãƒˆãƒ«** | æ™‚ç³»åˆ—äºˆæ¸¬ã‚·ã‚¹ãƒ†ãƒ  FAQ |
| **ãƒãƒ¼ã‚¸ãƒ§ãƒ³** | v1.0.0 |
| **ä½œæˆæ—¥** | 2025-11-03 |
| **æœ€çµ‚æ›´æ–°æ—¥** | 2025-11-03 |
| **å¯¾è±¡èª­è€…** | å…¨ãƒ¦ãƒ¼ã‚¶ãƒ¼ |

---

## ç›®æ¬¡

1. [ä¸€èˆ¬çš„ãªè³ªå•](#1-ä¸€èˆ¬çš„ãªè³ªå•)
2. [ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã¨ç’°å¢ƒè¨­å®š](#2-ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã¨ç’°å¢ƒè¨­å®š)
3. [ãƒ‡ãƒ¼ã‚¿æº–å‚™](#3-ãƒ‡ãƒ¼ã‚¿æº–å‚™)
4. [ãƒ¢ãƒ‡ãƒ«å­¦ç¿’](#4-ãƒ¢ãƒ‡ãƒ«å­¦ç¿’)
5. [äºˆæ¸¬ã¨è©•ä¾¡](#5-äºˆæ¸¬ã¨è©•ä¾¡)
6. [ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹](#6-ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹)
7. [ãƒˆãƒ©ãƒ–ãƒ«ã‚·ãƒ¥ãƒ¼ãƒ†ã‚£ãƒ³ã‚°](#7-ãƒˆãƒ©ãƒ–ãƒ«ã‚·ãƒ¥ãƒ¼ãƒ†ã‚£ãƒ³ã‚°)
8. [ãƒ™ã‚¹ãƒˆãƒ—ãƒ©ã‚¯ãƒ†ã‚£ã‚¹](#8-ãƒ™ã‚¹ãƒˆãƒ—ãƒ©ã‚¯ãƒ†ã‚£ã‚¹)
9. [Tips & Tricks](#9-tips--tricks)

---

## 1. ä¸€èˆ¬çš„ãªè³ªå•

### Q1.1: ã“ã®ã‚·ã‚¹ãƒ†ãƒ ã¯ä½•ãŒã§ãã¾ã™ã‹ï¼Ÿ

**A**: æ™‚ç³»åˆ—äºˆæ¸¬ã‚·ã‚¹ãƒ†ãƒ ã¯ä»¥ä¸‹ã®æ©Ÿèƒ½ã‚’æä¾›ã—ã¾ã™ï¼š

- âœ… **è‡ªå‹•ãƒ¢ãƒ‡ãƒ«é¸æŠ**: AutoNHITSã€AutoLSTMã€AutoGRUãªã©è¤‡æ•°ã®ãƒ¢ãƒ‡ãƒ«
- âœ… **ãƒã‚¤ãƒ‘ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æ¢ç´¢**: Optunaã¾ãŸã¯Rayã«ã‚ˆã‚‹è‡ªå‹•æœ€é©åŒ–
- âœ… **ä¸¦åˆ—å®Ÿè¡Œ**: è¤‡æ•°ãƒ¢ãƒ‡ãƒ«ã®åŒæ™‚å­¦ç¿’
- âœ… **å®Ÿé¨“ç®¡ç†**: PostgreSQL + MLflow/W&Bã«ã‚ˆã‚‹ãƒˆãƒ©ãƒƒã‚­ãƒ³ã‚°
- âœ… **ãƒãƒƒãƒäºˆæ¸¬**: å¤§è¦æ¨¡ãƒ‡ãƒ¼ã‚¿ã®åŠ¹ç‡çš„ãªäºˆæ¸¬
- âœ… **ãƒ¢ãƒ‡ãƒ«ãƒ¬ã‚¸ã‚¹ãƒˆãƒª**: ãƒãƒ¼ã‚¸ãƒ§ãƒ³ç®¡ç†ã¨æœ¬ç•ªãƒ‡ãƒ—ãƒ­ã‚¤

---

### Q1.2: ã©ã®ã‚ˆã†ãªæ™‚ç³»åˆ—ãƒ‡ãƒ¼ã‚¿ã«å¯¾å¿œã—ã¦ã„ã¾ã™ã‹?

**A**: ä»¥ä¸‹ã®å½¢å¼ã‚’ã‚µãƒãƒ¼ãƒˆã—ã¦ã„ã¾ã™ï¼š

| é »åº¦ | ã‚³ãƒ¼ãƒ‰ | ä¾‹ |
|------|--------|-----|
| **ç§’** | S | ã‚»ãƒ³ã‚µãƒ¼ãƒ‡ãƒ¼ã‚¿ |
| **åˆ†** | T, min | ãƒˆãƒ©ãƒ•ã‚£ãƒƒã‚¯ãƒ‡ãƒ¼ã‚¿ |
| **æ™‚é–“** | H | é›»åŠ›æ¶ˆè²»é‡ |
| **æ—¥** | D | å£²ä¸Šãƒ‡ãƒ¼ã‚¿ |
| **é€±** | W | åœ¨åº«ãƒ‡ãƒ¼ã‚¿ |
| **æœˆ** | M, MS | è²¡å‹™ãƒ‡ãƒ¼ã‚¿ |
| **å››åŠæœŸ** | Q, QS | æ¥­ç¸¾ãƒ‡ãƒ¼ã‚¿ |
| **å¹´** | Y, YS | çµŒæ¸ˆæŒ‡æ¨™ |

**ãƒ‡ãƒ¼ã‚¿å½¢å¼**:
```csv
unique_id,ds,y
series_1,2025-01-01,100.0
series_1,2025-01-02,102.5
```

---

### Q1.3: ã©ã®ãã‚‰ã„ã®ãƒ‡ãƒ¼ã‚¿é‡ãŒå¿…è¦ã§ã™ã‹ï¼Ÿ

**A**: ãƒ¢ãƒ‡ãƒ«ã¨äºˆæ¸¬æœŸé–“ã«ã‚ˆã£ã¦ç•°ãªã‚Šã¾ã™ï¼š

| ãƒ¢ãƒ‡ãƒ« | æœ€å°ãƒ‡ãƒ¼ã‚¿ç‚¹æ•° | æ¨å¥¨ãƒ‡ãƒ¼ã‚¿ç‚¹æ•° | äºˆæ¸¬æœŸé–“ã®ç›®å®‰ |
|--------|--------------|--------------|---------------|
| **AutoNHITS** | 2 Ã— h | 10 Ã— h | h â‰¤ ãƒ‡ãƒ¼ã‚¿ç‚¹æ•° / 2 |
| **AutoLSTM** | 3 Ã— h | 20 Ã— h | h â‰¤ ãƒ‡ãƒ¼ã‚¿ç‚¹æ•° / 3 |
| **AutoGRU** | 3 Ã— h | 20 Ã— h | h â‰¤ ãƒ‡ãƒ¼ã‚¿ç‚¹æ•° / 3 |
| **AutoTCN** | 2 Ã— h | 15 Ã— h | h â‰¤ ãƒ‡ãƒ¼ã‚¿ç‚¹æ•° / 2 |

**ä¾‹**:
- æ—¥æ¬¡ãƒ‡ãƒ¼ã‚¿ã§7æ—¥å…ˆã‚’äºˆæ¸¬ (h=7): æœ€ä½14ç‚¹ã€æ¨å¥¨70ç‚¹ä»¥ä¸Š
- æœˆæ¬¡ãƒ‡ãƒ¼ã‚¿ã§12ãƒ¶æœˆå…ˆã‚’äºˆæ¸¬ (h=12): æœ€ä½24ç‚¹ã€æ¨å¥¨120ç‚¹ä»¥ä¸Š

---

### Q1.4: GPU ã¯å¿…è¦ã§ã™ã‹ï¼Ÿ

**A**: å¿…é ˆã§ã¯ã‚ã‚Šã¾ã›ã‚“ãŒã€æ¨å¥¨ã—ã¾ã™ï¼š

| ä½¿ç”¨ç’°å¢ƒ | GPU | å­¦ç¿’æ™‚é–“ï¼ˆä¾‹ï¼‰* | æ¨å¥¨ |
|---------|-----|---------------|------|
| **é–‹ç™ºãƒ»ãƒ†ã‚¹ãƒˆ** | ä¸è¦ | 5-10åˆ† | CPUå¯ |
| **å°è¦æ¨¡é‹ç”¨** (< 100ç³»åˆ—) | ä¸è¦ | 10-30åˆ† | CPUå¯ |
| **ä¸­è¦æ¨¡é‹ç”¨** (100-1000ç³»åˆ—) | æ¨å¥¨ | 30åˆ†-2æ™‚é–“ | GPUæ¨å¥¨ |
| **å¤§è¦æ¨¡é‹ç”¨** (> 1000ç³»åˆ—) | å¿…é ˆ | 2æ™‚é–“ä»¥ä¸Š | GPUå¿…é ˆ |

*å˜ä¸€ãƒ¢ãƒ‡ãƒ«ã€100ç³»åˆ—ã€365ãƒ‡ãƒ¼ã‚¿ç‚¹ã®å ´åˆ

**GPUã®è¨­å®š**:
```bash
# GPUã‚’ä½¿ç”¨
nf-runner train --data data.csv --backend cuda

# CPUã‚’ä½¿ç”¨
nf-runner train --data data.csv --backend cpu
```

---

### Q1.5: ã‚¯ãƒ©ã‚¦ãƒ‰ç’°å¢ƒã§ã‚‚å‹•ä½œã—ã¾ã™ã‹ï¼Ÿ

**A**: ã¯ã„ã€ä¸»è¦ãªã‚¯ãƒ©ã‚¦ãƒ‰ãƒ—ãƒ©ãƒƒãƒˆãƒ•ã‚©ãƒ¼ãƒ ã§å‹•ä½œã—ã¾ã™ï¼š

| ãƒ—ãƒ©ãƒƒãƒˆãƒ•ã‚©ãƒ¼ãƒ  | ã‚µãƒãƒ¼ãƒˆ | æ¨å¥¨æ§‹æˆ |
|----------------|---------|---------|
| **AWS** | âœ… | EC2 (g4dn.xlarge) + RDS PostgreSQL |
| **Google Cloud** | âœ… | Compute Engine (n1-standard-4 + GPU) + Cloud SQL |
| **Azure** | âœ… | VM (NC6) + Azure Database for PostgreSQL |
| **ã‚ªãƒ³ãƒ—ãƒ¬ãƒŸã‚¹** | âœ… | Ubuntu 20.04+, PostgreSQL 14+ |

---

## 2. ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã¨ç’°å¢ƒè¨­å®š

### Q2.1: ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ãŒå¤±æ•—ã—ã¾ã™

**A**: ã‚ˆãã‚ã‚‹åŸå› ã¨è§£æ±ºç­–ï¼š

#### åŸå› 1: Pythonãƒãƒ¼ã‚¸ãƒ§ãƒ³ãŒå¤ã„
```bash
# ãƒãƒ¼ã‚¸ãƒ§ãƒ³ç¢ºèª
python --version  # 3.11ä»¥ä¸ŠãŒå¿…è¦

# pyenvã§ã‚¢ãƒƒãƒ—ã‚°ãƒ¬ãƒ¼ãƒ‰
pyenv install 3.11.6
pyenv local 3.11.6
```

#### åŸå› 2: ä¾å­˜é–¢ä¿‚ã®ç«¶åˆ
```bash
# ä»®æƒ³ç’°å¢ƒã‚’ä½œã‚Šç›´ã™
rm -rf .venv
python3.11 -m venv .venv
source .venv/bin/activate
pip install --upgrade pip
pip install nf-auto-runner
```

#### åŸå› 3: PyTorchã®ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã‚¨ãƒ©ãƒ¼
```bash
# CPUç‰ˆã‚’æ˜ç¤ºçš„ã«ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«
pip install torch --index-url https://download.pytorch.org/whl/cpu

# GPUç‰ˆï¼ˆCUDA 11.8ï¼‰
pip install torch --index-url https://download.pytorch.org/whl/cu118
```

---

### Q2.2: ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹æ¥ç¶šãŒã§ãã¾ã›ã‚“

**A**: æ¥ç¶šç¢ºèªã®æ‰‹é †ï¼š

```bash
# 1. PostgreSQLãŒèµ·å‹•ã—ã¦ã„ã‚‹ã‹ç¢ºèª
sudo systemctl status postgresql

# 2. æ¥ç¶šãƒ†ã‚¹ãƒˆ
psql -U postgres -h localhost -c "SELECT version();"

# 3. ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ãŒå­˜åœ¨ã™ã‚‹ã‹ç¢ºèª
psql -U postgres -l | grep ts_forecast

# 4. ç’°å¢ƒå¤‰æ•°ã‚’ç¢ºèª
echo $DATABASE_URL
# æœŸå¾…å€¤: postgresql://user:password@host:5432/dbname

# 5. æ¥ç¶šæ–‡å­—åˆ—ã®ãƒ†ã‚¹ãƒˆ
python -c "
from sqlalchemy import create_engine
engine = create_engine('$DATABASE_URL')
with engine.connect() as conn:
    print('âœ“ Connection successful')
"
```

**ã‚ˆãã‚ã‚‹ã‚¨ãƒ©ãƒ¼**:
- `FATAL: role "postgres" does not exist` â†’ ãƒ¦ãƒ¼ã‚¶ãƒ¼ã‚’ä½œæˆ
- `FATAL: database "ts_forecast" does not exist` â†’ ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‚’ä½œæˆ
- `FATAL: password authentication failed` â†’ ãƒ‘ã‚¹ãƒ¯ãƒ¼ãƒ‰ã‚’ç¢ºèª

---

### Q2.3: ã©ã®ç’°å¢ƒå¤‰æ•°ãŒå¿…é ˆã§ã™ã‹ï¼Ÿ

**A**: æœ€å°é™ã®å¿…é ˆç’°å¢ƒå¤‰æ•°ï¼š

```bash
# å¿…é ˆï¼ˆãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹æ¥ç¶šï¼‰
DATABASE_URL=postgresql://postgres:password@localhost:5432/ts_forecast

# æ¨å¥¨ï¼ˆãƒ‘ã‚¹è¨­å®šï¼‰
DATA_DIR=/path/to/data
MODEL_DIR=/path/to/models
OUTPUT_DIR=/path/to/outputs
LOG_DIR=/path/to/logs

# ã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼ˆå®Ÿè¡Œåˆ¶å¾¡ï¼‰
MAX_WORKERS=4
DEFAULT_BACKEND=cpu  # ã¾ãŸã¯ cuda
```

**å®Œå…¨ãªä¾‹**ï¼ˆ`.env`ãƒ•ã‚¡ã‚¤ãƒ«ï¼‰:
```bash
# Database
DATABASE_URL=postgresql://postgres:password@localhost:5432/ts_forecast

# Paths
DATA_DIR=./data
MODEL_DIR=./models
OUTPUT_DIR=./outputs
LOG_DIR=./logs

# Execution
MAX_WORKERS=4
DEFAULT_BACKEND=cpu
DEFAULT_H=7
H_RATIO=0.8

# Tracking (ã‚ªãƒ—ã‚·ãƒ§ãƒ³)
MLFLOW_TRACKING_URI=http://localhost:5000
ENABLE_WANDB=false

# Logging
LOG_LEVEL=INFO
LOG_FORMAT=json
```

---

### Q2.4: Docker ã§å®Ÿè¡Œã§ãã¾ã™ã‹ï¼Ÿ

**A**: ã¯ã„ã€Dockerã‚’ã‚µãƒãƒ¼ãƒˆã—ã¦ã„ã¾ã™ï¼š

```bash
# 1. ã‚¤ãƒ¡ãƒ¼ã‚¸ã‚’ãƒ“ãƒ«ãƒ‰
docker build -t nf-auto-runner:latest .

# 2. Docker Composeã§èµ·å‹•
docker-compose up -d

# 3. å­¦ç¿’å®Ÿè¡Œ
docker exec nf-runner nf-runner train \
  --data /data/sample.csv \
  --models AutoNHITS

# 4. ãƒ­ã‚°ç¢ºèª
docker logs nf-runner -f
```

**docker-compose.yml ã®ä¾‹**:
```yaml
version: '3.8'
services:
  postgres:
    image: postgres:14
    environment:
      POSTGRES_USER: postgres
      POSTGRES_PASSWORD: password
      POSTGRES_DB: ts_forecast
    volumes:
      - postgres_data:/var/lib/postgresql/data
    ports:
      - "5432:5432"

  app:
    build: .
    depends_on:
      - postgres
    environment:
      DATABASE_URL: postgresql://postgres:password@postgres:5432/ts_forecast
    volumes:
      - ./data:/data
      - ./models:/models
      - ./outputs:/outputs
    command: python -m nf_auto_runner.app.main

volumes:
  postgres_data:
```

---

## 3. ãƒ‡ãƒ¼ã‚¿æº–å‚™

### Q3.1: CSVãƒ•ã‚¡ã‚¤ãƒ«ã®å¿…é ˆåˆ—ã¯ä½•ã§ã™ã‹ï¼Ÿ

**A**: æœ€å°é™ã®3åˆ—ãŒå¿…è¦ã§ã™ï¼š

```csv
unique_id,ds,y
series_1,2025-01-01,100.0
series_1,2025-01-02,102.5
series_2,2025-01-01,200.0
series_2,2025-01-02,205.0
```

**åˆ—ã®èª¬æ˜**:
- `unique_id`: æ™‚ç³»åˆ—ã®è­˜åˆ¥å­ï¼ˆæ–‡å­—åˆ—ï¼‰
- `ds`: æ—¥æ™‚ï¼ˆISO 8601å½¢å¼ã€ä¾‹: `2025-01-01` ã¾ãŸã¯ `2025-01-01 10:30:00`ï¼‰
- `y`: ç›®çš„å¤‰æ•°ï¼ˆæ•°å€¤ï¼‰

**ã‚ªãƒ—ã‚·ãƒ§ãƒ³ã®åˆ—**:
- `futr_*`: å°†æ¥ã®ç‰¹å¾´é‡ï¼ˆäºˆæ¸¬æ™‚ã«å¿…è¦ï¼‰
- `hist_*`: éå»ã®èª¬æ˜å¤‰æ•°ï¼ˆå­¦ç¿’æ™‚ã®ã¿ï¼‰
- `stat_*`: é™çš„ç‰¹å¾´é‡ï¼ˆç³»åˆ—ãƒ¬ãƒ™ãƒ«ã®å®šæ•°ï¼‰

---

### Q3.2: æ—¥æ™‚ã®ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆã¯ï¼Ÿ

**A**: è¤‡æ•°ã®ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆã‚’ã‚µãƒãƒ¼ãƒˆã—ã¦ã„ã¾ã™ï¼š

| ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆ | ä¾‹ | ç”¨é€” |
|------------|-----|------|
| **ISO 8601** | `2025-01-01` | æ—¥æ¬¡ãƒ‡ãƒ¼ã‚¿ |
| **ISO 8601 + æ™‚åˆ»** | `2025-01-01 10:30:00` | æ™‚é–“ãƒ‡ãƒ¼ã‚¿ |
| **UNIX timestamp** | `1704067200` | ã‚·ã‚¹ãƒ†ãƒ é–“é€£æº |
| **ã‚«ã‚¹ã‚¿ãƒ ** | `01/01/2025` | è¨­å®šã§æŒ‡å®š |

**æ¨å¥¨**: ISO 8601å½¢å¼ï¼ˆ`YYYY-MM-DD`ï¼‰

**ã‚«ã‚¹ã‚¿ãƒ ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆã®æŒ‡å®š**:
```yaml
# conf/data.yaml
data:
  date_format: "%d/%m/%Y"  # 01/01/2025
```

---

### Q3.3: æ¬ æå€¤ã¯ã©ã†æ‰±ãˆã°ã„ã„ã§ã™ã‹ï¼Ÿ

**A**: æ¬ æå€¤ã®å‡¦ç†æ–¹æ³•ï¼š

#### æ–¹æ³•1: å‰å‡¦ç†ã§è£œå®Œï¼ˆæ¨å¥¨ï¼‰
```python
import pandas as pd

# å‰æ–¹åŸ‹ã‚
df['y'] = df.groupby('unique_id')['y'].fillna(method='ffill')

# ç·šå½¢è£œé–“
df['y'] = df.groupby('unique_id')['y'].interpolate()

# å¹³å‡å€¤è£œå®Œ
df['y'] = df.groupby('unique_id')['y'].fillna(
    df.groupby('unique_id')['y'].transform('mean')
)
```

#### æ–¹æ³•2: ã‚·ã‚¹ãƒ†ãƒ ã®è‡ªå‹•å‡¦ç†
```bash
# æ¬ æå€¤å‡¦ç†ã‚’æœ‰åŠ¹åŒ–
nf-runner train \
  --data data.csv \
  --handle-missing forward_fill  # ã¾ãŸã¯ linear, mean, drop
```

#### æ–¹æ³•3: æ¤œè¨¼ã§è­¦å‘Š
```bash
# ãƒ‡ãƒ¼ã‚¿æ¤œè¨¼
nf-runner data validate --data data.csv

# å‡ºåŠ›ä¾‹ï¼š
# âš  Warning: 25 missing values detected in 'y' column
# Suggestion: Use forward fill or interpolation
```

---

### Q3.4: è¤‡æ•°ã®æ™‚ç³»åˆ—ã‚’1ã¤ã®ãƒ•ã‚¡ã‚¤ãƒ«ã«å…¥ã‚Œã‚‰ã‚Œã¾ã™ã‹ï¼Ÿ

**A**: ã¯ã„ã€`unique_id`ã§åŒºåˆ¥ã—ã¾ã™ï¼š

```csv
unique_id,ds,y
tokyo,2025-01-01,100
tokyo,2025-01-02,105
tokyo,2025-01-03,110
osaka,2025-01-01,200
osaka,2025-01-02,210
osaka,2025-01-03,220
kyoto,2025-01-01,150
kyoto,2025-01-02,155
kyoto,2025-01-03,160
```

**åˆ©ç‚¹**:
- 1å›ã®å®Ÿè¡Œã§è¤‡æ•°ç³»åˆ—ã‚’å­¦ç¿’
- ç³»åˆ—é–“ã§å…±é€šã®ãƒ¢ãƒ‡ãƒ«ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£
- ãƒ¡ãƒ¢ãƒªåŠ¹ç‡ãŒè‰¯ã„

**æ³¨æ„ç‚¹**:
- ã™ã¹ã¦ã®ç³»åˆ—ã¯åŒã˜é »åº¦ï¼ˆæ—¥æ¬¡ã€æ™‚é–“ãªã©ï¼‰ã§ã‚ã‚‹å¿…è¦ãŒã‚ã‚‹
- ç³»åˆ—ã”ã¨ã«ç•°ãªã‚‹é•·ã•ã¯å¯èƒ½

---

### Q3.5: å¤–ç”Ÿå¤‰æ•°ã¯ã©ã†è¿½åŠ ã—ã¾ã™ã‹ï¼Ÿ

**A**: åˆ—åã®æ¥é ­è¾ã§ç¨®é¡ã‚’æŒ‡å®šï¼š

```csv
unique_id,ds,y,futr_temperature,hist_demand_lag,stat_region
series_1,2025-01-01,100,25.0,95,tokyo
series_1,2025-01-02,105,26.0,100,tokyo
```

**æ¥é ­è¾ã®æ„å‘³**:
- `futr_*`: **å°†æ¥ã®ç‰¹å¾´é‡**
  - äºˆæ¸¬æ™‚ç‚¹ã§ã‚‚å€¤ãŒåˆ†ã‹ã‚‹ï¼ˆä¾‹: æ°—æ¸©äºˆå ±ã€ã‚«ãƒ¬ãƒ³ãƒ€ãƒ¼æƒ…å ±ï¼‰
  - äºˆæ¸¬æ™‚ã«å¿…é ˆ
  
- `hist_*`: **éå»ã®èª¬æ˜å¤‰æ•°**
  - å­¦ç¿’æ™‚ã®ã¿ä½¿ç”¨ï¼ˆä¾‹: éå»ã®éœ€è¦ã€é…ã‚Œå¤‰æ•°ï¼‰
  - äºˆæ¸¬æ™‚ã¯ä¸è¦
  
- `stat_*`: **é™çš„ç‰¹å¾´é‡**
  - æ™‚ç³»åˆ—å…¨ä½“ã§ä¸€å®šï¼ˆä¾‹: åœ°åŸŸã€ã‚«ãƒ†ã‚´ãƒªï¼‰
  - å­¦ç¿’ãƒ»äºˆæ¸¬ã®ä¸¡æ–¹ã§ä½¿ç”¨

**ä½¿ç”¨ä¾‹**:
```bash
nf-runner train \
  --data data_with_exog.csv \
  --exog-future temperature,holiday \
  --exog-historical demand_lag_1,demand_lag_2 \
  --exog-static region,category
```

---

## 4. ãƒ¢ãƒ‡ãƒ«å­¦ç¿’

### Q4.1: ã©ã®ãƒ¢ãƒ‡ãƒ«ã‚’é¸ã¹ã°ã„ã„ã§ã™ã‹ï¼Ÿ

**A**: ãƒ‡ãƒ¼ã‚¿ã¨ç”¨é€”ã«å¿œã˜ã¦é¸æŠï¼š

| ãƒ¢ãƒ‡ãƒ« | ç‰¹å¾´ | é©ã—ãŸç”¨é€” | å­¦ç¿’æ™‚é–“ |
|--------|------|-----------|---------|
| **AutoNHITS** | é«˜ç²¾åº¦ã€åŠ¹ç‡çš„ | ä¸€èˆ¬çš„ãªæ™‚ç³»åˆ—å…¨èˆ¬ | ä¸­ |
| **AutoLSTM** | é•·æœŸä¾å­˜é–¢ä¿‚ | é•·æœŸäºˆæ¸¬ã€è¤‡é›‘ãªãƒ‘ã‚¿ãƒ¼ãƒ³ | é•· |
| **AutoGRU** | LSTMã‚ˆã‚Šé«˜é€Ÿ | ä¸­æœŸäºˆæ¸¬ | ä¸­ |
| **AutoTCN** | ä¸¦åˆ—åŒ–å¯èƒ½ | å¤§è¦æ¨¡ãƒ‡ãƒ¼ã‚¿ã€ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ  | çŸ­ |
| **AutoPatchTST** | Transformer | é•·æœŸäºˆæ¸¬ã€è¤‡é›‘ãªãƒ‘ã‚¿ãƒ¼ãƒ³ | é•· |

**æ¨å¥¨ã‚¢ãƒ—ãƒ­ãƒ¼ãƒ**:
1. ã¾ãš**AutoNHITS**ã§è©¦ã™ï¼ˆãƒãƒ©ãƒ³ã‚¹ãŒè‰¯ã„ï¼‰
2. ç²¾åº¦ãŒä¸ååˆ†ãªã‚‰**AutoPatchTST**ã¾ãŸã¯**AutoLSTM**
3. é€Ÿåº¦ãŒå¿…è¦ãªã‚‰**AutoTCN**

```bash
# è¤‡æ•°ãƒ¢ãƒ‡ãƒ«ã§æ¯”è¼ƒ
nf-runner train \
  --data data.csv \
  --models AutoNHITS,AutoLSTM,AutoGRU,AutoTCN \
  --h 7

# æœ€è‰¯ãƒ¢ãƒ‡ãƒ«ã‚’ç¢ºèª
nf-runner results best --metric mae
```

---

### Q4.2: å­¦ç¿’æ™‚é–“ã‚’çŸ­ç¸®ã™ã‚‹ã«ã¯ï¼Ÿ

**A**: ä»¥ä¸‹ã®æ–¹æ³•ã§é«˜é€ŸåŒ–ã§ãã¾ã™ï¼š

#### æ–¹æ³•1: ä¸¦åˆ—å®Ÿè¡Œ
```bash
nf-runner train \
  --data data.csv \
  --models AutoNHITS,AutoLSTM,AutoGRU \
  --max-workers 4  # CPUã‚³ã‚¢æ•°ã«å¿œã˜ã¦èª¿æ•´
```

#### æ–¹æ³•2: max_stepsã‚’æ¸›ã‚‰ã™
```bash
nf-runner train \
  --data data.csv \
  --models AutoNHITS \
  --max-steps 500  # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: 1000
```

#### æ–¹æ³•3: ãƒ‡ãƒ¼ã‚¿ã‚’ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°
```python
# å¤§è¦æ¨¡ãƒ‡ãƒ¼ã‚¿ã®å ´åˆã€ä¸€éƒ¨ã§å®Ÿé¨“
df_sample = df.sample(frac=0.1, random_state=42)
```

#### æ–¹æ³•4: GPUã‚’ä½¿ç”¨
```bash
nf-runner train \
  --data data.csv \
  --models AutoNHITS \
  --backend cuda  # GPUãŒã‚ã‚‹å ´åˆ
```

#### æ–¹æ³•5: Rayã§åˆ†æ•£å®Ÿè¡Œ
```bash
# Ray ã‚¯ãƒ©ã‚¹ã‚¿èµ·å‹•
ray start --head

# Ray ä¸¦åˆ—å®Ÿè¡Œ
nf-runner train \
  --data data.csv \
  --models AutoNHITS,AutoLSTM \
  --backend ray \
  --max-workers 10
```

**åŠ¹æœã®ç›®å®‰**ï¼ˆ100ãƒ¢ãƒ‡ãƒ«å­¦ç¿’ã®å ´åˆï¼‰:
- CPUã‚·ãƒªã‚¢ãƒ«: ç´„10æ™‚é–“
- CPUä¸¦åˆ—ï¼ˆ4ã‚³ã‚¢ï¼‰: ç´„3æ™‚é–“
- GPUä¸¦åˆ—: ç´„1æ™‚é–“
- Rayåˆ†æ•£ï¼ˆ10ãƒãƒ¼ãƒ‰ï¼‰: ç´„30åˆ†

---

### Q4.3: ãƒã‚¤ãƒ‘ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æ¢ç´¢ã¯ã©ã†ã™ã‚Œã°ã„ã„ã§ã™ã‹ï¼Ÿ

**A**: Optunaã‚’ä½¿ã£ãŸè‡ªå‹•æ¢ç´¢ã‚’æ¨å¥¨ï¼š

```bash
# åŸºæœ¬çš„ãªæ¢ç´¢
nf-runner train \
  --data data.csv \
  --models AutoNHITS \
  --search-alg optuna \
  --num-trials 50

# ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆã‚’è¨­å®š
nf-runner train \
  --data data.csv \
  --models AutoNHITS \
  --search-alg optuna \
  --num-trials 100 \
  --timeout 3600  # 1æ™‚é–“
```

**æ¢ç´¢ç©ºé–“ã®ã‚«ã‚¹ã‚¿ãƒã‚¤ã‚º**:
```yaml
# conf/hyperparameter.yaml
model:
  AutoNHITS:
    input_size: [7, 14, 21, 28]
    n_pool_kernel_size:
      - [2, 2, 2]
      - [4, 4, 4]
      - [8, 8, 8]
    max_steps: [500, 1000, 1500]
```

**æ¢ç´¢çµæœã®åˆ†æ**:
```python
from nf_auto_runner import HyperparameterAnalyzer

analyzer = HyperparameterAnalyzer()
study = analyzer.load_study(study_name='optuna_study_001')

# æœ€é©ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿
print(study.best_params)

# é‡è¦åº¦ãƒ—ãƒ­ãƒƒãƒˆ
analyzer.plot_param_importances(
    save_path='./outputs/param_importance.png'
)
```

---

### Q4.4: æ¤œè¨¼ãƒ‡ãƒ¼ã‚¿ã®ã‚µã‚¤ã‚ºã¯ã©ã†ã™ã‚Œã°ã„ã„ã§ã™ã‹ï¼Ÿ

**A**: ãƒ‡ãƒ¼ã‚¿é‡ã¨äºˆæ¸¬æœŸé–“ã«å¿œã˜ã¦èª¿æ•´ï¼š

| ãƒ‡ãƒ¼ã‚¿ç‚¹æ•° | äºˆæ¸¬æœŸé–“ (h) | æ¨å¥¨æ¤œè¨¼ã‚µã‚¤ã‚º |
|-----------|-------------|--------------|
| < 100 | ä»»æ„ | 0.2 (20%) |
| 100-500 | h < 50 | 0.2 (20%) |
| 100-500 | h â‰¥ 50 | 0.3 (30%) |
| > 500 | h < 50 | 0.15 (15%) |
| > 500 | h â‰¥ 50 | 0.2 (20%) |

**val_sizeã®æŒ‡å®šæ–¹æ³•**:
```bash
# æ¯”ç‡ã§æŒ‡å®šï¼ˆæ¨å¥¨ï¼‰
nf-runner train --data data.csv --val-size 0.2  # 20%

# çµ¶å¯¾æ•°ã§æŒ‡å®š
nf-runner train --data data.csv --val-size 50  # 50ãƒ‡ãƒ¼ã‚¿ç‚¹

# hã®å€æ•°ã§æŒ‡å®š
nf-runner train --data data.csv --val-size 24/h  # 24 Ã— h

# è‡ªå‹•è¨­å®š
nf-runner train --data data.csv --val-size auto  # ã‚·ã‚¹ãƒ†ãƒ ãŒæ±ºå®š
```

---

### Q4.5: å­¦ç¿’ãŒå¤±æ•—ã™ã‚‹å ´åˆã®å¯¾å‡¦æ³•ã¯ï¼Ÿ

**A**: ã‚¨ãƒ©ãƒ¼ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã«å¿œã˜ã¦å¯¾å‡¦ï¼š

#### ã‚¨ãƒ©ãƒ¼1: `ValueError: input_size must be less than or equal to data length`
**åŸå› **: ãƒ‡ãƒ¼ã‚¿ãŒçŸ­ã™ãã‚‹
**è§£æ±º**:
```bash
# input_size ã‚’å°ã•ãã™ã‚‹
nf-runner train --data data.csv --input-size 7  # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: è‡ªå‹•

# ã¾ãŸã¯ h ã‚’å°ã•ãã™ã‚‹
nf-runner train --data data.csv --h 3
```

#### ã‚¨ãƒ©ãƒ¼2: `RuntimeError: CUDA out of memory`
**åŸå› **: GPU ãƒ¡ãƒ¢ãƒªä¸è¶³
**è§£æ±º**:
```bash
# ãƒãƒƒãƒã‚µã‚¤ã‚ºã‚’å°ã•ã
nf-runner train --data data.csv --batch-size 32

# CPUã«åˆ‡ã‚Šæ›¿ãˆ
nf-runner train --data data.csv --backend cpu
```

#### ã‚¨ãƒ©ãƒ¼3: `KeyError: 'unique_id'`
**åŸå› **: åˆ—åãŒä¸æ­£
**è§£æ±º**:
```python
# åˆ—åã‚’ç¢ºèª
df = pd.read_csv('data.csv')
print(df.columns)

# åˆ—åã‚’ä¿®æ­£
df = df.rename(columns={'id': 'unique_id', 'date': 'ds', 'value': 'y'})
df.to_csv('data_fixed.csv', index=False)
```

---

## 5. äºˆæ¸¬ã¨è©•ä¾¡

### Q5.1: äºˆæ¸¬ã®å®Ÿè¡Œæ–¹æ³•ã¯ï¼Ÿ

**A**: 3ã¤ã®æ–¹æ³•ãŒã‚ã‚Šã¾ã™ï¼š

#### æ–¹æ³•1: ãƒ¢ãƒ‡ãƒ«IDã§äºˆæ¸¬
```bash
nf-runner predict \
  --model-id 123 \
  --data new_data.csv \
  --h 7
```

#### æ–¹æ³•2: ãƒ¢ãƒ‡ãƒ«ãƒ•ã‚¡ã‚¤ãƒ«ã§äºˆæ¸¬
```bash
nf-runner predict \
  --model ./outputs/models/AutoNHITS_20251103_120000.pkl \
  --data new_data.csv \
  --h 14
```

#### æ–¹æ³•3: Python APIã§äºˆæ¸¬
```python
from nf_auto_runner import NeuralForecastRunner

# ãƒ¢ãƒ‡ãƒ«èª­ã¿è¾¼ã¿
runner = NeuralForecastRunner.load_model(
    model_path='./outputs/models/AutoNHITS_*.pkl'
)

# äºˆæ¸¬å®Ÿè¡Œ
forecasts = runner.predict(data, h=7)

# çµæœä¿å­˜
forecasts.to_csv('./outputs/predictions/forecast.csv', index=False)
```

---

### Q5.2: äºˆæ¸¬ç²¾åº¦ã¯ã©ã†è©•ä¾¡ã™ã‚Œã°ã„ã„ã§ã™ã‹ï¼Ÿ

**A**: è¤‡æ•°ã®ãƒ¡ãƒˆãƒªã‚¯ã‚¹ã§è©•ä¾¡ï¼š

| ãƒ¡ãƒˆãƒªã‚¯ã‚¹ | èª¬æ˜ | æ¨å¥¨ç”¨é€” | è¨ˆç®—å¼ |
|-----------|------|---------|--------|
| **MAE** | å¹³å‡çµ¶å¯¾èª¤å·® | ä¸€èˆ¬çš„ | `mean(\|y - Å·\|)` |
| **RMSE** | äºŒä¹—å¹³å‡å¹³æ–¹æ ¹èª¤å·® | å¤–ã‚Œå€¤ã«æ•æ„Ÿ | `sqrt(mean((y - Å·)Â²))` |
| **MAPE** | å¹³å‡çµ¶å¯¾ãƒ‘ãƒ¼ã‚»ãƒ³ãƒˆèª¤å·® | ç›¸å¯¾èª¤å·® | `mean(\|y - Å·\| / \|y\|) Ã— 100` |
| **sMAPE** | å¯¾ç§°MAPE | ç›¸å¯¾èª¤å·®ï¼ˆæ”¹è‰¯ç‰ˆï¼‰ | `mean(2 Ã— \|y - Å·\| / (\|y\| + \|Å·\|)) Ã— 100` |

**è©•ä¾¡ã®å®Ÿè¡Œ**:
```bash
# ã™ã¹ã¦ã®ãƒ¡ãƒˆãƒªã‚¯ã‚¹ã§è©•ä¾¡
nf-runner evaluate \
  --run-id 456 \
  --data test_data.csv

# ç‰¹å®šã®ãƒ¡ãƒˆãƒªã‚¯ã‚¹ã®ã¿
nf-runner evaluate \
  --run-id 456 \
  --metrics mae,rmse,mape
```

**çµæœã®è§£é‡ˆ**:
- MAE < 10%: å„ªç§€
- MAE 10-20%: è‰¯å¥½
- MAE 20-30%: è¨±å®¹ç¯„å›²
- MAE > 30%: æ”¹å–„ãŒå¿…è¦

---

### Q5.3: ä¿¡é ¼åŒºé–“ã¯ã©ã†è§£é‡ˆã™ã‚Œã°ã„ã„ã§ã™ã‹ï¼Ÿ

**A**: äºˆæ¸¬ã®ä¸ç¢ºå®Ÿæ€§ã‚’è¡¨ã—ã¾ã™ï¼š

```csv
unique_id,ds,y_pred,y_pred_lower,y_pred_upper
series_1,2025-11-04,105.2,100.0,110.4
```

**è§£é‡ˆ**:
- `y_pred`: ç‚¹äºˆæ¸¬ï¼ˆæœ€ã‚‚å¯èƒ½æ€§ãŒé«˜ã„å€¤ï¼‰
- `y_pred_lower`: ä¿¡é ¼åŒºé–“ã®ä¸‹é™ï¼ˆ95%ä¿¡é ¼åŒºé–“ï¼‰
- `y_pred_upper`: ä¿¡é ¼åŒºé–“ã®ä¸Šé™ï¼ˆ95%ä¿¡é ¼åŒºé–“ï¼‰

**æ„å‘³**:
- 95%ã®ç¢ºç‡ã§å®Ÿéš›ã®å€¤ãŒ`[y_pred_lower, y_pred_upper]`ã®ç¯„å›²å†…ã«å…¥ã‚‹
- åŒºé–“ãŒç‹­ã„ = äºˆæ¸¬ã®ç¢ºä¿¡åº¦ãŒé«˜ã„
- åŒºé–“ãŒåºƒã„ = äºˆæ¸¬ã®ä¸ç¢ºå®Ÿæ€§ãŒé«˜ã„

**å¯è¦–åŒ–**:
```python
import matplotlib.pyplot as plt

plt.plot(forecasts['ds'], forecasts['y_pred'], label='Prediction')
plt.fill_between(
    forecasts['ds'],
    forecasts['y_pred_lower'],
    forecasts['y_pred_upper'],
    alpha=0.3,
    label='95% CI'
)
plt.legend()
plt.show()
```

---

### Q5.4: éå»ã®ãƒ‡ãƒ¼ã‚¿ã§äºˆæ¸¬ç²¾åº¦ã‚’ç¢ºèªã™ã‚‹ã«ã¯ï¼Ÿ

**A**: ãƒãƒƒã‚¯ãƒ†ã‚¹ãƒˆã‚’å®Ÿè¡Œï¼š

```bash
# ãƒãƒƒã‚¯ãƒ†ã‚¹ãƒˆï¼ˆäº¤å·®æ¤œè¨¼ï¼‰
nf-runner backtest \
  --data data.csv \
  --models AutoNHITS \
  --h 7 \
  --n-folds 5  # 5åˆ†å‰²äº¤å·®æ¤œè¨¼
```

**æ‰‹å‹•ã§ã®ãƒãƒƒã‚¯ãƒ†ã‚¹ãƒˆ**:
```python
from sklearn.model_selection import TimeSeriesSplit

# ãƒ‡ãƒ¼ã‚¿åˆ†å‰²
tscv = TimeSeriesSplit(n_splits=5)

results = []
for train_idx, test_idx in tscv.split(df):
    train = df.iloc[train_idx]
    test = df.iloc[test_idx]
    
    # å­¦ç¿’
    runner.fit(train)
    
    # äºˆæ¸¬
    forecasts = runner.predict(train, h=len(test))
    
    # è©•ä¾¡
    mae = calculate_mae(test['y'], forecasts['y_pred'])
    results.append(mae)

print(f"Average MAE: {np.mean(results):.2f}")
```

---

## 6. ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹

### Q6.1: ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡ã‚’å‰Šæ¸›ã™ã‚‹ã«ã¯ï¼Ÿ

**A**: ä»¥ä¸‹ã®æ–¹æ³•ã§å‰Šæ¸›ã§ãã¾ã™ï¼š

#### æ–¹æ³•1: ãƒãƒƒãƒã‚µã‚¤ã‚ºã‚’å°ã•ã
```bash
nf-runner train \
  --data data.csv \
  --batch-size 32  # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: 128
```

#### æ–¹æ³•2: ãƒ‡ãƒ¼ã‚¿å‹ã‚’æœ€é©åŒ–
```python
# ã‚«ãƒ†ã‚´ãƒªå‹ã‚’ä½¿ç”¨
df['unique_id'] = df['unique_id'].astype('category')

# float32ã‚’ä½¿ç”¨ï¼ˆfloat64ã®åŠåˆ†ã®ãƒ¡ãƒ¢ãƒªï¼‰
df['y'] = df['y'].astype('float32')
```

#### æ–¹æ³•3: ãƒãƒ£ãƒ³ã‚¯å‡¦ç†
```python
# å¤§è¦æ¨¡ãƒ‡ãƒ¼ã‚¿ã‚’ãƒãƒ£ãƒ³ã‚¯ã§å‡¦ç†
for chunk in pd.read_csv('large.csv', chunksize=10000):
    process_chunk(chunk)
```

#### æ–¹æ³•4: ä¸è¦ãªãƒ‡ãƒ¼ã‚¿ã‚’å‰Šé™¤
```python
# å­¦ç¿’å¾Œã«ãƒ¢ãƒ‡ãƒ«ã‹ã‚‰ä¸è¦ãªæƒ…å ±ã‚’å‰Šé™¤
runner.cleanup_model()

# Pythonã®ã‚¬ãƒ™ãƒ¼ã‚¸ã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³
import gc
gc.collect()
```

---

### Q6.2: CPUä½¿ç”¨ç‡ã‚’ä¸Šã’ã‚‹ã«ã¯ï¼Ÿ

**A**: ä¸¦åˆ—å‡¦ç†ã‚’æ´»ç”¨ï¼š

```bash
# ä¸¦åˆ—å®Ÿè¡Œæ•°ã‚’å¢—ã‚„ã™
nf-runner train \
  --data data.csv \
  --models AutoNHITS,AutoLSTM,AutoGRU,AutoTCN \
  --max-workers 8  # CPUã‚³ã‚¢æ•°ã¾ã§

# Ray ã§åˆ†æ•£å®Ÿè¡Œ
ray start --head
nf-runner train \
  --data data.csv \
  --models AutoNHITS,AutoLSTM \
  --backend ray \
  --max-workers 16
```

---

### Q6.3: GPUä½¿ç”¨ç‡ãŒä½ã„å ´åˆã®å¯¾å‡¦æ³•ã¯ï¼Ÿ

**A**: ä»¥ä¸‹ã‚’ç¢ºèªãƒ»èª¿æ•´ï¼š

#### ç¢ºèª1: GPUãŒæ­£ã—ãèªè­˜ã•ã‚Œã¦ã„ã‚‹ã‹
```bash
# CUDA ãƒ‡ãƒã‚¤ã‚¹ç¢ºèª
python -c "import torch; print(torch.cuda.is_available())"

# GPUæƒ…å ±
nvidia-smi
```

#### ç¢ºèª2: ãƒãƒƒã‚¯ã‚¨ãƒ³ãƒ‰ãŒcudaã«ãªã£ã¦ã„ã‚‹ã‹
```bash
nf-runner train \
  --data data.csv \
  --backend cuda  # cpuã§ã¯ãªãcuda
```

#### èª¿æ•´1: ãƒãƒƒãƒã‚µã‚¤ã‚ºã‚’å¤§ãã
```bash
nf-runner train \
  --data data.csv \
  --batch-size 256  # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: 128
```

#### èª¿æ•´2: num_workersã‚’èª¿æ•´
```yaml
# conf/execution.yaml
execution:
  num_workers: 4  # ãƒ‡ãƒ¼ã‚¿ãƒ­ãƒ¼ãƒ€ãƒ¼ã®ãƒ¯ãƒ¼ã‚«ãƒ¼æ•°
```

---

## 7. ãƒˆãƒ©ãƒ–ãƒ«ã‚·ãƒ¥ãƒ¼ãƒ†ã‚£ãƒ³ã‚°

### Q7.1: "loss is NaN" ã‚¨ãƒ©ãƒ¼ãŒå‡ºã¾ã™

**A**: å­¦ç¿’ã®ä¸å®‰å®šæ€§ãŒåŸå› ã§ã™ï¼š

#### è§£æ±ºç­–1: å­¦ç¿’ç‡ã‚’ä¸‹ã’ã‚‹
```bash
nf-runner train \
  --data data.csv \
  --learning-rate 0.0001  # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: 0.001
```

#### è§£æ±ºç­–2: ãƒ‡ãƒ¼ã‚¿ã‚’æ­£è¦åŒ–
```python
# æ¨™æº–åŒ–
from sklearn.preprocessing import StandardScaler

scaler = StandardScaler()
df['y_scaled'] = scaler.fit_transform(df[['y']])
```

#### è§£æ±ºç­–3: ã‚°ãƒ©ãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³ã‚¯ãƒªãƒƒãƒ”ãƒ³ã‚°
```yaml
# conf/model.yaml
model:
  gradient_clip_val: 1.0
```

---

### Q7.2: "Connection refused" ã‚¨ãƒ©ãƒ¼ãŒå‡ºã¾ã™

**A**: ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã¾ãŸã¯ã‚µãƒ¼ãƒ“ã‚¹ã«æ¥ç¶šã§ãã¾ã›ã‚“ï¼š

#### PostgreSQLã®å ´åˆ
```bash
# PostgreSQLèµ·å‹•ç¢ºèª
sudo systemctl status postgresql

# èµ·å‹•ã—ã¦ã„ãªã„å ´åˆ
sudo systemctl start postgresql

# æ¥ç¶šãƒ†ã‚¹ãƒˆ
psql -U postgres -h localhost -c "SELECT 1;"
```

#### MLflowã®å ´åˆ
```bash
# MLflow ã‚µãƒ¼ãƒãƒ¼èµ·å‹•
mlflow ui --port 5000

# ãƒãƒƒã‚¯ã‚°ãƒ©ã‚¦ãƒ³ãƒ‰ã§èµ·å‹•
nohup mlflow ui --port 5000 &
```

#### Rayã®å ´åˆ
```bash
# Ray ã‚¯ãƒ©ã‚¹ã‚¿èµ·å‹•
ray start --head

# æ—¢å­˜ã®ã‚¯ãƒ©ã‚¹ã‚¿ã«æ¥ç¶š
ray start --address='ray://localhost:10001'
```

---

### Q7.3: äºˆæ¸¬çµæœãŒä¸è‡ªç„¶ã§ã™

**A**: ãƒ‡ãƒ¼ã‚¿ã‚„ãƒ¢ãƒ‡ãƒ«ã®å•é¡Œã‚’ç¢ºèªï¼š

#### ç¢ºèª1: ãƒ‡ãƒ¼ã‚¿ã«ç•°å¸¸å€¤ãŒãªã„ã‹
```python
# çµ±è¨ˆæƒ…å ±ç¢ºèª
print(df['y'].describe())

# å¤–ã‚Œå€¤æ¤œå‡º
Q1 = df['y'].quantile(0.25)
Q3 = df['y'].quantile(0.75)
IQR = Q3 - Q1
outliers = df[(df['y'] < Q1 - 1.5*IQR) | (df['y'] > Q3 + 1.5*IQR)]
print(f"Outliers: {len(outliers)}")
```

#### ç¢ºèª2: é »åº¦ãŒæ­£ã—ã„ã‹
```python
# é »åº¦æ¨å®š
from pandas.tseries.frequencies import infer_freq
freq = infer_freq(df['ds'])
print(f"Inferred frequency: {freq}")
```

#### ç¢ºèª3: ãƒ¢ãƒ‡ãƒ«ã®éå­¦ç¿’
```bash
# æ¤œè¨¼ãƒ‡ãƒ¼ã‚¿ã‚µã‚¤ã‚ºã‚’å¢—ã‚„ã™
nf-runner train \
  --data data.csv \
  --val-size 0.3  # 30%

# Early stoppingã‚’æœ‰åŠ¹åŒ–
nf-runner train \
  --data data.csv \
  --early-stopping-patience 10
```

---

### Q7.4: ãƒ­ã‚°ãŒè¡¨ç¤ºã•ã‚Œã¾ã›ã‚“

**A**: ãƒ­ã‚°ãƒ¬ãƒ™ãƒ«ã‚’èª¿æ•´ï¼š

```bash
# ãƒ­ã‚°ãƒ¬ãƒ™ãƒ«ã‚’ DEBUG ã«
nf-runner train \
  --data data.csv \
  --log-level DEBUG

# ã¾ãŸã¯ç’°å¢ƒå¤‰æ•°ã§è¨­å®š
export LOG_LEVEL=DEBUG
nf-runner train --data data.csv
```

**ãƒ­ã‚°ãƒ•ã‚¡ã‚¤ãƒ«ã®ç¢ºèª**:
```bash
# ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ãƒ­ã‚°
tail -f ./logs/app.log

# å®Ÿè¡Œãƒ­ã‚°
cat ./logs/run_<run_id>.log

# ã‚¨ãƒ©ãƒ¼ãƒ­ã‚°
grep ERROR ./logs/*.log
```

---

## 8. ãƒ™ã‚¹ãƒˆãƒ—ãƒ©ã‚¯ãƒ†ã‚£ã‚¹

### Q8.1: é–‹ç™ºã‹ã‚‰æœ¬ç•ªã¸ã®ç§»è¡Œæ‰‹é †ã¯ï¼Ÿ

**A**: æ®µéšçš„ã«ç§»è¡Œã—ã¾ã™ï¼š

#### ã‚¹ãƒ†ãƒƒãƒ—1: é–‹ç™ºç’°å¢ƒã§ãƒ—ãƒ­ãƒˆã‚¿ã‚¤ãƒ—
```bash
# å°è¦æ¨¡ãƒ‡ãƒ¼ã‚¿ã§ãƒ†ã‚¹ãƒˆ
nf-runner train \
  --data sample_data.csv \
  --models AutoNHITS \
  --max-steps 500
```

#### ã‚¹ãƒ†ãƒƒãƒ—2: ã‚¹ãƒ†ãƒ¼ã‚¸ãƒ³ã‚°ç’°å¢ƒã§æ¤œè¨¼
```bash
# æœ¬ç•ªç›¸å½“ã®ãƒ‡ãƒ¼ã‚¿ã§æ¤œè¨¼
nf-runner train \
  --data full_data.csv \
  --models AutoNHITS,AutoLSTM \
  --val-size 0.2 \
  --save-model true
```

#### ã‚¹ãƒ†ãƒƒãƒ—3: ãƒ¢ãƒ‡ãƒ«ã®è©•ä¾¡
```bash
# ãƒãƒƒã‚¯ãƒ†ã‚¹ãƒˆ
nf-runner backtest \
  --data historical_data.csv \
  --models AutoNHITS \
  --h 7 \
  --n-folds 5

# è©•ä¾¡
nf-runner evaluate \
  --run-id <run_id> \
  --data test_data.csv
```

#### ã‚¹ãƒ†ãƒƒãƒ—4: æœ¬ç•ªç’°å¢ƒã¸ãƒ‡ãƒ—ãƒ­ã‚¤
```bash
# ãƒ¢ãƒ‡ãƒ«ã‚’æœ¬ç•ªç’°å¢ƒã«æ˜‡æ ¼
nf-runner registry promote \
  --model-id <model_id> \
  --stage production

# æœ¬ç•ªäºˆæ¸¬
nf-runner predict \
  --model-id <model_id> \
  --data latest_data.csv
```

---

### Q8.2: å†å­¦ç¿’ã®é »åº¦ã¯ã©ã†ã™ã‚Œã°ã„ã„ã§ã™ã‹ï¼Ÿ

**A**: ãƒ‡ãƒ¼ã‚¿ã®æ€§è³ªã«å¿œã˜ã¦æ±ºå®šï¼š

| ãƒ‡ãƒ¼ã‚¿ç‰¹æ€§ | æ¨å¥¨å†å­¦ç¿’é »åº¦ | ç†ç”± |
|----------|--------------|------|
| **å®‰å®šçš„** (å­£ç¯€æ€§ã®ã¿) | æœˆæ¬¡ã€œå››åŠæœŸ | ãƒ‘ã‚¿ãƒ¼ãƒ³ã®å¤‰åŒ–ãŒé…ã„ |
| **å¤‰å‹•çš„** (ãƒˆãƒ¬ãƒ³ãƒ‰å¤‰åŒ–) | é€±æ¬¡ã€œæœˆæ¬¡ | å®šæœŸçš„ãªæ›´æ–°ãŒå¿…è¦ |
| **ä¸å®‰å®š** (æ€¥å¤‰ã‚ã‚Š) | æ—¥æ¬¡ã€œé€±æ¬¡ | é »ç¹ãªæ›´æ–°ãŒå¿…è¦ |
| **ã‚¤ãƒ™ãƒ³ãƒˆé§†å‹•** | ã‚¤ãƒ™ãƒ³ãƒˆç™ºç”Ÿæ™‚ | é‡è¦ãªå¤‰åŒ–ã«å¿œã˜ã¦ |

**è‡ªå‹•å†å­¦ç¿’ã®è¨­å®š**:
```python
# ãƒ‰ãƒªãƒ•ãƒˆæ¤œå‡ºã«ã‚ˆã‚‹è‡ªå‹•å†å­¦ç¿’
from nf_auto_runner import DriftDetector

detector = DriftDetector()
has_drift = detector.detect(new_data)

if has_drift:
    print("Drift detected. Retraining model...")
    runner.fit(new_data)
```

---

### Q8.3: ãƒ¢ãƒ‡ãƒ«ã®ãƒãƒ¼ã‚¸ãƒ§ãƒ³ç®¡ç†ã¯ã©ã†ã™ã‚Œã°ã„ã„ã§ã™ã‹ï¼Ÿ

**A**: MLflowã‚’æ´»ç”¨ï¼š

```bash
# MLflowæœ‰åŠ¹åŒ–
export MLFLOW_TRACKING_URI=http://localhost:5000
nf-runner train \
  --data data.csv \
  --models AutoNHITS \
  --enable-mlflow

# MLflow UI ã§ç¢ºèª
mlflow ui --port 5000
```

**ãƒãƒ¼ã‚¸ãƒ§ãƒ‹ãƒ³ã‚°ã®æˆ¦ç•¥**:
1. **å®Ÿé¨“å˜ä½**: å„å®Ÿé¨“ã«ãƒ¦ãƒ‹ãƒ¼ã‚¯ãªID
2. **ãƒ¢ãƒ‡ãƒ«å˜ä½**: å„ãƒ¢ãƒ‡ãƒ«ã«ãƒãƒ¼ã‚¸ãƒ§ãƒ³ç•ªå·
3. **ã‚¹ãƒ†ãƒ¼ã‚¸ç®¡ç†**: Staging â†’ Production

```bash
# ãƒ¢ãƒ‡ãƒ«ç™»éŒ²
nf-runner registry register \
  --model-path ./models/AutoNHITS_*.pkl \
  --name AutoNHITS_v1

# ã‚¹ãƒ†ãƒ¼ã‚¸å¤‰æ›´
nf-runner registry promote \
  --model-name AutoNHITS_v1 \
  --stage production
```

---

### Q8.4: ãƒ‡ãƒ¼ã‚¿ã®å“è³ªã‚’ã©ã†ä¿è¨¼ã™ã‚Œã°ã„ã„ã§ã™ã‹ï¼Ÿ

**A**: è‡ªå‹•æ¤œè¨¼ã‚’å°å…¥ï¼š

```bash
# ãƒ‡ãƒ¼ã‚¿æ¤œè¨¼
nf-runner data validate \
  --data data.csv \
  --strict  # å³æ ¼ãƒ¢ãƒ¼ãƒ‰

# æ¤œè¨¼é …ç›®:
# âœ“ å¿…é ˆåˆ—ã®å­˜åœ¨
# âœ“ ãƒ‡ãƒ¼ã‚¿å‹ã®æ­£ã—ã•
# âœ“ æ¬ æå€¤ã®æœ‰ç„¡
# âœ“ é‡è¤‡ã®æœ‰ç„¡
# âœ“ æ—¥æ™‚ã®é€£ç¶šæ€§
# âœ“ å¤–ã‚Œå€¤ã®æ¤œå‡º
```

**CI/CDãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã«çµ„ã¿è¾¼ã‚€**:
```yaml
# .github/workflows/data-validation.yml
name: Data Validation

on: [push]

jobs:
  validate:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v2
      - name: Validate Data
        run: |
          nf-runner data validate --data data/latest.csv
```

---

## 9. Tips & Tricks

### Q9.1: é«˜é€Ÿã«å®Ÿé¨“ã‚’å›ã™ã‚³ãƒ„ã¯ï¼Ÿ

**A**: ä»¥ä¸‹ã®ãƒ†ã‚¯ãƒ‹ãƒƒã‚¯ã‚’æ´»ç”¨ï¼š

#### Tip 1: ãƒ‡ãƒ¼ã‚¿ã‚’ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°
```python
# é–‹ç™ºæ™‚ã¯å°è¦æ¨¡ãƒ‡ãƒ¼ã‚¿ã§å®Ÿé¨“
df_dev = df.sample(frac=0.1, random_state=42)
```

#### Tip 2: max_stepsã‚’å‰Šæ¸›
```bash
# é–‹ç™ºæ™‚ã¯å°‘ãªã„ã‚¹ãƒ†ãƒƒãƒ—ã§
nf-runner train --data data.csv --max-steps 100  # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: 1000
```

#### Tip 3: dry-runã§ç¢ºèª
```bash
# å®Ÿè¡Œå‰ã«è¨ˆç”»ã‚’ç¢ºèª
nf-runner train --data data.csv --dry-run
```

#### Tip 4: è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã‚’æ´»ç”¨
```yaml
# conf/dev.yaml (é–‹ç™ºç”¨)
data:
  sample_frac: 0.1

execution:
  max_steps: 100
  max_workers: 2

# conf/prod.yaml (æœ¬ç•ªç”¨)
data:
  sample_frac: 1.0

execution:
  max_steps: 1000
  max_workers: 8
```

---

### Q9.2: ãƒ‡ãƒãƒƒã‚°ã®ã‚³ãƒ„ã¯ï¼Ÿ

**A**: æ®µéšçš„ã«ãƒ‡ãƒãƒƒã‚°ï¼š

#### Tip 1: ãƒ­ã‚°ãƒ¬ãƒ™ãƒ«ã‚’ä¸Šã’ã‚‹
```bash
nf-runner train --data data.csv --log-level DEBUG
```

#### Tip 2: æœ€å°é™ã®ãƒ‡ãƒ¼ã‚¿ã§ãƒ†ã‚¹ãƒˆ
```python
# 1ç³»åˆ—ã€å°‘æ•°ãƒ‡ãƒ¼ã‚¿ç‚¹ã§ç¢ºèª
df_minimal = df[df['unique_id'] == 'series_1'].head(50)
```

#### Tip 3: Python ãƒ‡ãƒãƒƒã‚¬ãƒ¼ã‚’ä½¿ç”¨
```python
import pdb

# ãƒ‡ãƒãƒƒã‚°ãƒã‚¤ãƒ³ãƒˆ
pdb.set_trace()

# ã¾ãŸã¯IPython
from IPython import embed
embed()
```

#### Tip 4: ãƒ†ã‚¹ãƒˆã‚’æ›¸ã
```python
# tests/test_data_loader.py
def test_load_csv_success():
    loader = DataLoader()
    result = loader.load_csv('sample.csv')
    assert result is not None
```

---

### Q9.3: çµæœã‚’è¦‹ã‚„ã™ãã™ã‚‹ã‚³ãƒ„ã¯ï¼Ÿ

**A**: å¯è¦–åŒ–ãƒ„ãƒ¼ãƒ«ã‚’æ´»ç”¨ï¼š

#### Tip 1: MLflow UI
```bash
mlflow ui --port 5000
# http://localhost:5000 ã§ã‚¢ã‚¯ã‚»ã‚¹
```

#### Tip 2: ã‚«ã‚¹ã‚¿ãƒ ãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰
```python
import matplotlib.pyplot as plt
import seaborn as sns

# ãƒ¢ãƒ‡ãƒ«æ¯”è¼ƒãƒ—ãƒ­ãƒƒãƒˆ
results = analyzer.load_experiment(experiment_id=123)
results_df = pd.DataFrame(results)

sns.barplot(data=results_df, x='model', y='mae')
plt.title('Model Comparison (MAE)')
plt.xticks(rotation=45)
plt.tight_layout()
plt.savefig('./outputs/model_comparison.png')
```

#### Tip 3: Jupyter Notebook
```python
# notebooks/analysis.ipynb
from nf_auto_runner import NeuralForecastRunner

runner = NeuralForecastRunner.load_model(model_path='...')
forecasts = runner.predict(data, h=7)

# ã‚¤ãƒ³ã‚¿ãƒ©ã‚¯ãƒ†ã‚£ãƒ–ã«ãƒ—ãƒ­ãƒƒãƒˆ
import plotly.express as px
fig = px.line(forecasts, x='ds', y='y_pred')
fig.show()
```

---

### Q9.4: åŠ¹ç‡çš„ãªè¨­å®šç®¡ç†ã®ã‚³ãƒ„ã¯ï¼Ÿ

**A**: Hydraã‚’æ´»ç”¨ï¼š

#### Tip 1: è¨­å®šã‚’éšå±¤åŒ–
```
conf/
â”œâ”€â”€ config.yaml           # ãƒ¡ã‚¤ãƒ³è¨­å®š
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ small.yaml       # å°è¦æ¨¡ãƒ‡ãƒ¼ã‚¿
â”‚   â”œâ”€â”€ medium.yaml      # ä¸­è¦æ¨¡ãƒ‡ãƒ¼ã‚¿
â”‚   â””â”€â”€ large.yaml       # å¤§è¦æ¨¡ãƒ‡ãƒ¼ã‚¿
â”œâ”€â”€ model/
â”‚   â”œâ”€â”€ fast.yaml        # é«˜é€Ÿãƒ¢ãƒ‡ãƒ«
â”‚   â””â”€â”€ accurate.yaml    # é«˜ç²¾åº¦ãƒ¢ãƒ‡ãƒ«
â””â”€â”€ experiment/
    â”œâ”€â”€ dev.yaml         # é–‹ç™ºç”¨
    â”œâ”€â”€ staging.yaml     # ã‚¹ãƒ†ãƒ¼ã‚¸ãƒ³ã‚°ç”¨
    â””â”€â”€ prod.yaml        # æœ¬ç•ªç”¨
```

#### Tip 2: ã‚³ãƒãƒ³ãƒ‰ãƒ©ã‚¤ãƒ³ã§ä¸Šæ›¸ã
```bash
# è¨­å®šã‚’å‹•çš„ã«ä¸Šæ›¸ã
nf-runner train \
  --config-name config \
  data=large \
  model=accurate \
  execution.max_workers=8
```

#### Tip 3: å®Ÿé¨“ã‚°ãƒ«ãƒ¼ãƒ—ã‚’ä½œæˆ
```yaml
# conf/config.yaml
defaults:
  - data: small
  - model: fast
  - experiment: dev

# ã‚°ãƒ«ãƒ¼ãƒ—æŒ‡å®šã§ä¸€æ‹¬å¤‰æ›´
# nf-runner train --config-name config experiment=prod
```

---

### Q9.5: ã‚¨ãƒ©ãƒ¼å›å¾©ã®ã‚³ãƒ„ã¯ï¼Ÿ

**A**: å†ªç­‰æ€§ã¨ä¸­é–“ä¿å­˜ã‚’æ´»ç”¨ï¼š

#### Tip 1: ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆã‚’ä¿å­˜
```yaml
# conf/execution.yaml
execution:
  save_checkpoint: true
  checkpoint_interval: 100  # 100ã‚¹ãƒ†ãƒƒãƒ—ã”ã¨
```

#### Tip 2: å¤±æ•—æ™‚ã®å†é–‹
```bash
# å¤±æ•—ã—ãŸrunã‚’å†é–‹
nf-runner train --resume-from <run_id>
```

#### Tip 3: æ®µéšçš„ãªå®Ÿè¡Œ
```bash
# Phase 1: ãƒ‡ãƒ¼ã‚¿æº–å‚™
nf-runner data prepare --data raw_data.csv --output prepared_data.csv

# Phase 2: å­¦ç¿’
nf-runner train --data prepared_data.csv
```

---

## âœ¨ ã¾ã¨ã‚

ã“ã®FAQã¯æ™‚ç³»åˆ—äºˆæ¸¬ã‚·ã‚¹ãƒ†ãƒ ã®ã‚ˆãã‚ã‚‹è³ªå•ã‚’ç¶²ç¾…ã—ã¦ã„ã¾ã™ã€‚

### ä¸»è¦ãƒˆãƒ”ãƒƒã‚¯

1. **ä¸€èˆ¬çš„ãªè³ªå•**: ã‚·ã‚¹ãƒ†ãƒ ã®æ¦‚è¦ã¨å¯¾å¿œç¯„å›²
2. **ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«**: ç’°å¢ƒè¨­å®šã¨ãƒˆãƒ©ãƒ–ãƒ«ã‚·ãƒ¥ãƒ¼ãƒ†ã‚£ãƒ³ã‚°
3. **ãƒ‡ãƒ¼ã‚¿æº–å‚™**: å½¢å¼ã€æ¬ æå€¤ã€å¤–ç”Ÿå¤‰æ•°
4. **ãƒ¢ãƒ‡ãƒ«å­¦ç¿’**: é¸æŠã€æœ€é©åŒ–ã€é«˜é€ŸåŒ–
5. **äºˆæ¸¬ã¨è©•ä¾¡**: å®Ÿè¡Œæ–¹æ³•ã€ç²¾åº¦è©•ä¾¡ã€ãƒãƒƒã‚¯ãƒ†ã‚¹ãƒˆ
6. **ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹**: ãƒ¡ãƒ¢ãƒªã€CPUã€GPU ã®æœ€é©åŒ–
7. **ãƒˆãƒ©ãƒ–ãƒ«ã‚·ãƒ¥ãƒ¼ãƒ†ã‚£ãƒ³ã‚°**: ã‚ˆãã‚ã‚‹ã‚¨ãƒ©ãƒ¼ã¨è§£æ±ºç­–
8. **ãƒ™ã‚¹ãƒˆãƒ—ãƒ©ã‚¯ãƒ†ã‚£ã‚¹**: æœ¬ç•ªé‹ç”¨ã®æ¨å¥¨äº‹é …
9. **Tips & Tricks**: åŠ¹ç‡çš„ãªé–‹ç™ºæ‰‹æ³•

---

**æ›´ã«è³ªå•ãŒã‚ã‚‹å ´åˆã¯**:
- ğŸ“– [ã‚¯ã‚¤ãƒƒã‚¯ã‚¹ã‚¿ãƒ¼ãƒˆã‚¬ã‚¤ãƒ‰](./18_QUICKSTART.md)
- ğŸ“– [è©³ç´°ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆ](./01_REQUIREMENTS_SPECIFICATION_DETAILED.md)
- ğŸ’¬ [GitHub Discussions](https://github.com/your-org/nf-auto-runner/discussions)
- ğŸ’¬ [Slack: #nf-auto-runner]()

---
**End of Document**
