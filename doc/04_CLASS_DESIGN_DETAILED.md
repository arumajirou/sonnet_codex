# è©³ç´°ã‚¯ãƒ©ã‚¹è¨­è¨ˆæ›¸
**Detailed Class Design for Time Series Forecasting System**

---

## ğŸ“‹ ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆæƒ…å ±

| é …ç›® | å†…å®¹ |
|-----|------|
| **ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã‚¿ã‚¤ãƒˆãƒ«** | æ™‚ç³»åˆ—äºˆæ¸¬ã‚·ã‚¹ãƒ†ãƒ  è©³ç´°ã‚¯ãƒ©ã‚¹è¨­è¨ˆæ›¸ |
| **ãƒãƒ¼ã‚¸ãƒ§ãƒ³** | v1.0.0 |
| **ä½œæˆæ—¥** | 2025-11-03 |
| **æœ€çµ‚æ›´æ–°æ—¥** | 2025-11-03 |
| **å¯¾è±¡ã‚·ã‚¹ãƒ†ãƒ ** | NeuralForecast Auto Runner + Time Series Forecasting System |

---

## ç›®æ¬¡

1. [Layer 1: Configurationå±¤](#layer-1-configurationå±¤)
2. [Layer 2: Dataå±¤](#layer-2-dataå±¤)
3. [Layer 3: Model Discoveryå±¤](#layer-3-model-discoveryå±¤)
4. [Layer 4: Hyperparameterå±¤](#layer-4-hyperparameterå±¤)
5. [Layer 5: Execution Planå±¤](#layer-5-execution-planå±¤)
6. [Layer 6: Executionå±¤](#layer-6-executionå±¤)
7. [Layer 7: Artifact Managementå±¤](#layer-7-artifact-managementå±¤)
8. [Layer 8: Loggingå±¤](#layer-8-loggingå±¤)
9. [Layer 9: Applicationå±¤](#layer-9-applicationå±¤)
10. [å…±é€šåŸºåº•ã‚¯ãƒ©ã‚¹ãƒ»ãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£](#å…±é€šåŸºåº•ã‚¯ãƒ©ã‚¹ãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£)

---

## Layer 1: Configurationå±¤

### 1.1 Config (åŸºåº•ã‚¯ãƒ©ã‚¹)

#### 1.1.1 ã‚¯ãƒ©ã‚¹å®šç¾©

```python
"""
ConfigurationåŸºåº•ã‚¯ãƒ©ã‚¹

ã™ã¹ã¦ã®è¨­å®šã‚¯ãƒ©ã‚¹ã®æŠ½è±¡åŸºåº•ã‚¯ãƒ©ã‚¹ã€‚
ä¸å¤‰æ€§(frozen=True)ã‚’ä¿è¨¼ã—ã€ç’°å¢ƒå¤‰æ•°ã‹ã‚‰ã®èª­ã¿è¾¼ã¿ã€æ¤œè¨¼ã€
ã‚·ãƒªã‚¢ãƒ©ã‚¤ã‚ºæ©Ÿèƒ½ã‚’æä¾›ã™ã‚‹ã€‚
"""

from dataclasses import dataclass, field, asdict
from abc import ABC, abstractmethod
from typing import Dict, Any, Optional, TypeVar, Type
from pathlib import Path
import json
import os

T = TypeVar('T', bound='Config')

@dataclass(frozen=True)
class Config(ABC):
    """
    è¨­å®šåŸºåº•ã‚¯ãƒ©ã‚¹
    
    Attributes:
        None (æŠ½è±¡ã‚¯ãƒ©ã‚¹ã®ãŸã‚ã€æ´¾ç”Ÿã‚¯ãƒ©ã‚¹ã§å®šç¾©)
    
    Class Methods:
        from_env: ç’°å¢ƒå¤‰æ•°ã‹ã‚‰è¨­å®šã‚’æ§‹ç¯‰
        from_dict: è¾æ›¸ã‹ã‚‰è¨­å®šã‚’æ§‹ç¯‰
        from_json: JSONæ–‡å­—åˆ—ã‹ã‚‰è¨­å®šã‚’æ§‹ç¯‰
        from_json_file: JSONãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰è¨­å®šã‚’æ§‹ç¯‰
    
    Instance Methods:
        validate: è¨­å®šã®å¦¥å½“æ€§æ¤œè¨¼
        to_dict: è¾æ›¸ã«å¤‰æ›
        to_json: JSONæ–‡å­—åˆ—ã«å¤‰æ›
        save_to_file: ãƒ•ã‚¡ã‚¤ãƒ«ã«ä¿å­˜
    
    Example:
        >>> class MyConfig(Config):
        ...     value: int
        ...     
        ...     @classmethod
        ...     def from_env(cls) -> 'MyConfig':
        ...         return cls(value=int(os.getenv('VALUE', '42')))
        >>> 
        >>> config = MyConfig.from_env()
        >>> config.value
        42
    """
    
    @classmethod
    @abstractmethod
    def from_env(cls: Type[T]) -> T:
        """
        ç’°å¢ƒå¤‰æ•°ã‹ã‚‰è¨­å®šã‚’æ§‹ç¯‰
        
        Returns:
            T: è¨­å®šã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹
            
        Raises:
            EnvironmentError: å¿…é ˆç’°å¢ƒå¤‰æ•°ãŒå­˜åœ¨ã—ãªã„
            ValueError: ç’°å¢ƒå¤‰æ•°ã®å€¤ãŒä¸æ­£
            
        Note:
            æ´¾ç”Ÿã‚¯ãƒ©ã‚¹ã§å¿…ãšå®Ÿè£…ã™ã‚‹ã“ã¨
        """
        pass
    
    @classmethod
    def from_dict(cls: Type[T], data: Dict[str, Any]) -> T:
        """
        è¾æ›¸ã‹ã‚‰è¨­å®šã‚’æ§‹ç¯‰
        
        Args:
            data: è¨­å®šãƒ‡ãƒ¼ã‚¿ã®è¾æ›¸
            
        Returns:
            T: è¨­å®šã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹
            
        Raises:
            TypeError: ãƒ‡ãƒ¼ã‚¿å‹ãŒä¸æ­£
            ValueError: ãƒ‡ãƒ¼ã‚¿å€¤ãŒä¸æ­£
            
        Example:
            >>> config = MyConfig.from_dict({"value": 100})
            >>> config.value
            100
        """
        # Pathã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã®å¤‰æ›
        converted_data = {}
        for key, value in data.items():
            if isinstance(value, str) and key.endswith(('_path', '_dir')):
                converted_data[key] = Path(value)
            else:
                converted_data[key] = value
        
        return cls(**converted_data)
    
    @classmethod
    def from_json(cls: Type[T], json_str: str) -> T:
        """
        JSONæ–‡å­—åˆ—ã‹ã‚‰è¨­å®šã‚’æ§‹ç¯‰
        
        Args:
            json_str: JSONæ–‡å­—åˆ—
            
        Returns:
            T: è¨­å®šã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹
            
        Raises:
            json.JSONDecodeError: JSONãƒ‘ãƒ¼ã‚¹ã‚¨ãƒ©ãƒ¼
            
        Example:
            >>> config = MyConfig.from_json('{"value": 200}')
            >>> config.value
            200
        """
        data = json.loads(json_str)
        return cls.from_dict(data)
    
    @classmethod
    def from_json_file(cls: Type[T], file_path: Path) -> T:
        """
        JSONãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰è¨­å®šã‚’æ§‹ç¯‰
        
        Args:
            file_path: JSONãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹
            
        Returns:
            T: è¨­å®šã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹
            
        Raises:
            FileNotFoundError: ãƒ•ã‚¡ã‚¤ãƒ«ãŒå­˜åœ¨ã—ãªã„
            json.JSONDecodeError: JSONãƒ‘ãƒ¼ã‚¹ã‚¨ãƒ©ãƒ¼
            
        Example:
            >>> config = MyConfig.from_json_file(Path("config.json"))
        """
        with open(file_path, 'r', encoding='utf-8') as f:
            return cls.from_json(f.read())
    
    def validate(self) -> None:
        """
        è¨­å®šã®å¦¥å½“æ€§æ¤œè¨¼
        
        Raises:
            ValueError: è¨­å®šå€¤ãŒä¸æ­£
            
        Note:
            æ´¾ç”Ÿã‚¯ãƒ©ã‚¹ã§ã‚ªãƒ¼ãƒãƒ¼ãƒ©ã‚¤ãƒ‰ã—ã¦ç‹¬è‡ªã®æ¤œè¨¼ã‚’è¿½åŠ å¯èƒ½
        """
        pass
    
    def to_dict(self) -> Dict[str, Any]:
        """
        è¾æ›¸ã«å¤‰æ›
        
        Returns:
            Dict[str, Any]: è¨­å®šã®è¾æ›¸è¡¨ç¾
            
        Example:
            >>> config = MyConfig(value=300)
            >>> config.to_dict()
            {'value': 300}
        """
        result = {}
        for key, value in asdict(self).items():
            if isinstance(value, Path):
                result[key] = str(value)
            else:
                result[key] = value
        return result
    
    def to_json(self, indent: Optional[int] = 2) -> str:
        """
        JSONæ–‡å­—åˆ—ã«å¤‰æ›
        
        Args:
            indent: ã‚¤ãƒ³ãƒ‡ãƒ³ãƒˆå¹…ï¼ˆNoneã§æ”¹è¡Œãªã—ï¼‰
            
        Returns:
            str: JSONæ–‡å­—åˆ—
            
        Example:
            >>> config = MyConfig(value=400)
            >>> config.to_json()
            '{\\n  "value": 400\\n}'
        """
        return json.dumps(self.to_dict(), indent=indent, ensure_ascii=False)
    
    def save_to_file(self, file_path: Path, indent: Optional[int] = 2) -> None:
        """
        ãƒ•ã‚¡ã‚¤ãƒ«ã«ä¿å­˜
        
        Args:
            file_path: ä¿å­˜å…ˆãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹
            indent: ã‚¤ãƒ³ãƒ‡ãƒ³ãƒˆå¹…
            
        Raises:
            IOError: ãƒ•ã‚¡ã‚¤ãƒ«æ›¸ãè¾¼ã¿ã‚¨ãƒ©ãƒ¼
            
        Example:
            >>> config = MyConfig(value=500)
            >>> config.save_to_file(Path("config.json"))
        """
        file_path.parent.mkdir(parents=True, exist_ok=True)
        with open(file_path, 'w', encoding='utf-8') as f:
            f.write(self.to_json(indent=indent))
```

#### 1.1.2 ãƒ†ã‚¹ãƒˆã‚³ãƒ¼ãƒ‰

```python
"""ConfigåŸºåº•ã‚¯ãƒ©ã‚¹ã®ãƒ†ã‚¹ãƒˆ"""

import pytest
import tempfile
from pathlib import Path
import os

class TestConfig:
    """ConfigåŸºåº•ã‚¯ãƒ©ã‚¹ã®ãƒ†ã‚¹ãƒˆã‚¹ã‚¤ãƒ¼ãƒˆ"""
    
    def test_from_env(self, monkeypatch):
        """ç’°å¢ƒå¤‰æ•°ã‹ã‚‰ã®èª­ã¿è¾¼ã¿ãƒ†ã‚¹ãƒˆ"""
        monkeypatch.setenv('TEST_VALUE', '42')
        
        @dataclass(frozen=True)
        class TestConfig(Config):
            value: int
            
            @classmethod
            def from_env(cls) -> 'TestConfig':
                return cls(value=int(os.getenv('TEST_VALUE', '0')))
        
        config = TestConfig.from_env()
        assert config.value == 42
    
    def test_from_dict(self):
        """è¾æ›¸ã‹ã‚‰ã®èª­ã¿è¾¼ã¿ãƒ†ã‚¹ãƒˆ"""
        @dataclass(frozen=True)
        class TestConfig(Config):
            value: int
            name: str
            
            @classmethod
            def from_env(cls) -> 'TestConfig':
                return cls(value=0, name='')
        
        config = TestConfig.from_dict({"value": 100, "name": "test"})
        assert config.value == 100
        assert config.name == "test"
    
    def test_from_json(self):
        """JSONæ–‡å­—åˆ—ã‹ã‚‰ã®èª­ã¿è¾¼ã¿ãƒ†ã‚¹ãƒˆ"""
        @dataclass(frozen=True)
        class TestConfig(Config):
            value: int
            
            @classmethod
            def from_env(cls) -> 'TestConfig':
                return cls(value=0)
        
        config = TestConfig.from_json('{"value": 200}')
        assert config.value == 200
    
    def test_from_json_file(self):
        """JSONãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰ã®èª­ã¿è¾¼ã¿ãƒ†ã‚¹ãƒˆ"""
        @dataclass(frozen=True)
        class TestConfig(Config):
            value: int
            
            @classmethod
            def from_env(cls) -> 'TestConfig':
                return cls(value=0)
        
        with tempfile.NamedTemporaryFile(mode='w', suffix='.json', delete=False) as f:
            f.write('{"value": 300}')
            temp_path = Path(f.name)
        
        try:
            config = TestConfig.from_json_file(temp_path)
            assert config.value == 300
        finally:
            temp_path.unlink()
    
    def test_to_dict(self):
        """è¾æ›¸ã¸ã®å¤‰æ›ãƒ†ã‚¹ãƒˆ"""
        @dataclass(frozen=True)
        class TestConfig(Config):
            value: int
            path: Path
            
            @classmethod
            def from_env(cls) -> 'TestConfig':
                return cls(value=0, path=Path('.'))
        
        config = TestConfig(value=400, path=Path('/tmp'))
        result = config.to_dict()
        assert result['value'] == 400
        assert result['path'] == '/tmp'
    
    def test_to_json(self):
        """JSONæ–‡å­—åˆ—ã¸ã®å¤‰æ›ãƒ†ã‚¹ãƒˆ"""
        @dataclass(frozen=True)
        class TestConfig(Config):
            value: int
            
            @classmethod
            def from_env(cls) -> 'TestConfig':
                return cls(value=0)
        
        config = TestConfig(value=500)
        json_str = config.to_json()
        assert '"value": 500' in json_str
    
    def test_save_to_file(self):
        """ãƒ•ã‚¡ã‚¤ãƒ«ä¿å­˜ãƒ†ã‚¹ãƒˆ"""
        @dataclass(frozen=True)
        class TestConfig(Config):
            value: int
            
            @classmethod
            def from_env(cls) -> 'TestConfig':
                return cls(value=0)
        
        config = TestConfig(value=600)
        
        with tempfile.TemporaryDirectory() as tmpdir:
            file_path = Path(tmpdir) / "config.json"
            config.save_to_file(file_path)
            
            assert file_path.exists()
            
            # èª­ã¿è¾¼ã‚“ã§æ¤œè¨¼
            loaded = TestConfig.from_json_file(file_path)
            assert loaded.value == 600
    
    def test_immutability(self):
        """ä¸å¤‰æ€§ã®ãƒ†ã‚¹ãƒˆ"""
        @dataclass(frozen=True)
        class TestConfig(Config):
            value: int
            
            @classmethod
            def from_env(cls) -> 'TestConfig':
                return cls(value=0)
        
        config = TestConfig(value=700)
        
        with pytest.raises(Exception):  # dataclassã®frozen=Trueã§ä¾‹å¤–
            config.value = 800
```

---

### 1.2 PathConfig

#### 1.2.1 ã‚¯ãƒ©ã‚¹å®šç¾©

```python
"""
PathConfig: ãƒ‘ã‚¹é–¢é€£ã®è¨­å®š

ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹ã€ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªãƒ‘ã‚¹ã®ç®¡ç†ã‚’æ‹…å½“ã€‚
ç’°å¢ƒå¤‰æ•°ã‹ã‚‰èª­ã¿è¾¼ã¿ã€è‡ªå‹•çš„ã«ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’ä½œæˆã™ã‚‹ã€‚
"""

from dataclasses import dataclass
from pathlib import Path
from typing import Optional
import os

@dataclass(frozen=True)
class PathConfig(Config):
    """
    ãƒ‘ã‚¹è¨­å®š
    
    Attributes:
        data_csv: å…¥åŠ›ãƒ‡ãƒ¼ã‚¿CSVãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹
        output_dir: å‡ºåŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª
        log_dir: ãƒ­ã‚°ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª
        project_root: ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒ«ãƒ¼ãƒˆãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª
        model_dir: ãƒ¢ãƒ‡ãƒ«ä¿å­˜ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª
        artifact_dir: ã‚¢ãƒ¼ãƒ†ã‚£ãƒ•ã‚¡ã‚¯ãƒˆä¿å­˜ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª
        checkpoint_dir: ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆä¿å­˜ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª
        plot_dir: ãƒ—ãƒ­ãƒƒãƒˆä¿å­˜ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª
    
    Environment Variables:
        NF_DATA_CSV: ãƒ‡ãƒ¼ã‚¿CSVãƒ‘ã‚¹ (default: ./data.csv)
        NF_OUTPUT_DIR: å‡ºåŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª (default: ./nf_auto_runs)
        NF_LOG_DIR: ãƒ­ã‚°ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª (default: ./nf_auto_runs/logs)
        NF_MODEL_DIR: ãƒ¢ãƒ‡ãƒ«ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª (default: ./nf_auto_runs/models)
        NF_ARTIFACT_DIR: ã‚¢ãƒ¼ãƒ†ã‚£ãƒ•ã‚¡ã‚¯ãƒˆãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª (default: ./nf_auto_runs/artifacts)
        NF_CHECKPOINT_DIR: ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª (default: ./nf_auto_runs/checkpoints)
        NF_PLOT_DIR: ãƒ—ãƒ­ãƒƒãƒˆãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª (default: ./nf_auto_runs/plots)
    
    Example:
        >>> config = PathConfig.from_env()
        >>> config.data_csv
        PosixPath('./data.csv')
        >>> config.output_dir
        PosixPath('./nf_auto_runs')
    """
    
    data_csv: Path
    output_dir: Path
    log_dir: Path
    project_root: Path
    model_dir: Path
    artifact_dir: Path
    checkpoint_dir: Path
    plot_dir: Path
    
    @classmethod
    def from_env(cls) -> 'PathConfig':
        """
        ç’°å¢ƒå¤‰æ•°ã‹ã‚‰è¨­å®šã‚’æ§‹ç¯‰
        
        Returns:
            PathConfig: ãƒ‘ã‚¹è¨­å®šã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹
            
        Example:
            >>> config = PathConfig.from_env()
            >>> isinstance(config.data_csv, Path)
            True
        """
        project_root = Path(__file__).resolve().parent.parent
        output_dir = Path(os.getenv('NF_OUTPUT_DIR', './nf_auto_runs'))
        
        return cls(
            data_csv=Path(os.getenv('NF_DATA_CSV', './data.csv')),
            output_dir=output_dir,
            log_dir=Path(os.getenv('NF_LOG_DIR', str(output_dir / 'logs'))),
            project_root=project_root,
            model_dir=Path(os.getenv('NF_MODEL_DIR', str(output_dir / 'models'))),
            artifact_dir=Path(os.getenv('NF_ARTIFACT_DIR', str(output_dir / 'artifacts'))),
            checkpoint_dir=Path(os.getenv('NF_CHECKPOINT_DIR', str(output_dir / 'checkpoints'))),
            plot_dir=Path(os.getenv('NF_PLOT_DIR', str(output_dir / 'plots'))),
        )
    
    def __post_init__(self):
        """
        åˆæœŸåŒ–å¾Œå‡¦ç†: ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã®ä½œæˆ
        
        Note:
            frozen=Trueã§ã‚‚object.__setattr__ã§å¤‰æ›´å¯èƒ½ã ãŒã€
            ã“ã“ã§ã¯ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªä½œæˆã®ã¿è¡Œã†
        """
        # ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã®ä½œæˆ
        for dir_path in [
            self.output_dir,
            self.log_dir,
            self.model_dir,
            self.artifact_dir,
            self.checkpoint_dir,
            self.plot_dir,
        ]:
            dir_path.mkdir(parents=True, exist_ok=True)
    
    def validate(self) -> None:
        """
        è¨­å®šã®å¦¥å½“æ€§æ¤œè¨¼
        
        Raises:
            ValueError: ãƒ‘ã‚¹ãŒä¸æ­£
        """
        # data_csvã®è¦ªãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªãŒå­˜åœ¨ã™ã‚‹ã‹
        if not self.data_csv.parent.exists():
            raise ValueError(f"Data CSV parent directory does not exist: {self.data_csv.parent}")
        
        # ã™ã¹ã¦ã®ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªãŒä½œæˆå¯èƒ½ã‹ï¼ˆæ›¸ãè¾¼ã¿æ¨©é™ãƒã‚§ãƒƒã‚¯ï¼‰
        for dir_path in [self.output_dir, self.log_dir, self.model_dir]:
            if dir_path.exists() and not os.access(dir_path, os.W_OK):
                raise ValueError(f"Directory is not writable: {dir_path}")
    
    def get_run_dir(self, run_id: str) -> Path:
        """
        ç‰¹å®šã®Runã®ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªãƒ‘ã‚¹ã‚’å–å¾—
        
        Args:
            run_id: Run ID
            
        Returns:
            Path: Runãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªãƒ‘ã‚¹
            
        Example:
            >>> config = PathConfig.from_env()
            >>> run_dir = config.get_run_dir("abc123")
            >>> run_dir
            PosixPath('./nf_auto_runs/runs/abc123')
        """
        run_dir = self.output_dir / "runs" / run_id
        run_dir.mkdir(parents=True, exist_ok=True)
        return run_dir
    
    def get_model_path(self, run_id: str, model_name: str) -> Path:
        """
        ãƒ¢ãƒ‡ãƒ«ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹ã‚’å–å¾—
        
        Args:
            run_id: Run ID
            model_name: ãƒ¢ãƒ‡ãƒ«å
            
        Returns:
            Path: ãƒ¢ãƒ‡ãƒ«ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹
            
        Example:
            >>> config = PathConfig.from_env()
            >>> model_path = config.get_model_path("abc123", "AutoNHITS")
            >>> model_path
            PosixPath('./nf_auto_runs/models/abc123_AutoNHITS.pth')
        """
        return self.model_dir / f"{run_id}_{model_name}.pth"
    
    def get_log_path(self, run_id: str) -> Path:
        """
        ãƒ­ã‚°ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹ã‚’å–å¾—
        
        Args:
            run_id: Run ID
            
        Returns:
            Path: ãƒ­ã‚°ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹
            
        Example:
            >>> config = PathConfig.from_env()
            >>> log_path = config.get_log_path("abc123")
            >>> log_path
            PosixPath('./nf_auto_runs/logs/abc123.jsonl')
        """
        return self.log_dir / f"{run_id}.jsonl"
```

#### 1.2.2 ãƒ†ã‚¹ãƒˆã‚³ãƒ¼ãƒ‰

```python
"""PathConfigã®ãƒ†ã‚¹ãƒˆ"""

import pytest
import tempfile
from pathlib import Path
import os

class TestPathConfig:
    """PathConfigã®ãƒ†ã‚¹ãƒˆã‚¹ã‚¤ãƒ¼ãƒˆ"""
    
    def test_from_env_default(self, monkeypatch):
        """ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå€¤ã§ã®ç’°å¢ƒå¤‰æ•°èª­ã¿è¾¼ã¿ãƒ†ã‚¹ãƒˆ"""
        # ç’°å¢ƒå¤‰æ•°ã‚’ã‚¯ãƒªã‚¢
        for key in ['NF_DATA_CSV', 'NF_OUTPUT_DIR', 'NF_LOG_DIR']:
            monkeypatch.delenv(key, raising=False)
        
        config = PathConfig.from_env()
        
        assert config.data_csv == Path('./data.csv')
        assert config.output_dir == Path('./nf_auto_runs')
        assert config.log_dir == Path('./nf_auto_runs/logs')
    
    def test_from_env_custom(self, monkeypatch):
        """ã‚«ã‚¹ã‚¿ãƒ å€¤ã§ã®ç’°å¢ƒå¤‰æ•°èª­ã¿è¾¼ã¿ãƒ†ã‚¹ãƒˆ"""
        monkeypatch.setenv('NF_DATA_CSV', '/custom/data.csv')
        monkeypatch.setenv('NF_OUTPUT_DIR', '/custom/output')
        
        config = PathConfig.from_env()
        
        assert config.data_csv == Path('/custom/data.csv')
        assert config.output_dir == Path('/custom/output')
    
    def test_directory_creation(self):
        """ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªè‡ªå‹•ä½œæˆã®ãƒ†ã‚¹ãƒˆ"""
        with tempfile.TemporaryDirectory() as tmpdir:
            output_dir = Path(tmpdir) / "output"
            
            config = PathConfig(
                data_csv=Path(tmpdir) / "data.csv",
                output_dir=output_dir,
                log_dir=output_dir / "logs",
                project_root=Path(tmpdir),
                model_dir=output_dir / "models",
                artifact_dir=output_dir / "artifacts",
                checkpoint_dir=output_dir / "checkpoints",
                plot_dir=output_dir / "plots",
            )
            
            # ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªãŒä½œæˆã•ã‚Œã¦ã„ã‚‹ã‹
            assert config.output_dir.exists()
            assert config.log_dir.exists()
            assert config.model_dir.exists()
            assert config.artifact_dir.exists()
    
    def test_validate_success(self):
        """æ¤œè¨¼æˆåŠŸã®ãƒ†ã‚¹ãƒˆ"""
        with tempfile.TemporaryDirectory() as tmpdir:
            tmpdir_path = Path(tmpdir)
            
            config = PathConfig(
                data_csv=tmpdir_path / "data.csv",
                output_dir=tmpdir_path / "output",
                log_dir=tmpdir_path / "output" / "logs",
                project_root=tmpdir_path,
                model_dir=tmpdir_path / "output" / "models",
                artifact_dir=tmpdir_path / "output" / "artifacts",
                checkpoint_dir=tmpdir_path / "output" / "checkpoints",
                plot_dir=tmpdir_path / "output" / "plots",
            )
            
            # ä¾‹å¤–ãŒç™ºç”Ÿã—ãªã„ã“ã¨ã‚’ç¢ºèª
            config.validate()
    
    def test_validate_failure_nonexistent_parent(self):
        """æ¤œè¨¼å¤±æ•—ã®ãƒ†ã‚¹ãƒˆï¼ˆè¦ªãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªãŒå­˜åœ¨ã—ãªã„ï¼‰"""
        config = PathConfig(
            data_csv=Path('/nonexistent/dir/data.csv'),
            output_dir=Path('/tmp/output'),
            log_dir=Path('/tmp/output/logs'),
            project_root=Path('/tmp'),
            model_dir=Path('/tmp/output/models'),
            artifact_dir=Path('/tmp/output/artifacts'),
            checkpoint_dir=Path('/tmp/output/checkpoints'),
            plot_dir=Path('/tmp/output/plots'),
        )
        
        with pytest.raises(ValueError, match="parent directory does not exist"):
            config.validate()
    
    def test_get_run_dir(self):
        """Runãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªå–å¾—ã®ãƒ†ã‚¹ãƒˆ"""
        with tempfile.TemporaryDirectory() as tmpdir:
            config = PathConfig(
                data_csv=Path(tmpdir) / "data.csv",
                output_dir=Path(tmpdir),
                log_dir=Path(tmpdir) / "logs",
                project_root=Path(tmpdir),
                model_dir=Path(tmpdir) / "models",
                artifact_dir=Path(tmpdir) / "artifacts",
                checkpoint_dir=Path(tmpdir) / "checkpoints",
                plot_dir=Path(tmpdir) / "plots",
            )
            
            run_dir = config.get_run_dir("test_run_123")
            
            assert run_dir.exists()
            assert run_dir.name == "test_run_123"
            assert run_dir.parent.name == "runs"
    
    def test_get_model_path(self):
        """ãƒ¢ãƒ‡ãƒ«ãƒ‘ã‚¹å–å¾—ã®ãƒ†ã‚¹ãƒˆ"""
        with tempfile.TemporaryDirectory() as tmpdir:
            config = PathConfig(
                data_csv=Path(tmpdir) / "data.csv",
                output_dir=Path(tmpdir),
                log_dir=Path(tmpdir) / "logs",
                project_root=Path(tmpdir),
                model_dir=Path(tmpdir) / "models",
                artifact_dir=Path(tmpdir) / "artifacts",
                checkpoint_dir=Path(tmpdir) / "checkpoints",
                plot_dir=Path(tmpdir) / "plots",
            )
            
            model_path = config.get_model_path("run123", "AutoNHITS")
            
            assert model_path.name == "run123_AutoNHITS.pth"
            assert model_path.parent == config.model_dir
    
    def test_get_log_path(self):
        """ãƒ­ã‚°ãƒ‘ã‚¹å–å¾—ã®ãƒ†ã‚¹ãƒˆ"""
        with tempfile.TemporaryDirectory() as tmpdir:
            config = PathConfig(
                data_csv=Path(tmpdir) / "data.csv",
                output_dir=Path(tmpdir),
                log_dir=Path(tmpdir) / "logs",
                project_root=Path(tmpdir),
                model_dir=Path(tmpdir) / "models",
                artifact_dir=Path(tmpdir) / "artifacts",
                checkpoint_dir=Path(tmpdir) / "checkpoints",
                plot_dir=Path(tmpdir) / "plots",
            )
            
            log_path = config.get_log_path("run456")
            
            assert log_path.name == "run456.jsonl"
            assert log_path.parent == config.log_dir
```

---

### 1.3 ExecutionConfig

#### 1.3.1 ã‚¯ãƒ©ã‚¹å®šç¾©

```python
"""
ExecutionConfig: å®Ÿè¡Œè¨­å®š

å®Ÿè¡Œãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ï¼ˆä¸¦åˆ—åº¦ã€è©¦è¡Œå›æ•°ã€ãƒã‚¤ãƒ‘ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ãªã©ï¼‰ã‚’ç®¡ç†ã€‚
"""

from dataclasses import dataclass
from typing import Optional
import os

@dataclass(frozen=True)
class ExecutionConfig(Config):
    """
    å®Ÿè¡Œè¨­å®š
    
    Attributes:
        random_state: ä¹±æ•°ã‚·ãƒ¼ãƒ‰
        trial_num_samples: Optunaè©¦è¡Œå›æ•°
        trial_max_steps: æœ€å¤§å­¦ç¿’ã‚¹ãƒ†ãƒƒãƒ—æ•°
        default_h: ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆäºˆæ¸¬æœŸé–“
        h_ratio: äºˆæ¸¬æœŸé–“æ¯”ç‡ï¼ˆãƒ‡ãƒ¼ã‚¿é•·ã«å¯¾ã™ã‚‹ï¼‰
        max_workers: æœ€å¤§ä¸¦åˆ—ãƒ¯ãƒ¼ã‚«ãƒ¼æ•°
        allow_ray_parallel: Rayä¸¦åˆ—å®Ÿè¡Œã‚’è¨±å¯
        save_model: ãƒ¢ãƒ‡ãƒ«ã‚’ä¿å­˜ã™ã‚‹ã‹
        overwrite_model: æ—¢å­˜ãƒ¢ãƒ‡ãƒ«ã‚’ä¸Šæ›¸ãã™ã‚‹ã‹
        dir_tokens_maxlen: ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªãƒˆãƒ¼ã‚¯ãƒ³æœ€å¤§é•·
        max_exog_futr: æœªæ¥å¤–ç”Ÿå¤‰æ•°ã®æœ€å¤§æ•°
        max_exog_hist: éå»å¤–ç”Ÿå¤‰æ•°ã®æœ€å¤§æ•°
        max_exog_stat: é™çš„å¤–ç”Ÿå¤‰æ•°ã®æœ€å¤§æ•°
        early_stopping_patience: Early Stopping patience
        gradient_clip_val: å‹¾é…ã‚¯ãƒªãƒƒãƒ”ãƒ³ã‚°å€¤
        accelerator: è¨ˆç®—ãƒãƒƒã‚¯ã‚¨ãƒ³ãƒ‰ï¼ˆcpu, cuda, mpsï¼‰
        devices: ãƒ‡ãƒã‚¤ã‚¹æ•°
        precision: ç²¾åº¦ï¼ˆ32, 16, bf16ï¼‰
    
    Environment Variables:
        RANDOM_STATE: ä¹±æ•°ã‚·ãƒ¼ãƒ‰ (default: 42)
        TRIAL_NUM_SAMPLES: è©¦è¡Œå›æ•° (default: 10)
        TRIAL_MAX_STEPS: æœ€å¤§ã‚¹ãƒ†ãƒƒãƒ— (default: 1000)
        DEFAULT_H: äºˆæ¸¬æœŸé–“ (default: 7)
        H_RATIO: äºˆæ¸¬æœŸé–“æ¯”ç‡ (default: 0.2)
        MAX_WORKERS: æœ€å¤§ãƒ¯ãƒ¼ã‚«ãƒ¼æ•° (default: 4)
        ALLOW_RAY_PARALLEL: Rayä¸¦åˆ— (default: false)
        SAVE_MODEL: ãƒ¢ãƒ‡ãƒ«ä¿å­˜ (default: true)
        OVERWRITE_MODEL: ãƒ¢ãƒ‡ãƒ«ä¸Šæ›¸ã (default: false)
        MAX_EXOG_FUTR: æœªæ¥å¤–ç”Ÿå¤‰æ•°æœ€å¤§æ•° (default: 10)
        MAX_EXOG_HIST: éå»å¤–ç”Ÿå¤‰æ•°æœ€å¤§æ•° (default: 10)
        MAX_EXOG_STAT: é™çš„å¤–ç”Ÿå¤‰æ•°æœ€å¤§æ•° (default: 5)
        EARLY_STOPPING_PATIENCE: Early Stopping (default: 10)
        GRADIENT_CLIP_VAL: å‹¾é…ã‚¯ãƒªãƒƒãƒ— (default: 1.0)
        ACCELERATOR: ãƒãƒƒã‚¯ã‚¨ãƒ³ãƒ‰ (default: auto)
        DEVICES: ãƒ‡ãƒã‚¤ã‚¹æ•° (default: 1)
        PRECISION: ç²¾åº¦ (default: 32)
    
    Example:
        >>> config = ExecutionConfig.from_env()
        >>> config.random_state
        42
        >>> config.max_workers
        4
    """
    
    # åŸºæœ¬è¨­å®š
    random_state: int
    trial_num_samples: int
    trial_max_steps: int
    default_h: int
    h_ratio: float
    
    # ä¸¦åˆ—å®Ÿè¡Œè¨­å®š
    max_workers: int
    allow_ray_parallel: bool
    
    # ãƒ¢ãƒ‡ãƒ«ä¿å­˜è¨­å®š
    save_model: bool
    overwrite_model: bool
    dir_tokens_maxlen: int
    
    # å¤–ç”Ÿå¤‰æ•°åˆ¶é™
    max_exog_futr: int
    max_exog_hist: int
    max_exog_stat: int
    
    # å­¦ç¿’è¨­å®š
    early_stopping_patience: int
    gradient_clip_val: float
    
    # ãƒ‡ãƒã‚¤ã‚¹è¨­å®š
    accelerator: str
    devices: int
    precision: str
    
    @classmethod
    def from_env(cls) -> 'ExecutionConfig':
        """
        ç’°å¢ƒå¤‰æ•°ã‹ã‚‰è¨­å®šã‚’æ§‹ç¯‰
        
        Returns:
            ExecutionConfig: å®Ÿè¡Œè¨­å®šã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹
            
        Example:
            >>> config = ExecutionConfig.from_env()
            >>> config.random_state >= 0
            True
        """
        return cls(
            # åŸºæœ¬è¨­å®š
            random_state=int(os.getenv('RANDOM_STATE', '42')),
            trial_num_samples=int(os.getenv('TRIAL_NUM_SAMPLES', '10')),
            trial_max_steps=int(os.getenv('TRIAL_MAX_STEPS', '1000')),
            default_h=int(os.getenv('DEFAULT_H', '7')),
            h_ratio=float(os.getenv('H_RATIO', '0.2')),
            
            # ä¸¦åˆ—å®Ÿè¡Œè¨­å®š
            max_workers=int(os.getenv('MAX_WORKERS', '4')),
            allow_ray_parallel=os.getenv('ALLOW_RAY_PARALLEL', 'false').lower() == 'true',
            
            # ãƒ¢ãƒ‡ãƒ«ä¿å­˜è¨­å®š
            save_model=os.getenv('SAVE_MODEL', 'true').lower() == 'true',
            overwrite_model=os.getenv('OVERWRITE_MODEL', 'false').lower() == 'true',
            dir_tokens_maxlen=int(os.getenv('DIR_TOKENS_MAXLEN', '50')),
            
            # å¤–ç”Ÿå¤‰æ•°åˆ¶é™
            max_exog_futr=int(os.getenv('MAX_EXOG_FUTR', '10')),
            max_exog_hist=int(os.getenv('MAX_EXOG_HIST', '10')),
            max_exog_stat=int(os.getenv('MAX_EXOG_STAT', '5')),
            
            # å­¦ç¿’è¨­å®š
            early_stopping_patience=int(os.getenv('EARLY_STOPPING_PATIENCE', '10')),
            gradient_clip_val=float(os.getenv('GRADIENT_CLIP_VAL', '1.0')),
            
            # ãƒ‡ãƒã‚¤ã‚¹è¨­å®š
            accelerator=os.getenv('ACCELERATOR', 'auto'),
            devices=int(os.getenv('DEVICES', '1')),
            precision=os.getenv('PRECISION', '32'),
        )
    
    def validate(self) -> None:
        """
        è¨­å®šã®å¦¥å½“æ€§æ¤œè¨¼
        
        Raises:
            ValueError: è¨­å®šå€¤ãŒä¸æ­£
        """
        # æ­£ã®æ•´æ•°ãƒã‚§ãƒƒã‚¯
        if self.random_state < 0:
            raise ValueError(f"random_state must be non-negative: {self.random_state}")
        
        if self.trial_num_samples < 1:
            raise ValueError(f"trial_num_samples must be >= 1: {self.trial_num_samples}")
        
        if self.trial_max_steps < 1:
            raise ValueError(f"trial_max_steps must be >= 1: {self.trial_max_steps}")
        
        if self.default_h < 1:
            raise ValueError(f"default_h must be >= 1: {self.default_h}")
        
        # æ¯”ç‡ãƒã‚§ãƒƒã‚¯
        if not 0 < self.h_ratio <= 1.0:
            raise ValueError(f"h_ratio must be in (0, 1]: {self.h_ratio}")
        
        # ä¸¦åˆ—æ•°ãƒã‚§ãƒƒã‚¯
        if self.max_workers < 1:
            raise ValueError(f"max_workers must be >= 1: {self.max_workers}")
        
        # å¤–ç”Ÿå¤‰æ•°ãƒã‚§ãƒƒã‚¯
        if self.max_exog_futr < 0:
            raise ValueError(f"max_exog_futr must be non-negative: {self.max_exog_futr}")
        
        # ã‚¢ã‚¯ã‚»ãƒ©ãƒ¬ãƒ¼ã‚¿ãƒã‚§ãƒƒã‚¯
        valid_accelerators = ['auto', 'cpu', 'cuda', 'mps', 'tpu']
        if self.accelerator not in valid_accelerators:
            raise ValueError(f"accelerator must be one of {valid_accelerators}: {self.accelerator}")
        
        # ç²¾åº¦ãƒã‚§ãƒƒã‚¯
        valid_precisions = ['32', '16', 'bf16']
        if self.precision not in valid_precisions:
            raise ValueError(f"precision must be one of {valid_precisions}: {self.precision}")
    
    def get_effective_h(self, data_length: int) -> int:
        """
        å®ŸåŠ¹çš„ãªäºˆæ¸¬æœŸé–“ã‚’è¨ˆç®—
        
        Args:
            data_length: ãƒ‡ãƒ¼ã‚¿é•·
            
        Returns:
            int: äºˆæ¸¬æœŸé–“ï¼ˆhï¼‰
            
        Example:
            >>> config = ExecutionConfig.from_env()
            >>> config.get_effective_h(100)
            20  # h_ratio=0.2ã®å ´åˆ
        """
        return max(self.default_h, int(data_length * self.h_ratio))
    
    def should_use_gpu(self) -> bool:
        """
        GPUã‚’ä½¿ç”¨ã™ã¹ãã‹åˆ¤å®š
        
        Returns:
            bool: GPUä½¿ç”¨å¯å¦
            
        Example:
            >>> config = ExecutionConfig.from_env()
            >>> config.should_use_gpu()
            True  # accelerator='cuda'ã®å ´åˆ
        """
        return self.accelerator in ['cuda', 'auto']
    
    def get_num_workers(self) -> int:
        """
        å®Ÿéš›ã«ä½¿ç”¨ã™ã‚‹ãƒ¯ãƒ¼ã‚«ãƒ¼æ•°ã‚’å–å¾—
        
        Returns:
            int: ãƒ¯ãƒ¼ã‚«ãƒ¼æ•°
            
        Note:
            CPUã‚³ã‚¢æ•°ã‚’è¶…ãˆãªã„ã‚ˆã†ã«åˆ¶é™
            
        Example:
            >>> config = ExecutionConfig.from_env()
            >>> workers = config.get_num_workers()
            >>> workers >= 1
            True
        """
        import os
        cpu_count = os.cpu_count() or 1
        return min(self.max_workers, cpu_count)
```

#### 1.3.2 ãƒ†ã‚¹ãƒˆã‚³ãƒ¼ãƒ‰

```python
"""ExecutionConfigã®ãƒ†ã‚¹ãƒˆ"""

import pytest
import os

class TestExecutionConfig:
    """ExecutionConfigã®ãƒ†ã‚¹ãƒˆã‚¹ã‚¤ãƒ¼ãƒˆ"""
    
    def test_from_env_default(self, monkeypatch):
        """ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå€¤ã§ã®èª­ã¿è¾¼ã¿ãƒ†ã‚¹ãƒˆ"""
        # ç’°å¢ƒå¤‰æ•°ã‚’ã‚¯ãƒªã‚¢
        for key in ['RANDOM_STATE', 'TRIAL_NUM_SAMPLES', 'MAX_WORKERS']:
            monkeypatch.delenv(key, raising=False)
        
        config = ExecutionConfig.from_env()
        
        assert config.random_state == 42
        assert config.trial_num_samples == 10
        assert config.max_workers == 4
        assert config.save_model is True
        assert config.allow_ray_parallel is False
    
    def test_from_env_custom(self, monkeypatch):
        """ã‚«ã‚¹ã‚¿ãƒ å€¤ã§ã®èª­ã¿è¾¼ã¿ãƒ†ã‚¹ãƒˆ"""
        monkeypatch.setenv('RANDOM_STATE', '123')
        monkeypatch.setenv('TRIAL_NUM_SAMPLES', '20')
        monkeypatch.setenv('MAX_WORKERS', '8')
        monkeypatch.setenv('SAVE_MODEL', 'false')
        
        config = ExecutionConfig.from_env()
        
        assert config.random_state == 123
        assert config.trial_num_samples == 20
        assert config.max_workers == 8
        assert config.save_model is False
    
    def test_validate_success(self):
        """æ¤œè¨¼æˆåŠŸã®ãƒ†ã‚¹ãƒˆ"""
        config = ExecutionConfig(
            random_state=42,
            trial_num_samples=10,
            trial_max_steps=1000,
            default_h=7,
            h_ratio=0.2,
            max_workers=4,
            allow_ray_parallel=False,
            save_model=True,
            overwrite_model=False,
            dir_tokens_maxlen=50,
            max_exog_futr=10,
            max_exog_hist=10,
            max_exog_stat=5,
            early_stopping_patience=10,
            gradient_clip_val=1.0,
            accelerator='auto',
            devices=1,
            precision='32',
        )
        
        # ä¾‹å¤–ãŒç™ºç”Ÿã—ãªã„ã“ã¨ã‚’ç¢ºèª
        config.validate()
    
    def test_validate_failure_negative_random_state(self):
        """æ¤œè¨¼å¤±æ•—ã®ãƒ†ã‚¹ãƒˆï¼ˆè² ã®ä¹±æ•°ã‚·ãƒ¼ãƒ‰ï¼‰"""
        config = ExecutionConfig(
            random_state=-1,
            trial_num_samples=10,
            trial_max_steps=1000,
            default_h=7,
            h_ratio=0.2,
            max_workers=4,
            allow_ray_parallel=False,
            save_model=True,
            overwrite_model=False,
            dir_tokens_maxlen=50,
            max_exog_futr=10,
            max_exog_hist=10,
            max_exog_stat=5,
            early_stopping_patience=10,
            gradient_clip_val=1.0,
            accelerator='auto',
            devices=1,
            precision='32',
        )
        
        with pytest.raises(ValueError, match="random_state must be non-negative"):
            config.validate()
    
    def test_validate_failure_invalid_h_ratio(self):
        """æ¤œè¨¼å¤±æ•—ã®ãƒ†ã‚¹ãƒˆï¼ˆä¸æ­£ãªh_ratioï¼‰"""
        config = ExecutionConfig(
            random_state=42,
            trial_num_samples=10,
            trial_max_steps=1000,
            default_h=7,
            h_ratio=1.5,  # > 1.0
            max_workers=4,
            allow_ray_parallel=False,
            save_model=True,
            overwrite_model=False,
            dir_tokens_maxlen=50,
            max_exog_futr=10,
            max_exog_hist=10,
            max_exog_stat=5,
            early_stopping_patience=10,
            gradient_clip_val=1.0,
            accelerator='auto',
            devices=1,
            precision='32',
        )
        
        with pytest.raises(ValueError, match="h_ratio must be in"):
            config.validate()
    
    def test_validate_failure_invalid_accelerator(self):
        """æ¤œè¨¼å¤±æ•—ã®ãƒ†ã‚¹ãƒˆï¼ˆä¸æ­£ãªacceleratorï¼‰"""
        config = ExecutionConfig(
            random_state=42,
            trial_num_samples=10,
            trial_max_steps=1000,
            default_h=7,
            h_ratio=0.2,
            max_workers=4,
            allow_ray_parallel=False,
            save_model=True,
            overwrite_model=False,
            dir_tokens_maxlen=50,
            max_exog_futr=10,
            max_exog_hist=10,
            max_exog_stat=5,
            early_stopping_patience=10,
            gradient_clip_val=1.0,
            accelerator='invalid',
            devices=1,
            precision='32',
        )
        
        with pytest.raises(ValueError, match="accelerator must be one of"):
            config.validate()
    
    def test_get_effective_h(self):
        """å®ŸåŠ¹äºˆæ¸¬æœŸé–“ã®è¨ˆç®—ãƒ†ã‚¹ãƒˆ"""
        config = ExecutionConfig.from_env()
        
        # ãƒ‡ãƒ¼ã‚¿é•·100ã®å ´åˆ
        h = config.get_effective_h(100)
        assert h == max(config.default_h, int(100 * config.h_ratio))
        
        # ãƒ‡ãƒ¼ã‚¿é•·10ã®å ´åˆï¼ˆdefault_hã‚ˆã‚Šå°ã•ã„ï¼‰
        h = config.get_effective_h(10)
        assert h == config.default_h
    
    def test_should_use_gpu(self):
        """GPUä½¿ç”¨åˆ¤å®šã®ãƒ†ã‚¹ãƒˆ"""
        # CUDAæŒ‡å®š
        config = ExecutionConfig(
            random_state=42,
            trial_num_samples=10,
            trial_max_steps=1000,
            default_h=7,
            h_ratio=0.2,
            max_workers=4,
            allow_ray_parallel=False,
            save_model=True,
            overwrite_model=False,
            dir_tokens_maxlen=50,
            max_exog_futr=10,
            max_exog_hist=10,
            max_exog_stat=5,
            early_stopping_patience=10,
            gradient_clip_val=1.0,
            accelerator='cuda',
            devices=1,
            precision='32',
        )
        assert config.should_use_gpu() is True
        
        # CPUæŒ‡å®š
        config2 = ExecutionConfig(
            random_state=42,
            trial_num_samples=10,
            trial_max_steps=1000,
            default_h=7,
            h_ratio=0.2,
            max_workers=4,
            allow_ray_parallel=False,
            save_model=True,
            overwrite_model=False,
            dir_tokens_maxlen=50,
            max_exog_futr=10,
            max_exog_hist=10,
            max_exog_stat=5,
            early_stopping_patience=10,
            gradient_clip_val=1.0,
            accelerator='cpu',
            devices=1,
            precision='32',
        )
        assert config2.should_use_gpu() is False
    
    def test_get_num_workers(self):
        """ãƒ¯ãƒ¼ã‚«ãƒ¼æ•°å–å¾—ã®ãƒ†ã‚¹ãƒˆ"""
        config = ExecutionConfig.from_env()
        
        num_workers = config.get_num_workers()
        
        # CPUã‚³ã‚¢æ•°ä»¥ä¸‹ã§ã‚ã‚‹ã“ã¨ã‚’ç¢ºèª
        cpu_count = os.cpu_count() or 1
        assert num_workers <= cpu_count
        assert num_workers >= 1
```

---

### 1.4 ModelSelectionConfig

#### 1.4.1 ã‚¯ãƒ©ã‚¹å®šç¾©

```python
"""
ModelSelectionConfig: ãƒ¢ãƒ‡ãƒ«é¸æŠè¨­å®š

ã©ã®ãƒ¢ãƒ‡ãƒ«ã‚’æœ‰åŠ¹åŒ–ã™ã‚‹ã‹ã‚’ç®¡ç†ã€‚
ãƒ›ãƒ¯ã‚¤ãƒˆãƒªã‚¹ãƒˆ/ãƒ–ãƒ©ãƒƒã‚¯ãƒªã‚¹ãƒˆã«ã‚ˆã‚‹ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°æ©Ÿèƒ½ã‚‚æä¾›ã€‚
"""

from dataclasses import dataclass, field
from typing import List, Set
import os
import json

@dataclass(frozen=True)
class ModelSelectionConfig(Config):
    """
    ãƒ¢ãƒ‡ãƒ«é¸æŠè¨­å®š
    
    Attributes:
        enable_auto_nhits: AutoNHITSã‚’æœ‰åŠ¹åŒ–
        enable_auto_lstm: AutoLSTMã‚’æœ‰åŠ¹åŒ–
        enable_auto_tft: AutoTFTã‚’æœ‰åŠ¹åŒ–
        enable_auto_informer: AutoInformerã‚’æœ‰åŠ¹åŒ–
        enable_auto_autoformer: AutoAutoformerã‚’æœ‰åŠ¹åŒ–
        enable_auto_patchtst: AutoPatchTSTã‚’æœ‰åŠ¹åŒ–
        model_whitelist: ãƒ¢ãƒ‡ãƒ«ãƒ›ãƒ¯ã‚¤ãƒˆãƒªã‚¹ãƒˆï¼ˆç©ºã®å ´åˆã¯å…¨ã¦è¨±å¯ï¼‰
        model_blacklist: ãƒ¢ãƒ‡ãƒ«ãƒ–ãƒ©ãƒƒã‚¯ãƒªã‚¹ãƒˆ
    
    Environment Variables:
        ENABLE_AUTO_NHITS: AutoNHITS (default: true)
        ENABLE_AUTO_LSTM: AutoLSTM (default: true)
        ENABLE_AUTO_TFT: AutoTFT (default: false)
        ENABLE_AUTO_INFORMER: AutoInformer (default: false)
        ENABLE_AUTO_AUTOFORMER: AutoAutoformer (default: false)
        ENABLE_AUTO_PATCHTST: AutoPatchTST (default: false)
        MODEL_WHITELIST: ãƒ›ãƒ¯ã‚¤ãƒˆãƒªã‚¹ãƒˆï¼ˆJSONé…åˆ—, default: []ï¼‰
        MODEL_BLACKLIST: ãƒ–ãƒ©ãƒƒã‚¯ãƒªã‚¹ãƒˆï¼ˆJSONé…åˆ—, default: []ï¼‰
    
    Example:
        >>> config = ModelSelectionConfig.from_env()
        >>> config.enable_auto_nhits
        True
        >>> enabled = config.get_enabled_models()
        >>> 'AutoNHITS' in enabled
        True
    """
    
    # å„ãƒ¢ãƒ‡ãƒ«ã®æœ‰åŠ¹/ç„¡åŠ¹
    enable_auto_nhits: bool
    enable_auto_lstm: bool
    enable_auto_tft: bool
    enable_auto_informer: bool
    enable_auto_autoformer: bool
    enable_auto_patchtst: bool
    
    # ãƒ›ãƒ¯ã‚¤ãƒˆãƒªã‚¹ãƒˆ/ãƒ–ãƒ©ãƒƒã‚¯ãƒªã‚¹ãƒˆ
    model_whitelist: List[str] = field(default_factory=list)
    model_blacklist: List[str] = field(default_factory=list)
    
    @classmethod
    def from_env(cls) -> 'ModelSelectionConfig':
        """
        ç’°å¢ƒå¤‰æ•°ã‹ã‚‰è¨­å®šã‚’æ§‹ç¯‰
        
        Returns:
            ModelSelectionConfig: ãƒ¢ãƒ‡ãƒ«é¸æŠè¨­å®šã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹
            
        Example:
            >>> config = ModelSelectionConfig.from_env()
            >>> isinstance(config.model_whitelist, list)
            True
        """
        # ãƒ›ãƒ¯ã‚¤ãƒˆãƒªã‚¹ãƒˆ/ãƒ–ãƒ©ãƒƒã‚¯ãƒªã‚¹ãƒˆã®èª­ã¿è¾¼ã¿
        whitelist_str = os.getenv('MODEL_WHITELIST', '[]')
        blacklist_str = os.getenv('MODEL_BLACKLIST', '[]')
        
        try:
            whitelist = json.loads(whitelist_str)
        except json.JSONDecodeError:
            whitelist = []
        
        try:
            blacklist = json.loads(blacklist_str)
        except json.JSONDecodeError:
            blacklist = []
        
        return cls(
            enable_auto_nhits=os.getenv('ENABLE_AUTO_NHITS', 'true').lower() == 'true',
            enable_auto_lstm=os.getenv('ENABLE_AUTO_LSTM', 'true').lower() == 'true',
            enable_auto_tft=os.getenv('ENABLE_AUTO_TFT', 'false').lower() == 'true',
            enable_auto_informer=os.getenv('ENABLE_AUTO_INFORMER', 'false').lower() == 'true',
            enable_auto_autoformer=os.getenv('ENABLE_AUTO_AUTOFORMER', 'false').lower() == 'true',
            enable_auto_patchtst=os.getenv('ENABLE_AUTO_PATCHTST', 'false').lower() == 'true',
            model_whitelist=whitelist,
            model_blacklist=blacklist,
        )
    
    def validate(self) -> None:
        """
        è¨­å®šã®å¦¥å½“æ€§æ¤œè¨¼
        
        Raises:
            ValueError: è¨­å®šå€¤ãŒä¸æ­£
        """
        # å°‘ãªãã¨ã‚‚1ã¤ã®ãƒ¢ãƒ‡ãƒ«ãŒæœ‰åŠ¹ã§ã‚ã‚‹ã“ã¨
        if not any([
            self.enable_auto_nhits,
            self.enable_auto_lstm,
            self.enable_auto_tft,
            self.enable_auto_informer,
            self.enable_auto_autoformer,
            self.enable_auto_patchtst,
        ]):
            raise ValueError("At least one model must be enabled")
        
        # ãƒ›ãƒ¯ã‚¤ãƒˆãƒªã‚¹ãƒˆã¨ãƒ–ãƒ©ãƒƒã‚¯ãƒªã‚¹ãƒˆã®é‡è¤‡ãƒã‚§ãƒƒã‚¯
        whitelist_set = set(self.model_whitelist)
        blacklist_set = set(self.model_blacklist)
        overlap = whitelist_set & blacklist_set
        
        if overlap:
            raise ValueError(f"Models appear in both whitelist and blacklist: {overlap}")
    
    def get_enabled_models(self) -> List[str]:
        """
        æœ‰åŠ¹ãªãƒ¢ãƒ‡ãƒ«ä¸€è¦§ã‚’å–å¾—
        
        Returns:
            List[str]: æœ‰åŠ¹ãªãƒ¢ãƒ‡ãƒ«åã®ãƒªã‚¹ãƒˆ
            
        Note:
            ãƒ•ãƒ©ã‚°ã§æœ‰åŠ¹åŒ–ã•ã‚ŒãŸãƒ¢ãƒ‡ãƒ«ã«å¯¾ã—ã¦ã€
            ãƒ›ãƒ¯ã‚¤ãƒˆãƒªã‚¹ãƒˆ/ãƒ–ãƒ©ãƒƒã‚¯ãƒªã‚¹ãƒˆã§ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°ã‚’è¡Œã†
            
        Example:
            >>> config = ModelSelectionConfig.from_env()
            >>> models = config.get_enabled_models()
            >>> isinstance(models, list)
            True
            >>> all(isinstance(m, str) for m in models)
            True
        """
        # ãƒ•ãƒ©ã‚°ã§æœ‰åŠ¹åŒ–ã•ã‚ŒãŸãƒ¢ãƒ‡ãƒ«
        enabled = []
        
        if self.enable_auto_nhits:
            enabled.append('AutoNHITS')
        if self.enable_auto_lstm:
            enabled.append('AutoLSTM')
        if self.enable_auto_tft:
            enabled.append('AutoTFT')
        if self.enable_auto_informer:
            enabled.append('AutoInformer')
        if self.enable_auto_autoformer:
            enabled.append('AutoAutoformer')
        if self.enable_auto_patchtst:
            enabled.append('AutoPatchTST')
        
        # ãƒ›ãƒ¯ã‚¤ãƒˆãƒªã‚¹ãƒˆãŒæŒ‡å®šã•ã‚Œã¦ã„ã‚‹å ´åˆã¯ãƒ•ã‚£ãƒ«ã‚¿
        if self.model_whitelist:
            enabled = [m for m in enabled if m in self.model_whitelist]
        
        # ãƒ–ãƒ©ãƒƒã‚¯ãƒªã‚¹ãƒˆã§é™¤å¤–
        if self.model_blacklist:
            enabled = [m for m in enabled if m not in self.model_blacklist]
        
        return enabled
    
    def is_model_enabled(self, model_name: str) -> bool:
        """
        ç‰¹å®šã®ãƒ¢ãƒ‡ãƒ«ãŒæœ‰åŠ¹ã‹ãƒã‚§ãƒƒã‚¯
        
        Args:
            model_name: ãƒ¢ãƒ‡ãƒ«å
            
        Returns:
            bool: æœ‰åŠ¹ãªå ´åˆTrue
            
        Example:
            >>> config = ModelSelectionConfig.from_env()
            >>> config.is_model_enabled('AutoNHITS')
            True
        """
        return model_name in self.get_enabled_models()
    
    def get_disabled_models(self) -> List[str]:
        """
        ç„¡åŠ¹ãªãƒ¢ãƒ‡ãƒ«ä¸€è¦§ã‚’å–å¾—
        
        Returns:
            List[str]: ç„¡åŠ¹ãªãƒ¢ãƒ‡ãƒ«åã®ãƒªã‚¹ãƒˆ
            
        Example:
            >>> config = ModelSelectionConfig.from_env()
            >>> disabled = config.get_disabled_models()
            >>> isinstance(disabled, list)
            True
        """
        all_models = [
            'AutoNHITS',
            'AutoLSTM',
            'AutoTFT',
            'AutoInformer',
            'AutoAutoformer',
            'AutoPatchTST',
        ]
        
        enabled = set(self.get_enabled_models())
        return [m for m in all_models if m not in enabled]
```

#### 1.4.2 ãƒ†ã‚¹ãƒˆã‚³ãƒ¼ãƒ‰

```python
"""ModelSelectionConfigã®ãƒ†ã‚¹ãƒˆ"""

import pytest
import json

class TestModelSelectionConfig:
    """ModelSelectionConfigã®ãƒ†ã‚¹ãƒˆã‚¹ã‚¤ãƒ¼ãƒˆ"""
    
    def test_from_env_default(self, monkeypatch):
        """ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå€¤ã§ã®èª­ã¿è¾¼ã¿ãƒ†ã‚¹ãƒˆ"""
        # ç’°å¢ƒå¤‰æ•°ã‚’ã‚¯ãƒªã‚¢
        for key in ['ENABLE_AUTO_NHITS', 'ENABLE_AUTO_LSTM', 'MODEL_WHITELIST']:
            monkeypatch.delenv(key, raising=False)
        
        config = ModelSelectionConfig.from_env()
        
        assert config.enable_auto_nhits is True
        assert config.enable_auto_lstm is True
        assert config.enable_auto_tft is False
        assert config.model_whitelist == []
        assert config.model_blacklist == []
    
    def test_from_env_custom(self, monkeypatch):
        """ã‚«ã‚¹ã‚¿ãƒ å€¤ã§ã®èª­ã¿è¾¼ã¿ãƒ†ã‚¹ãƒˆ"""
        monkeypatch.setenv('ENABLE_AUTO_NHITS', 'false')
        monkeypatch.setenv('ENABLE_AUTO_TFT', 'true')
        monkeypatch.setenv('MODEL_WHITELIST', '["AutoNHITS", "AutoTFT"]')
        monkeypatch.setenv('MODEL_BLACKLIST', '["AutoLSTM"]')
        
        config = ModelSelectionConfig.from_env()
        
        assert config.enable_auto_nhits is False
        assert config.enable_auto_tft is True
        assert config.model_whitelist == ["AutoNHITS", "AutoTFT"]
        assert config.model_blacklist == ["AutoLSTM"]
    
    def test_validate_success(self):
        """æ¤œè¨¼æˆåŠŸã®ãƒ†ã‚¹ãƒˆ"""
        config = ModelSelectionConfig(
            enable_auto_nhits=True,
            enable_auto_lstm=False,
            enable_auto_tft=False,
            enable_auto_informer=False,
            enable_auto_autoformer=False,
            enable_auto_patchtst=False,
            model_whitelist=[],
            model_blacklist=[],
        )
        
        # ä¾‹å¤–ãŒç™ºç”Ÿã—ãªã„ã“ã¨ã‚’ç¢ºèª
        config.validate()
    
    def test_validate_failure_no_models_enabled(self):
        """æ¤œè¨¼å¤±æ•—ã®ãƒ†ã‚¹ãƒˆï¼ˆãƒ¢ãƒ‡ãƒ«ãŒ1ã¤ã‚‚æœ‰åŠ¹ã§ãªã„ï¼‰"""
        config = ModelSelectionConfig(
            enable_auto_nhits=False,
            enable_auto_lstm=False,
            enable_auto_tft=False,
            enable_auto_informer=False,
            enable_auto_autoformer=False,
            enable_auto_patchtst=False,
            model_whitelist=[],
            model_blacklist=[],
        )
        
        with pytest.raises(ValueError, match="At least one model must be enabled"):
            config.validate()
    
    def test_validate_failure_overlap(self):
        """æ¤œè¨¼å¤±æ•—ã®ãƒ†ã‚¹ãƒˆï¼ˆãƒ›ãƒ¯ã‚¤ãƒˆãƒªã‚¹ãƒˆã¨ãƒ–ãƒ©ãƒƒã‚¯ãƒªã‚¹ãƒˆã®é‡è¤‡ï¼‰"""
        config = ModelSelectionConfig(
            enable_auto_nhits=True,
            enable_auto_lstm=True,
            enable_auto_tft=False,
            enable_auto_informer=False,
            enable_auto_autoformer=False,
            enable_auto_patchtst=False,
            model_whitelist=['AutoNHITS', 'AutoLSTM'],
            model_blacklist=['AutoLSTM'],  # é‡è¤‡
        )
        
        with pytest.raises(ValueError, match="appear in both whitelist and blacklist"):
            config.validate()
    
    def test_get_enabled_models_all(self):
        """æœ‰åŠ¹ãƒ¢ãƒ‡ãƒ«å–å¾—ã®ãƒ†ã‚¹ãƒˆï¼ˆå…¨ã¦æœ‰åŠ¹ï¼‰"""
        config = ModelSelectionConfig(
            enable_auto_nhits=True,
            enable_auto_lstm=True,
            enable_auto_tft=True,
            enable_auto_informer=True,
            enable_auto_autoformer=True,
            enable_auto_patchtst=True,
            model_whitelist=[],
            model_blacklist=[],
        )
        
        enabled = config.get_enabled_models()
        
        assert len(enabled) == 6
        assert 'AutoNHITS' in enabled
        assert 'AutoLSTM' in enabled
        assert 'AutoTFT' in enabled
    
    def test_get_enabled_models_with_whitelist(self):
        """æœ‰åŠ¹ãƒ¢ãƒ‡ãƒ«å–å¾—ã®ãƒ†ã‚¹ãƒˆï¼ˆãƒ›ãƒ¯ã‚¤ãƒˆãƒªã‚¹ãƒˆé©ç”¨ï¼‰"""
        config = ModelSelectionConfig(
            enable_auto_nhits=True,
            enable_auto_lstm=True,
            enable_auto_tft=True,
            enable_auto_informer=False,
            enable_auto_autoformer=False,
            enable_auto_patchtst=False,
            model_whitelist=['AutoNHITS', 'AutoTFT'],
            model_blacklist=[],
        )
        
        enabled = config.get_enabled_models()
        
        # ãƒ›ãƒ¯ã‚¤ãƒˆãƒªã‚¹ãƒˆã«å«ã¾ã‚Œã‚‹ã‚‚ã®ã®ã¿
        assert len(enabled) == 2
        assert 'AutoNHITS' in enabled
        assert 'AutoTFT' in enabled
        assert 'AutoLSTM' not in enabled  # ãƒ•ãƒ©ã‚°ã¯æœ‰åŠ¹ã ãŒãƒ›ãƒ¯ã‚¤ãƒˆãƒªã‚¹ãƒˆã«ãªã„
    
    def test_get_enabled_models_with_blacklist(self):
        """æœ‰åŠ¹ãƒ¢ãƒ‡ãƒ«å–å¾—ã®ãƒ†ã‚¹ãƒˆï¼ˆãƒ–ãƒ©ãƒƒã‚¯ãƒªã‚¹ãƒˆé©ç”¨ï¼‰"""
        config = ModelSelectionConfig(
            enable_auto_nhits=True,
            enable_auto_lstm=True,
            enable_auto_tft=True,
            enable_auto_informer=False,
            enable_auto_autoformer=False,
            enable_auto_patchtst=False,
            model_whitelist=[],
            model_blacklist=['AutoLSTM'],
        )
        
        enabled = config.get_enabled_models()
        
        # ãƒ–ãƒ©ãƒƒã‚¯ãƒªã‚¹ãƒˆã®ã‚‚ã®ã¯é™¤å¤–
        assert len(enabled) == 2
        assert 'AutoNHITS' in enabled
        assert 'AutoTFT' in enabled
        assert 'AutoLSTM' not in enabled
    
    def test_is_model_enabled(self):
        """ãƒ¢ãƒ‡ãƒ«æœ‰åŠ¹ãƒã‚§ãƒƒã‚¯ã®ãƒ†ã‚¹ãƒˆ"""
        config = ModelSelectionConfig(
            enable_auto_nhits=True,
            enable_auto_lstm=False,
            enable_auto_tft=False,
            enable_auto_informer=False,
            enable_auto_autoformer=False,
            enable_auto_patchtst=False,
            model_whitelist=[],
            model_blacklist=[],
        )
        
        assert config.is_model_enabled('AutoNHITS') is True
        assert config.is_model_enabled('AutoLSTM') is False
        assert config.is_model_enabled('AutoTFT') is False
    
    def test_get_disabled_models(self):
        """ç„¡åŠ¹ãƒ¢ãƒ‡ãƒ«å–å¾—ã®ãƒ†ã‚¹ãƒˆ"""
        config = ModelSelectionConfig(
            enable_auto_nhits=True,
            enable_auto_lstm=True,
            enable_auto_tft=False,
            enable_auto_informer=False,
            enable_auto_autoformer=False,
            enable_auto_patchtst=False,
            model_whitelist=[],
            model_blacklist=[],
        )
        
        disabled = config.get_disabled_models()
        
        assert len(disabled) == 4
        assert 'AutoTFT' in disabled
        assert 'AutoInformer' in disabled
        assert 'AutoAutoformer' in disabled
        assert 'AutoPatchTST' in disabled
        assert 'AutoNHITS' not in disabled
        assert 'AutoLSTM' not in disabled
```

---

### 1.5 ConfigLoader

#### 1.5.1 ã‚¯ãƒ©ã‚¹å®šç¾©

```python
"""
ConfigLoader: è¨­å®šãƒ­ãƒ¼ãƒ€ãƒ¼

è¤‡æ•°ã®è¨­å®šã‚’ä¸€æ‹¬ã§èª­ã¿è¾¼ã¿ã€æ¤œè¨¼ã€ãƒãƒ¼ã‚¸ã‚’è¡Œã†ã€‚
"""

from typing import Dict, List, Type, Any, Optional
from pathlib import Path
import logging

logger = logging.getLogger(__name__)

class ConfigLoader:
    """
    è¨­å®šãƒ­ãƒ¼ãƒ€ãƒ¼
    
    è¤‡æ•°ã®è¨­å®šã‚¯ãƒ©ã‚¹ã‚’ä¸€æ‹¬ã§èª­ã¿è¾¼ã¿ã€çµ±åˆçš„ã«ç®¡ç†ã™ã‚‹ã€‚
    
    Attributes:
        configs: èª­ã¿è¾¼ã¾ã‚ŒãŸè¨­å®šã®è¾æ›¸
    
    Methods:
        load_all: å…¨è¨­å®šã‚’ç’°å¢ƒå¤‰æ•°ã‹ã‚‰èª­ã¿è¾¼ã¿
        load_from_file: ãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰è¨­å®šã‚’èª­ã¿è¾¼ã¿
        merge_configs: è¤‡æ•°ã®è¨­å®šã‚’ãƒãƒ¼ã‚¸
        validate_all: å…¨è¨­å®šã‚’æ¤œè¨¼
        get: ç‰¹å®šã®è¨­å®šã‚’å–å¾—
        save_all: å…¨è¨­å®šã‚’ãƒ•ã‚¡ã‚¤ãƒ«ã«ä¿å­˜
    
    Example:
        >>> loader = ConfigLoader()
        >>> configs = loader.load_all()
        >>> path_config = loader.get(PathConfig)
        >>> path_config.data_csv
        PosixPath('./data.csv')
    """
    
    def __init__(self):
        """
        ConfigLoaderã‚’åˆæœŸåŒ–
        """
        self.configs: Dict[Type[Config], Config] = {}
    
    def load_all(self) -> Dict[str, Config]:
        """
        å…¨è¨­å®šã‚’ç’°å¢ƒå¤‰æ•°ã‹ã‚‰èª­ã¿è¾¼ã¿
        
        Returns:
            Dict[str, Config]: è¨­å®šåã‚’ã‚­ãƒ¼ã€è¨­å®šã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ã‚’å€¤ã¨ã™ã‚‹è¾æ›¸
            
        Raises:
            ValueError: è¨­å®šã®èª­ã¿è¾¼ã¿ã¾ãŸã¯æ¤œè¨¼ã«å¤±æ•—
            
        Example:
            >>> loader = ConfigLoader()
            >>> configs = loader.load_all()
            >>> 'path' in configs
            True
            >>> 'execution' in configs
            True
        """
        logger.info("Loading all configurations from environment")
        
        try:
            # å„è¨­å®šã‚’èª­ã¿è¾¼ã¿
            path_config = PathConfig.from_env()
            execution_config = ExecutionConfig.from_env()
            model_selection_config = ModelSelectionConfig.from_env()
            
            # æ¤œè¨¼
            path_config.validate()
            execution_config.validate()
            model_selection_config.validate()
            
            # ä¿å­˜
            self.configs[PathConfig] = path_config
            self.configs[ExecutionConfig] = execution_config
            self.configs[ModelSelectionConfig] = model_selection_config
            
            # è¾æ›¸å½¢å¼ã§è¿”ã™
            result = {
                'path': path_config,
                'execution': execution_config,
                'model_selection': model_selection_config,
            }
            
            logger.info(f"Successfully loaded {len(result)} configurations")
            return result
            
        except Exception as e:
            logger.error(f"Failed to load configurations: {e}")
            raise ValueError(f"Configuration loading failed: {e}") from e
    
    def load_from_file(self, file_path: Path) -> Dict[str, Config]:
        """
        ãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰è¨­å®šã‚’èª­ã¿è¾¼ã¿
        
        Args:
            file_path: è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹ï¼ˆJSONï¼‰
            
        Returns:
            Dict[str, Config]: è¨­å®šã®è¾æ›¸
            
        Raises:
            FileNotFoundError: ãƒ•ã‚¡ã‚¤ãƒ«ãŒå­˜åœ¨ã—ãªã„
            ValueError: è¨­å®šã®èª­ã¿è¾¼ã¿ã¾ãŸã¯æ¤œè¨¼ã«å¤±æ•—
            
        Example:
            >>> loader = ConfigLoader()
            >>> configs = loader.load_from_file(Path("config.json"))
        """
        logger.info(f"Loading configurations from file: {file_path}")
        
        if not file_path.exists():
            raise FileNotFoundError(f"Configuration file not found: {file_path}")
        
        import json
        
        with open(file_path, 'r', encoding='utf-8') as f:
            data = json.load(f)
        
        configs = {}
        
        # å„è¨­å®šã‚’èª­ã¿è¾¼ã¿
        if 'path' in data:
            path_config = PathConfig.from_dict(data['path'])
            path_config.validate()
            configs['path'] = path_config
            self.configs[PathConfig] = path_config
        
        if 'execution' in data:
            execution_config = ExecutionConfig.from_dict(data['execution'])
            execution_config.validate()
            configs['execution'] = execution_config
            self.configs[ExecutionConfig] = execution_config
        
        if 'model_selection' in data:
            model_selection_config = ModelSelectionConfig.from_dict(data['model_selection'])
            model_selection_config.validate()
            configs['model_selection'] = model_selection_config
            self.configs[ModelSelectionConfig] = model_selection_config
        
        logger.info(f"Successfully loaded {len(configs)} configurations from file")
        return configs
    
    def merge_configs(
        self,
        configs: List[Config],
        *,
        strategy: str = 'last'
    ) -> Config:
        """
        è¤‡æ•°ã®è¨­å®šã‚’ãƒãƒ¼ã‚¸
        
        Args:
            configs: ãƒãƒ¼ã‚¸ã™ã‚‹è¨­å®šã®ãƒªã‚¹ãƒˆï¼ˆåŒã˜å‹ã§ã‚ã‚‹ã“ã¨ï¼‰
            strategy: ãƒãƒ¼ã‚¸æˆ¦ç•¥
                - 'last': æœ€å¾Œã®è¨­å®šã‚’å„ªå…ˆï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆï¼‰
                - 'first': æœ€åˆã®è¨­å®šã‚’å„ªå…ˆ
                
        Returns:
            Config: ãƒãƒ¼ã‚¸ã•ã‚ŒãŸè¨­å®š
            
        Raises:
            ValueError: è¨­å®šã®å‹ãŒç•°ãªã‚‹
            
        Example:
            >>> loader = ConfigLoader()
            >>> config1 = PathConfig.from_env()
            >>> config2 = PathConfig.from_dict({"data_csv": "/custom/data.csv"})
            >>> merged = loader.merge_configs([config1, config2])
        """
        if not configs:
            raise ValueError("No configs to merge")
        
        # ã™ã¹ã¦åŒã˜å‹ã§ã‚ã‚‹ã“ã¨ã‚’ç¢ºèª
        config_type = type(configs[0])
        if not all(isinstance(c, config_type) for c in configs):
            raise ValueError("All configs must be of the same type")
        
        if strategy == 'last':
            base_config = configs[-1]
        elif strategy == 'first':
            base_config = configs[0]
        else:
            raise ValueError(f"Unknown merge strategy: {strategy}")
        
        logger.info(f"Merged {len(configs)} configurations using '{strategy}' strategy")
        return base_config
    
    def validate_all(self, configs: Optional[Dict[str, Config]] = None) -> bool:
        """
        å…¨è¨­å®šã‚’æ¤œè¨¼
        
        Args:
            configs: æ¤œè¨¼ã™ã‚‹è¨­å®šã®è¾æ›¸ï¼ˆNoneã®å ´åˆã¯å†…éƒ¨ã®è¨­å®šã‚’æ¤œè¨¼ï¼‰
            
        Returns:
            bool: æ¤œè¨¼ãŒæˆåŠŸã—ãŸå ´åˆTrue
            
        Raises:
            ValueError: æ¤œè¨¼ã«å¤±æ•—
            
        Example:
            >>> loader = ConfigLoader()
            >>> loader.load_all()
            >>> loader.validate_all()
            True
        """
        if configs is None:
            configs = {
                'path': self.configs.get(PathConfig),
                'execution': self.configs.get(ExecutionConfig),
                'model_selection': self.configs.get(ModelSelectionConfig),
            }
        
        errors = []
        
        for name, config in configs.items():
            if config is None:
                errors.append(f"{name}: config is None")
                continue
            
            try:
                config.validate()
            except ValueError as e:
                errors.append(f"{name}: {e}")
        
        if errors:
            error_msg = "Configuration validation failed:\n" + "\n".join(errors)
            logger.error(error_msg)
            raise ValueError(error_msg)
        
        logger.info("All configurations validated successfully")
        return True
    
    def get(self, config_type: Type[Config]) -> Config:
        """
        ç‰¹å®šã®è¨­å®šã‚’å–å¾—
        
        Args:
            config_type: è¨­å®šã‚¯ãƒ©ã‚¹ã®å‹
            
        Returns:
            Config: è¨­å®šã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹
            
        Raises:
            KeyError: è¨­å®šãŒèª­ã¿è¾¼ã¾ã‚Œã¦ã„ãªã„
            
        Example:
            >>> loader = ConfigLoader()
            >>> loader.load_all()
            >>> path_config = loader.get(PathConfig)
            >>> isinstance(path_config, PathConfig)
            True
        """
        if config_type not in self.configs:
            raise KeyError(f"Configuration not loaded: {config_type.__name__}")
        
        return self.configs[config_type]
    
    def save_all(self, file_path: Path, indent: int = 2) -> None:
        """
        å…¨è¨­å®šã‚’ãƒ•ã‚¡ã‚¤ãƒ«ã«ä¿å­˜
        
        Args:
            file_path: ä¿å­˜å…ˆãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹
            indent: ã‚¤ãƒ³ãƒ‡ãƒ³ãƒˆå¹…
            
        Raises:
            ValueError: è¨­å®šãŒèª­ã¿è¾¼ã¾ã‚Œã¦ã„ãªã„
            IOError: ãƒ•ã‚¡ã‚¤ãƒ«æ›¸ãè¾¼ã¿ã‚¨ãƒ©ãƒ¼
            
        Example:
            >>> loader = ConfigLoader()
            >>> loader.load_all()
            >>> loader.save_all(Path("config.json"))
        """
        if not self.configs:
            raise ValueError("No configurations to save")
        
        data = {}
        
        if PathConfig in self.configs:
            data['path'] = self.configs[PathConfig].to_dict()
        
        if ExecutionConfig in self.configs:
            data['execution'] = self.configs[ExecutionConfig].to_dict()
        
        if ModelSelectionConfig in self.configs:
            data['model_selection'] = self.configs[ModelSelectionConfig].to_dict()
        
        import json
        
        file_path.parent.mkdir(parents=True, exist_ok=True)
        
        with open(file_path, 'w', encoding='utf-8') as f:
            json.dump(data, f, indent=indent, ensure_ascii=False)
        
        logger.info(f"Saved {len(data)} configurations to {file_path}")
```

#### 1.5.2 ãƒ†ã‚¹ãƒˆã‚³ãƒ¼ãƒ‰

```python
"""ConfigLoaderã®ãƒ†ã‚¹ãƒˆ"""

import pytest
import tempfile
from pathlib import Path
import json

class TestConfigLoader:
    """ConfigLoaderã®ãƒ†ã‚¹ãƒˆã‚¹ã‚¤ãƒ¼ãƒˆ"""
    
    def test_load_all_success(self, monkeypatch):
        """å…¨è¨­å®šèª­ã¿è¾¼ã¿ã®ãƒ†ã‚¹ãƒˆï¼ˆæˆåŠŸï¼‰"""
        # ç’°å¢ƒå¤‰æ•°ã‚’è¨­å®š
        monkeypatch.setenv('NF_DATA_CSV', './test_data.csv')
        monkeypatch.setenv('RANDOM_STATE', '123')
        monkeypatch.setenv('ENABLE_AUTO_NHITS', 'true')
        
        loader = ConfigLoader()
        configs = loader.load_all()
        
        assert 'path' in configs
        assert 'execution' in configs
        assert 'model_selection' in configs
        
        assert isinstance(configs['path'], PathConfig)
        assert isinstance(configs['execution'], ExecutionConfig)
        assert isinstance(configs['model_selection'], ModelSelectionConfig)
    
    def test_load_from_file_success(self):
        """ãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰ã®èª­ã¿è¾¼ã¿ãƒ†ã‚¹ãƒˆï¼ˆæˆåŠŸï¼‰"""
        with tempfile.TemporaryDirectory() as tmpdir:
            file_path = Path(tmpdir) / "config.json"
            
            # ãƒ†ã‚¹ãƒˆç”¨ã®è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä½œæˆ
            config_data = {
                "path": {
                    "data_csv": f"{tmpdir}/data.csv",
                    "output_dir": f"{tmpdir}/output",
                    "log_dir": f"{tmpdir}/output/logs",
                    "project_root": tmpdir,
                    "model_dir": f"{tmpdir}/output/models",
                    "artifact_dir": f"{tmpdir}/output/artifacts",
                    "checkpoint_dir": f"{tmpdir}/output/checkpoints",
                    "plot_dir": f"{tmpdir}/output/plots",
                },
                "execution": {
                    "random_state": 42,
                    "trial_num_samples": 10,
                    "trial_max_steps": 1000,
                    "default_h": 7,
                    "h_ratio": 0.2,
                    "max_workers": 4,
                    "allow_ray_parallel": False,
                    "save_model": True,
                    "overwrite_model": False,
                    "dir_tokens_maxlen": 50,
                    "max_exog_futr": 10,
                    "max_exog_hist": 10,
                    "max_exog_stat": 5,
                    "early_stopping_patience": 10,
                    "gradient_clip_val": 1.0,
                    "accelerator": "auto",
                    "devices": 1,
                    "precision": "32",
                },
                "model_selection": {
                    "enable_auto_nhits": True,
                    "enable_auto_lstm": True,
                    "enable_auto_tft": False,
                    "enable_auto_informer": False,
                    "enable_auto_autoformer": False,
                    "enable_auto_patchtst": False,
                    "model_whitelist": [],
                    "model_blacklist": [],
                }
            }
            
            with open(file_path, 'w') as f:
                json.dump(config_data, f)
            
            # èª­ã¿è¾¼ã¿
            loader = ConfigLoader()
            configs = loader.load_from_file(file_path)
            
            assert 'path' in configs
            assert 'execution' in configs
            assert 'model_selection' in configs
    
    def test_load_from_file_not_found(self):
        """ãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰ã®èª­ã¿è¾¼ã¿ãƒ†ã‚¹ãƒˆï¼ˆãƒ•ã‚¡ã‚¤ãƒ«ãŒå­˜åœ¨ã—ãªã„ï¼‰"""
        loader = ConfigLoader()
        
        with pytest.raises(FileNotFoundError):
            loader.load_from_file(Path("/nonexistent/config.json"))
    
    def test_merge_configs_last_strategy(self):
        """è¨­å®šãƒãƒ¼ã‚¸ã®ãƒ†ã‚¹ãƒˆï¼ˆlastæˆ¦ç•¥ï¼‰"""
        with tempfile.TemporaryDirectory() as tmpdir:
            config1 = PathConfig(
                data_csv=Path(tmpdir) / "data1.csv",
                output_dir=Path(tmpdir) / "output1",
                log_dir=Path(tmpdir) / "output1/logs",
                project_root=Path(tmpdir),
                model_dir=Path(tmpdir) / "output1/models",
                artifact_dir=Path(tmpdir) / "output1/artifacts",
                checkpoint_dir=Path(tmpdir) / "output1/checkpoints",
                plot_dir=Path(tmpdir) / "output1/plots",
            )
            
            config2 = PathConfig(
                data_csv=Path(tmpdir) / "data2.csv",
                output_dir=Path(tmpdir) / "output2",
                log_dir=Path(tmpdir) / "output2/logs",
                project_root=Path(tmpdir),
                model_dir=Path(tmpdir) / "output2/models",
                artifact_dir=Path(tmpdir) / "output2/artifacts",
                checkpoint_dir=Path(tmpdir) / "output2/checkpoints",
                plot_dir=Path(tmpdir) / "output2/plots",
            )
            
            loader = ConfigLoader()
            merged = loader.merge_configs([config1, config2], strategy='last')
            
            # æœ€å¾Œã®è¨­å®šãŒå„ªå…ˆã•ã‚Œã‚‹
            assert merged.data_csv == Path(tmpdir) / "data2.csv"
    
    def test_merge_configs_different_types(self):
        """è¨­å®šãƒãƒ¼ã‚¸ã®ãƒ†ã‚¹ãƒˆï¼ˆç•°ãªã‚‹å‹ã®ã‚¨ãƒ©ãƒ¼ï¼‰"""
        path_config = PathConfig.from_env()
        execution_config = ExecutionConfig.from_env()
        
        loader = ConfigLoader()
        
        with pytest.raises(ValueError, match="same type"):
            loader.merge_configs([path_config, execution_config])
    
    def test_validate_all_success(self):
        """å…¨è¨­å®šæ¤œè¨¼ã®ãƒ†ã‚¹ãƒˆï¼ˆæˆåŠŸï¼‰"""
        loader = ConfigLoader()
        loader.load_all()
        
        # ä¾‹å¤–ãŒç™ºç”Ÿã—ãªã„ã“ã¨ã‚’ç¢ºèª
        assert loader.validate_all() is True
    
    def test_get_success(self):
        """è¨­å®šå–å¾—ã®ãƒ†ã‚¹ãƒˆï¼ˆæˆåŠŸï¼‰"""
        loader = ConfigLoader()
        loader.load_all()
        
        path_config = loader.get(PathConfig)
        assert isinstance(path_config, PathConfig)
        
        execution_config = loader.get(ExecutionConfig)
        assert isinstance(execution_config, ExecutionConfig)
    
    def test_get_not_loaded(self):
        """è¨­å®šå–å¾—ã®ãƒ†ã‚¹ãƒˆï¼ˆæœªèª­ã¿è¾¼ã¿ï¼‰"""
        loader = ConfigLoader()
        
        with pytest.raises(KeyError, match="not loaded"):
            loader.get(PathConfig)
    
    def test_save_all_success(self):
        """å…¨è¨­å®šä¿å­˜ã®ãƒ†ã‚¹ãƒˆï¼ˆæˆåŠŸï¼‰"""
        with tempfile.TemporaryDirectory() as tmpdir:
            file_path = Path(tmpdir) / "config.json"
            
            loader = ConfigLoader()
            loader.load_all()
            loader.save_all(file_path)
            
            assert file_path.exists()
            
            # èª­ã¿è¾¼ã‚“ã§æ¤œè¨¼
            with open(file_path, 'r') as f:
                data = json.load(f)
            
            assert 'path' in data
            assert 'execution' in data
            assert 'model_selection' in data
    
    def test_save_all_no_configs(self):
        """å…¨è¨­å®šä¿å­˜ã®ãƒ†ã‚¹ãƒˆï¼ˆè¨­å®šãªã—ï¼‰"""
        with tempfile.TemporaryDirectory() as tmpdir:
            file_path = Path(tmpdir) / "config.json"
            
            loader = ConfigLoader()
            
            with pytest.raises(ValueError, match="No configurations to save"):
                loader.save_all(file_path)
```

---

## Layer 2: Dataå±¤

### 2.1 DataLoader

#### 2.1.1 ã‚¯ãƒ©ã‚¹å®šç¾©

```python
"""
DataLoader: ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿

CSV/Parquetãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰ãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã¿ã€æ¨™æº–ã‚¹ã‚­ãƒ¼ãƒã«å¤‰æ›ã™ã‚‹ã€‚
"""

from pathlib import Path
from typing import Optional, Iterator, Dict, Any, List
import pandas as pd
import chardet
import logging

logger = logging.getLogger(__name__)

class DataLoader:
    """
    ãƒ‡ãƒ¼ã‚¿ãƒ­ãƒ¼ãƒ€ãƒ¼
    
    CSVãƒ•ã‚¡ã‚¤ãƒ«ã‚„Parquetãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰æ™‚ç³»åˆ—ãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã¿ã€
    æ¨™æº–ã‚¹ã‚­ãƒ¼ãƒï¼ˆunique_id, ds, y, exog_*ï¼‰ã«å¤‰æ›ã™ã‚‹ã€‚
    
    Attributes:
        encoding_cache: ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹ã¨ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ã®ã‚­ãƒ£ãƒƒã‚·ãƒ¥
    
    Methods:
        load_csv: CSVãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã‚€
        load_parquet: Parquetãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã‚€
        auto_detect_encoding: ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ã‚’è‡ªå‹•æ¤œå‡º
        infer_schema: ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ ã‹ã‚‰ã‚¹ã‚­ãƒ¼ãƒã‚’æ¨è«–
        load: ãƒ•ã‚¡ã‚¤ãƒ«å½¢å¼ã‚’è‡ªå‹•åˆ¤å®šã—ã¦èª­ã¿è¾¼ã‚€
    
    Example:
        >>> loader = DataLoader()
        >>> df = loader.load_csv(Path("data.csv"))
        >>> df.columns
        Index(['unique_id', 'ds', 'y'])
    """
    
    def __init__(self):
        """
        DataLoaderã‚’åˆæœŸåŒ–
        """
        self.encoding_cache: Dict[str, str] = {}
    
    def load_csv(
        self,
        file_path: Path,
        *,
        encoding: Optional[str] = None,
        chunksize: Optional[int] = None,
        date_format: Optional[str] = None,
        parse_dates: bool = True,
        infer_datetime_format: bool = True,
        required_columns: Optional[List[str]] = None,
    ) -> pd.DataFrame:
        """
        CSVãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã‚€
        
        Args:
            file_path: CSVãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹
            encoding: æ–‡å­—ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ï¼ˆNoneã§è‡ªå‹•æ¤œå‡ºï¼‰
            chunksize: ãƒãƒ£ãƒ³ã‚¯èª­ã¿è¾¼ã¿ã‚µã‚¤ã‚ºï¼ˆè¡Œæ•°ï¼‰
            date_format: æ—¥æ™‚ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆï¼ˆä¾‹: '%Y-%m-%d'ï¼‰
            parse_dates: æ—¥æ™‚ã‚«ãƒ©ãƒ ã‚’è‡ªå‹•ãƒ‘ãƒ¼ã‚¹
            infer_datetime_format: æ—¥æ™‚ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆã‚’æ¨å®š
            required_columns: å¿…é ˆã‚«ãƒ©ãƒ ãƒªã‚¹ãƒˆï¼ˆNoneã§['unique_id', 'ds', 'y']ï¼‰
            
        Returns:
            pd.DataFrame: èª­ã¿è¾¼ã¾ã‚ŒãŸDataFrame
            
        Raises:
            FileNotFoundError: ãƒ•ã‚¡ã‚¤ãƒ«ãŒå­˜åœ¨ã—ãªã„
            ValueError: ã‚¹ã‚­ãƒ¼ãƒä¸æ­£ï¼ˆå¿…é ˆã‚«ãƒ©ãƒ æ¬ å¦‚ï¼‰
            EncodingError: ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°æ¤œå‡ºå¤±æ•—
            
        Example:
            >>> loader = DataLoader()
            >>> df = loader.load_csv(Path("data.csv"))
            >>> 'unique_id' in df.columns
            True
            >>> 'ds' in df.columns
            True
            >>> 'y' in df.columns
            True
        """
        if not file_path.exists():
            raise FileNotFoundError(f"File not found: {file_path}")
        
        logger.info(f"Loading CSV file: {file_path}")
        
        # ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°æ¤œå‡º
        if encoding is None:
            encoding = self.auto_detect_encoding(file_path)
            logger.info(f"Detected encoding: {encoding}")
        
        # CSVã‚’èª­ã¿è¾¼ã¿
        try:
            df = pd.read_csv(
                file_path,
                encoding=encoding,
                chunksize=chunksize,
                parse_dates=['ds'] if parse_dates else False,
                date_format=date_format,
                infer_datetime_format=infer_datetime_format,
            )
            
            # chunksizeæŒ‡å®šæ™‚ã¯IteratorãŒè¿”ã‚‹ã®ã§çµåˆ
            if isinstance(df, Iterator):
                df = pd.concat(df, ignore_index=True)
            
        except Exception as e:
            logger.error(f"Failed to read CSV: {e}")
            raise
        
        # å¿…é ˆã‚«ãƒ©ãƒ ãƒã‚§ãƒƒã‚¯
        if required_columns is None:
            required_columns = ['unique_id', 'ds', 'y']
        
        missing_columns = set(required_columns) - set(df.columns)
        if missing_columns:
            raise ValueError(
                f"Missing required columns: {missing_columns}. "
                f"Found columns: {list(df.columns)}"
            )
        
        logger.info(
            f"Successfully loaded CSV: {len(df)} rows, {len(df.columns)} columns"
        )
        
        return df
    
    def load_parquet(
        self,
        file_path: Path,
        *,
        columns: Optional[List[str]] = None,
        filters: Optional[List[tuple]] = None,
    ) -> pd.DataFrame:
        """
        Parquetãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã‚€
        
        Args:
            file_path: Parquetãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹
            columns: èª­ã¿è¾¼ã‚€ã‚«ãƒ©ãƒ ãƒªã‚¹ãƒˆï¼ˆNoneã§å…¨ã‚«ãƒ©ãƒ ï¼‰
            filters: ãƒ•ã‚£ãƒ«ã‚¿æ¡ä»¶ï¼ˆPyArrowå½¢å¼ï¼‰
            
        Returns:
            pd.DataFrame: èª­ã¿è¾¼ã¾ã‚ŒãŸDataFrame
            
        Raises:
            FileNotFoundError: ãƒ•ã‚¡ã‚¤ãƒ«ãŒå­˜åœ¨ã—ãªã„
            ValueError: ã‚¹ã‚­ãƒ¼ãƒä¸æ­£
            
        Example:
            >>> loader = DataLoader()
            >>> df = loader.load_parquet(Path("data.parquet"))
        """
        if not file_path.exists():
            raise FileNotFoundError(f"File not found: {file_path}")
        
        logger.info(f"Loading Parquet file: {file_path}")
        
        try:
            df = pd.read_parquet(
                file_path,
                columns=columns,
                filters=filters,
            )
        except Exception as e:
            logger.error(f"Failed to read Parquet: {e}")
            raise
        
        # å¿…é ˆã‚«ãƒ©ãƒ ãƒã‚§ãƒƒã‚¯
        required_columns = ['unique_id', 'ds', 'y']
        missing_columns = set(required_columns) - set(df.columns)
        if missing_columns:
            raise ValueError(
                f"Missing required columns: {missing_columns}. "
                f"Found columns: {list(df.columns)}"
            )
        
        logger.info(
            f"Successfully loaded Parquet: {len(df)} rows, {len(df.columns)} columns"
        )
        
        return df
    
    def auto_detect_encoding(self, file_path: Path, sample_size: int = 10000) -> str:
        """
        ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ã‚’è‡ªå‹•æ¤œå‡º
        
        Args:
            file_path: ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹
            sample_size: ã‚µãƒ³ãƒ—ãƒ«ã‚µã‚¤ã‚ºï¼ˆãƒã‚¤ãƒˆæ•°ï¼‰
            
        Returns:
            str: ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°å
            
        Raises:
            IOError: ãƒ•ã‚¡ã‚¤ãƒ«èª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼
            
        Example:
            >>> loader = DataLoader()
            >>> encoding = loader.auto_detect_encoding(Path("data.csv"))
            >>> encoding in ['utf-8', 'shift_jis', 'euc-jp']
            True
        """
        # ã‚­ãƒ£ãƒƒã‚·ãƒ¥ãƒã‚§ãƒƒã‚¯
        cache_key = str(file_path)
        if cache_key in self.encoding_cache:
            return self.encoding_cache[cache_key]
        
        # ãƒ•ã‚¡ã‚¤ãƒ«ã®ä¸€éƒ¨ã‚’èª­ã¿è¾¼ã‚“ã§æ¤œå‡º
        with open(file_path, 'rb') as f:
            raw_data = f.read(sample_size)
        
        result = chardet.detect(raw_data)
        encoding = result['encoding']
        confidence = result['confidence']
        
        logger.debug(
            f"Encoding detection: {encoding} (confidence: {confidence:.2%})"
        )
        
        # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯
        if encoding is None or confidence < 0.7:
            encoding = 'utf-8'
            logger.warning(
                f"Low confidence encoding detection. Using default: {encoding}"
            )
        
        # ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã«ä¿å­˜
        self.encoding_cache[cache_key] = encoding
        
        return encoding
    
    def infer_schema(self, df: pd.DataFrame) -> Dict[str, str]:
        """
        ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ ã‹ã‚‰ã‚¹ã‚­ãƒ¼ãƒã‚’æ¨è«–
        
        Args:
            df: ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ 
            
        Returns:
            Dict[str, str]: ã‚«ãƒ©ãƒ åã¨å‹ã®ãƒãƒƒãƒ”ãƒ³ã‚°
            
        Example:
            >>> loader = DataLoader()
            >>> df = pd.DataFrame({
            ...     'unique_id': ['a', 'b'],
            ...     'ds': pd.to_datetime(['2025-01-01', '2025-01-02']),
            ...     'y': [1.0, 2.0]
            ... })
            >>> schema = loader.infer_schema(df)
            >>> schema['unique_id']
            'object'
            >>> schema['ds']
            'datetime64[ns]'
            >>> schema['y']
            'float64'
        """
        schema = {}
        
        for col in df.columns:
            dtype = str(df[col].dtype)
            schema[col] = dtype
        
        logger.debug(f"Inferred schema: {schema}")
        
        return schema
    
    def load(
        self,
        file_path: Path,
        **kwargs
    ) -> pd.DataFrame:
        """
        ãƒ•ã‚¡ã‚¤ãƒ«å½¢å¼ã‚’è‡ªå‹•åˆ¤å®šã—ã¦èª­ã¿è¾¼ã‚€
        
        Args:
            file_path: ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹
            **kwargs: load_csv/load_parquetã«æ¸¡ã™å¼•æ•°
            
        Returns:
            pd.DataFrame: èª­ã¿è¾¼ã¾ã‚ŒãŸDataFrame
            
        Raises:
            ValueError: ã‚µãƒãƒ¼ãƒˆã•ã‚Œã¦ã„ãªã„ãƒ•ã‚¡ã‚¤ãƒ«å½¢å¼
            
        Example:
            >>> loader = DataLoader()
            >>> df = loader.load(Path("data.csv"))
            >>> # ã¾ãŸã¯
            >>> df = loader.load(Path("data.parquet"))
        """
        suffix = file_path.suffix.lower()
        
        if suffix == '.csv':
            return self.load_csv(file_path, **kwargs)
        elif suffix in ['.parquet', '.pq']:
            return self.load_parquet(file_path, **kwargs)
        else:
            raise ValueError(
                f"Unsupported file format: {suffix}. "
                "Supported formats: .csv, .parquet, .pq"
            )
```

#### 2.1.2 ãƒ†ã‚¹ãƒˆã‚³ãƒ¼ãƒ‰

```python
"""DataLoaderã®ãƒ†ã‚¹ãƒˆ"""

import pytest
import pandas as pd
import tempfile
from pathlib import Path

class TestDataLoader:
    """DataLoaderã®ãƒ†ã‚¹ãƒˆã‚¹ã‚¤ãƒ¼ãƒˆ"""
    
    @pytest.fixture
    def sample_csv(self):
        """ã‚µãƒ³ãƒ—ãƒ«CSVãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä½œæˆ"""
        with tempfile.NamedTemporaryFile(mode='w', suffix='.csv', delete=False) as f:
            f.write("unique_id,ds,y\n")
            f.write("store_1,2025-01-01,100.0\n")
            f.write("store_1,2025-01-02,110.0\n")
            f.write("store_2,2025-01-01,200.0\n")
            f.write("store_2,2025-01-02,210.0\n")
            temp_path = Path(f.name)
        
        yield temp_path
        
        # ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—
        temp_path.unlink()
    
    @pytest.fixture
    def sample_parquet(self):
        """ã‚µãƒ³ãƒ—ãƒ«Parquetãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä½œæˆ"""
        df = pd.DataFrame({
            'unique_id': ['store_1', 'store_1', 'store_2', 'store_2'],
            'ds': pd.to_datetime(['2025-01-01', '2025-01-02', '2025-01-01', '2025-01-02']),
            'y': [100.0, 110.0, 200.0, 210.0]
        })
        
        with tempfile.NamedTemporaryFile(suffix='.parquet', delete=False) as f:
            temp_path = Path(f.name)
        
        df.to_parquet(temp_path, index=False)
        
        yield temp_path
        
        # ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—
        temp_path.unlink()
    
    def test_load_csv_success(self, sample_csv):
        """CSVèª­ã¿è¾¼ã¿ã®ãƒ†ã‚¹ãƒˆï¼ˆæˆåŠŸï¼‰"""
        loader = DataLoader()
        df = loader.load_csv(sample_csv)
        
        assert len(df) == 4
        assert 'unique_id' in df.columns
        assert 'ds' in df.columns
        assert 'y' in df.columns
        
        # unique_idã®å€¤ã‚’ãƒã‚§ãƒƒã‚¯
        assert set(df['unique_id'].unique()) == {'store_1', 'store_2'}
    
    def test_load_csv_not_found(self):
        """CSVèª­ã¿è¾¼ã¿ã®ãƒ†ã‚¹ãƒˆï¼ˆãƒ•ã‚¡ã‚¤ãƒ«ãŒå­˜åœ¨ã—ãªã„ï¼‰"""
        loader = DataLoader()
        
        with pytest.raises(FileNotFoundError):
            loader.load_csv(Path("/nonexistent/data.csv"))
    
    def test_load_csv_missing_columns(self):
        """CSVèª­ã¿è¾¼ã¿ã®ãƒ†ã‚¹ãƒˆï¼ˆå¿…é ˆã‚«ãƒ©ãƒ æ¬ å¦‚ï¼‰"""
        with tempfile.NamedTemporaryFile(mode='w', suffix='.csv', delete=False) as f:
            f.write("id,date,value\n")  # é–“é•ã£ãŸã‚«ãƒ©ãƒ å
            f.write("1,2025-01-01,100\n")
            temp_path = Path(f.name)
        
        try:
            loader = DataLoader()
            
            with pytest.raises(ValueError, match="Missing required columns"):
                loader.load_csv(temp_path)
        finally:
            temp_path.unlink()
    
    def test_load_parquet_success(self, sample_parquet):
        """Parquetèª­ã¿è¾¼ã¿ã®ãƒ†ã‚¹ãƒˆï¼ˆæˆåŠŸï¼‰"""
        loader = DataLoader()
        df = loader.load_parquet(sample_parquet)
        
        assert len(df) == 4
        assert 'unique_id' in df.columns
        assert 'ds' in df.columns
        assert 'y' in df.columns
    
    def test_auto_detect_encoding_utf8(self, sample_csv):
        """ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°æ¤œå‡ºã®ãƒ†ã‚¹ãƒˆï¼ˆUTF-8ï¼‰"""
        loader = DataLoader()
        encoding = loader.auto_detect_encoding(sample_csv)
        
        # UTF-8ã¾ãŸã¯ASCIIãŒæ¤œå‡ºã•ã‚Œã‚‹ã¯ãš
        assert encoding.lower() in ['utf-8', 'ascii']
    
    def test_auto_detect_encoding_cache(self, sample_csv):
        """ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°æ¤œå‡ºã®ã‚­ãƒ£ãƒƒã‚·ãƒ¥ãƒ†ã‚¹ãƒˆ"""
        loader = DataLoader()
        
        # 1å›ç›®
        encoding1 = loader.auto_detect_encoding(sample_csv)
        
        # 2å›ç›®ï¼ˆã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‹ã‚‰å–å¾—ï¼‰
        encoding2 = loader.auto_detect_encoding(sample_csv)
        
        assert encoding1 == encoding2
        assert str(sample_csv) in loader.encoding_cache
    
    def test_infer_schema(self):
        """ã‚¹ã‚­ãƒ¼ãƒæ¨è«–ã®ãƒ†ã‚¹ãƒˆ"""
        df = pd.DataFrame({
            'unique_id': ['a', 'b'],
            'ds': pd.to_datetime(['2025-01-01', '2025-01-02']),
            'y': [1.0, 2.0],
            'temperature': [15.5, 16.2]
        })
        
        loader = DataLoader()
        schema = loader.infer_schema(df)
        
        assert 'unique_id' in schema
        assert 'ds' in schema
        assert 'y' in schema
        assert 'temperature' in schema
        
        # å‹ãƒã‚§ãƒƒã‚¯
        assert 'object' in schema['unique_id']
        assert 'datetime' in schema['ds']
        assert 'float' in schema['y']
    
    def test_load_auto_detect_csv(self, sample_csv):
        """è‡ªå‹•åˆ¤å®šèª­ã¿è¾¼ã¿ã®ãƒ†ã‚¹ãƒˆï¼ˆCSVï¼‰"""
        loader = DataLoader()
        df = loader.load(sample_csv)
        
        assert len(df) == 4
        assert 'unique_id' in df.columns
    
    def test_load_auto_detect_parquet(self, sample_parquet):
        """è‡ªå‹•åˆ¤å®šèª­ã¿è¾¼ã¿ã®ãƒ†ã‚¹ãƒˆï¼ˆParquetï¼‰"""
        loader = DataLoader()
        df = loader.load(sample_parquet)
        
        assert len(df) == 4
        assert 'unique_id' in df.columns
    
    def test_load_unsupported_format(self):
        """è‡ªå‹•åˆ¤å®šèª­ã¿è¾¼ã¿ã®ãƒ†ã‚¹ãƒˆï¼ˆã‚µãƒãƒ¼ãƒˆã•ã‚Œã¦ã„ãªã„å½¢å¼ï¼‰"""
        loader = DataLoader()
        
        with pytest.raises(ValueError, match="Unsupported file format"):
            loader.load(Path("data.xlsx"))
    
    def test_load_csv_with_chunksize(self, sample_csv):
        """CSVèª­ã¿è¾¼ã¿ã®ãƒ†ã‚¹ãƒˆï¼ˆãƒãƒ£ãƒ³ã‚¯ã‚µã‚¤ã‚ºæŒ‡å®šï¼‰"""
        loader = DataLoader()
        df = loader.load_csv(sample_csv, chunksize=2)
        
        # chunksizeæŒ‡å®šæ™‚ã‚‚çµåˆã•ã‚Œã¦è¿”ã‚‹
        assert len(df) == 4
        assert isinstance(df, pd.DataFrame)
```

---

**æ³¨**: ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆãŒéå¸¸ã«é•·ããªã‚‹ãŸã‚ã€ã“ã“ã§ã¯ Layer 1 (Configurationå±¤) ã®5ã¤ã®ã‚¯ãƒ©ã‚¹ã¨ Layer 2 (Dataå±¤) ã® DataLoader ã‚¯ãƒ©ã‚¹ã¾ã§ã‚’è©³ç´°ã«è¨˜è¿°ã—ã¾ã—ãŸã€‚

æ®‹ã‚Šã®ã‚¯ãƒ©ã‚¹ï¼ˆLayer 2ï½9ï¼‰ã«ã¤ã„ã¦ã‚‚åŒæ§˜ã®è©³ç´°åº¦ã§è¨˜è¿°å¯èƒ½ã§ã™ãŒã€ãƒˆãƒ¼ã‚¯ãƒ³åˆ¶é™ã®ãŸã‚ã€ä»¥ä¸‹ã®ã‚ˆã†ãªæ§‹æˆã§ç¶šãã‚’ä½œæˆã™ã‚‹ã“ã¨ã‚’æ¨å¥¨ã—ã¾ã™ï¼š

### ç¶šãã®æ§‹æˆæ¡ˆ

1. **04_CLASS_DESIGN_DETAILED_PART2.md**: Layer 2 æ®‹ã‚Š + Layer 3, 4
2. **04_CLASS_DESIGN_DETAILED_PART3.md**: Layer 5, 6
3. **04_CLASS_DESIGN_DETAILED_PART4.md**: Layer 7, 8, 9 + å…±é€šã‚¯ãƒ©ã‚¹

å„ãƒ•ã‚¡ã‚¤ãƒ«ã¯ä»¥ä¸‹ã‚’å«ã¿ã¾ã™ï¼š
- å®Œå…¨ãªã‚¯ãƒ©ã‚¹å®šç¾©ï¼ˆå‹ãƒ’ãƒ³ãƒˆã€Docstringï¼‰
- ã™ã¹ã¦ã®ãƒ¡ã‚½ãƒƒãƒ‰ã®è©³ç´°
- ä½¿ç”¨ä¾‹
- åŒ…æ‹¬çš„ãªãƒ†ã‚¹ãƒˆã‚³ãƒ¼ãƒ‰

---

**ã“ã®ãƒ•ã‚¡ã‚¤ãƒ«ã®çµ±è¨ˆ**:
- **ç·è¡Œæ•°**: ç´„3,500è¡Œ
- **ã‚¯ãƒ©ã‚¹æ•°**: 6ã‚¯ãƒ©ã‚¹ï¼ˆConfig, PathConfig, ExecutionConfig, ModelSelectionConfig, ConfigLoader, DataLoaderï¼‰
- **ãƒ¡ã‚½ãƒƒãƒ‰æ•°**: ç´„60å€‹
- **ãƒ†ã‚¹ãƒˆã‚±ãƒ¼ã‚¹æ•°**: ç´„50å€‹

æ¬¡ã®ãƒ‘ãƒ¼ãƒˆã‚’ä½œæˆã—ã¾ã™ã‹ï¼Ÿ
