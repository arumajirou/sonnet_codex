# ğŸ“– 11_OPERATIONS_RUNBOOK.md - é‹ç”¨æ‰‹é †æ›¸

**Time Series Forecasting System - Operations Runbook**

---

## ğŸ“‹ ç›®æ¬¡

1. [æ¦‚è¦](#1-æ¦‚è¦)
2. [ã‚·ã‚¹ãƒ†ãƒ æ¦‚è¦](#2-ã‚·ã‚¹ãƒ†ãƒ æ¦‚è¦)
3. [æ—¥å¸¸é‹ç”¨ã‚¿ã‚¹ã‚¯](#3-æ—¥å¸¸é‹ç”¨ã‚¿ã‚¹ã‚¯)
4. [ã‚·ã‚¹ãƒ†ãƒ ç›£è¦–](#4-ã‚·ã‚¹ãƒ†ãƒ ç›£è¦–)
5. [éšœå®³å¯¾å¿œæ‰‹é †](#5-éšœå®³å¯¾å¿œæ‰‹é †)
6. [ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°](#6-ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°)
7. [ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°æ‰‹é †](#7-ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°æ‰‹é †)
8. [ãƒ¡ãƒ³ãƒ†ãƒŠãƒ³ã‚¹ä½œæ¥­](#8-ãƒ¡ãƒ³ãƒ†ãƒŠãƒ³ã‚¹ä½œæ¥­)
9. [ã‚¤ãƒ³ã‚·ãƒ‡ãƒ³ãƒˆç®¡ç†](#9-ã‚¤ãƒ³ã‚·ãƒ‡ãƒ³ãƒˆç®¡ç†)
10. [ã‚¨ã‚¹ã‚«ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ãƒ‘ã‚¹](#10-ã‚¨ã‚¹ã‚«ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ãƒ‘ã‚¹)
11. [ã‚ªãƒ³ã‚³ãƒ¼ãƒ«å¯¾å¿œ](#11-ã‚ªãƒ³ã‚³ãƒ¼ãƒ«å¯¾å¿œ)
12. [ãƒŠãƒ¬ãƒƒã‚¸ãƒ™ãƒ¼ã‚¹](#12-ãƒŠãƒ¬ãƒƒã‚¸ãƒ™ãƒ¼ã‚¹)
13. [ä»˜éŒ²](#13-ä»˜éŒ²)

---

## 1. æ¦‚è¦

### 1.1 ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã®ç›®çš„

æœ¬é‹ç”¨æ‰‹é †æ›¸ï¼ˆOperations Runbookï¼‰ã¯ã€æ™‚ç³»åˆ—äºˆæ¸¬ã‚·ã‚¹ãƒ†ãƒ ã®æ—¥å¸¸é‹ç”¨ã€éšœå®³å¯¾å¿œã€ãƒ¡ãƒ³ãƒ†ãƒŠãƒ³ã‚¹ä½œæ¥­ã®æ¨™æº–æ‰‹é †ã‚’æä¾›ã—ã¾ã™ã€‚

### 1.2 å¯¾è±¡èª­è€…

- **é‹ç”¨æ‹…å½“è€…**: æ—¥å¸¸ã®ã‚·ã‚¹ãƒ†ãƒ ç›£è¦–ãƒ»é‹ç”¨
- **ã‚ªãƒ³ã‚³ãƒ¼ãƒ«æ‹…å½“è€…**: éšœå®³å¯¾å¿œãƒ»ã‚¨ã‚¹ã‚«ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³
- **SREã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢**: ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ãƒ»ã‚­ãƒ£ãƒ‘ã‚·ãƒ†ã‚£ç®¡ç†
- **ãƒãƒãƒ¼ã‚¸ãƒ£ãƒ¼**: ã‚¤ãƒ³ã‚·ãƒ‡ãƒ³ãƒˆç®¡ç†ãƒ»ãƒ¬ãƒãƒ¼ãƒˆä½œæˆ

### 1.3 é–¢é€£ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆ

| ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆ | èª¬æ˜ |
|------------|------|
| `10_DEPLOYMENT_GUIDE.md` | ãƒ‡ãƒ—ãƒ­ã‚¤æ‰‹é † |
| `12_MONITORING_GUIDE.md` | ç›£è¦–è¨­å®š |
| `02_NON_FUNCTIONAL_REQUIREMENTS.md` | éæ©Ÿèƒ½è¦ä»¶ãƒ»SLO |
| `09_TESTING_STRATEGY.md` | ãƒ†ã‚¹ãƒˆæˆ¦ç•¥ |

---

## 2. ã‚·ã‚¹ãƒ†ãƒ æ¦‚è¦

### 2.1 ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£æ¦‚è¦

```mermaid
graph TB
    subgraph "Application Layer"
        API[FastAPI Server]
        CLI[CLI Interface]
        SCHEDULER[Scheduler]
    end
    
    subgraph "Processing Layer"
        EXECUTOR[Execution Engine]
        TRAINER[Model Trainer]
        PREDICTOR[Predictor]
    end
    
    subgraph "Data Layer"
        DB[(PostgreSQL)]
        CACHE[(Redis Cache)]
        STORAGE[Model Storage]
    end
    
    subgraph "Optional Services"
        MLFLOW[MLflow]
        RAY[Ray Cluster]
    end
    
    subgraph "Monitoring"
        PROM[Prometheus]
        GRAF[Grafana]
        ALERT[Alertmanager]
    end
    
    API --> EXECUTOR
    CLI --> EXECUTOR
    SCHEDULER --> EXECUTOR
    
    EXECUTOR --> TRAINER
    EXECUTOR --> PREDICTOR
    
    TRAINER --> DB
    TRAINER --> STORAGE
    TRAINER --> MLFLOW
    TRAINER --> RAY
    
    PREDICTOR --> DB
    PREDICTOR --> CACHE
    
    PROM --> API
    PROM --> DB
    GRAF --> PROM
    ALERT --> PROM
```

---

### 2.2 ä¸»è¦ã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆ

| ã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆ | å½¹å‰² | é‡è¦åº¦ | ãƒãƒ¼ãƒˆ |
|--------------|------|--------|-------|
| **FastAPI Server** | Web APIæä¾› | Critical | 8000 |
| **PostgreSQL** | ãƒ‡ãƒ¼ã‚¿æ°¸ç¶šåŒ– | Critical | 5432 |
| **Model Storage** | ãƒ¢ãƒ‡ãƒ«ãƒ•ã‚¡ã‚¤ãƒ«ä¿å­˜ | High | - |
| **MLflow** | å®Ÿé¨“ãƒˆãƒ©ãƒƒã‚­ãƒ³ã‚° | Medium | 5000 |
| **Ray Cluster** | åˆ†æ•£å®Ÿè¡Œ | Medium | 8265 |
| **Prometheus** | ãƒ¡ãƒˆãƒªã‚¯ã‚¹åé›† | High | 9090 |
| **Grafana** | ãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰ | High | 3000 |
| **Redis** | ã‚­ãƒ£ãƒƒã‚·ãƒ¥ï¼ˆå°†æ¥ï¼‰ | Low | 6379 |

---

### 2.3 ã‚µãƒ¼ãƒ“ã‚¹ãƒ¬ãƒ™ãƒ«ç›®æ¨™ï¼ˆSLOï¼‰

| æŒ‡æ¨™ | ç›®æ¨™å€¤ | æ¸¬å®šæœŸé–“ |
|-----|--------|---------|
| **æœˆé–“ç¨¼åƒç‡** | â‰¥99.0% | æœˆæ¬¡ |
| **APIæˆåŠŸç‡** | â‰¥99.9% | æœˆæ¬¡ |
| **äºˆæ¸¬ãƒ¬ã‚¤ãƒ†ãƒ³ã‚·ï¼ˆp95ï¼‰** | <500ms | æ—¥æ¬¡ |
| **å­¦ç¿’å®Œäº†ç‡** | â‰¥98% | é€±æ¬¡ |
| **MTTR** | <1æ™‚é–“ | ã‚¤ãƒ³ã‚·ãƒ‡ãƒ³ãƒˆæ¯ |

---

## 3. æ—¥å¸¸é‹ç”¨ã‚¿ã‚¹ã‚¯

### 3.1 ãƒ‡ã‚¤ãƒªãƒ¼ã‚¿ã‚¹ã‚¯

#### 3.1.1 æœã®å¥å…¨æ€§ãƒã‚§ãƒƒã‚¯ï¼ˆ9:00ï¼‰

**ãƒã‚§ãƒƒã‚¯ãƒªã‚¹ãƒˆ**:

```bash
#!/bin/bash
# daily_health_check.sh

echo "=========================================="
echo "Daily Health Check - $(date)"
echo "=========================================="

# 1. ã‚µãƒ¼ãƒ“ã‚¹çŠ¶æ…‹ç¢ºèª
echo -e "\n[1/8] Checking service status..."
systemctl status ts-forecast || docker compose ps

# 2. ãƒ‡ã‚£ã‚¹ã‚¯ä½¿ç”¨é‡ç¢ºèª
echo -e "\n[2/8] Checking disk usage..."
df -h | grep -E 'Filesystem|/data|/models|/logs'

# 3. ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹æ¥ç¶šç¢ºèª
echo -e "\n[3/8] Checking database connection..."
psql -h localhost -U postgres -d ts_forecast_system -c "SELECT 1;" > /dev/null 2>&1
if [ $? -eq 0 ]; then
    echo "âœ“ Database connection OK"
else
    echo "âœ— Database connection FAILED"
fi

# 4. APIå¥å…¨æ€§ç¢ºèª
echo -e "\n[4/8] Checking API health..."
curl -f http://localhost:8000/health > /dev/null 2>&1
if [ $? -eq 0 ]; then
    echo "âœ“ API health OK"
else
    echo "âœ— API health FAILED"
fi

# 5. ã‚¢ã‚¯ãƒ†ã‚£ãƒ–Runæ•°ç¢ºèª
echo -e "\n[5/8] Checking active runs..."
ACTIVE_RUNS=$(psql -h localhost -U postgres -d ts_forecast_system -t -c \
    "SELECT COUNT(*) FROM runs WHERE status='running';")
echo "Active runs: ${ACTIVE_RUNS}"

# 6. å‰æ—¥ã®ã‚¨ãƒ©ãƒ¼æ•°ç¢ºèª
echo -e "\n[6/8] Checking yesterday's errors..."
ERROR_COUNT=$(psql -h localhost -U postgres -d ts_forecast_system -t -c \
    "SELECT COUNT(*) FROM system_logs WHERE log_level='ERROR' AND created_at > NOW() - INTERVAL '24 hours';")
echo "Errors in last 24h: ${ERROR_COUNT}"

# 7. ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡ç¢ºèª
echo -e "\n[7/8] Checking memory usage..."
free -h

# 8. æœ€æ–°ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ç¢ºèª
echo -e "\n[8/8] Checking latest backup..."
LATEST_BACKUP=$(ls -t /backup/postgres/full_*.dump.gz 2>/dev/null | head -n1)
if [ -n "${LATEST_BACKUP}" ]; then
    echo "âœ“ Latest backup: ${LATEST_BACKUP}"
    echo "  Age: $(find ${LATEST_BACKUP} -mtime -1 2>/dev/null && echo '<24h' || echo '>24h')"
else
    echo "âœ— No backup found!"
fi

echo -e "\n=========================================="
echo "Health check completed"
echo "=========================================="
```

**å®Ÿè¡Œ**:
```bash
chmod +x /usr/local/bin/daily_health_check.sh
/usr/local/bin/daily_health_check.sh | tee /var/log/health_check_$(date +%Y%m%d).log
```

---

#### 3.1.2 ãƒ­ã‚°ç¢ºèªï¼ˆéšæ™‚ï¼‰

**ã‚¨ãƒ©ãƒ¼ãƒ­ã‚°ç¢ºèª**:

```bash
# ç›´è¿‘1æ™‚é–“ã®ã‚¨ãƒ©ãƒ¼ãƒ­ã‚°
tail -n 100 /app/logs/app/error.log

# ã¾ãŸã¯ PostgreSQLã‹ã‚‰
psql -h localhost -U postgres -d ts_forecast_system << EOF
SELECT 
    created_at,
    log_level,
    log_message,
    run_id
FROM system_logs
WHERE log_level IN ('ERROR', 'CRITICAL')
  AND created_at > NOW() - INTERVAL '1 hour'
ORDER BY created_at DESC
LIMIT 20;
EOF
```

**ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ãƒ­ã‚°ç›£è¦–**:

```bash
# ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ç›£è¦–
tail -f /app/logs/app/app.log | grep -E 'ERROR|WARNING'

# Dockerç’°å¢ƒ
docker compose logs -f app | grep -E 'ERROR|WARNING'
```

---

#### 3.1.3 å®Ÿè¡ŒçŠ¶æ³ç¢ºèªï¼ˆéšæ™‚ï¼‰

**ã‚¢ã‚¯ãƒ†ã‚£ãƒ–Runç¢ºèª**:

```sql
-- ã‚¢ã‚¯ãƒ†ã‚£ãƒ–ãªå®Ÿè¡ŒçŠ¶æ³
SELECT 
    r.run_id,
    r.run_name,
    r.status,
    r.start_time,
    NOW() - r.start_time AS duration,
    e.experiment_name
FROM runs r
JOIN experiments e ON r.experiment_id = e.experiment_id
WHERE r.status = 'running'
ORDER BY r.start_time;
```

**ã‚­ãƒ¥ãƒ¼çŠ¶æ³ç¢ºèª**:

```sql
-- ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ«æ¸ˆã¿ã ãŒæœªå®Ÿè¡Œã®Run
SELECT 
    COUNT(*) as queued_runs,
    MIN(created_at) as oldest_queued
FROM runs
WHERE status = 'scheduled';
```

---

### 3.2 ã‚¦ã‚£ãƒ¼ã‚¯ãƒªãƒ¼ã‚¿ã‚¹ã‚¯

#### 3.2.1 é€±æ¬¡ãƒ¡ãƒ³ãƒ†ãƒŠãƒ³ã‚¹ï¼ˆæ—¥æ›œæ—¥ 2:00ï¼‰

```bash
#!/bin/bash
# weekly_maintenance.sh

set -e

echo "[$(date)] Starting weekly maintenance"

# 1. ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹VACUUM
echo "[$(date)] Running VACUUM ANALYZE..."
psql -h localhost -U postgres -d ts_forecast_system -c "VACUUM ANALYZE;"

# 2. æœªä½¿ç”¨ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ç¢ºèª
echo "[$(date)] Checking unused indexes..."
psql -h localhost -U postgres -d ts_forecast_system << EOF
SELECT
    schemaname,
    tablename,
    indexname,
    idx_scan,
    pg_size_pretty(pg_relation_size(indexrelid)) AS index_size
FROM pg_stat_user_indexes
WHERE schemaname = 'public'
  AND idx_scan = 0
  AND pg_relation_size(indexrelid) > 10485760  -- 10MBä»¥ä¸Š
ORDER BY pg_relation_size(indexrelid) DESC;
EOF

# 3. ãƒ†ãƒ¼ãƒ–ãƒ«ãƒ–ãƒ­ãƒ¼ãƒˆç¢ºèª
echo "[$(date)] Checking table bloat..."
psql -h localhost -U postgres -d ts_forecast_system << EOF
SELECT
    schemaname,
    tablename,
    pg_size_pretty(pg_total_relation_size(schemaname||'.'||tablename)) AS size,
    n_live_tup AS live_rows,
    n_dead_tup AS dead_rows,
    ROUND(n_dead_tup * 100.0 / NULLIF(n_live_tup + n_dead_tup, 0), 2) AS dead_ratio
FROM pg_stat_user_tables
WHERE schemaname = 'public'
  AND n_dead_tup > 1000
ORDER BY n_dead_tup DESC
LIMIT 10;
EOF

# 4. é•·æœŸé–“å®Ÿè¡Œä¸­ã®Runç¢ºèª
echo "[$(date)] Checking long-running jobs..."
psql -h localhost -U postgres -d ts_forecast_system << EOF
SELECT 
    run_id,
    run_name,
    status,
    start_time,
    NOW() - start_time AS duration
FROM runs
WHERE status = 'running'
  AND start_time < NOW() - INTERVAL '24 hours'
ORDER BY start_time;
EOF

# 5. å¤ã„ãƒ­ã‚°ã®ã‚¢ãƒ¼ã‚«ã‚¤ãƒ–ï¼ˆ90æ—¥ä»¥ä¸Šå‰ï¼‰
echo "[$(date)] Archiving old logs..."
psql -h localhost -U postgres -d ts_forecast_system << EOF
DELETE FROM system_logs
WHERE created_at < NOW() - INTERVAL '90 days';
EOF

# 6. Materialized Viewæ›´æ–°
echo "[$(date)] Refreshing materialized views..."
psql -h localhost -U postgres -d ts_forecast_system << EOF
REFRESH MATERIALIZED VIEW CONCURRENTLY mv_experiment_summary;
REFRESH MATERIALIZED VIEW CONCURRENTLY mv_model_performance;
EOF

echo "[$(date)] Weekly maintenance completed"
```

**cronè¨­å®š**:

```bash
# crontab -e
0 2 * * 0 /usr/local/bin/weekly_maintenance.sh >> /var/log/weekly_maintenance.log 2>&1
```

---

#### 3.2.2 ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãƒ¬ãƒãƒ¼ãƒˆä½œæˆï¼ˆé‡‘æ›œæ—¥ï¼‰

```bash
#!/bin/bash
# weekly_performance_report.sh

REPORT_FILE="/var/log/reports/performance_report_$(date +%Y%m%d).txt"
mkdir -p /var/log/reports

cat > "${REPORT_FILE}" << 'EOF'
========================================
Weekly Performance Report
========================================
Report Date: $(date)

## 1. System Performance

### CPU Usage
$(top -bn1 | grep "Cpu(s)" | sed "s/.*, *\([0-9.]*\)%* id.*/\1/" | awk '{print 100 - $1"%"}')

### Memory Usage
$(free -h | grep Mem | awk '{print "Used: "$3" / Total: "$2" ("$3/$2*100"%)"}')

### Disk Usage
$(df -h | grep -E '/data|/models|/logs')

## 2. Database Performance

### Database Size
$(psql -h localhost -U postgres -d ts_forecast_system -t -c "SELECT pg_size_pretty(pg_database_size('ts_forecast_system'));")

### Top 10 Slowest Queries (Last 7 days)
$(psql -h localhost -U postgres -d ts_forecast_system -c "
SELECT 
    query,
    calls,
    mean_exec_time,
    max_exec_time
FROM pg_stat_statements
WHERE query NOT LIKE '%pg_%'
ORDER BY mean_exec_time DESC
LIMIT 10;
")

## 3. Application Performance

### Runs Summary (Last 7 days)
$(psql -h localhost -U postgres -d ts_forecast_system -c "
SELECT 
    status,
    COUNT(*) as count,
    ROUND(AVG(execution_duration_seconds), 2) as avg_duration_sec
FROM runs
WHERE start_time > NOW() - INTERVAL '7 days'
GROUP BY status;
")

### Average Training Time by Model (Last 7 days)
$(psql -h localhost -U postgres -d ts_forecast_system -c "
SELECT 
    m.model_name,
    COUNT(*) as runs,
    ROUND(AVG(m.training_duration_seconds), 2) as avg_training_sec,
    ROUND(AVG(m.model_size_bytes / 1048576.0), 2) as avg_size_mb
FROM models m
JOIN runs r ON m.run_id = r.run_id
WHERE r.start_time > NOW() - INTERVAL '7 days'
GROUP BY m.model_name
ORDER BY avg_training_sec DESC;
")

## 4. Error Summary

### Error Count by Level (Last 7 days)
$(psql -h localhost -U postgres -d ts_forecast_system -c "
SELECT 
    log_level,
    COUNT(*) as count
FROM system_logs
WHERE created_at > NOW() - INTERVAL '7 days'
  AND log_level IN ('ERROR', 'CRITICAL')
GROUP BY log_level
ORDER BY log_level;
")

========================================
End of Report
========================================
EOF

# ãƒ¬ãƒãƒ¼ãƒˆé€ä¿¡ï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰
# mail -s "Weekly Performance Report" ops@example.com < "${REPORT_FILE}"

echo "Report generated: ${REPORT_FILE}"
```

---

### 3.3 ãƒãƒ³ã‚¹ãƒªãƒ¼ã‚¿ã‚¹ã‚¯

#### 3.3.1 æœˆæ¬¡ãƒ¬ãƒ“ãƒ¥ãƒ¼ï¼ˆæ¯æœˆ1æ—¥ï¼‰

**ã‚­ãƒ£ãƒ‘ã‚·ãƒ†ã‚£ãƒ¬ãƒ“ãƒ¥ãƒ¼**:

```sql
-- æœˆæ¬¡ãƒ‡ãƒ¼ã‚¿å¢—åŠ é‡
SELECT 
    DATE_TRUNC('month', created_at) AS month,
    COUNT(*) as runs_created,
    SUM(CASE WHEN status = 'completed' THEN 1 ELSE 0 END) as completed,
    SUM(CASE WHEN status = 'failed' THEN 1 ELSE 0 END) as failed,
    ROUND(AVG(execution_duration_seconds / 60.0), 2) as avg_duration_min
FROM runs
WHERE created_at > NOW() - INTERVAL '6 months'
GROUP BY DATE_TRUNC('month', created_at)
ORDER BY month DESC;

-- ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‚µã‚¤ã‚ºãƒˆãƒ¬ãƒ³ãƒ‰
SELECT 
    pg_size_pretty(pg_database_size('ts_forecast_system')) as current_size;

-- ãƒ¢ãƒ‡ãƒ«ã‚¹ãƒˆãƒ¬ãƒ¼ã‚¸ä½¿ç”¨é‡
SELECT 
    SUM(model_size_bytes) / 1073741824.0 as total_models_gb
FROM models;
```

---

#### 3.3.2 ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£ãƒ¬ãƒ“ãƒ¥ãƒ¼

```bash
#!/bin/bash
# monthly_security_review.sh

echo "=========================================="
echo "Monthly Security Review - $(date)"
echo "=========================================="

# 1. ãƒ‘ãƒƒã‚±ãƒ¼ã‚¸è„†å¼±æ€§ã‚¹ã‚­ãƒ£ãƒ³
echo -e "\n[1/5] Running security scan..."
pip-audit --desc

# 2. ä¸å¯©ãªãƒ­ã‚°ã‚¤ãƒ³è©¦è¡Œç¢ºèª
echo -e "\n[2/5] Checking failed login attempts..."
psql -h localhost -U postgres -d ts_forecast_system << EOF
SELECT 
    DATE(created_at) as date,
    COUNT(*) as failed_logins
FROM system_logs
WHERE log_message LIKE '%authentication failed%'
  AND created_at > NOW() - INTERVAL '30 days'
GROUP BY DATE(created_at)
ORDER BY date DESC;
EOF

# 3. ç’°å¢ƒå¤‰æ•°ç¢ºèª
echo -e "\n[3/5] Checking for secrets in environment..."
env | grep -i 'password\|secret\|key' | sed 's/=.*/=***REDACTED***/'

# 4. ãƒ•ã‚¡ã‚¤ãƒ«æ¨©é™ç¢ºèª
echo -e "\n[4/5] Checking file permissions..."
find /app -type f -perm /go+w -ls | head -10

# 5. è¨¼æ˜æ›¸æœ‰åŠ¹æœŸé™ç¢ºèª
echo -e "\n[5/5] Checking SSL certificate expiry..."
echo | openssl s_client -servername ts-forecast.example.com \
    -connect ts-forecast.example.com:443 2>/dev/null | \
    openssl x509 -noout -dates

echo -e "\n=========================================="
echo "Security review completed"
echo "=========================================="
```

---

#### 3.3.3 å¤ã„ãƒ‡ãƒ¼ã‚¿ã®ã‚¢ãƒ¼ã‚«ã‚¤ãƒ–

```bash
#!/bin/bash
# monthly_archive.sh

set -e

ARCHIVE_DIR="/archive/$(date +%Y%m)"
mkdir -p "${ARCHIVE_DIR}"

echo "[$(date)] Starting monthly archive..."

# 1. 6ãƒ¶æœˆä»¥ä¸Šå‰ã®å®Œäº†Runã‚’ã‚¢ãƒ¼ã‚«ã‚¤ãƒ–
psql -h localhost -U postgres -d ts_forecast_system << EOF
COPY (
    SELECT * FROM runs
    WHERE status IN ('completed', 'failed')
      AND end_time < NOW() - INTERVAL '6 months'
) TO '${ARCHIVE_DIR}/runs_archive.csv' WITH CSV HEADER;

-- ã‚¢ãƒ¼ã‚«ã‚¤ãƒ–å¾Œå‰Šé™¤
DELETE FROM runs
WHERE status IN ('completed', 'failed')
  AND end_time < NOW() - INTERVAL '6 months';
EOF

# 2. ã‚¢ãƒ¼ã‚«ã‚¤ãƒ–ãƒ•ã‚¡ã‚¤ãƒ«ã‚’åœ§ç¸®
gzip "${ARCHIVE_DIR}/runs_archive.csv"

# 3. S3ã¸ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰
# aws s3 cp "${ARCHIVE_DIR}/runs_archive.csv.gz" \
#     "s3://ts-forecast-archive/$(date +%Y/%m)/"

echo "[$(date)] Monthly archive completed"
```

---

## 4. ã‚·ã‚¹ãƒ†ãƒ ç›£è¦–

### 4.1 ç›£è¦–ãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰

#### 4.1.1 Grafanaãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰

**ã‚¢ã‚¯ã‚»ã‚¹**: https://grafana.example.com/d/ts-forecast

**ä¸»è¦ãƒ‘ãƒãƒ«**:

1. **System Overview**
   - CPUä½¿ç”¨ç‡
   - ãƒ¡ãƒ¢ãƒªä½¿ç”¨ç‡
   - ãƒ‡ã‚£ã‚¹ã‚¯ä½¿ç”¨ç‡
   - ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯I/O

2. **Application Metrics**
   - ã‚¢ã‚¯ãƒ†ã‚£ãƒ–Runæ•°
   - å®Ÿè¡Œå®Œäº†ç‡
   - å¹³å‡å®Ÿè¡Œæ™‚é–“
   - ã‚¨ãƒ©ãƒ¼ç‡

3. **Database Metrics**
   - æ¥ç¶šæ•°
   - ã‚¯ã‚¨ãƒªãƒ¬ã‚¤ãƒ†ãƒ³ã‚·
   - ãƒˆãƒ©ãƒ³ã‚¶ã‚¯ã‚·ãƒ§ãƒ³ç‡
   - ã‚­ãƒ£ãƒƒã‚·ãƒ¥ãƒ’ãƒƒãƒˆç‡

4. **Performance Metrics**
   - APIå¿œç­”æ™‚é–“ï¼ˆp50/p95/p99ï¼‰
   - å­¦ç¿’æ™‚é–“åˆ†å¸ƒ
   - äºˆæ¸¬ãƒ¬ã‚¤ãƒ†ãƒ³ã‚·
   - ã‚¹ãƒ«ãƒ¼ãƒ—ãƒƒãƒˆ

---

#### 4.1.2 ä¸»è¦ãƒ¡ãƒˆãƒªã‚¯ã‚¹

| ãƒ¡ãƒˆãƒªã‚¯ã‚¹ | æ­£å¸¸ç¯„å›² | è­¦å‘Šé–¾å€¤ | é‡å¤§é–¾å€¤ |
|----------|---------|---------|---------|
| **CPUä½¿ç”¨ç‡** | <70% | >80% | >95% |
| **ãƒ¡ãƒ¢ãƒªä½¿ç”¨ç‡** | <75% | >85% | >95% |
| **ãƒ‡ã‚£ã‚¹ã‚¯ä½¿ç”¨ç‡** | <80% | >85% | >95% |
| **APIå¿œç­”æ™‚é–“ï¼ˆp95ï¼‰** | <500ms | >1s | >2s |
| **ã‚¨ãƒ©ãƒ¼ç‡** | <1% | >5% | >10% |
| **ã‚¢ã‚¯ãƒ†ã‚£ãƒ–Runæ•°** | <50 | >80 | >100 |
| **DBæ¥ç¶šæ•°** | <100 | >150 | >180 |

---

### 4.2 ã‚¢ãƒ©ãƒ¼ãƒˆè¨­å®š

#### 4.2.1 Critical ã‚¢ãƒ©ãƒ¼ãƒˆ

**ã‚·ã‚¹ãƒ†ãƒ ãƒ€ã‚¦ãƒ³**:

```yaml
# alertmanager/alerts/critical.yml

groups:
  - name: critical_alerts
    interval: 30s
    rules:
      - alert: ServiceDown
        expr: up{job="ts-forecast-app"} == 0
        for: 2m
        labels:
          severity: critical
        annotations:
          summary: "Service {{ $labels.instance }} is down"
          description: "{{ $labels.job }} on {{ $labels.instance }} has been down for more than 2 minutes."
      
      - alert: DatabaseDown
        expr: up{job="postgres"} == 0
        for: 1m
        labels:
          severity: critical
        annotations:
          summary: "Database is down"
          description: "PostgreSQL database is unreachable."
      
      - alert: HighErrorRate
        expr: rate(http_requests_total{status=~"5.."}[5m]) > 0.1
        for: 5m
        labels:
          severity: critical
        annotations:
          summary: "High error rate detected"
          description: "Error rate is {{ $value | humanizePercentage }} over the last 5 minutes."
```

---

#### 4.2.2 Warning ã‚¢ãƒ©ãƒ¼ãƒˆ

```yaml
groups:
  - name: warning_alerts
    interval: 1m
    rules:
      - alert: HighMemoryUsage
        expr: (node_memory_MemTotal_bytes - node_memory_MemAvailable_bytes) / node_memory_MemTotal_bytes > 0.85
        for: 10m
        labels:
          severity: warning
        annotations:
          summary: "High memory usage"
          description: "Memory usage is above 85% for more than 10 minutes."
      
      - alert: HighDiskUsage
        expr: (node_filesystem_size_bytes - node_filesystem_avail_bytes) / node_filesystem_size_bytes > 0.85
        for: 5m
        labels:
          severity: warning
        annotations:
          summary: "High disk usage"
          description: "Disk usage on {{ $labels.device }} is above 85%."
      
      - alert: LongRunningJob
        expr: time() - ts_forecast_run_start_time > 7200
        labels:
          severity: warning
        annotations:
          summary: "Long running job detected"
          description: "Run {{ $labels.run_id }} has been running for more than 2 hours."
      
      - alert: QueueBacklog
        expr: ts_forecast_queued_runs > 50
        for: 15m
        labels:
          severity: warning
        annotations:
          summary: "Job queue backlog"
          description: "There are {{ $value }} jobs waiting in the queue."
```

---

### 4.3 ãƒ­ã‚°åˆ†æ

#### 4.3.1 ã‚¨ãƒ©ãƒ¼ãƒ‘ã‚¿ãƒ¼ãƒ³æ¤œå‡º

```bash
#!/bin/bash
# analyze_errors.sh

# ç›´è¿‘24æ™‚é–“ã®ã‚¨ãƒ©ãƒ¼ãƒ‘ã‚¿ãƒ¼ãƒ³
psql -h localhost -U postgres -d ts_forecast_system << EOF
SELECT 
    exception_type,
    COUNT(*) as occurrences,
    array_agg(DISTINCT log_message ORDER BY log_message) as sample_messages
FROM system_logs
WHERE log_level = 'ERROR'
  AND created_at > NOW() - INTERVAL '24 hours'
GROUP BY exception_type
ORDER BY occurrences DESC
LIMIT 10;
EOF
```

---

#### 4.3.2 ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãƒ­ã‚°åˆ†æ

```sql
-- é…ã„Run TOP 10
SELECT 
    r.run_id,
    r.run_name,
    r.execution_duration_seconds / 60.0 as duration_minutes,
    m.model_name,
    r.start_time
FROM runs r
LEFT JOIN models m ON r.run_id = m.run_id
WHERE r.status = 'completed'
  AND r.start_time > NOW() - INTERVAL '7 days'
ORDER BY r.execution_duration_seconds DESC
LIMIT 10;

-- ãƒ¢ãƒ‡ãƒ«åˆ¥å¹³å‡å®Ÿè¡Œæ™‚é–“
SELECT 
    m.model_name,
    COUNT(*) as runs,
    ROUND(AVG(m.training_duration_seconds / 60.0), 2) as avg_training_min,
    ROUND(MIN(m.training_duration_seconds / 60.0), 2) as min_training_min,
    ROUND(MAX(m.training_duration_seconds / 60.0), 2) as max_training_min
FROM models m
JOIN runs r ON m.run_id = r.run_id
WHERE r.start_time > NOW() - INTERVAL '30 days'
  AND r.status = 'completed'
GROUP BY m.model_name
ORDER BY avg_training_min DESC;
```

---

## 5. éšœå®³å¯¾å¿œæ‰‹é †

### 5.1 éšœå®³å¯¾å¿œãƒ•ãƒ­ãƒ¼

```mermaid
graph TB
    A[ã‚¢ãƒ©ãƒ¼ãƒˆå—ä¿¡] --> B{é‡å¤§åº¦ã¯?}
    
    B -->|Critical| C[å³åº§ã«å¯¾å¿œé–‹å§‹]
    B -->|Warning| D[çŠ¶æ³ç¢ºèª]
    B -->|Info| E[è¨˜éŒ²ã®ã¿]
    
    C --> F[ã‚¤ãƒ³ã‚·ãƒ‡ãƒ³ãƒˆä½œæˆ]
    D --> G{å¯¾å¿œå¿…è¦?}
    
    G -->|Yes| F
    G -->|No| H[ç›£è¦–ç¶™ç¶š]
    
    F --> I[ä¸€æ¬¡å¯¾å¿œå®Ÿæ–½]
    I --> J{è§£æ±º?}
    
    J -->|Yes| K[ã‚¤ãƒ³ã‚·ãƒ‡ãƒ³ãƒˆã‚¯ãƒ­ãƒ¼ã‚º]
    J -->|No| L[ã‚¨ã‚¹ã‚«ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³]
    
    L --> M[å°‚é–€å®¶å¯¾å¿œ]
    M --> N{è§£æ±º?}
    
    N -->|Yes| K
    N -->|No| O[ãƒ™ãƒ³ãƒ€ãƒ¼ã‚¨ã‚¹ã‚«ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³]
    
    K --> P[äº‹å¾Œãƒ¬ãƒ“ãƒ¥ãƒ¼]
    O --> Q[é•·æœŸå¯¾å¿œ]
```

---

### 5.2 ä¸€èˆ¬çš„ãªéšœå®³ãƒ‘ã‚¿ãƒ¼ãƒ³

#### 5.2.1 ã‚µãƒ¼ãƒ“ã‚¹ãŒèµ·å‹•ã—ãªã„

**ç—‡çŠ¶**:
```
systemctl status ts-forecast
â— ts-forecast.service - Time Series Forecasting Service
   Loaded: loaded
   Active: failed (Result: exit-code)
```

**è¨ºæ–­æ‰‹é †**:

```bash
# 1. ãƒ­ã‚°ç¢ºèª
journalctl -u ts-forecast -n 50 --no-pager

# 2. è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ç¢ºèª
python -m nf_auto_runner.app.main --check-config

# 3. ä¾å­˜ã‚µãƒ¼ãƒ“ã‚¹ç¢ºèª
systemctl status postgresql
docker ps | grep postgres

# 4. ãƒãƒ¼ãƒˆç«¶åˆç¢ºèª
lsof -i :8000
```

**å¯¾å¿œæ‰‹é †**:

```bash
# Case 1: ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹æ¥ç¶šã‚¨ãƒ©ãƒ¼
# â†’ PostgreSQLèµ·å‹•ç¢ºèª
systemctl start postgresql

# Case 2: ãƒãƒ¼ãƒˆç«¶åˆ
# â†’ ç«¶åˆãƒ—ãƒ­ã‚»ã‚¹åœæ­¢
kill -9 <PID>

# Case 3: è¨­å®šã‚¨ãƒ©ãƒ¼
# â†’ è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ä¿®æ­£
vi /app/conf/config.yaml

# ã‚µãƒ¼ãƒ“ã‚¹å†èµ·å‹•
systemctl restart ts-forecast

# ç¢ºèª
systemctl status ts-forecast
curl http://localhost:8000/health
```

---

#### 5.2.2 ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹æ¥ç¶šã‚¨ãƒ©ãƒ¼

**ç—‡çŠ¶**:
```
sqlalchemy.exc.OperationalError: could not connect to server
```

**è¨ºæ–­æ‰‹é †**:

```bash
# 1. PostgreSQLç¨¼åƒç¢ºèª
systemctl status postgresql
docker ps | grep postgres

# 2. æ¥ç¶šãƒ†ã‚¹ãƒˆ
psql -h localhost -U postgres -d ts_forecast_system -c "SELECT 1;"

# 3. æ¥ç¶šæ•°ç¢ºèª
psql -h localhost -U postgres -d ts_forecast_system -c "
SELECT 
    count(*),
    state
FROM pg_stat_activity
GROUP BY state;
"

# 4. ãƒ­ãƒƒã‚¯ç¢ºèª
psql -h localhost -U postgres -d ts_forecast_system -c "
SELECT 
    pid,
    state,
    wait_event_type,
    wait_event,
    query
FROM pg_stat_activity
WHERE wait_event IS NOT NULL;
"
```

**å¯¾å¿œæ‰‹é †**:

```bash
# Case 1: PostgreSQLåœæ­¢
systemctl start postgresql

# Case 2: æ¥ç¶šãƒ—ãƒ¼ãƒ«æ¯æ¸‡
# ã‚¢ã‚¤ãƒ‰ãƒ«æ¥ç¶šã‚’å¼·åˆ¶çµ‚äº†
psql -h localhost -U postgres -d ts_forecast_system -c "
SELECT pg_terminate_backend(pid)
FROM pg_stat_activity
WHERE state = 'idle'
  AND state_change < NOW() - INTERVAL '1 hour';
"

# Case 3: ãƒ­ãƒƒã‚¯ç«¶åˆ
# ãƒ–ãƒ­ãƒƒã‚­ãƒ³ã‚°ã‚¯ã‚¨ãƒªã‚’ç‰¹å®šã—ã¦çµ‚äº†
psql -h localhost -U postgres -d ts_forecast_system -c "
SELECT pg_terminate_backend(<blocking_pid>);
"

# ç¢ºèª
curl http://localhost:8000/health
```

---

#### 5.2.3 ãƒ¡ãƒ¢ãƒªä¸è¶³

**ç—‡çŠ¶**:
```
RuntimeError: CUDA out of memory
MemoryError: Unable to allocate array
```

**è¨ºæ–­æ‰‹é †**:

```bash
# 1. ãƒ¡ãƒ¢ãƒªä½¿ç”¨çŠ¶æ³
free -h
htop

# 2. GPU ãƒ¡ãƒ¢ãƒªï¼ˆGPUä½¿ç”¨æ™‚ï¼‰
nvidia-smi

# 3. ãƒ—ãƒ­ã‚»ã‚¹ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡
ps aux --sort=-%mem | head -20

# 4. ã‚¢ã‚¯ãƒ†ã‚£ãƒ–Runæ•°
psql -h localhost -U postgres -d ts_forecast_system -c "
SELECT COUNT(*) FROM runs WHERE status='running';
"
```

**å¯¾å¿œæ‰‹é †**:

```bash
# Case 1: ãƒ¡ãƒ¢ãƒªãƒªãƒ¼ã‚¯ç–‘ã„
# â†’ ã‚µãƒ¼ãƒ“ã‚¹å†èµ·å‹•
systemctl restart ts-forecast

# Case 2: ä¸¦åˆ—å®Ÿè¡Œæ•°éå¤š
# â†’ å®Ÿè¡Œä¸­Runã®ä¸€éƒ¨ã‚’åœæ­¢
psql -h localhost -U postgres -d ts_forecast_system -c "
UPDATE runs 
SET status='cancelled', 
    end_time=NOW() 
WHERE status='running' 
  AND run_id IN (
    SELECT run_id FROM runs WHERE status='running' ORDER BY start_time DESC LIMIT 5
  );
"

# Case 3: GPU ãƒ¡ãƒ¢ãƒªä¸è¶³
# â†’ GPU ãƒ¡ãƒ¢ãƒªã‚¯ãƒªã‚¢
python << EOF
import torch
torch.cuda.empty_cache()
EOF

# ç’°å¢ƒå¤‰æ•°èª¿æ•´
export GPU_MEMORY_LIMIT=0.7
export MAX_PARALLEL_RUNS=2

systemctl restart ts-forecast
```

---

#### 5.2.4 ãƒ‡ã‚£ã‚¹ã‚¯å®¹é‡ä¸è¶³

**ç—‡çŠ¶**:
```
OSError: [Errno 28] No space left on device
```

**è¨ºæ–­æ‰‹é †**:

```bash
# 1. ãƒ‡ã‚£ã‚¹ã‚¯ä½¿ç”¨çŠ¶æ³
df -h

# 2. å¤§ããªãƒ•ã‚¡ã‚¤ãƒ«ç‰¹å®š
du -h --max-depth=2 /app | sort -hr | head -20

# 3. ãƒ­ã‚°ã‚µã‚¤ã‚ºç¢ºèª
du -sh /app/logs/*

# 4. ãƒ¢ãƒ‡ãƒ«ã‚µã‚¤ã‚ºç¢ºèª
du -sh /app/models/*
```

**å¯¾å¿œæ‰‹é †**:

```bash
# Case 1: ãƒ­ã‚°ãƒ•ã‚¡ã‚¤ãƒ«è‚¥å¤§åŒ–
# â†’ å¤ã„ãƒ­ã‚°å‰Šé™¤
find /app/logs -name "*.log" -mtime +30 -delete
find /app/logs -name "*.log.*" -mtime +7 -delete

# Case 2: ãƒ¢ãƒ‡ãƒ«ãƒ•ã‚¡ã‚¤ãƒ«è“„ç©
# â†’ å¤ã„ãƒ¢ãƒ‡ãƒ«å‰Šé™¤
find /app/models -name "*.pth" -mtime +90 -delete

# Case 3: ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹è‚¥å¤§åŒ–
# â†’ VACUUMå®Ÿè¡Œ
psql -h localhost -U postgres -d ts_forecast_system -c "VACUUM FULL;"

# Case 4: ç·Šæ€¥å¯¾å¿œ
# â†’ tmpãƒ•ã‚¡ã‚¤ãƒ«å‰Šé™¤
find /tmp -type f -atime +7 -delete

# ç¢ºèª
df -h
```

---

#### 5.2.5 APIå¿œç­”é…å»¶

**ç—‡çŠ¶**:
```
API response time p95 > 2s
```

**è¨ºæ–­æ‰‹é †**:

```bash
# 1. CPU/ãƒ¡ãƒ¢ãƒªç¢ºèª
top
htop

# 2. ã‚¢ã‚¯ãƒ†ã‚£ãƒ–æ¥ç¶šæ•°
curl http://localhost:8000/metrics | grep http_requests_in_progress

# 3. ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹é…å»¶
psql -h localhost -U postgres -d ts_forecast_system -c "
SELECT 
    query,
    state,
    NOW() - query_start AS duration
FROM pg_stat_activity
WHERE state != 'idle'
ORDER BY duration DESC
LIMIT 10;
"

# 4. ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ãƒ¬ã‚¤ãƒ†ãƒ³ã‚·
ping -c 10 <database_host>
```

**å¯¾å¿œæ‰‹é †**:

```bash
# Case 1: ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‚¹ãƒ­ãƒ¼ã‚¯ã‚¨ãƒª
# â†’ EXPLAIN ANALYZEã§åˆ†æ
psql -h localhost -U postgres -d ts_forecast_system -c "
EXPLAIN ANALYZE <slow_query>;
"

# ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹è¿½åŠ æ¤œè¨
psql -h localhost -U postgres -d ts_forecast_system -c "
CREATE INDEX CONCURRENTLY idx_<table>_<column> ON <table>(<column>);
"

# Case 2: CPUé«˜è² è·
# â†’ ãƒ¯ãƒ¼ã‚«ãƒ¼æ•°å‰Šæ¸›
export MAX_PARALLEL_RUNS=2
systemctl restart ts-forecast

# Case 3: ã‚­ãƒ£ãƒƒã‚·ãƒ¥ãƒŸã‚¹
# â†’ ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹çµ±è¨ˆæ›´æ–°
psql -h localhost -U postgres -d ts_forecast_system -c "ANALYZE;"

# ç¢ºèª
curl -w "@curl-format.txt" -o /dev/null -s http://localhost:8000/health
```

---

### 5.3 éšœå®³å¾©æ—§æ‰‹é †

#### 5.3.1 ã‚µãƒ¼ãƒ“ã‚¹å†èµ·å‹•æ‰‹é †

```bash
#!/bin/bash
# service_restart.sh

set -e

echo "[$(date)] Starting service restart procedure..."

# 1. ç¾åœ¨ã®çŠ¶æ…‹ç¢ºèª
echo "[$(date)] Checking current status..."
systemctl status ts-forecast || true

# 2. ã‚°ãƒ¬ãƒ¼ã‚¹ãƒ•ãƒ«åœæ­¢ï¼ˆ30ç§’ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆï¼‰
echo "[$(date)] Stopping service gracefully..."
systemctl stop ts-forecast || true
sleep 5

# 3. ãƒ—ãƒ­ã‚»ã‚¹å¼·åˆ¶çµ‚äº†ï¼ˆå¿…è¦ãªå ´åˆï¼‰
if pgrep -f "nf_auto_runner" > /dev/null; then
    echo "[$(date)] Force killing remaining processes..."
    pkill -9 -f "nf_auto_runner"
    sleep 2
fi

# 4. ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—
echo "[$(date)] Cleaning up..."
rm -f /var/run/ts-forecast.pid
rm -f /tmp/ts-forecast-*.sock

# 5. ã‚µãƒ¼ãƒ“ã‚¹èµ·å‹•
echo "[$(date)] Starting service..."
systemctl start ts-forecast

# 6. èµ·å‹•ç¢ºèª
echo "[$(date)] Waiting for service to be ready..."
for i in {1..30}; do
    if curl -f http://localhost:8000/health > /dev/null 2>&1; then
        echo "[$(date)] Service is healthy"
        exit 0
    fi
    echo "Attempt $i/30..."
    sleep 2
done

echo "[$(date)] ERROR: Service failed to start"
systemctl status ts-forecast
exit 1
```

---

#### 5.3.2 ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹å¾©æ—§æ‰‹é †

```bash
#!/bin/bash
# database_recovery.sh

set -e

echo "[$(date)] Starting database recovery..."

# 1. ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ãƒ•ã‚¡ã‚¤ãƒ«ç¢ºèª
LATEST_BACKUP=$(ls -t /backup/postgres/full_*.dump.gz | head -n1)
if [ -z "${LATEST_BACKUP}" ]; then
    echo "ERROR: No backup found"
    exit 1
fi

echo "[$(date)] Using backup: ${LATEST_BACKUP}"

# 2. ç¾åœ¨ã®DBãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ï¼ˆå¿µã®ãŸã‚ï¼‰
echo "[$(date)] Creating safety backup..."
pg_dump -h localhost -U postgres -d ts_forecast_system \
    -Fc -f /tmp/safety_backup_$(date +%Y%m%d_%H%M%S).dump

# 3. ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³åœæ­¢
echo "[$(date)] Stopping application..."
systemctl stop ts-forecast

# 4. ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹å‰Šé™¤ãƒ»å†ä½œæˆ
echo "[$(date)] Dropping and recreating database..."
psql -h localhost -U postgres << EOF
SELECT pg_terminate_backend(pid)
FROM pg_stat_activity
WHERE datname = 'ts_forecast_system'
  AND pid != pg_backend_pid();

DROP DATABASE IF EXISTS ts_forecast_system;
CREATE DATABASE ts_forecast_system;
EOF

# 5. ãƒªã‚¹ãƒˆã‚¢
echo "[$(date)] Restoring database..."
gunzip -c "${LATEST_BACKUP}" | \
    pg_restore -h localhost -U postgres -d ts_forecast_system -Fc

# 6. çµ±è¨ˆæƒ…å ±æ›´æ–°
echo "[$(date)] Analyzing database..."
psql -h localhost -U postgres -d ts_forecast_system -c "ANALYZE;"

# 7. ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³èµ·å‹•
echo "[$(date)] Starting application..."
systemctl start ts-forecast

# 8. ç¢ºèª
echo "[$(date)] Verifying recovery..."
sleep 10
curl -f http://localhost:8000/health

echo "[$(date)] Database recovery completed successfully"
```

---

## 6. ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°

### 6.1 ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°

#### 6.1.1 ã‚¹ãƒ­ãƒ¼ã‚¯ã‚¨ãƒªæœ€é©åŒ–

```sql
-- 1. ã‚¹ãƒ­ãƒ¼ã‚¯ã‚¨ãƒªç‰¹å®š
SELECT 
    query,
    calls,
    total_exec_time,
    mean_exec_time,
    max_exec_time
FROM pg_stat_statements
WHERE query NOT LIKE '%pg_%'
ORDER BY mean_exec_time DESC
LIMIT 20;

-- 2. EXPLAIN ANALYZEã§åˆ†æ
EXPLAIN (ANALYZE, BUFFERS) 
SELECT * FROM runs WHERE status = 'running';

-- 3. ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹å€™è£œç¢ºèª
SELECT 
    schemaname,
    tablename,
    attname,
    n_distinct,
    correlation
FROM pg_stats
WHERE schemaname = 'public'
  AND tablename = 'runs'
ORDER BY n_distinct DESC;

-- 4. ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ä½œæˆï¼ˆCONCURRENTLYï¼‰
CREATE INDEX CONCURRENTLY idx_runs_status_start_time 
    ON runs(status, start_time DESC);
```

---

#### 6.1.2 æ¥ç¶šãƒ—ãƒ¼ãƒ«è¨­å®šæœ€é©åŒ–

```python
# src/nf_auto_runner/db/connection.py

from sqlalchemy import create_engine
from sqlalchemy.pool import QueuePool
import os

# æœ€é©ãªè¨­å®š
engine = create_engine(
    os.getenv('DATABASE_URL'),
    poolclass=QueuePool,
    pool_size=20,              # åŸºæœ¬æ¥ç¶šæ•°: CPUæ•° * 2
    max_overflow=40,           # è¿½åŠ æ¥ç¶šæ•°: pool_size * 2
    pool_timeout=30,           # ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆ: 30ç§’
    pool_recycle=3600,         # æ¥ç¶šå†åˆ©ç”¨: 1æ™‚é–“
    pool_pre_ping=True,        # æ¥ç¶šãƒã‚§ãƒƒã‚¯æœ‰åŠ¹åŒ–
    echo=False
)
```

---

### 6.2 ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°

#### 6.2.1 ä¸¦åˆ—å®Ÿè¡Œæ•°ã®èª¿æ•´

```bash
# CPU boundå‡¦ç†
export MAX_PARALLEL_RUNS=$(nproc)  # CPUæ•°

# GPU boundå‡¦ç†
export MAX_PARALLEL_RUNS=2  # GPUæ•° * 1-2

# ãƒ¡ãƒ¢ãƒª boundå‡¦ç†
TOTAL_MEM_GB=$(free -g | awk '/^Mem:/{print $2}')
AVG_MEM_PER_RUN_GB=4
export MAX_PARALLEL_RUNS=$((TOTAL_MEM_GB / AVG_MEM_PER_RUN_GB))

echo "Optimal MAX_PARALLEL_RUNS: ${MAX_PARALLEL_RUNS}"
```

---

#### 6.2.2 ã‚­ãƒ£ãƒƒã‚·ãƒ³ã‚°æˆ¦ç•¥

```python
# è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã‚­ãƒ£ãƒƒã‚·ãƒ³ã‚°
from functools import lru_cache
from pathlib import Path
import yaml

@lru_cache(maxsize=1)
def load_config(config_path: Path) -> dict:
    """è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã—ã¦èª­ã¿è¾¼ã¿"""
    with open(config_path) as f:
        return yaml.safe_load(f)

# ãƒ‡ãƒ¼ã‚¿ã‚­ãƒ£ãƒƒã‚·ãƒ³ã‚°ï¼ˆRedisä½¿ç”¨ä¾‹ï¼‰
import redis
import pickle

cache = redis.Redis(host='localhost', port=6379, db=0)

def get_or_compute(key: str, compute_fn, ttl: int = 3600):
    """ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‹ã‚‰å–å¾—ã€ãªã‘ã‚Œã°è¨ˆç®—"""
    cached = cache.get(key)
    if cached:
        return pickle.loads(cached)
    
    result = compute_fn()
    cache.setex(key, ttl, pickle.dumps(result))
    return result
```

---

### 6.3 ã‚·ã‚¹ãƒ†ãƒ ãƒ¬ãƒ™ãƒ«ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°

#### 6.3.1 ã‚«ãƒ¼ãƒãƒ«ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿èª¿æ•´

```bash
# /etc/sysctl.conf

# ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯æ€§èƒ½å‘ä¸Š
net.core.somaxconn = 1024
net.core.netdev_max_backlog = 5000
net.ipv4.tcp_max_syn_backlog = 2048
net.ipv4.tcp_fin_timeout = 30

# ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‡ã‚£ã‚¹ã‚¯ãƒªãƒ—ã‚¿
fs.file-max = 2097152

# å…±æœ‰ãƒ¡ãƒ¢ãƒªï¼ˆPostgreSQLç”¨ï¼‰
kernel.shmmax = 17179869184  # 16GB
kernel.shmall = 4194304

# é©ç”¨
sudo sysctl -p
```

---

#### 6.3.2 ulimitè¨­å®š

```bash
# /etc/security/limits.conf

# ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‡ã‚£ã‚¹ã‚¯ãƒªãƒ—ã‚¿
*  soft  nofile  65536
*  hard  nofile  65536

# ãƒ—ãƒ­ã‚»ã‚¹æ•°
*  soft  nproc   32768
*  hard  nproc   32768

# ã‚³ã‚¢ãƒ€ãƒ³ãƒ—ã‚µã‚¤ã‚º
*  soft  core    0
*  hard  core    0
```

---

## 7. ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°æ‰‹é †

### 7.1 å‚ç›´ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°ï¼ˆScale Upï¼‰

#### 7.1.1 ãƒªã‚½ãƒ¼ã‚¹è¿½åŠ æ‰‹é †

```bash
#!/bin/bash
# scale_up.sh

# 1. ç¾åœ¨ã®ãƒªã‚½ãƒ¼ã‚¹ç¢ºèª
echo "Current resources:"
echo "CPU: $(nproc) cores"
echo "Memory: $(free -h | awk '/^Mem:/{print $2}')"
echo "Disk: $(df -h / | awk 'NR==2{print $2}')"

# 2. ã‚µãƒ¼ãƒ“ã‚¹åœæ­¢
echo "Stopping service..."
systemctl stop ts-forecast

# 3. ãƒªã‚½ãƒ¼ã‚¹èª¿æ•´ï¼ˆä¾‹ï¼šãƒ¡ãƒ¢ãƒªï¼‰
# â†’ ã‚¯ãƒ©ã‚¦ãƒ‰ã‚³ãƒ³ã‚½ãƒ¼ãƒ«ã§ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ã‚¿ã‚¤ãƒ—å¤‰æ›´

# 4. è¨­å®šæ›´æ–°
# PostgreSQLè¨­å®šæ›´æ–°
NEW_MEM_GB=$(free -g | awk '/^Mem:/{print $2}')
SHARED_BUFFERS=$((NEW_MEM_GB * 1024 / 4))  # ãƒ¡ãƒ¢ãƒªã®25%

sudo tee -a /etc/postgresql/14/main/postgresql.conf << EOF
shared_buffers = ${SHARED_BUFFERS}MB
effective_cache_size = $((SHARED_BUFFERS * 3))MB
EOF

# ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³è¨­å®šæ›´æ–°
export MAX_PARALLEL_RUNS=$(nproc)

# 5. ã‚µãƒ¼ãƒ“ã‚¹èµ·å‹•
echo "Starting services..."
systemctl restart postgresql
systemctl start ts-forecast

# 6. ç¢ºèª
echo "Verifying..."
curl -f http://localhost:8000/health
```

---

### 7.2 æ°´å¹³ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°ï¼ˆScale Outï¼‰

#### 7.2.1 ãƒ¯ãƒ¼ã‚«ãƒ¼ãƒãƒ¼ãƒ‰è¿½åŠ 

```bash
#!/bin/bash
# add_worker_node.sh

# 1. æ–°ãƒãƒ¼ãƒ‰ã®æº–å‚™
NEW_NODE=$1
if [ -z "${NEW_NODE}" ]; then
    echo "Usage: $0 <new_node_hostname>"
    exit 1
fi

# 2. ã‚½ãƒ•ãƒˆã‚¦ã‚§ã‚¢ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«
ssh ${NEW_NODE} << 'EOF'
# Pythonç’°å¢ƒã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—
sudo apt update
sudo apt install -y python3.11 python3.11-venv

# ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ãƒ‡ãƒ—ãƒ­ã‚¤
git clone https://github.com/your-org/ts-forecast.git
cd ts-forecast
python3.11 -m venv .venv
source .venv/bin/activate
pip install -r requirements.txt
EOF

# 3. è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«è»¢é€
scp /app/.env ${NEW_NODE}:/app/.env
scp /app/conf/config.yaml ${NEW_NODE}:/app/conf/config.yaml

# 4. ãƒ¯ãƒ¼ã‚«ãƒ¼ãƒ¢ãƒ¼ãƒ‰èµ·å‹•
ssh ${NEW_NODE} << 'EOF'
cd ts-forecast
source .venv/bin/activate

# Rayãƒ¯ãƒ¼ã‚«ãƒ¼ã¨ã—ã¦èµ·å‹•
ray start --address='ray-head:6379' \
    --num-cpus=$(nproc) \
    --num-gpus=$(nvidia-smi --list-gpus | wc -l)
EOF

# 5. ç¢ºèª
ray status
```

---

#### 7.2.2 ãƒ­ãƒ¼ãƒ‰ãƒãƒ©ãƒ³ã‚µãƒ¼è¨­å®š

```nginx
# /etc/nginx/conf.d/ts-forecast.conf

upstream ts_forecast_backend {
    least_conn;  # æœ€å°æ¥ç¶šæ•°æ–¹å¼
    
    server app1.example.com:8000 max_fails=3 fail_timeout=30s;
    server app2.example.com:8000 max_fails=3 fail_timeout=30s;
    server app3.example.com:8000 max_fails=3 fail_timeout=30s;
    
    keepalive 32;
}

server {
    listen 80;
    server_name ts-forecast.example.com;
    
    location / {
        proxy_pass http://ts_forecast_backend;
        proxy_http_version 1.1;
        proxy_set_header Connection "";
        proxy_set_header Host $host;
        proxy_set_header X-Real-IP $remote_addr;
        proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
        proxy_set_header X-Forwarded-Proto $scheme;
        
        # ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆè¨­å®š
        proxy_connect_timeout 60s;
        proxy_send_timeout 60s;
        proxy_read_timeout 60s;
    }
    
    location /health {
        access_log off;
        proxy_pass http://ts_forecast_backend/health;
    }
}
```

---

### 7.3 ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°

#### 7.3.1 Read Replicaè¿½åŠ 

```bash
#!/bin/bash
# add_read_replica.sh

REPLICA_HOST=$1
MASTER_HOST="localhost"

# 1. ãƒã‚¹ã‚¿ãƒ¼ã§ãƒ™ãƒ¼ã‚¹ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—
ssh ${MASTER_HOST} << 'EOF'
# WALã‚¢ãƒ¼ã‚«ã‚¤ãƒ–æœ‰åŠ¹åŒ–
psql -U postgres -c "ALTER SYSTEM SET wal_level = replica;"
psql -U postgres -c "ALTER SYSTEM SET archive_mode = on;"
psql -U postgres -c "ALTER SYSTEM SET max_wal_senders = 10;"
systemctl restart postgresql

# ãƒ¬ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ãƒ¦ãƒ¼ã‚¶ãƒ¼ä½œæˆ
psql -U postgres << EOSQL
CREATE USER replicator WITH REPLICATION ENCRYPTED PASSWORD 'repl_password';
EOSQL

# ãƒ™ãƒ¼ã‚¹ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—
pg_basebackup -h localhost -U replicator \
    -D /tmp/replica_backup \
    -Fp -Xs -P -R
EOSQL
EOF

# 2. ãƒ¬ãƒ—ãƒªã‚«ãƒãƒ¼ãƒ‰ã«ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—è»¢é€
rsync -av ${MASTER_HOST}:/tmp/replica_backup/ ${REPLICA_HOST}:/var/lib/postgresql/14/main/

# 3. ãƒ¬ãƒ—ãƒªã‚«èµ·å‹•
ssh ${REPLICA_HOST} << 'EOF'
chown -R postgres:postgres /var/lib/postgresql/14/main
systemctl start postgresql
EOF

# 4. ãƒ¬ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ç¢ºèª
psql -h ${MASTER_HOST} -U postgres -c "SELECT * FROM pg_stat_replication;"
```

---

## 8. ãƒ¡ãƒ³ãƒ†ãƒŠãƒ³ã‚¹ä½œæ¥­

### 8.1 è¨ˆç”»ãƒ¡ãƒ³ãƒ†ãƒŠãƒ³ã‚¹

#### 8.1.1 ãƒ¡ãƒ³ãƒ†ãƒŠãƒ³ã‚¹è¨ˆç”»ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆ

```markdown
# ãƒ¡ãƒ³ãƒ†ãƒŠãƒ³ã‚¹è¨ˆç”»æ›¸

## åŸºæœ¬æƒ…å ±
- **æ—¥æ™‚**: 2025-11-10 02:00-06:00 JST
- **æ‹…å½“è€…**: SRE Team
- **å½±éŸ¿ç¯„å›²**: å…¨ã‚µãƒ¼ãƒ“ã‚¹åœæ­¢
- **é€šçŸ¥**: 1é€±é–“å‰ã€3æ—¥å‰ã€1æ—¥å‰

## ä½œæ¥­å†…å®¹
1. ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ãƒ¡ã‚¸ãƒ£ãƒ¼ã‚¢ãƒƒãƒ—ã‚°ãƒ¬ãƒ¼ãƒ‰ï¼ˆPostgreSQL 14 â†’ 15ï¼‰
2. OSã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£ãƒ‘ãƒƒãƒé©ç”¨
3. ã‚¹ãƒˆãƒ¬ãƒ¼ã‚¸æ‹¡å¼µ

## ä½œæ¥­æ‰‹é †
### äº‹å‰æº–å‚™
- [ ] ãƒ•ãƒ«ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—å–å¾—
- [ ] ãƒ­ãƒ¼ãƒ«ãƒãƒƒã‚¯æ‰‹é †ç¢ºèª
- [ ] é€šçŸ¥é€ä¿¡

### ä½œæ¥­å®Ÿæ–½
- [ ] ã‚µãƒ¼ãƒ“ã‚¹åœæ­¢
- [ ] ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‚¢ãƒƒãƒ—ã‚°ãƒ¬ãƒ¼ãƒ‰
- [ ] OSãƒ‘ãƒƒãƒé©ç”¨
- [ ] ã‚µãƒ¼ãƒ“ã‚¹èµ·å‹•

### äº‹å¾Œç¢ºèª
- [ ] ãƒ˜ãƒ«ã‚¹ãƒã‚§ãƒƒã‚¯
- [ ] ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãƒ†ã‚¹ãƒˆ
- [ ] ãƒ¦ãƒ¼ã‚¶ãƒ¼é€šçŸ¥

## ãƒ­ãƒ¼ãƒ«ãƒãƒƒã‚¯ãƒ—ãƒ©ãƒ³
éšœå®³ç™ºç”Ÿæ™‚ã¯å³åº§ã«ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ã‹ã‚‰ãƒªã‚¹ãƒˆã‚¢

## ãƒªã‚¹ã‚¯è©•ä¾¡
- **ç™ºç”Ÿç¢ºç‡**: Low
- **å½±éŸ¿åº¦**: High
- **å¯¾ç­–**: äº‹å‰ãƒ†ã‚¹ãƒˆç’°å¢ƒã§æ¤œè¨¼æ¸ˆã¿
```

---

#### 8.1.2 ãƒ¡ãƒ³ãƒ†ãƒŠãƒ³ã‚¹ãƒ¢ãƒ¼ãƒ‰åˆ‡ã‚Šæ›¿ãˆ

```python
# scripts/maintenance_mode.py

import sys
from pathlib import Path

def enable_maintenance_mode():
    """ãƒ¡ãƒ³ãƒ†ãƒŠãƒ³ã‚¹ãƒ¢ãƒ¼ãƒ‰ã‚’æœ‰åŠ¹åŒ–"""
    maintenance_file = Path("/app/.maintenance")
    maintenance_file.touch()
    
    # NGINXè¨­å®šæ›´æ–°
    nginx_conf = """
    server {
        listen 80 default_server;
        return 503;
        
        location / {
            return 503 "Service under maintenance. We'll be back soon.";
            add_header Content-Type text/plain;
        }
    }
    """
    
    with open("/etc/nginx/sites-available/maintenance", "w") as f:
        f.write(nginx_conf)
    
    # NGINXå†èª­ã¿è¾¼ã¿
    import subprocess
    subprocess.run(["sudo", "nginx", "-s", "reload"])
    
    print("Maintenance mode enabled")


def disable_maintenance_mode():
    """ãƒ¡ãƒ³ãƒ†ãƒŠãƒ³ã‚¹ãƒ¢ãƒ¼ãƒ‰ç„¡åŠ¹åŒ–"""
    maintenance_file = Path("/app/.maintenance")
    maintenance_file.unlink(missing_ok=True)
    
    # NGINXè¨­å®šã‚’æˆ»ã™
    import subprocess
    subprocess.run(["sudo", "nginx", "-s", "reload"])
    
    print("Maintenance mode disabled")


if __name__ == "__main__":
    if len(sys.argv) != 2 or sys.argv[1] not in ["on", "off"]:
        print("Usage: python maintenance_mode.py <on|off>")
        sys.exit(1)
    
    if sys.argv[1] == "on":
        enable_maintenance_mode()
    else:
        disable_maintenance_mode()
```

---

### 8.2 ç·Šæ€¥ãƒ¡ãƒ³ãƒ†ãƒŠãƒ³ã‚¹

#### 8.2.1 ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£ãƒ‘ãƒƒãƒç·Šæ€¥é©ç”¨

```bash
#!/bin/bash
# emergency_patch.sh

set -e

PATCH_TYPE=$1  # system, python, database

echo "[$(date)] Starting emergency patch: ${PATCH_TYPE}"

# ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—
echo "[$(date)] Creating backup..."
/usr/local/bin/full_backup.sh

case "${PATCH_TYPE}" in
    system)
        # OSãƒ‘ãƒƒãƒ
        sudo apt update
        sudo apt upgrade -y
        ;;
    
    python)
        # Pythonãƒ‘ãƒƒã‚±ãƒ¼ã‚¸æ›´æ–°
        source /app/.venv/bin/activate
        pip install --upgrade $(pip list --outdated | awk 'NR>2 {print $1}')
        ;;
    
    database)
        # ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ãƒ‘ãƒƒãƒ
        sudo apt update
        sudo apt install --only-upgrade postgresql-14
        ;;
    
    *)
        echo "Unknown patch type: ${PATCH_TYPE}"
        exit 1
        ;;
esac

# ã‚µãƒ¼ãƒ“ã‚¹å†èµ·å‹•
echo "[$(date)] Restarting services..."
systemctl restart ts-forecast

# ç¢ºèª
echo "[$(date)] Verifying..."
curl -f http://localhost:8000/health

echo "[$(date)] Emergency patch completed successfully"
```

---

### 8.3 ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ãƒ¡ãƒ³ãƒ†ãƒŠãƒ³ã‚¹

#### 8.3.1 VACUUMå®Ÿè¡Œ

```bash
#!/bin/bash
# vacuum_database.sh

# é€šå¸¸VACUUMï¼ˆã‚ªãƒ³ãƒ©ã‚¤ãƒ³ï¼‰
psql -h localhost -U postgres -d ts_forecast_system << EOF
VACUUM ANALYZE;
EOF

# ãƒ†ãƒ¼ãƒ–ãƒ«å€‹åˆ¥VACUUM
psql -h localhost -U postgres -d ts_forecast_system << EOF
VACUUM ANALYZE runs;
VACUUM ANALYZE models;
VACUUM ANALYZE metrics;
EOF

# VACUUM FULLï¼ˆã‚ªãƒ•ãƒ©ã‚¤ãƒ³ã€ãƒ­ãƒƒã‚¯å¿…è¦ï¼‰
# ãƒ¡ãƒ³ãƒ†ãƒŠãƒ³ã‚¹ã‚¦ã‚£ãƒ³ãƒ‰ã‚¦ã§å®Ÿè¡Œ
psql -h localhost -U postgres -d ts_forecast_system << EOF
VACUUM FULL runs;
EOF
```

---

#### 8.3.2 ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹å†æ§‹ç¯‰

```sql
-- ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã®ãƒ–ãƒ­ãƒ¼ãƒˆç¢ºèª
SELECT 
    schemaname,
    tablename,
    indexname,
    pg_size_pretty(pg_relation_size(indexrelid)) AS index_size,
    idx_scan,
    idx_tup_read,
    idx_tup_fetch
FROM pg_stat_user_indexes
WHERE schemaname = 'public'
ORDER BY pg_relation_size(indexrelid) DESC;

-- ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹å†æ§‹ç¯‰ï¼ˆã‚ªãƒ³ãƒ©ã‚¤ãƒ³ï¼‰
REINDEX INDEX CONCURRENTLY idx_runs_status;
REINDEX INDEX CONCURRENTLY idx_models_run_id;

-- ãƒ†ãƒ¼ãƒ–ãƒ«å…¨ä½“ã®å†æ§‹ç¯‰ï¼ˆã‚ªãƒ•ãƒ©ã‚¤ãƒ³ï¼‰
REINDEX TABLE runs;
```

---

## 9. ã‚¤ãƒ³ã‚·ãƒ‡ãƒ³ãƒˆç®¡ç†

### 9.1 ã‚¤ãƒ³ã‚·ãƒ‡ãƒ³ãƒˆåˆ†é¡

| é‡è¦åº¦ | å®šç¾© | å¯¾å¿œæ™‚é–“ | ä¾‹ |
|-------|------|---------|---|
| **P0 - Critical** | å…¨ã‚µãƒ¼ãƒ“ã‚¹åœæ­¢ | å³æ™‚ | ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ãƒ€ã‚¦ãƒ³ |
| **P1 - High** | ä¸»è¦æ©Ÿèƒ½åœæ­¢ | 30åˆ†ä»¥å†… | APIå…¨ã‚¨ãƒ©ãƒ¼ |
| **P2 - Medium** | ä¸€éƒ¨æ©Ÿèƒ½å½±éŸ¿ | 2æ™‚é–“ä»¥å†… | å­¦ç¿’å‡¦ç†å¤±æ•— |
| **P3 - Low** | è»½å¾®ãªå½±éŸ¿ | 1å–¶æ¥­æ—¥ä»¥å†… | ãƒ­ã‚°å‡ºåŠ›ç•°å¸¸ |

---

### 9.2 ã‚¤ãƒ³ã‚·ãƒ‡ãƒ³ãƒˆå¯¾å¿œãƒ—ãƒ­ã‚»ã‚¹

#### 9.2.1 ã‚¤ãƒ³ã‚·ãƒ‡ãƒ³ãƒˆè¨˜éŒ²ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆ

```markdown
# ã‚¤ãƒ³ã‚·ãƒ‡ãƒ³ãƒˆãƒ¬ãƒãƒ¼ãƒˆ

## åŸºæœ¬æƒ…å ±
- **ã‚¤ãƒ³ã‚·ãƒ‡ãƒ³ãƒˆID**: INC-2025-001
- **é‡è¦åº¦**: P1 - High
- **æ¤œå‡ºæ—¥æ™‚**: 2025-11-03 14:30 JST
- **è§£æ±ºæ—¥æ™‚**: 2025-11-03 15:45 JST
- **æ‹…å½“è€…**: ops-team@example.com
- **ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹**: Resolved

## æ¦‚è¦
APIãŒ500ã‚¨ãƒ©ãƒ¼ã‚’è¿”ã—ã€äºˆæ¸¬ãƒªã‚¯ã‚¨ã‚¹ãƒˆãŒå¤±æ•—

## å½±éŸ¿ç¯„å›²
- **å½±éŸ¿ã‚µãƒ¼ãƒ“ã‚¹**: äºˆæ¸¬API
- **å½±éŸ¿ãƒ¦ãƒ¼ã‚¶ãƒ¼**: å…¨ãƒ¦ãƒ¼ã‚¶ãƒ¼
- **å¤±æ•—ãƒªã‚¯ã‚¨ã‚¹ãƒˆæ•°**: ç´„150ä»¶
- **ãƒ€ã‚¦ãƒ³ã‚¿ã‚¤ãƒ **: 75åˆ†

## ã‚¿ã‚¤ãƒ ãƒ©ã‚¤ãƒ³
| æ™‚åˆ» | ã‚¤ãƒ™ãƒ³ãƒˆ |
|-----|---------|
| 14:30 | ã‚¢ãƒ©ãƒ¼ãƒˆå—ä¿¡ï¼ˆHigh Error Rateï¼‰ |
| 14:32 | ã‚ªãƒ³ã‚³ãƒ¼ãƒ«æ‹…å½“è€…ãŒå¯¾å¿œé–‹å§‹ |
| 14:35 | ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹æ¥ç¶šã‚¨ãƒ©ãƒ¼ã¨åˆ¤æ˜ |
| 14:40 | æ¥ç¶šãƒ—ãƒ¼ãƒ«æ¯æ¸‡ãŒåŸå› ã¨ç‰¹å®š |
| 14:50 | ã‚¢ã‚¤ãƒ‰ãƒ«æ¥ç¶šã‚’å¼·åˆ¶çµ‚äº† |
| 15:00 | ã‚µãƒ¼ãƒ“ã‚¹å†èµ·å‹• |
| 15:15 | æ­£å¸¸åŒ–ç¢ºèª |
| 15:45 | ã‚¤ãƒ³ã‚·ãƒ‡ãƒ³ãƒˆã‚¯ãƒ­ãƒ¼ã‚º |

## æ ¹æœ¬åŸå› 
ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹æ¥ç¶šãƒ—ãƒ¼ãƒ«ãŒæ¯æ¸‡ã€‚
é•·æ™‚é–“å®Ÿè¡Œä¸­ã®ã‚¯ã‚¨ãƒªãŒã‚¢ã‚¤ãƒ‰ãƒ«æ¥ç¶šã‚’ä¿æŒã€‚

## å¯¾å¿œå†…å®¹
1. ã‚¢ã‚¤ãƒ‰ãƒ«æ¥ç¶šã®å¼·åˆ¶çµ‚äº†
2. æ¥ç¶šã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆè¨­å®šè¿½åŠ 
3. ã‚µãƒ¼ãƒ“ã‚¹å†èµ·å‹•

## æ’ä¹…å¯¾ç­–
- [ ] æ¥ç¶šãƒ—ãƒ¼ãƒ«ç›£è¦–ã‚¢ãƒ©ãƒ¼ãƒˆè¿½åŠ 
- [ ] ã‚¯ã‚¨ãƒªã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆè¨­å®šï¼ˆ30ç§’ï¼‰
- [ ] ã‚¢ã‚¤ãƒ‰ãƒ«æ¥ç¶šè‡ªå‹•ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—ï¼ˆ1æ™‚é–“ï¼‰

## æ•™è¨“
- æ¥ç¶šãƒ—ãƒ¼ãƒ«ç›£è¦–ãŒä¸ååˆ†ã ã£ãŸ
- ã‚¨ã‚¹ã‚«ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³æ‰‹é †ãŒæ©Ÿèƒ½ã—ãŸ
```

---

#### 9.2.2 ã‚¤ãƒ³ã‚·ãƒ‡ãƒ³ãƒˆç®¡ç†ã‚³ãƒãƒ³ãƒ‰

```bash
#!/bin/bash
# incident_tool.sh

INCIDENT_ID=$1
ACTION=$2

case "${ACTION}" in
    create)
        # æ–°è¦ã‚¤ãƒ³ã‚·ãƒ‡ãƒ³ãƒˆä½œæˆ
        cat > "/var/log/incidents/INC-${INCIDENT_ID}.md" << EOF
# Incident INC-${INCIDENT_ID}
Created: $(date)
Status: Open
Severity: TBD

## Description
TBD

## Timeline
- $(date): Incident detected
EOF
        echo "Incident INC-${INCIDENT_ID} created"
        ;;
    
    update)
        # ã‚¤ãƒ³ã‚·ãƒ‡ãƒ³ãƒˆæ›´æ–°
        echo "- $(date): $3" >> "/var/log/incidents/INC-${INCIDENT_ID}.md"
        ;;
    
    close)
        # ã‚¤ãƒ³ã‚·ãƒ‡ãƒ³ãƒˆã‚¯ãƒ­ãƒ¼ã‚º
        sed -i "s/Status: Open/Status: Closed/" "/var/log/incidents/INC-${INCIDENT_ID}.md"
        echo "Resolved: $(date)" >> "/var/log/incidents/INC-${INCIDENT_ID}.md"
        ;;
    
    *)
        echo "Usage: $0 <incident_id> <create|update|close> [note]"
        exit 1
        ;;
esac
```

---

### 9.3 äº‹å¾Œãƒ¬ãƒ“ãƒ¥ãƒ¼ï¼ˆPostmortemï¼‰

#### 9.3.1 Postmortemãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆ

```markdown
# Postmortem: [ã‚¿ã‚¤ãƒˆãƒ«]

## ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿
- **æ—¥ä»˜**: 2025-11-03
- **è‘—è€…**: SRE Team
- **ãƒ¬ãƒ“ãƒ¥ã‚¢ãƒ¼**: Engineering Manager
- **é‡è¦åº¦**: P1

## è¦ç´„ï¼ˆTL;DRï¼‰
3è¡Œã§è¦ç´„

## ã‚¤ãƒ³ãƒ‘ã‚¯ãƒˆ
- **ãƒ€ã‚¦ãƒ³ã‚¿ã‚¤ãƒ **: 75åˆ†
- **å½±éŸ¿ãƒ¦ãƒ¼ã‚¶ãƒ¼æ•°**: å…¨ãƒ¦ãƒ¼ã‚¶ãƒ¼
- **å¤±æ•—ãƒªã‚¯ã‚¨ã‚¹ãƒˆ**: 150ä»¶
- **ãƒ“ã‚¸ãƒã‚¹ã‚¤ãƒ³ãƒ‘ã‚¯ãƒˆ**: æ¨å®š$XXXæå¤±

## æ ¹æœ¬åŸå› 
æŠ€è¡“çš„ãªæ ¹æœ¬åŸå› ã‚’è©³ç´°ã«è¨˜è¿°

## ãƒˆãƒªã‚¬ãƒ¼
ä½•ãŒã‚¤ãƒ³ã‚·ãƒ‡ãƒ³ãƒˆã‚’å¼•ãèµ·ã“ã—ãŸã‹

## è§£æ±ºç­–
ã©ã®ã‚ˆã†ã«å•é¡Œã‚’è§£æ±ºã—ãŸã‹

## æ¤œå‡º
ã©ã®ã‚ˆã†ã«å•é¡Œã‚’æ¤œå‡ºã—ãŸã‹

## ã‚¢ã‚¯ã‚·ãƒ§ãƒ³ã‚¢ã‚¤ãƒ†ãƒ 
| ã‚¢ã‚¯ã‚·ãƒ§ãƒ³ | æ‹…å½“è€… | æœŸé™ | å„ªå…ˆåº¦ |
|-----------|-------|------|--------|
| æ¥ç¶šãƒ—ãƒ¼ãƒ«ç›£è¦–è¿½åŠ  | @ops-team | 2025-11-10 | High |
| ã‚¯ã‚¨ãƒªã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆè¨­å®š | @dev-team | 2025-11-07 | High |
| Runbookã‚¢ãƒƒãƒ—ãƒ‡ãƒ¼ãƒˆ | @sre-team | 2025-11-05 | Medium |

## æ•™è¨“
### ã†ã¾ãã„ã£ãŸã“ã¨
- ã‚¨ã‚¹ã‚«ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ãŒè¿…é€Ÿ
- ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ã‹ã‚‰å³åº§ã«å¾©æ—§å¯èƒ½ã ã£ãŸ

### ã†ã¾ãã„ã‹ãªã‹ã£ãŸã“ã¨
- æ¥ç¶šãƒ—ãƒ¼ãƒ«æ¯æ¸‡ã®æ—©æœŸæ¤œå‡ºãŒã§ããªã‹ã£ãŸ
- ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆãŒå¤ãæ··ä¹±ã—ãŸ

### å¹¸é‹ã ã£ãŸã“ã¨
- ãƒ”ãƒ¼ã‚¯æ™‚é–“å¤–ã ã£ãŸ
- ãƒ‡ãƒ¼ã‚¿æå¤±ãªã—

## ã‚¿ã‚¤ãƒ ãƒ©ã‚¤ãƒ³
è©³ç´°ãªã‚¿ã‚¤ãƒ ãƒ©ã‚¤ãƒ³ã‚’ã“ã“ã«è¨˜è¼‰
```

---

## 10. ã‚¨ã‚¹ã‚«ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ãƒ‘ã‚¹

### 10.1 ã‚¨ã‚¹ã‚«ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ãƒ•ãƒ­ãƒ¼

```mermaid
graph TB
    A[ã‚¤ãƒ³ã‚·ãƒ‡ãƒ³ãƒˆç™ºç”Ÿ] --> B{é‡è¦åº¦åˆ¤å®š}
    
    B -->|P0/P1| C[å³åº§ã«ã‚ªãƒ³ã‚³ãƒ¼ãƒ«ã«é€šçŸ¥]
    B -->|P2/P3| D[æ‹…å½“ãƒãƒ¼ãƒ ã«é€šçŸ¥]
    
    C --> E[L1: ã‚ªãƒ³ã‚³ãƒ¼ãƒ«æ‹…å½“è€…]
    E --> F{30åˆ†ä»¥å†…ã«<br/>è§£æ±ºå¯èƒ½?}
    
    F -->|Yes| G[å•é¡Œè§£æ±º]
    F -->|No| H[L2: SREãƒãƒ¼ãƒ ã«<br/>ã‚¨ã‚¹ã‚«ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³]
    
    H --> I{1æ™‚é–“ä»¥å†…ã«<br/>è§£æ±ºå¯èƒ½?}
    
    I -->|Yes| G
    I -->|No| J[L3: ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ãƒªãƒ³ã‚°<br/>ãƒãƒãƒ¼ã‚¸ãƒ£ãƒ¼ã«<br/>ã‚¨ã‚¹ã‚«ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³]
    
    J --> K{2æ™‚é–“ä»¥å†…ã«<br/>è§£æ±ºå¯èƒ½?}
    
    K -->|Yes| G
    K -->|No| L[L4: CTO/ãƒ™ãƒ³ãƒ€ãƒ¼ã«<br/>ã‚¨ã‚¹ã‚«ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³]
    
    D --> M[å¯¾å¿œé–‹å§‹]
    M --> N{è§£æ±º?}
    N -->|Yes| G
    N -->|No| E
    
    G --> O[Postmortemä½œæˆ]
```

---

### 10.2 é€£çµ¡å…ˆãƒªã‚¹ãƒˆ

| ãƒ¬ãƒ™ãƒ« | å½¹å‰² | é€£çµ¡å…ˆ | å¯¾å¿œæ™‚é–“ |
|-------|------|-------|---------|
| **L1** | ã‚ªãƒ³ã‚³ãƒ¼ãƒ«æ‹…å½“ | oncall@example.com<br/>+81-XX-XXXX-XXXX | 24/7 |
| **L2** | SREãƒãƒ¼ãƒ  | sre-team@example.com<br/>Slack: #sre-oncall | 24/7 |
| **L3** | Engineering Manager | eng-manager@example.com<br/>+81-XX-XXXX-XXXX | 24/7 |
| **L4** | CTO | cto@example.com<br/>+81-XX-XXXX-XXXX | 9-22 JST |
| **Vendor** | Anthropic Support | support@anthropic.com | 9-18 PST |

---

### 10.3 ã‚¨ã‚¹ã‚«ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³åŸºæº–

| çŠ¶æ³ | ã‚¨ã‚¹ã‚«ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³å…ˆ | ã‚¿ã‚¤ãƒŸãƒ³ã‚° |
|-----|-----------------|----------|
| P0ã‚¤ãƒ³ã‚·ãƒ‡ãƒ³ãƒˆ | L2 SREãƒãƒ¼ãƒ  | å³åº§ |
| 30åˆ†ä»¥å†…ã«è§£æ±ºä¸å¯ | L2 SREãƒãƒ¼ãƒ  | 30åˆ† |
| ãƒ‡ãƒ¼ã‚¿æå¤±ã®å¯èƒ½æ€§ | L3 Manager | å³åº§ |
| 1æ™‚é–“ä»¥å†…ã«è§£æ±ºä¸å¯ | L3 Manager | 1æ™‚é–“ |
| ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£ã‚¤ãƒ³ã‚·ãƒ‡ãƒ³ãƒˆ | L3 Manager + Security | å³åº§ |
| 2æ™‚é–“ä»¥å†…ã«è§£æ±ºä¸å¯ | L4 CTO | 2æ™‚é–“ |
| ãƒ™ãƒ³ãƒ€ãƒ¼é–¢é€£å•é¡Œ | Vendor Support | åˆ¤æ˜æ¬¡ç¬¬ |

---

## 11. ã‚ªãƒ³ã‚³ãƒ¼ãƒ«å¯¾å¿œ

### 11.1 ã‚ªãƒ³ã‚³ãƒ¼ãƒ«ä½“åˆ¶

#### 11.1.1 ãƒ­ãƒ¼ãƒ†ãƒ¼ã‚·ãƒ§ãƒ³

| é€± | ä¸€æ¬¡å¯¾å¿œï¼ˆL1ï¼‰ | äºŒæ¬¡å¯¾å¿œï¼ˆL2ï¼‰ | ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ— |
|----|--------------|--------------|------------|
| Week 1 | Engineer A | SRE X | Manager 1 |
| Week 2 | Engineer B | SRE Y | Manager 1 |
| Week 3 | Engineer C | SRE X | Manager 2 |
| Week 4 | Engineer D | SRE Y | Manager 2 |

**ãƒ­ãƒ¼ãƒ†ãƒ¼ã‚·ãƒ§ãƒ³æœŸé–“**: æ—¥æ›œ 9:00 - ç¿Œæ—¥æ›œ 9:00 JST

---

#### 11.1.2 ã‚ªãƒ³ã‚³ãƒ¼ãƒ«æº–å‚™ãƒã‚§ãƒƒã‚¯ãƒªã‚¹ãƒˆ

```markdown
## ã‚ªãƒ³ã‚³ãƒ¼ãƒ«é–‹å§‹å‰
- [ ] PagerDutyã«ãƒ­ã‚°ã‚¤ãƒ³ç¢ºèª
- [ ] Slackã®é€šçŸ¥è¨­å®šç¢ºèª
- [ ] ãƒãƒ¼ãƒˆPCã¨Wi-Fiå‹•ä½œç¢ºèª
- [ ] VPNæ¥ç¶šç¢ºèª
- [ ] ç®¡ç†è€…æ¨©é™ã®ç¢ºèª
- [ ] é€£çµ¡å…ˆãƒªã‚¹ãƒˆã®ç¢ºèª
- [ ] Runbookãƒ¬ãƒ“ãƒ¥ãƒ¼
- [ ] å‰é€±ã®å¼•ãç¶™ãäº‹é …ç¢ºèª

## ã‚ªãƒ³ã‚³ãƒ¼ãƒ«ä¸­
- [ ] ã‚¢ãƒ©ãƒ¼ãƒˆå—ä¿¡ã‹ã‚‰5åˆ†ä»¥å†…ã«ç¢ºèªå¿œç­”
- [ ] 15åˆ†ä»¥å†…ã«åˆæœŸå¯¾å¿œé–‹å§‹
- [ ] 30åˆ†ã”ã¨ã«ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹æ›´æ–°
- [ ] é‡å¤§ã‚¤ãƒ³ã‚·ãƒ‡ãƒ³ãƒˆã¯å³åº§ã«ã‚¨ã‚¹ã‚«ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³
- [ ] å…¨ã‚¤ãƒ³ã‚·ãƒ‡ãƒ³ãƒˆã‚’è¨˜éŒ²

## ã‚ªãƒ³ã‚³ãƒ¼ãƒ«çµ‚äº†å¾Œ
- [ ] æœªè§£æ±ºã‚¤ãƒ³ã‚·ãƒ‡ãƒ³ãƒˆã®å¼•ãç¶™ã
- [ ] ã‚¤ãƒ³ã‚·ãƒ‡ãƒ³ãƒˆãƒ¬ãƒãƒ¼ãƒˆä½œæˆ
- [ ] Runbookã®æ›´æ–°ï¼ˆå¿…è¦ã«å¿œã˜ã¦ï¼‰
- [ ] æ”¹å–„ææ¡ˆã®æå‡º
```

---

### 11.2 ã‚ªãƒ³ã‚³ãƒ¼ãƒ«å¯¾å¿œã‚¬ã‚¤ãƒ‰

#### 11.2.1 ã‚¢ãƒ©ãƒ¼ãƒˆå—ä¿¡æ™‚ã®å¯¾å¿œ

```bash
#!/bin/bash
# oncall_response.sh

ALERT_ID=$1
ALERT_SEVERITY=$2

echo "[$(date)] Oncall alert received: ${ALERT_ID} (${ALERT_SEVERITY})"

# 1. ã‚¢ãƒ©ãƒ¼ãƒˆç¢ºèªå¿œç­”ï¼ˆ5åˆ†ä»¥å†…ï¼‰
echo "[$(date)] Acknowledging alert..."
curl -X POST https://api.pagerduty.com/incidents/${ALERT_ID}/acknowledge \
    -H "Authorization: Token ${PAGERDUTY_TOKEN}"

# 2. Slacké€šçŸ¥
curl -X POST ${SLACK_WEBHOOK_URL} \
    -H 'Content-Type: application/json' \
    -d "{\"text\": \"Oncall: Responding to ${ALERT_ID} (${ALERT_SEVERITY})\"}"

# 3. åˆæœŸè¨ºæ–­å®Ÿæ–½
echo "[$(date)] Running initial diagnostics..."
/usr/local/bin/daily_health_check.sh > /tmp/diagnostics_${ALERT_ID}.log

# 4. ãƒ­ã‚°ç¢ºèª
echo "[$(date)] Checking logs..."
tail -n 100 /app/logs/app/error.log

# 5. ã‚¤ãƒ³ã‚·ãƒ‡ãƒ³ãƒˆä½œæˆï¼ˆP0/P1ã®å ´åˆï¼‰
if [[ "${ALERT_SEVERITY}" == "critical" ]] || [[ "${ALERT_SEVERITY}" == "high" ]]; then
    /usr/local/bin/incident_tool.sh ${ALERT_ID} create
fi

echo "[$(date)] Initial response completed"
```

---

#### 11.2.2 ã‚ªãƒ³ã‚³ãƒ¼ãƒ«ä¸­ã®ã‚³ãƒŸãƒ¥ãƒ‹ã‚±ãƒ¼ã‚·ãƒ§ãƒ³

**Slackãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆ**:

```markdown
# P0ã‚¤ãƒ³ã‚·ãƒ‡ãƒ³ãƒˆé€šçŸ¥
@here ğŸš¨ **P0 Incident**

**Incident ID**: INC-2025-001
**Severity**: Critical
**Status**: Investigating
**Impact**: All API requests failing
**Oncall**: @engineer-a

**Timeline**:
- 14:30 JST: Alert received
- 14:32 JST: Investigation started

**Updates**: Will post every 15 minutes

---

# é€²æ—æ›´æ–°
**Update @ 14:45 JST**

Root cause identified: Database connection pool exhausted
Working on fix...
ETA: 15 minutes

---

# è§£æ±ºé€šçŸ¥
**Resolved @ 15:00 JST** âœ…

Issue resolved. All systems operational.
Total downtime: 30 minutes

Postmortem will be shared tomorrow.
```

---

### 11.3 ã‚ªãƒ³ã‚³ãƒ¼ãƒ«ä¸­ã®ãƒ„ãƒ¼ãƒ«

#### 11.3.1 ã‚¯ã‚¤ãƒƒã‚¯ã‚³ãƒãƒ³ãƒ‰

```bash
# ~/.bashrc ã¾ãŸã¯ ~/.zshrc ã«è¿½åŠ 

# ã‚·ã‚¹ãƒ†ãƒ çŠ¶æ…‹ç¢ºèª
alias health='systemctl status ts-forecast && curl http://localhost:8000/health'

# ã‚¢ã‚¯ãƒ†ã‚£ãƒ–Runç¢ºèª
alias active='psql -h localhost -U postgres -d ts_forecast_system -c "SELECT COUNT(*) FROM runs WHERE status='"'"'running'"'"';"'

# ç›´è¿‘ã®ã‚¨ãƒ©ãƒ¼
alias errors='psql -h localhost -U postgres -d ts_forecast_system -c "SELECT * FROM system_logs WHERE log_level='"'"'ERROR'"'"' ORDER BY created_at DESC LIMIT 10;"'

# ãƒ­ã‚°ç›£è¦–
alias watchlogs='tail -f /app/logs/app/app.log'

# ç·Šæ€¥å†èµ·å‹•
alias emergency-restart='/usr/local/bin/service_restart.sh'

# ãƒ¡ãƒˆãƒªã‚¯ã‚¹ç¢ºèª
alias metrics='curl http://localhost:8000/metrics'
```

---

#### 11.3.2 è¨ºæ–­ã‚¹ã‚¯ãƒªãƒ—ãƒˆ

```bash
#!/bin/bash
# quick_diagnosis.sh

echo "=========================================="
echo "Quick Diagnosis - $(date)"
echo "=========================================="

# ã‚·ã‚¹ãƒ†ãƒ çŠ¶æ…‹
echo -e "\n## System Status"
systemctl status ts-forecast | head -5

# APIå¥å…¨æ€§
echo -e "\n## API Health"
curl -s http://localhost:8000/health | jq '.'

# ãƒªã‚½ãƒ¼ã‚¹ä½¿ç”¨çŠ¶æ³
echo -e "\n## Resource Usage"
echo "CPU: $(top -bn1 | grep "Cpu(s)" | sed "s/.*, *\([0-9.]*\)%* id.*/\1/" | awk '{print 100 - $1"%"}')"
echo "Memory: $(free | grep Mem | awk '{printf "%.1f%%", $3/$2 * 100.0}')"
echo "Disk: $(df -h / | awk 'NR==2 {print $5}')"

# ã‚¢ã‚¯ãƒ†ã‚£ãƒ–Run
echo -e "\n## Active Runs"
psql -h localhost -U postgres -d ts_forecast_system -t -c \
    "SELECT COUNT(*) FROM runs WHERE status='running';"

# ç›´è¿‘ã®ã‚¨ãƒ©ãƒ¼
echo -e "\n## Recent Errors (last 10)"
psql -h localhost -U postgres -d ts_forecast_system -c \
    "SELECT created_at, log_level, log_message FROM system_logs WHERE log_level IN ('ERROR', 'CRITICAL') ORDER BY created_at DESC LIMIT 10;"

echo -e "\n=========================================="
echo "Diagnosis completed"
echo "=========================================="
```

---

## 12. ãƒŠãƒ¬ãƒƒã‚¸ãƒ™ãƒ¼ã‚¹

### 12.1 ã‚ˆãã‚ã‚‹è³ªå•ï¼ˆFAQï¼‰

#### Q1: ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ã¯ã©ã“ã«ã‚ã‚Šã¾ã™ã‹ï¼Ÿ

**A**: 
```bash
# ãƒ­ãƒ¼ã‚«ãƒ«ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—
ls -lh /backup/postgres/

# æœ€æ–°ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—
ls -t /backup/postgres/full_*.dump.gz | head -1

# S3ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ï¼ˆè¨­å®šã—ã¦ã„ã‚‹å ´åˆï¼‰
aws s3 ls s3://ts-forecast-backups/
```

---

#### Q2: ã‚µãƒ¼ãƒ“ã‚¹ãŒå¿œç­”ã—ãªã„å ´åˆã¯ï¼Ÿ

**A**: ä»¥ä¸‹ã®é †ã§ç¢ºèªï¼š

```bash
# 1. ã‚µãƒ¼ãƒ“ã‚¹çŠ¶æ…‹ç¢ºèª
systemctl status ts-forecast

# 2. ãƒãƒ¼ãƒˆç¢ºèª
lsof -i :8000

# 3. ãƒ­ã‚°ç¢ºèª
journalctl -u ts-forecast -n 50

# 4. ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹æ¥ç¶šç¢ºèª
psql -h localhost -U postgres -d ts_forecast_system -c "SELECT 1;"

# 5. å†èµ·å‹•
systemctl restart ts-forecast

# 6. ç¢ºèª
curl http://localhost:8000/health
```

---

#### Q3: ãƒ‡ã‚£ã‚¹ã‚¯å®¹é‡ãŒè¶³ã‚Šãªã„å ´åˆã¯ï¼Ÿ

**A**: 

```bash
# 1. ä½¿ç”¨çŠ¶æ³ç¢ºèª
df -h
du -sh /app/* | sort -hr

# 2. å¤ã„ãƒ­ã‚°å‰Šé™¤
find /app/logs -name "*.log" -mtime +30 -delete

# 3. å¤ã„ãƒ¢ãƒ‡ãƒ«å‰Šé™¤
find /app/models -name "*.pth" -mtime +90 -delete

# 4. ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹VACUUM
psql -h localhost -U postgres -d ts_forecast_system -c "VACUUM FULL;"

# 5. Dockerä¸è¦ã‚¤ãƒ¡ãƒ¼ã‚¸å‰Šé™¤
docker system prune -a
```

---

#### Q4: ãƒ¢ãƒ‡ãƒ«å­¦ç¿’ãŒé…ã„å ´åˆã¯ï¼Ÿ

**A**:

```sql
-- 1. ä¸¦åˆ—å®Ÿè¡Œæ•°ç¢ºèª
SELECT COUNT(*) FROM runs WHERE status='running';

-- 2. ãƒªã‚½ãƒ¼ã‚¹ä½¿ç”¨çŠ¶æ³ç¢ºèª
-- CPU
SELECT * FROM pg_stat_activity WHERE state = 'active';

-- 3. GPUä½¿ç”¨çŠ¶æ³ï¼ˆGPUä½¿ç”¨æ™‚ï¼‰
-- nvidia-smi

-- 4. èª¿æ•´
-- ä¸¦åˆ—æ•°å‰Šæ¸›
-- export MAX_PARALLEL_RUNS=2
```

---

### 12.2 ãƒˆãƒ©ãƒ–ãƒ«ã‚·ãƒ¥ãƒ¼ãƒ†ã‚£ãƒ³ã‚°ãƒ•ãƒ­ãƒ¼ãƒãƒ£ãƒ¼ãƒˆ

```mermaid
graph TB
    A[å•é¡Œç™ºç”Ÿ] --> B{ã‚µãƒ¼ãƒ“ã‚¹èµ·å‹•ã—ã¦ã„ã‚‹?}
    
    B -->|No| C[systemctl start ts-forecast]
    B -->|Yes| D{APIå¿œç­”ã—ã¦ã„ã‚‹?}
    
    C --> D
    
    D -->|No| E{ãƒãƒ¼ãƒˆä½¿ç”¨ã•ã‚Œã¦ã„ã‚‹?}
    D -->|Yes| F{ã‚¨ãƒ©ãƒ¼ç™ºç”Ÿã—ã¦ã„ã‚‹?}
    
    E -->|Yes| G[ç«¶åˆãƒ—ãƒ­ã‚»ã‚¹åœæ­¢]
    E -->|No| H[è¨­å®šç¢ºèª]
    
    G --> C
    H --> C
    
    F -->|Yes| I{ã‚¨ãƒ©ãƒ¼ã‚¿ã‚¤ãƒ—ã¯?}
    F -->|No| J[æ­£å¸¸]
    
    I -->|DBæ¥ç¶š| K[ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ç¢ºèª]
    I -->|ãƒ¡ãƒ¢ãƒª| L[ãƒªã‚½ãƒ¼ã‚¹ç¢ºèª]
    I -->|ãã®ä»–| M[ãƒ­ã‚°è©³ç´°ç¢ºèª]
    
    K --> N{è§£æ±º?}
    L --> N
    M --> N
    
    N -->|Yes| J
    N -->|No| O[ã‚¨ã‚¹ã‚«ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³]
```

---

### 12.3 ã‚³ãƒãƒ³ãƒ‰ãƒªãƒ•ã‚¡ãƒ¬ãƒ³ã‚¹

#### 12.3.1 ã‚µãƒ¼ãƒ“ã‚¹ç®¡ç†

```bash
# ã‚µãƒ¼ãƒ“ã‚¹åˆ¶å¾¡
systemctl start ts-forecast      # èµ·å‹•
systemctl stop ts-forecast       # åœæ­¢
systemctl restart ts-forecast    # å†èµ·å‹•
systemctl status ts-forecast     # çŠ¶æ…‹ç¢ºèª
systemctl enable ts-forecast     # è‡ªå‹•èµ·å‹•æœ‰åŠ¹åŒ–

# Dockerç’°å¢ƒ
docker compose up -d             # èµ·å‹•
docker compose down              # åœæ­¢
docker compose restart app       # å†èµ·å‹•
docker compose ps                # çŠ¶æ…‹ç¢ºèª
docker compose logs -f app       # ãƒ­ã‚°ç›£è¦–
```

---

#### 12.3.2 ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹æ“ä½œ

```bash
# æ¥ç¶š
psql -h localhost -U postgres -d ts_forecast_system

# ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—
pg_dump -h localhost -U postgres -d ts_forecast_system \
    -Fc -f backup.dump

# ãƒªã‚¹ãƒˆã‚¢
pg_restore -h localhost -U postgres -d ts_forecast_system \
    -v backup.dump

# VACUUM
psql -h localhost -U postgres -d ts_forecast_system \
    -c "VACUUM ANALYZE;"

# çµ±è¨ˆæƒ…å ±æ›´æ–°
psql -h localhost -U postgres -d ts_forecast_system \
    -c "ANALYZE;"
```

---

#### 12.3.3 ãƒ­ã‚°æ“ä½œ

```bash
# ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ç›£è¦–
tail -f /app/logs/app/app.log

# ã‚¨ãƒ©ãƒ¼ã®ã¿
grep ERROR /app/logs/app/app.log

# ç›´è¿‘100è¡Œ
tail -n 100 /app/logs/app/app.log

# ç‰¹å®šæœŸé–“
journalctl -u ts-forecast --since "1 hour ago"

# Dockerç’°å¢ƒ
docker compose logs -f --tail=100 app
```

---

#### 12.3.4 ç›£è¦–ã‚³ãƒãƒ³ãƒ‰

```bash
# ã‚·ã‚¹ãƒ†ãƒ ãƒªã‚½ãƒ¼ã‚¹
top
htop
free -h
df -h

# GPUï¼ˆGPUä½¿ç”¨æ™‚ï¼‰
nvidia-smi
watch -n 1 nvidia-smi

# ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯
netstat -tulpn
ss -tulpn

# ãƒ—ãƒ­ã‚»ã‚¹
ps aux | grep python
pgrep -fa "nf_auto_runner"
```

---

## 13. ä»˜éŒ²

### 13.1 ç”¨èªé›†

| ç”¨èª | èª¬æ˜ |
|-----|------|
| **MTBF** | Mean Time Between Failuresï¼ˆå¹³å‡æ•…éšœé–“éš”ï¼‰ |
| **MTTR** | Mean Time To Repairï¼ˆå¹³å‡ä¿®å¾©æ™‚é–“ï¼‰ |
| **MTTD** | Mean Time To Detectï¼ˆå¹³å‡æ¤œå‡ºæ™‚é–“ï¼‰ |
| **SLO** | Service Level Objectiveï¼ˆã‚µãƒ¼ãƒ“ã‚¹ãƒ¬ãƒ™ãƒ«ç›®æ¨™ï¼‰ |
| **SLI** | Service Level Indicatorï¼ˆã‚µãƒ¼ãƒ“ã‚¹ãƒ¬ãƒ™ãƒ«æŒ‡æ¨™ï¼‰ |
| **RTO** | Recovery Time Objectiveï¼ˆç›®æ¨™å¾©æ—§æ™‚é–“ï¼‰ |
| **RPO** | Recovery Point Objectiveï¼ˆç›®æ¨™å¾©æ—§æ™‚ç‚¹ï¼‰ |
| **Postmortem** | äº‹å¾Œåˆ†æãƒ¬ãƒãƒ¼ãƒˆ |
| **Runbook** | é‹ç”¨æ‰‹é †æ›¸ |
| **Oncall** | å½“ç•ªãƒ»ã‚ªãƒ³ã‚³ãƒ¼ãƒ« |

---

### 13.2 é–¢é€£ãƒªãƒ³ã‚¯

| ãƒªã‚½ãƒ¼ã‚¹ | URL |
|---------|-----|
| **ã‚·ã‚¹ãƒ†ãƒ ãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰** | https://grafana.example.com/d/ts-forecast |
| **ã‚¢ãƒ©ãƒ¼ãƒˆãƒãƒãƒ¼ã‚¸ãƒ£ãƒ¼** | https://alertmanager.example.com |
| **ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆ** | https://docs.example.com/ts-forecast |
| **Slack ãƒãƒ£ãƒ³ãƒãƒ«** | #ts-forecast-ops |
| **Incident Management** | https://pagerduty.com |
| **Runbook Repository** | https://github.com/your-org/runbooks |

---

### 13.3 å¤‰æ›´å±¥æ­´

| æ—¥ä»˜ | ãƒãƒ¼ã‚¸ãƒ§ãƒ³ | å¤‰æ›´å†…å®¹ | æ‹…å½“è€… |
|------|-----------|---------|--------|
| 2025-11-03 | v1.0.0 | åˆç‰ˆä½œæˆ | SRE Team |

---

### 13.4 ãƒ¬ãƒ“ãƒ¥ãƒ¼ã‚µã‚¤ã‚¯ãƒ«

- **å®šæœŸãƒ¬ãƒ“ãƒ¥ãƒ¼**: å››åŠæœŸã”ã¨
- **æ¬¡å›ãƒ¬ãƒ“ãƒ¥ãƒ¼**: 2026-02-01
- **ãƒ¬ãƒ“ãƒ¥ãƒ¼æ‹…å½“**: SRE Manager
- **æ‰¿èªè€…**: Engineering Manager

---

## âœ¨ ã¾ã¨ã‚

æœ¬é‹ç”¨æ‰‹é †æ›¸ã¯ã€æ™‚ç³»åˆ—äºˆæ¸¬ã‚·ã‚¹ãƒ†ãƒ ã®å®‰å®šé‹ç”¨ã«å¿…è¦ãªã™ã¹ã¦ã®æ‰‹é †ã‚’æä¾›ã—ã¦ã„ã¾ã™ã€‚

### é‹ç”¨ã®ãƒã‚¤ãƒ³ãƒˆ

- âœ… **æ—¥å¸¸é‹ç”¨**: ãƒ‡ã‚¤ãƒªãƒ¼/ã‚¦ã‚£ãƒ¼ã‚¯ãƒªãƒ¼/ãƒãƒ³ã‚¹ãƒªãƒ¼ã®å®šæœŸã‚¿ã‚¹ã‚¯
- âœ… **ç›£è¦–**: Grafana/Prometheus ã«ã‚ˆã‚‹åŒ…æ‹¬çš„ç›£è¦–
- âœ… **éšœå®³å¯¾å¿œ**: ç—‡çŠ¶åˆ¥ã®æ˜ç¢ºãªå¯¾å¿œæ‰‹é †
- âœ… **ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹**: ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ãƒ»ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°
- âœ… **ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°**: å‚ç›´/æ°´å¹³ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°æ‰‹é †
- âœ… **ãƒ¡ãƒ³ãƒ†ãƒŠãƒ³ã‚¹**: è¨ˆç”»/ç·Šæ€¥ãƒ¡ãƒ³ãƒ†ãƒŠãƒ³ã‚¹æ‰‹é †
- âœ… **ã‚¤ãƒ³ã‚·ãƒ‡ãƒ³ãƒˆç®¡ç†**: åˆ†é¡ãƒ»å¯¾å¿œãƒ»ã‚¨ã‚¹ã‚«ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³
- âœ… **ã‚ªãƒ³ã‚³ãƒ¼ãƒ«**: 24/7å¯¾å¿œä½“åˆ¶ã¨ãƒ„ãƒ¼ãƒ«
- âœ… **ãƒŠãƒ¬ãƒƒã‚¸**: FAQãƒ»ãƒˆãƒ©ãƒ–ãƒ«ã‚·ãƒ¥ãƒ¼ãƒ†ã‚£ãƒ³ã‚°

### æ¬¡ã®ã‚¹ãƒ†ãƒƒãƒ—

1. âœ… **æœ¬é‹ç”¨æ‰‹é †æ›¸ã‚’èª­äº†**
2. ğŸ”§ æ—¥å¸¸é‹ç”¨ã‚¿ã‚¹ã‚¯ã®è‡ªå‹•åŒ–
3. ğŸ“Š ç›£è¦–ãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰ã®ç¢ºèª
4. ğŸš¨ ã‚¢ãƒ©ãƒ¼ãƒˆè¨­å®šã®æœ€é©åŒ–
5. ğŸ“ ã‚¤ãƒ³ã‚·ãƒ‡ãƒ³ãƒˆå¯¾å¿œè¨“ç·´
6. ğŸ”„ Runbookã®å®šæœŸæ›´æ–°
7. ğŸ“– ãƒãƒ¼ãƒ ã¸ã®å‘¨çŸ¥å¾¹åº•

---

**Stay Operational! ğŸš€**

---
**End of Document**
